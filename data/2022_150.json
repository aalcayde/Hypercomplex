{"search-results":{"opensearch:totalResults":"239","opensearch:startIndex":"150","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "150"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=150&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2022&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2022&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2022&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=175&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2022&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=214&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2022&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140973327"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140973327?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140973327&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140973327&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140973327","dc:identifier":"SCOPUS_ID:85140973327","eid":"2-s2.0-85140973327","dc:title":"Comparison of human skeleton trackers paired with a novel skeleton fusion algorithm","dc:creator":"Flowers J.T.","prism:publicationName":"Proceedings of ASME 2022 17th International Manufacturing Science and Engineering Conference, MSEC 2022","prism:isbn": [{"@_fa": "true", "$" :"9780791885819"}],"prism:volume":"2","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1115/MSEC2022-85269","dc:description":"The onset of Industry 4.0 brings a greater demand for Human-Robot Collaboration (HRC) in manufacturing. This has led to a critical need for bridging the sensing and AI with the mechanical-n-physical necessities to successfully augment the robot s awareness and intelligence. In a HRC work cell, options for sensors to detect human joint locations vary greatly in complexity, usability, and cost. In this paper, the use of depth cameras is explored, since they are a relatively low-cost option that does not require users to wear extra sensing hardware. Herein, the Google Media Pipe (BlazePose) and OpenPose skeleton tracking software packages are used to estimate the pixel coordinates of each human joint in images from depth cameras. The depth at each pixel is then used with the joint pixel coordinates to generate the 3D joint locations of the skeleton. In comparing these skeleton trackers, this paper also presents a novel method of combining the skeleton that the trackers generate from each camera s data utilizing a quaternion/linklength representation of the skeleton. Results show that the overall mean and standard deviation in position error between the fused skeleton and target locations was lower compared to the skeletons resulting directly from each camera s data.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013959","afid":"60013959","affilname":"University of Florida","affiliation-city":"Gainesville","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57226740539","authid":"57226740539","authname":"Flowers J.T.","surname":"Flowers","given-name":"Jared T.","initials":"J.T.","afid": [{"@_fa": "true", "$" :"60013959"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003372495","authid":"7003372495","authname":"Wiens G.J.","surname":"Wiens","given-name":"Gloria J.","initials":"G.J.","afid": [{"@_fa": "true", "$" :"60013959"}]}],"authkeywords":"cobot | control and automation. | human-robot interaction | skeleton tracking | smart manufacturing systems","article-number":"V002T06A010","source-id":"21101117306","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140770412"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140770412?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140770412&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140770412&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140770412","dc:identifier":"SCOPUS_ID:85140770412","eid":"2-s2.0-85140770412","dc:title":"Predicting polarization state based on quaternion neural networks to facilitate channel prediction","dc:creator":"Chen H.","prism:publicationName":"Proceedings of the International Joint Conference on Neural Networks","prism:isbn": [{"@_fa": "true", "$" :"9781728186719"}],"prism:volume":"2022-July","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/IJCNN55064.2022.9892509","dc:description":"Mobile communications are often affected by various fading phenomena. Since channel state information (CSI), important to overcome channel fading, is always changing over time, channel prediction is necessary to know the correct CSI. Current channel prediction methods are mainly based on the amplitude and phase of the received signal. However, because the polarization state of the propagating wave also changes with time, the polarization mismatch problem occurs between an arriving wave and a receiving antenna, resulting in lower communication quality. In this paper, we propose the prediction of polarization states by using a quaternion neural network (QNN), which makes full use of the geometric properties of polarization states represented on the Poincare sphere to achieve a high-precision prediction. The experimental results show that, by predicting the polarization state, we can obtain more accurate CSI and a lower bit error rate.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025272","afid":"60025272","affilname":"The University of Tokyo","affiliation-city":"Tokyo","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57789931000","authid":"57789931000","authname":"Chen H.","surname":"Chen","given-name":"Haotian","initials":"H.","afid": [{"@_fa": "true", "$" :"60025272"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35795724100","authid":"35795724100","authname":"Ryo N.","surname":"Ryo","given-name":"Natsuaki","initials":"N.","afid": [{"@_fa": "true", "$" :"60025272"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35416951600","authid":"35416951600","authname":"Hirose A.","surname":"Hirose","given-name":"Akira","initials":"A.","afid": [{"@_fa": "true", "$" :"60025272"}]}],"authkeywords":"Channel prediction | polarization state | quaternion neural network","source-id":"96537","fund-acr":"KAKEN","fund-no":"18H04105","fund-sponsor":"Japan Society for the Promotion of Science","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140762138"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140762138?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140762138&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140762138&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140762138","dc:identifier":"SCOPUS_ID:85140762138","eid":"2-s2.0-85140762138","dc:title":"Hypercomplex Image- to- Image Translation","dc:creator":"Grassucci E.","prism:publicationName":"Proceedings of the International Joint Conference on Neural Networks","prism:isbn": [{"@_fa": "true", "$" :"9781728186719"}],"prism:volume":"2022-July","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/IJCNN55064.2022.9892119","dc:description":"Image-to-image translation (I2I) aims at transferring the content representation from an input domain to an output one, bouncing along different target domains. Recent I2I generative models, which gain outstanding results in this task, comprise a set of diverse deep networks each with tens of million parameters. Moreover, images are usually three-dimensional being composed of RGB channels and common neural models do not take dimensions correlation into account, losing beneficial information. In this paper, we propose to leverage hypercomplex algebra properties to define lightweight I2I generative models capable of preserving pre-existing relations among image dimensions, thus exploiting additional input information. On manifold I2I benchmarks, we show how the proposed Quaternion StarGANv2 and parameterized hypercomplex StarGANv2 (PHStarGANv2) reduce parameters and storage memory amount while ensuring high domain translation performance and good image quality as measured by FID and LPIPS scores. Full code is available at https://github.com/ispamm/HI2I.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032350","afid":"60032350","affilname":"Sapienza Università di Roma","affiliation-city":"Rome","affiliation-country":"Italy"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57218250258","authid":"57218250258","authname":"Grassucci E.","surname":"Grassucci","given-name":"Eleonora","initials":"E.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57702863900","authid":"57702863900","authname":"Sigillo L.","surname":"Sigillo","given-name":"Luigi","initials":"L.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7005621339","authid":"7005621339","authname":"Uncini A.","surname":"Uncini","given-name":"Aurelio","initials":"A.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36444807900","authid":"36444807900","authname":"Comminiello D.","surname":"Comminiello","given-name":"Danilo","initials":"D.","afid": [{"@_fa": "true", "$" :"60032350"}]}],"authkeywords":"Generative Adversarial Networks | Hypercomplex Neural Networks | Image-to-Image Translation | Lightweight Models","source-id":"96537","fund-no":"RG11916B88E1942F","fund-sponsor":"Sapienza Università di Roma","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140740519"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140740519?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140740519&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140740519&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140740519","dc:identifier":"SCOPUS_ID:85140740519","eid":"2-s2.0-85140740519","dc:title":"Maximum Total Quaternion Correntropy for Adaptive Filtering","dc:creator":"Lin D.","prism:publicationName":"IEEE Transactions on Signal Processing","prism:issn":"1053587X","prism:eIssn":"19410476","prism:volume":"70","prism:pageRange":"4967-4980","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/TSP.2022.3215291","dc:description":"Quaternion adaptive filters have been widely used in processing three-dimensional (3-D) and 4-D signals. However, the performance of existing quaternion adaptive filtering algorithms will be deteriorated when both the input and output signals are disturbed by noises. To solve this problem, this paper first proposes a quaternion error-in-variables (QEIV) model in which the input and output signals are disturbed by noises, and develops a maximum total quaternion correntropy (MTQC) criterion to resist non-Gaussian noises. Then, combined with the total least squares (TLS) method, an MTQC algorithm is proposed based on the stochastic gradient method and quaternion generalized Hamilton-real (GHR) calculus for the proposed QEIV model. Furthermore, a variable kernel width strategy is given to avoid the problem of kernel width selection and a variable kernel width MTQC (VKWMTQC) algorithm is therefore proposed, simultaneously. More importantly, the local stability, the convergence condition, and steady-state performance of the proposed MTQC algorithm are theoretically analyzed by the quaternion calculus and quaternion matrix theories. Finally, simulation results verify the correctness of the theoretical analysis and demonstrate the superiority of the proposed MTQC algorithm for the QEIV model.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60122052","afid":"60122052","affilname":"Southwest University","affiliation-city":"Chongqing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57209805356","authid":"57209805356","orcid":"0000-0002-7451-2477","authname":"Lin D.","surname":"Lin","given-name":"Dongyuan","initials":"D.","afid": [{"@_fa": "true", "$" :"60122052"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57211914513","authid":"57211914513","orcid":"0000-0002-3683-4520","authname":"Zhang Q.","surname":"Zhang","given-name":"Qiangqiang","initials":"Q.","afid": [{"@_fa": "true", "$" :"60122052"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57393494600","authid":"57393494600","orcid":"0000-0002-1422-9717","authname":"Chen S.","surname":"Chen","given-name":"Shanmou","initials":"S.","afid": [{"@_fa": "true", "$" :"60122052"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55878634600","authid":"55878634600","orcid":"0000-0002-5028-5839","authname":"Wang S.","surname":"Wang","given-name":"Shiyuan","initials":"S.","afid": [{"@_fa": "true", "$" :"60122052"}]}],"authkeywords":"Adaptive filters | maximum total quaternion correntropy | quaternion signal processing | robust method | variable kernel width","source-id":"17391","fund-acr":"NSFC","fund-no":"62071391","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140734332"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140734332?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140734332&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140734332&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140734332","dc:identifier":"SCOPUS_ID:85140734332","eid":"2-s2.0-85140734332","dc:title":"2022 International Joint Conference on Neural Networks, IJCNN 2022 - Proceedings","prism:publicationName":"Proceedings of the International Joint Conference on Neural Networks","prism:isbn": [{"@_fa": "true", "$" :"9781728186719"}],"prism:volume":"2022-July","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","dc:description":"The proceedings contain 1089 papers. The topics discussed include: hand gesture classification on praxis dataset: trading accuracy for expense; aspect-dependent heterogeneous graph convolutional network for aspect-level sentiment analysis; LRTD: a low-rank transformer with dynamic depth and width for speech recognition; quaternion-based graph contrastive learning for recommendation; campus network intrusion detection based on federated learning; feature interactive convolutional network with structure-aware information for knowledge graph embedding; learning point processes using recurrent graph network; measuring drift severity by tree structure classifiers; combining deep convolutional feature extraction with hyperdimensional computing for visual object recognition; shaping the ultra-selectivity of a looming detection neural network from non-linear correlation of radial motion; regulating balance degree for more reasonable visual question answering benchmark; prioritized sampling with intrinsic motivation in multi-task reinforcement learning; facial image reconstruction from functional magnetic resonance imaging via GAN inversion with improved attribute consistency; and novel applications for VAE-based anomaly detection systems.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"96537","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140729667"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140729667?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140729667&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140729667&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140729667","dc:identifier":"SCOPUS_ID:85140729667","eid":"2-s2.0-85140729667","dc:title":"Deep Human Motion Detection and Multi-Features Analysis for Smart Healthcare Learning Tools","dc:creator":"Hajjej F.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"10","prism:pageRange":"116527-116539","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/ACCESS.2022.3214986","dc:description":"Unhealthy lifestyle causes several chronic diseases in humans. Many products are introduced to avoid such illnesses and provide e-learning-based healthcare services. However, the main focus is still on providing comfortable and reliable solutions. Inertial measurement units (IMU) are considered as the most independent and non-intrusive way to monitor human health via motion patterns detection. In this paper, a deep-learning-based human motion detection approach for smart healthcare learning tool has been proposed. A novel hybrid descriptors-based pre-classification and multi-features analysis algorithm is proposed to classify the human motion for healthcare e-learning. For pre-processing, a quaternion-based filter is used to filter the IMU signals. An experiment is performed over the acceleration signals using minimum and average gravity removal techniques. Next, signal segmentation of multiple time intervals has been applied to segment data and ultimately compare the results to decide which type provides better performance. Then, pre-classification is done using motion pattern identification in the form of active and passive patterns. During the features analysis phase, features are extracted based on both active and passive motion patterns. Further, an orthogonal fuzzy neighborhood discriminant analysis technique has been used to reduce the dimensionality of the extracted feature vector. Finally, a deep learner known as long-short term memory has been applied to classify the actions of both active and passive motion features for healthcare e-learning systems. For this purpose, we utilized two datasets: REALDISP and wearable computing. The experimental results show that our proposed system for smart healthcare learning outperformed other state-of-the-art systems. The proposed implemented system provided 87.35% accuracy for REALDISP and 85.18% accuracy for wearable computing datasets. Furthermore, the classified motion patterns are provided to a smart healthcare advisor in order to provide live feedback about human health for immediate action.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105222","afid":"60105222","affilname":"Prince Sattam Bin Abdulaziz University","affiliation-city":"Al Kharj","affiliation-country":"Saudi Arabia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105146","afid":"60105146","affilname":"Princess Nourah Bint Abdulrahman University","affiliation-city":"Riyadh","affiliation-country":"Saudi Arabia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60091164","afid":"60091164","affilname":"Taif University","affiliation-city":"Taif","affiliation-country":"Saudi Arabia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60070604","afid":"60070604","affilname":"Air University Islamabad","affiliation-city":"Islamabad","affiliation-country":"Pakistan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60068714","afid":"60068714","affilname":"Tech University of Korea","affiliation-city":"Siheung","affiliation-country":"South Korea"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030736","afid":"60030736","affilname":"King Faisal University","affiliation-city":"Al-Ahsa","affiliation-country":"Saudi Arabia"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "9", "$" :"9"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56180409300","authid":"56180409300","orcid":"0000-0003-1709-5790","authname":"Hajjej F.","surname":"Hajjej","given-name":"Fahima","initials":"F.","afid": [{"@_fa": "true", "$" :"60105146"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57221934294","authid":"57221934294","orcid":"0000-0001-5093-7334","authname":"Javeed M.","surname":"Javeed","given-name":"Madiha","initials":"M.","afid": [{"@_fa": "true", "$" :"60070604"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/46062194200","authid":"46062194200","orcid":"0000-0001-6019-5960","authname":"Ksibi A.","surname":"Ksibi","given-name":"Amel","initials":"A.","afid": [{"@_fa": "true", "$" :"60105146"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57201553957","authid":"57201553957","authname":"Alarfaj M.","surname":"Alarfaj","given-name":"Mohammed","initials":"M.","afid": [{"@_fa": "true", "$" :"60030736"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57217020290","authid":"57217020290","orcid":"0000-0003-3980-843X","authname":"Alnowaiser K.","surname":"Alnowaiser","given-name":"Khaled","initials":"K.","afid": [{"@_fa": "true", "$" :"60105222"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/41661536000","authid":"41661536000","authname":"Jalal A.","surname":"Jalal","given-name":"Ahmad","initials":"A.","afid": [{"@_fa": "true", "$" :"60070604"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/57198352588","authid":"57198352588","authname":"Alsufyani N.","surname":"Alsufyani","given-name":"Nawal","initials":"N.","afid": [{"@_fa": "true", "$" :"60091164"}]},{"@_fa": "true", "@seq": "8", "author-url":"https://api.elsevier.com/content/author/author_id/8298383000","authid":"8298383000","orcid":"0000-0002-8050-8431","authname":"Shorfuzzaman M.","surname":"Shorfuzzaman","given-name":"Mohammad","initials":"M.","afid": [{"@_fa": "true", "$" :"60091164"}]},{"@_fa": "true", "@seq": "9", "author-url":"https://api.elsevier.com/content/author/author_id/8899154600","authid":"8899154600","orcid":"0000-0001-8027-0876","authname":"Park J.","surname":"Park","given-name":"Jeongmin","initials":"J.","afid": [{"@_fa": "true", "$" :"60068714"}]}],"authkeywords":"E-learning | features analysis | inertial measurement unit | live feedback | motion detection | noise filter | pre-classification | smart healthcare","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140717562"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140717562?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140717562&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140717562&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140717562","dc:identifier":"SCOPUS_ID:85140717562","eid":"2-s2.0-85140717562","dc:title":"Acute Lymphoblastic Leukemia Detection Using Hypercomplex-Valued Convolutional Neural Networks","dc:creator":"Vieira G.","prism:publicationName":"Proceedings of the International Joint Conference on Neural Networks","prism:isbn": [{"@_fa": "true", "$" :"9781728186719"}],"prism:volume":"2022-July","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/IJCNN55064.2022.9892036","dc:description":"This paper features convolutional neural networks defined on hypercomplex algebras applied to classify lymphocytes in blood smear digital microscopic images. Such classification is helpful for the diagnosis of acute lymphoblast leukemia (ALL), a type of blood cancer. We perform the classification task using eight hypercomplex-valued convolutional neural networks (HvCNNs) along with real-valued convolutional networks. Our results show that HvCNNs perform better than the real-valued model, showcasing higher accuracy with a much smaller number of parameters. Moreover, we found that HvCNNs based on Clifford algebras processing HSV-encoded images attained the highest observed accuracies. Precisely, our HvCNN yielded an average accuracy rate of 96.6% using the ALL-IDB2 dataset with a 50% train-test split, a value extremely close to the state-of-the-art models but using a much simpler architecture with significantly fewer parameters.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029570","afid":"60029570","affilname":"Universidade Estadual de Campinas","affiliation-city":"Campinas","affiliation-country":"Brazil"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57219554292","authid":"57219554292","authname":"Vieira G.","surname":"Vieira","given-name":"Guilherme","initials":"G.","afid": [{"@_fa": "true", "$" :"60029570"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/13408783400","authid":"13408783400","authname":"Eduardo Valle M.","surname":"Eduardo Valle","given-name":"Marcos","initials":"M.","afid": [{"@_fa": "true", "$" :"60029570"}]}],"authkeywords":"Acute Lymphoblastic Leukemia | Clifford algebras | computer assisted diagnosis | Convolutional neural network | hypercomplex algebras","source-id":"96537","fund-acr":"FAPESP","fund-no":"2019/02278-2","fund-sponsor":"Fundação de Amparo à Pesquisa do Estado de São Paulo","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140448019"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140448019?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140448019&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140448019&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140448019","dc:identifier":"SCOPUS_ID:85140448019","eid":"2-s2.0-85140448019","dc:title":"Multiple-criteria-Based Object Pose Tracking in RGB Videos","dc:creator":"Majcher M.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783031160134"}],"prism:volume":"13501 LNAI","prism:pageRange":"477-490","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1007/978-3-031-16014-1_38","dc:description":"In this work, a multi-criteria analysis is leveraged to improve object pose tracking in RGB videos on the basis of keypoints and object shape. A quaternion representing object pose in the previous frame and RGB image in the current frame are fed to a multi-input neural network that predicts 2D locations for a set of predefined 3D object keypoints. The shape features are utilized to exclude keypoints, which are not consistent with object shape. We demonstrate experimentally that by combining shape information with sparse object keypoints considerable gains in tracking accuracy can be achieved in least-squares-based pose refinement. Owing to multiple-criteria decision-making and harnessing such object representations, the proposed method gains significant performance improvements on the OPT benchmark and achieves promising results on challenging YCB-Video dataset.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017351","afid":"60017351","affilname":"AGH University of Krakow","affiliation-city":"Krakow","affiliation-country":"Poland"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57215896487","authid":"57215896487","authname":"Majcher M.","surname":"Majcher","given-name":"Mateusz","initials":"M.","afid": [{"@_fa": "true", "$" :"60017351"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55948049900","authid":"55948049900","authname":"Kwolek B.","surname":"Kwolek","given-name":"Bogdan","initials":"B.","afid": [{"@_fa": "true", "$" :"60017351"}]}],"authkeywords":"Intelligent image processing | Machine learning | Multiple objective decision-making","source-id":"25674","fund-acr":"NCN","fund-no":"2017/27/B/ST6/01743","fund-sponsor":"Narodowe Centrum Nauki","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140420859"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140420859?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140420859&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140420859&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140420859","dc:identifier":"SCOPUS_ID:85140420859","eid":"2-s2.0-85140420859","dc:title":"The images of multilinear and semihomogeneous polynomials on the algebra of octonions","dc:creator":"Kanel-Belov A.","prism:publicationName":"Linear and Multilinear Algebra","prism:issn":"03081087","prism:eIssn":"15635139","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1080/03081087.2022.2158170","dc:description":"The generalized L'vov–Kaplansky conjecture states that for any finite-dimensional simple algebra A the image of a multilinear polynomial on A is a vector space. In this paper, we prove it for the algebra of octonions (Formula presented.) over a field F satisfying certain specified conditions (in particular, we prove it for quadratically closed fields, and for the field (Formula presented.)). In fact, letting V be the space of pure octonions in (Formula presented.), we prove that the image set must be either (Formula presented.), F, V or (Formula presented.). We discuss possible evaluations of semihomogeneous polynomials on (Formula presented.) and of arbitrary polynomials on the corresponding Malcev algebra.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60080064","afid":"60080064","affilname":"Ariel University","affiliation-city":"Ariel","affiliation-country":"Israel"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002765","afid":"60002765","affilname":"Bar-Ilan University","affiliation-city":"Ramat Gan","affiliation-country":"Israel"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57217180353","authid":"57217180353","orcid":"0000-0002-1371-7479","authname":"Kanel-Belov A.","surname":"Kanel-Belov","given-name":"Alexei","initials":"A.","afid": [{"@_fa": "true", "$" :"60002765"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/15750889700","authid":"15750889700","orcid":"0000-0003-4708-3977","authname":"Malev S.","surname":"Malev","given-name":"Sergey","initials":"S.","afid": [{"@_fa": "true", "$" :"60080064"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57219756755","authid":"57219756755","authname":"Pines C.","surname":"Pines","given-name":"Coby","initials":"C.","afid": [{"@_fa": "true", "$" :"60080064"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7004189683","authid":"7004189683","authname":"Rowen L.","surname":"Rowen","given-name":"Louis","initials":"L.","afid": [{"@_fa": "true", "$" :"60002765"}]}],"source-id":"24476","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140359401"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140359401?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140359401&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140359401&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140359401","dc:identifier":"SCOPUS_ID:85140359401","eid":"2-s2.0-85140359401","dc:title":"Proposal of PolSAR Land Classification Using Full-Learning Quaternion Convolutional Neural Networks","dc:creator":"Matsumoto Y.","prism:publicationName":"International Geoscience and Remote Sensing Symposium (IGARSS)","prism:isbn": [{"@_fa": "true", "$" :"9781665427920"}],"prism:volume":"2022-July","prism:pageRange":"235-238","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/IGARSS46834.2022.9883874","dc:description":"Quaternion convolutional neural networks (QCNNs) are in-herently useful for image processing and PolSAR land classification, since they can learn the relationship between the components of input vectors with quaternionic rotations. However, conventional QCNNs fix their rotation axes represented by quaternion weights, resulting in reduction of the degree of freedom (DoF) and the lose of the expression ability. In this paper, we propose QCNNs which learn all the four parameters of the quaternion weights by backpropagation. They perform learning with the maximum of DoF so that they take full advantages of quaternion learning. In addition, we use two totally different features, namely, Pauli RGB features and normalized Stokes vectors. We experimentally found that Pauli RGB features are suitable for discrimination between town and forest, and Stokes vectors between water and grass. Combining their two results complementarily improves classification results. Our proposed QCNNs show the best classification performance compared with real-valued convolutional neural networks and fixed-axis QCNN. These results demonstrate the strength of the proposed QCNN in adaptive polarization processing in multimodal data in the PolSAR field.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025272","afid":"60025272","affilname":"The University of Tokyo","affiliation-city":"Tokyo","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57608068300","authid":"57608068300","authname":"Matsumoto Y.","surname":"Matsumoto","given-name":"Yuya","initials":"Y.","afid": [{"@_fa": "true", "$" :"60025272"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35795724100","authid":"35795724100","authname":"Natsuaki R.","surname":"Natsuaki","given-name":"Ryo","initials":"R.","afid": [{"@_fa": "true", "$" :"60025272"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35416951600","authid":"35416951600","authname":"Hirose A.","surname":"Hirose","given-name":"Akira","initials":"A.","afid": [{"@_fa": "true", "$" :"60025272"}]}],"authkeywords":"convolutional neural network (CNN) | Polarimetric synthetic aperture radar (PolSAR) | quaternion neural network (QNN)","source-id":"82000","fund-acr":"KAKEN","fund-no":"18H04105","fund-sponsor":"Japan Society for the Promotion of Science","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140230362"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140230362?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140230362&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140230362&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140230362","dc:identifier":"SCOPUS_ID:85140230362","eid":"2-s2.0-85140230362","dc:title":"Alpha-Rooting Color Image Enhancement Method for Discrete Fourier Transform and Discrete Quaternion Fourier Transform","dc:creator":"Bahri M.","prism:publicationName":"Studies in Systems, Decision and Control","prism:issn":"21984182","prism:eIssn":"21984190","prism:volume":"444","prism:pageRange":"179-194","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1007/978-3-031-04028-3_12","dc:description":"In this paper, color images enhancement using alpha-rooting will be compared with the discrete Fourier transform and discrete quaternion Fourier transform. The increase in color images was measured by Gray Level Co-Occurrence Matrix (GLCM) by looking at the contrast in each image. It was found that the selection of α values greatly affect the results of image in an image. The results of experiments conducted using several images inform that the discrete Fourier transform has a GLCM value at a higher contrast than the discrete quaternion Fourier transform.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069390","afid":"60069390","affilname":"Hasanuddin University","affiliation-city":"Makassar","affiliation-country":"Indonesia"}],"prism:aggregationType":"Book Series","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/24491506600","authid":"24491506600","authname":"Bahri M.","surname":"Bahri","given-name":"Mawardi","initials":"M.","afid": [{"@_fa": "true", "$" :"60069390"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57933921400","authid":"57933921400","authname":"Puspitasari I.","surname":"Puspitasari","given-name":"Indah","initials":"I.","afid": [{"@_fa": "true", "$" :"60069390"}]}],"authkeywords":"Alpha-rooting | Discrete Fourier transform | Discrete quaternion Fourier transform | GLCM","source-id":"21100828949","fund-no":"undefined","fund-sponsor":"Kementerian Pendidikan, Kebudayaan, Riset, dan Teknologi","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140192084"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140192084?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140192084&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140192084&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140192084","dc:identifier":"SCOPUS_ID:85140192084","eid":"2-s2.0-85140192084","dc:title":"Research on Continuous Dynamic Gesture Recognition of Chinese Sign Language Based on Multi-Mode Fusion","dc:creator":"Li J.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"10","prism:pageRange":"106946-106957","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/ACCESS.2022.3212064","dc:description":"To solve the problem of the low recognition rate of continuous dynamic gestures in Chinese sign language, a non-invasive end-to-end continuous dynamic gesture recognition system combining Inertial Measurement Unit (IMU) signal and surface electromyography (sEMG) signal is constructed. After the preprocessing and fusion of the IMU signal and sEMG signal, the fusion gesture features which include acceleration, angular velocity, attitude quaternion, and sEMG information are extracted. A network model based on the Bi-directional Long-Short Term Memory (BiLSTM) network and Connectionist Temporal Classification (CTC) as loss function is then constructed, which avoids the adverse effects of inaccurate pre-segmentation of gesture sequences on continuous dynamic gesture recognition and realizes the end-to-end continuous dynamic gesture recognition. Finally, the Chinese Sign Language Database (CSLD), containing 10 kinds of Chinese sign language and 20000 gesture samples, is established. The training and testing of the database indicate that the average recognition rate reaches 98.66%, confirming the superiority of this method.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016930","afid":"60016930","affilname":"Beijing University of Posts and Telecommunications","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55116578200","authid":"55116578200","orcid":"0000-0002-4915-3222","authname":"Li J.","surname":"Li","given-name":"Jinquan","initials":"J.","afid": [{"@_fa": "true", "$" :"60016930"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57933802600","authid":"57933802600","orcid":"0000-0001-6069-6474","authname":"Meng J.","surname":"Meng","given-name":"Jiaojiao","initials":"J.","afid": [{"@_fa": "true", "$" :"60016930"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57933802700","authid":"57933802700","authname":"Gong H.","surname":"Gong","given-name":"Haijun","initials":"H.","afid": [{"@_fa": "true", "$" :"60016930"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57222142973","authid":"57222142973","orcid":"0000-0001-6293-3808","authname":"Fan Z.","surname":"Fan","given-name":"Zixuan","initials":"Z.","afid": [{"@_fa": "true", "$" :"60016930"}]}],"authkeywords":"bi-directional long short term memory network | Gesture recognition | inertial measurement unit | multimode fusion | surface electromyography","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139560908"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139560908?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139560908&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85139560908&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85139560908","dc:identifier":"SCOPUS_ID:85139560908","eid":"2-s2.0-85139560908","dc:title":"H<inf>∞</inf> inverse optimal attitude tracking on the special orthogonal group SO(3)","dc:creator":"Aslam F.","prism:publicationName":"International Journal of Control","prism:issn":"00207179","prism:eIssn":"13665820","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1080/00207179.2022.2129790","dc:description":"The problem of attitude tracking in the presence of disturbances is addressed by combining inverse optimality and (Formula presented.) disturbance attenuation. Conditions are provided which ensure that an inverse optimal nonlinear (Formula presented.) attitude control problem is solved and a meaningful cost function is minimised. The approach results in a PD-type attitude control law on the Special Orthogonal Group (Formula presented.) which guarantees that, for almost all initial conditions, the energy gain from an exogenous disturbance to a specified error signal respects a given upper bound. For numerical simulations, a satellite attitude tracking problem from literature is considered. The controller gains are tuned using a decoupled linearised single-axis model and the structured (Formula presented.) control synthesis method. Results indicate that the proposed controller has good tracking and disturbance attenuation capability. In particular, for the problem under consideration, the (Formula presented.) inverse optimal (Formula presented.) controller is seen to have better transient performance than its continuous-time quaternion counterpart. Moreover, for initial errors up to (Formula presented.) radians, it has comparable performance to the shortest-path quaternion PD controller.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60089655","afid":"60089655","affilname":"Institute of Space Technology, Islamabad","affiliation-city":"Islamabad","affiliation-country":"Pakistan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57225339385","authid":"57225339385","orcid":"0000-0002-1227-7942","authname":"Aslam F.","surname":"Aslam","given-name":"Farooq","initials":"F.","afid": [{"@_fa": "true", "$" :"60089655"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56145372900","authid":"56145372900","orcid":"0000-0002-5028-2929","authname":"Haydar M.F.","surname":"Haydar","given-name":"M. Farooq","initials":"M.F.","afid": [{"@_fa": "true", "$" :"60089655"}]}],"authkeywords":"Attitude control | inverse optimal control | special orthogonal group","source-id":"12342","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139407397"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139407397?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139407397&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85139407397&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85139407397","dc:identifier":"SCOPUS_ID:85139407397","eid":"2-s2.0-85139407397","dc:title":"Quaternion Graph Wavelet Transform for Color Texture Classification","dc:creator":"Cheng W.","prism:publicationName":"2022 7th International Conference on Signal and Image Processing, ICSIP 2022","prism:isbn": [{"@_fa": "true", "$" :"9781665495639"}],"prism:pageRange":"521-526","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/ICSIP55141.2022.9886681","dc:description":"The utilization of color and texture information is an important research direction in image processing and pattern recognition. Quaternion graph wavelet transform can combine the structure and relationship between samples to provide richer information at different scales. Therefore, this paper proposes a color texture classification method based on quaternion graph wavelet transform. Specifically, the quaternion graph wavelet transform is used to decompose the color texture. Then the local quaternion singular value decomposition is performed on the subband coefficients to extract local texture information and the Weibull distributions are used to model effective singular values. Finally, experiments on two datasets using the nearest neighbor classifier measured by KL divergence demonstrate that the proposed method is effective for color texture classification.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003353","afid":"60003353","affilname":"Harbin Engineering University","affiliation-city":"Harbin","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57917894900","authid":"57917894900","authname":"Cheng W.","surname":"Cheng","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60003353"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/14021900400","authid":"14021900400","authname":"Qiao Y.","surname":"Qiao","given-name":"Yulong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60003353"}]}],"authkeywords":"local quaternion SVD | quaternion graph wavelet transform color texture classification | quaternion Laplace matrix","source-id":"21101112524","fund-acr":"NSFC","fund-no":"61871142","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137932786"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137932786?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137932786&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137932786&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85137932786","dc:identifier":"SCOPUS_ID:85137932786","eid":"2-s2.0-85137932786","dc:title":"Evaluation of Motion Standard Based on Kinect Human Bone and Joint Data Acquisition","dc:creator":"Zhang X.","prism:publicationName":"Wireless Communications and Mobile Computing","prism:issn":"15308669","prism:eIssn":"15308677","prism:volume":"2022","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1155/2022/7624968","dc:description":"In order to improve human bone and joint data, we propose a method to collect data and judge the standard of motion. Kinect is a 3D somatosensory camera released by Microsoft. It has three cameras in total. The middle is a color camera, which can take color images and obtain 30 images per second; on the left is the infrared projector, which irradiates the object to form speckle. On the right is the depth camera to analyze the infrared spectrum. On both sides are two depth sensors to detect the relative position of people. On both sides of Kinect are a set of quaternion linear microphone arrays for speech recognition and filtering background noise, which can locate the sound source. There is also a base with built-in motor below, which can adjust the elevation angle. It can not only complete the collection of color images, but also measure the depth information of objects. The experimental results show that we use MSRAction3D data set and compare the same cross-validation method with other latest research methods in the figures. The highest recognition rate of this method (algorithm 10) is the second, and the lowest and average recognition rates are the highest. The improvement in the lowest recognition rate is obvious, which can show that this method has good recognition performance and better stability than other research methods. Kinect plays a relatively important role in the movement of human bone and joint data acquisition.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073552","afid":"60073552","affilname":"Huaibei Coal Industry Teachers College","affiliation-city":"Huaibei","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57888414300","authid":"57888414300","orcid":"0000-0002-4055-4011","authname":"Zhang X.","surname":"Zhang","given-name":"Xiaoning","initials":"X.","afid": [{"@_fa": "true", "$" :"60073552"}]}],"article-number":"7624968","source-id":"17543","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137840724"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137840724?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137840724&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137840724&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85137840724","dc:identifier":"SCOPUS_ID:85137840724","eid":"2-s2.0-85137840724","dc:title":"Learning rotations","dc:creator":"Pepe A.","prism:publicationName":"Mathematical Methods in the Applied Sciences","prism:issn":"01704214","prism:eIssn":"10991476","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1002/mma.8698","dc:description":"Many problems in computer vision today are solved via deep learning. Tasks like pose estimation from images, pose estimation from point clouds or structure from motion can all be formulated as a regression on rotations. However, there is no unique way of parametrizing rotations mathematically: matrices, quaternions, axis-angle representation or Euler angles are all commonly used in the field. Some of them, however, present intrinsic limitations, including discontinuities, gimbal lock or antipodal symmetry. These limitations may make the learning of rotations via neural networks a challenging problem, potentially introducing large errors. Following recent literature, we propose three case studies: a sanity check, a pose estimation from 3D point clouds and an inverse kinematic problem. We do so by employing a full geometric algebra (GA) description of rotations. We compare the GA formulation with a 6D continuous representation previously presented in the literature in terms of regression error and reconstruction accuracy. We empirically demonstrate that parametrizing rotations as bivectors outperforms the 6D representation. The GA approach overcomes the continuity issue of representations as the 6D representation does, but it also needs fewer parameters to be learned and offers an enhanced robustness to noise. GA hence provides a broader framework for describing rotations in a simple and compact way that is suitable for regression tasks via deep learning, showing high regression accuracy and good generalizability in realistic high-noise scenarios.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60120016","afid":"60120016","affilname":"Department of Engineering","affiliation-city":"Cambridge","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007643","afid":"60007643","affilname":"CSIC - Instituto de Quimica Fisica Rocasolano (IQFR)","affiliation-city":"Madrid","affiliation-country":"Spain"}],"prism:aggregationType":"Journal","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57887069000","authid":"57887069000","orcid":"0000-0001-8775-4427","authname":"Pepe A.","surname":"Pepe","given-name":"Alberto","initials":"A.","afid": [{"@_fa": "true", "$" :"60120016"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6701831900","authid":"6701831900","orcid":"0000-0002-0571-0218","authname":"Lasenby J.","surname":"Lasenby","given-name":"Joan","initials":"J.","afid": [{"@_fa": "true", "$" :"60120016"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7005148641","authid":"7005148641","authname":"Chacón P.","surname":"Chacón","given-name":"Pablo","initials":"P.","afid": [{"@_fa": "true", "$" :"60007643"}]}],"authkeywords":"bivectors | computer vision | deep learning | geometric algebra | inverse kinematics | pose estimation | rotation representation","source-id":"24594","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137771188"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137771188?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137771188&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137771188&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85137771188","dc:identifier":"SCOPUS_ID:85137771188","eid":"2-s2.0-85137771188","dc:title":"Shape Enhanced Keypoints Learning with Geometric Prior for 6D Object Pose Tracking","dc:creator":"Majcher M.","prism:publicationName":"IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","prism:issn":"21607508","prism:eIssn":"21607516","prism:isbn": [{"@_fa": "true", "$" :"9781665487399"}],"prism:volume":"2022-June","prism:pageRange":"2985-2991","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/CVPRW56347.2022.00337","dc:description":"Until now, there has not been much research in exploiting geometric reasoning on object shape and keypoints in object pose estimation. First, the current RGB image and quaternion representing rotation in the previous frame are fed to a multi-branch neural network responsible for regressing sparse object keypoints. The initial object pose is estimated using PnP, which is adjusted in a least-square optimization. The weights of boundary and keypoints components are determined in each iteration via geometric reasoning on the projected and segmented 3D object boundary, object shape extracted by a pretrained neural network and keypoints extracted by our network. Different from previous methods, our voting scheme is object boundary-based. We demonstrate experimentally that the accuracy of pose estimation is competitive in comparison to the accuracy of SOTA algorithms achieved on challenging YCB-Video dataset.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017351","afid":"60017351","affilname":"AGH University of Krakow","affiliation-city":"Krakow","affiliation-country":"Poland"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57215896487","authid":"57215896487","authname":"Majcher M.","surname":"Majcher","given-name":"Mateusz","initials":"M.","afid": [{"@_fa": "true", "$" :"60017351"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55948049900","authid":"55948049900","authname":"Kwolek B.","surname":"Kwolek","given-name":"Bogdan","initials":"B.","afid": [{"@_fa": "true", "$" :"60017351"}]}],"source-id":"20100195041","fund-acr":"NCN","fund-no":"2017/27/B/ST6/01743","fund-sponsor":"Narodowe Centrum Nauki","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137610937"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137610937?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137610937&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137610937&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85137610937","dc:identifier":"SCOPUS_ID:85137610937","eid":"2-s2.0-85137610937","dc:title":"Biomedical Multimedia Encryption by Fractional-Order Meixner Polynomials Map and Quaternion Fractional-Order Meixner Moments","dc:creator":"Daoui A.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"10","prism:pageRange":"102599-102617","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/ACCESS.2022.3203067","dc:description":"Chaotic systems are widely used in signal and image encryption schemes. Therefore, the design of new chaotic systems is always useful for improving the performance of encryption schemes in terms of security. In this work, we first demonstrate the chaotic behavior of fractional order Meixner polynomials (FrMPs) for introducing a new two-dimensional (2D) chaotic system called FrMPs map. This system is very sensitive to any variation by 10-15 of its control parameters (μm {and}β ).Next, we use FrMPs to introduce a new type of orthogonal transforms called quaternion fractional order Meixner moments (QFrMMs). The latter generalize the existing fractional order Meixner moments. To demonstrate the relevance of the proposed FrMPs map and QFrMMs in the field of signal and image processing, they are applied in the development of a new encryption scheme. The main advantage of this scheme is its applicability to the encryption of different types of biomedical data such as multi-biomedical signals, multiple grayscale medical images, color medical image, and grayscale medical image. Several simulation analysis (visual, histogram, runtime, correlation, robustness, etc.) are conducted to verify the efficiency of the proposed scheme. Simulation and comparison results confirm that our encryption method is effective in terms of high security level, high quality of the decrypted information, strong resistance to different types of attacks, etc. These findings support the suitability of the proposed scheme for the secure exchange of biomedical multimedia via a public communication channel.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60274028","afid":"60274028","affilname":"Faculty of Science","affiliation-city":"Shibin El Kom","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024326","afid":"60024326","affilname":"Laboratoire d'Electronique, Signaux, Systèmes et d'Informatique, Université Sidi Mohamed Ben Abdellah","affiliation-city":"Fez","affiliation-country":"Morocco"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60020458","afid":"60020458","affilname":"Jamia Millia Islamia","affiliation-city":"New Delhi","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017021","afid":"60017021","affilname":"Université Sidi Mohamed Ben Abdellah","affiliation-city":"Fez","affiliation-country":"Morocco"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015723","afid":"60015723","affilname":"Prince Sultan University","affiliation-city":"Riyadh","affiliation-country":"Saudi Arabia"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57207617031","authid":"57207617031","authname":"Daoui A.","surname":"Daoui","given-name":"Achraf","initials":"A.","afid": [{"@_fa": "true", "$" :"60017021"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57207620865","authid":"57207620865","authname":"Yamni M.","surname":"Yamni","given-name":"Mohamed","initials":"M.","afid": [{"@_fa": "true", "$" :"60024326"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57190495161","authid":"57190495161","authname":"Karmouni H.","surname":"Karmouni","given-name":"Hicham","initials":"H.","afid": [{"@_fa": "true", "$" :"60017021"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55561914300","authid":"55561914300","authname":"Sayyouri M.","surname":"Sayyouri","given-name":"Mhamed","initials":"M.","afid": [{"@_fa": "true", "$" :"60017021"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/12144280900","authid":"12144280900","authname":"Qjidaa H.","surname":"Qjidaa","given-name":"Hassan","initials":"H.","afid": [{"@_fa": "true", "$" :"60024326"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/56339090200","authid":"56339090200","orcid":"0000-0002-4915-9325","authname":"Ahmad M.","surname":"Ahmad","given-name":"Musheer","initials":"M.","afid": [{"@_fa": "true", "$" :"60020458"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/8578949200","authid":"8578949200","orcid":"0000-0002-5068-2033","authname":"Abd El-Latif A.A.","surname":"Abd El-Latif","given-name":"Ahmed A.","initials":"A.A.","afid": [{"@_fa": "true", "$" :"60015723"},{"@_fa": "true", "$" :"60274028"}]}],"authkeywords":"fractional-order polynomials | medical image encryption | multiple image encryption | quaternion fractional order moments | Quaternion theory","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137544207"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137544207?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137544207&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137544207&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85137544207","dc:identifier":"SCOPUS_ID:85137544207","eid":"2-s2.0-85137544207","dc:title":"Refined Astrometry on Board a CubeSat","dc:creator":"Segret B.","prism:publicationName":"IEEE Aerospace Conference Proceedings","prism:issn":"1095323X","prism:isbn": [{"@_fa": "true", "$" :"9781665437608"}],"prism:volume":"2022-March","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/AERO53065.2022.9843818","dc:description":"Optical navigation on a CubeSat must rely on the best extraction of the directions of some beacons from on-board images. We present an experiment on OPS-SAT, a CubeSat of the European Space Agency (ESA), that will characterize an on-board algorithm to this aim, named Angle-based Correlation (AbC). OPS-SAT is a 3-unit CubeSat with an Attitude Deter-mination and Control System (ADCS) and an imager that have proved their reliability with typical performance at CubeSat scale. We selected a few star-fields that all present enough visible stars within a 10º field of view. When our experiment is run, OPS-SAT is pointed to the most convenient star-field at that time. There, the star-field is imaged and subwindows are extracted from the image around the expected location of each star, based on the attitude-quaternion reported by the ADCS. The AbC reconstructs the absolute direction of the central body, in principle unknown, which is the pointed known star in the experiment. The method intensively uses the quaternion algebra. The beacon location is first consolidated in the field of view with the AbC. Then, the field of view is finely positioned against the sky, again with the AbC. A covariance is associated with the found beacon direction. Our experiment with OPS-SAT manages the pointing and the imager, and processes the taken images. Then, it downloads the on-board computed absolute directions and their covariances, to be compared with the actual directions. After a campaign of intensive use of the experiment, the statistical performance of the algorithm will be established and compared to the on-board computed covariances. As a bonus, an assessment of OPS-SAT's inertial pointing stability will be available. The AbC can theoretically get rid of the Attitude Control Error (ACE) of the platform and of the Attitude Knowledge Error (AKE) estimated by the ADCS, and potentially converge to sub-arcsec measurements, whereas 15 to 90 arcsec for AKE are expected on CubeSats and imager pixel size ranges in 10 to 15 arcsec. Results will be available from 2022, thus, instead, we illustrate here possible applications for commissioning and autonomous operations.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60123796","afid":"60123796","affilname":"Université Paris Cité","affiliation-city":"Paris","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028894","afid":"60028894","affilname":"LESIA - Laboratoire d'Etudes Spatiales et d'Instrumentation en Astrophysique","affiliation-city":"Meudon","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025005","afid":"60025005","affilname":"Institut de Mecanique Celeste et de Calcul des Ephemerides","affiliation-city":"Paris","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008134","afid":"60008134","affilname":"CNRS Centre National de la Recherche Scientifique","affiliation-city":"Paris","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/128549299","afid":"128549299","affilname":"Census","affiliation-city":null,"affiliation-country":null}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56347580300","authid":"56347580300","authname":"Segret B.","surname":"Segret","given-name":"Boris","initials":"B.","afid": [{"@_fa": "true", "$" :"128549299"},{"@_fa": "true", "$" :"60028894"},{"@_fa": "true", "$" :"60123796"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57317382900","authid":"57317382900","authname":"Diaw Y.","surname":"Diaw","given-name":"Youssoupha","initials":"Y.","afid": [{"@_fa": "true", "$" :"128549299"},{"@_fa": "true", "$" :"60028894"},{"@_fa": "true", "$" :"60123796"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6505761457","authid":"6505761457","authname":"Lainey V.","surname":"Lainey","given-name":"Valery","initials":"V.","afid": [{"@_fa": "true", "$" :"60123796"},{"@_fa": "true", "$" :"60025005"},{"@_fa": "true", "$" :"60008134"}]}],"source-id":"75113","fund-no":"undefined","fund-sponsor":"Université Paris-Sud","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136823291"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136823291?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136823291&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85136823291&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85136823291","dc:identifier":"SCOPUS_ID:85136823291","eid":"2-s2.0-85136823291","dc:title":"Image Splicing Detection Based on Adaptive Quaternion Singular Value Decomposition","dc:creator":"Zhao X.","prism:publicationName":"Jisuanji Gongcheng/Computer Engineering","prism:issn":"10003428","prism:volume":"48","prism:issueIdentifier":"4","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.19678/j.issn.1000-3428.0060758","dc:description":"Image splicing combines images from different sources into one image, resulting in inconsistencies in the illumination direction, noise, and other characteristics of the image.Currently, most methods detect forged areas based on the inconsistency of noise in stitched images；however, the accuracy of noise estimation for image blocks of different sizes is generally not high, resulting in a low True Positive Rate(TPR), and the detection fails when the noise difference is small.To solve this problem, a noise estimation method based on adaptive Quaternion Singular Value Decomposition (QSVD) is proposed. The image is segmented by super-pixels, and the noise of these super-pixels is estimated by adaptive QSVD. Combined with image brightness, the image noise-brightness function is established by polynomial fitting, and the minimum distance measure from each super-pixel to the function curve is obtained.To improve detection accuracy, the color temperature feature of the super-pixel is extracted using a color temperature estimation algorithm.The distance measure and color temperature feature are fused as the final feature vector.The stitching region is located by FCM fuzzy clustering.Experiments on the Columbia IPDED splicing image dataset demonstrate that the detection TPR value of this method on the unprocessed image set is at least 8.21 percentage points highter than that of the comparison method.The method is robust to Gaussian blur, JPEG compression, and Gamma correction.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030922","afid":"60030922","affilname":"Shihezi University","affiliation-city":"Shihezi","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003640","afid":"60003640","affilname":"Northwest Normal University China","affiliation-city":"Lanzhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57217875327","authid":"57217875327","authname":"Zhao X.","surname":"Zhao","given-name":"Xiufeng","initials":"X.","afid": [{"@_fa": "true", "$" :"60003640"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35758063000","authid":"35758063000","authname":"Wei W.","surname":"Wei","given-name":"Weiyi","initials":"W.","afid": [{"@_fa": "true", "$" :"60003640"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57208283800","authid":"57208283800","authname":"Chen J.","surname":"Chen","given-name":"Jinshou","initials":"J.","afid": [{"@_fa": "true", "$" :"60030922"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57863720900","authid":"57863720900","authname":"Chen G.","surname":"Chen","given-name":"Guo","initials":"G.","afid": [{"@_fa": "true", "$" :"60003640"}]}],"authkeywords":"Adaptive Quaternion Singular Value Decomposition(QSVD) | Color temperature estimation | FCM clustering | Noise level | Splicing tamper detection","source-id":"26713","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136782132"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136782132?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136782132&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85136782132&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85136782132","dc:identifier":"SCOPUS_ID:85136782132","eid":"2-s2.0-85136782132","dc:title":"Quaternion keyed Least Square Approximation for image encryption","dc:creator":"Kalaiarasan D.","prism:publicationName":"Journal of Intelligent and Fuzzy Systems","prism:issn":"10641246","prism:eIssn":"18758967","prism:volume":"43","prism:issueIdentifier":"4","prism:pageRange":"5221-5236","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.3233/JIFS-213600","dc:description":"Securing image data from prying hackers is crucial in safeguarding the secrecy of data. Over the years, this was done by encrypting the image using an algorithm and a key, where the visible image was converted into a meaningless object. It is a difficult problem to design an image encryption technique based on chaotic systems with predictable cryptographic features. In this paper, the Quaternion, along with the Rossler attractor, was used to generate the key combination. The ciphering was done using the Least Square Approximation Algorithm (LSA). The algorithm was tested on a grayscale image database. The algorithm was initially tested in software using MATLAB R2018b, and was implemented in the Cyclone II EP2C35F672C6 device FPGA. On average, for a cipher image, the Peak Signal to Noise ratio (PSNR) was 9.09303dB and the entropy was 7.9990 bits. For the cipher image, the Number of Pixels Change Rate (NPCR) and Unified Average Change Intensity (UACI) were 99.6039 and 33.4980, respectively. This proved that the algorithm could effectively mitigate the statistical and differential attacks. The key space was 2 (M ×N ×7 ×8), which was sufficiently high and mitigated the brute force attacks. The obtained results confirm that the cipher images resulting from the proposed ciphering scheme possess good cryptographic properties in terms of entropy, PSNR, UACI, NPCR, and keyspace analysis. Furthermore, the strength of the key is evaluated by the NIST test suite.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60094008","afid":"60094008","affilname":"PSN College of Engineering &amp; Technology","affiliation-city":"Palayamkottai","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/126245253","afid":"126245253","affilname":"Government College of Engineering","affiliation-city":"Srirangam","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57215558886","authid":"57215558886","authname":"Kalaiarasan D.","surname":"Kalaiarasan","given-name":"D.","initials":"D.","afid": [{"@_fa": "true", "$" :"126245253"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57188654703","authid":"57188654703","authname":"Ahilan A.","surname":"Ahilan","given-name":"A.","initials":"A.","afid": [{"@_fa": "true", "$" :"60094008"}]}],"authkeywords":"image encryption | Least Square Approximation | Pseudo random number generation | Quaternion | rossler attractor","source-id":"23917","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136000047"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136000047?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136000047&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85136000047&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85136000047","dc:identifier":"SCOPUS_ID:85136000047","eid":"2-s2.0-85136000047","dc:title":"TOTAL VARIATION BASED PURE QUATERNION DICTIONARY LEARNING METHOD FOR COLOR IMAGE DENOISING","dc:creator":"Wu T.","prism:publicationName":"International Journal of Numerical Analysis and Modeling","prism:issn":"17055105","prism:volume":"19","prism:issueIdentifier":"5","prism:pageRange":"709-737","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","dc:description":"As an important pre-processing step for many related computer vision tasks, color image denoising has attracted considerable attention in image processing. However, traditional methods often regard the red, green, and blue channels of color images independently without considering the correlations among the three channels. In order to overcome this deficiency, this paper proposes a novel dictionary method for color image denoising based on pure quaternion representation, which efficiently deals with both single-channel and cross-channel information. The pure quaternion constraint is firstly used to force the sparse representations of color images to contain only red, green, and blue color information. Moreover, a total variation regularization is proposed in the quaternion domain and embedded into the pure quaternion-based representation model, which is effective to recover the sharp edges of color images. To solve the proposed model, a new numerical scheme is also developed based on the alternating minimization method (AMM). Experimental results demonstrate that the proposed model has better denoising results than the state-of-the-art methods, including a deep learning approach DnCNN, in terms of PSNR, SSIM, and visual quality.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009400","afid":"60009400","affilname":"Nanjing University of Post and TeleCommunications","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60006541","afid":"60006541","affilname":"The University of Hong Kong","affiliation-city":"Hong Kong","affiliation-country":"Hong Kong"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004691","afid":"60004691","affilname":"Jiangsu Normal University","affiliation-city":"Xuzhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57129572900","authid":"57129572900","authname":"Wu T.","surname":"Wu","given-name":"Tingting","initials":"T.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57238469700","authid":"57238469700","authname":"Huang C.","surname":"Huang","given-name":"Chaoyan","initials":"C.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/33368118000","authid":"33368118000","authname":"Jin Z.","surname":"Jin","given-name":"Zhengmeng","initials":"Z.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/8264355300","authid":"8264355300","authname":"Jia Z.","surname":"Jia","given-name":"Zhigang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60004691"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/34571761900","authid":"34571761900","authname":"Ng M.K.","surname":"Ng","given-name":"Michael K.","initials":"M.K.","afid": [{"@_fa": "true", "$" :"60006541"}]}],"authkeywords":"Color image denoising | pure quaternion matrix | singular value decomposition | sparse representation | total variation","source-id":"11200153520","fund-acr":"NSF","fund-no":"12300218","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135954560"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135954560?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85135954560&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85135954560&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85135954560","dc:identifier":"SCOPUS_ID:85135954560","eid":"2-s2.0-85135954560","dc:title":"QSRNet - Towards Quaternion-based Single Image Super-Resolution","dc:creator":"Shreyas Kamath K.M.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510650763"}],"prism:volume":"12100","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1117/12.2618542","dc:description":"Single-image super-resolution (SISR), which maps a low-resolution observation to a high-resolution image, has been extensively utilized in various computer vision applications. With the advent of convolutional neural networks (CNNs), numerous algorithms have emerged that achieve state-of-the-art results. However, the main drawback of CNN is the negligence in the interrelationship between the RGB color channel. This negligence further reduces crucial structural information of color and provides a non-optimal representation of color images. Furthermore, most of these CNN-based methods contain millions of parameters and layers, limiting the practical applications. To overcome these drawbacks, an endto-end trainable single image super-resolution method - Quaternion-based Image Super-Resolution network (QSRNet) that takes advantage of the quaternion theory is proposed in this paper. QSRNet aims at maintaining the local and global interrelationship between the channels and produces high-resolution images with approximately 4x fewer parameters when compared to standard CNNs. Extensive computer experimentations were conducted on publicly available benchmarking thermal datasets, including DIV2K, Flickr2K, Set5, Set14, BSD100, Urban100, and UEC100, to demonstrate the effectiveness of the proposed QSRNet compared to traditional CNNs.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032373","afid":"60032373","affilname":"The Graduate Center","affiliation-city":"New York","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023143","afid":"60023143","affilname":"Tufts University","affiliation-city":"Medford","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57200569514","authid":"57200569514","authname":"Shreyas Kamath K.M.","surname":"Shreyas Kamath","given-name":"K. M.","initials":"K.M.","afid": [{"@_fa": "true", "$" :"60023143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57191541404","authid":"57191541404","authname":"Rao S.P.","surname":"Rao","given-name":"Shishir Paramathma","initials":"S.P.","afid": [{"@_fa": "true", "$" :"60023143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6507727793","authid":"6507727793","authname":"Panetta K.","surname":"Panetta","given-name":"Karen","initials":"K.","afid": [{"@_fa": "true", "$" :"60023143"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/35321805400","authid":"35321805400","authname":"Agaian S.S.","surname":"Agaian","given-name":"Sos S.","initials":"S.S.","afid": [{"@_fa": "true", "$" :"60032373"}]}],"authkeywords":"hypercomplex neural networks | quaternion | quaternion convolutional neural networks | quaternion neural networks | soft-edge | super-resolution","article-number":"121000I","source-id":"40067","fund-acr":"NIH","fund-no":"AR9008","fund-sponsor":"National Institutes of Health","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135373151"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135373151?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85135373151&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85135373151&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85135373151","dc:identifier":"SCOPUS_ID:85135373151","eid":"2-s2.0-85135373151","dc:title":"A Joint Particle Filter for Quaternion-Valued a-Stable Signals via the Characteristic Function","dc:creator":"Talebi S.P.","prism:publicationName":"Proceedings of the IEEE Sensor Array and Multichannel Signal Processing Workshop","prism:eIssn":"2151870X","prism:isbn": [{"@_fa": "true", "$" :"9781665406338"}],"prism:volume":"2022-June","prism:pageRange":"390-394","prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1109/SAM53842.2022.9827868","dc:description":"The filtering paradigm is revisited through the perspective of characteristic functions. This results in the derivation of a novel particle filtering technique for sequential estimation/tracking of quaternion-valued a-stable random signals. Importantly, the derived particle filter incorporates an efficient information fusion format and collaborative/distributed estimation framework to accommodate the push toward use of sensor networks. The distributed setting provides for the distribution of computational complexity among agents of a sensor network, while allowing each agent to retain an estimate of the state. Furthermore, the quaternion-valued structure allows for the derivation of a rigorous algorithm that is advantageous when dealing with signals of a multidimensional nature commonly encountered in sensor arrays.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60020595","afid":"60020595","affilname":"Royal Holloway, University of London","affiliation-city":"Egham","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015150","afid":"60015150","affilname":"Imperial College London","affiliation-city":"London","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013141","afid":"60013141","affilname":"Norges Teknisk-Naturvitenskapelige Universitet","affiliation-city":"Trondheim","affiliation-country":"Norway"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005244","afid":"60005244","affilname":"Southeast University","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56297174200","authid":"56297174200","authname":"Talebi S.P.","surname":"Talebi","given-name":"Sayed Pouria","initials":"S.P.","afid": [{"@_fa": "true", "$" :"60013141"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7202886122","authid":"7202886122","authname":"Werner S.","surname":"Werner","given-name":"Stefan","initials":"S.","afid": [{"@_fa": "true", "$" :"60013141"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/25958477900","authid":"25958477900","authname":"Xia Y.","surname":"Xia","given-name":"Yili","initials":"Y.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57829404900","authid":"57829404900","authname":"Took C.C.","surname":"Took","given-name":"Clive Cheong","initials":"C.C.","afid": [{"@_fa": "true", "$" :"60020595"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7006513328","authid":"7006513328","authname":"Mandic D.P.","surname":"Mandic","given-name":"Danilo P.","initials":"D.P.","afid": [{"@_fa": "true", "$" :"60015150"}]}],"authkeywords":"a-stable random signals | distributed estimation | particle filtering | quaternion-valued signal processing","source-id":"21100217219","fund-no":"undefined","fund-sponsor":"Norges Forskningsråd","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135372039"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85135372039?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85135372039&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85135372039&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85135372039","dc:identifier":"SCOPUS_ID:85135372039","eid":"2-s2.0-85135372039","dc:title":"Color Image Feature Matching Method Based on the Improved Firework Algorithm","dc:creator":"Liu D.","prism:publicationName":"Mathematical Problems in Engineering","prism:issn":"1024123X","prism:eIssn":"15635147","prism:volume":"2022","prism:pageRange":null,"prism:coverDate":"2022-01-01","prism:coverDisplayDate":"2022","prism:doi":"10.1155/2022/9447410","dc:description":"An improved ORB feature point purification method has been proposed to address the problem of large feature point matching error and low image registration rate in the oriented FAST and rotated BRIEF (ORB) feature point color image matching algorithm. Pure virtual quaternions were used to represent the color image pixels in this method, and an improved FAST algorithm was used to detect the color feature points at first. The firework algorithm has been used to divide the detected feature points into key areas, auxiliary areas, and small influence areas, depending on the degree of attachment. The feature points of the key area and the subsidiary area are the required feature points. In order to further improve the efficiency of matching the color image feature points, the firework explosion radius formula and the explosion number formula in the firework algorithm have been improved, and an improved firework algorithm is proposed. This improved algorithm purifies the quaternion-represented color image feature points. For feature matching, the hamming distance was used. Experiments show that, when compared to the traditional ORB algorithm, the improved algorithm retains the key feature points of the color image with high accuracy, removes a large number of irrelevant feature points and noise points, and provides significantly higher accuracy and efficiency of color image matching.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60092861","afid":"60092861","affilname":"Sichuan University of Arts and Science","affiliation-city":"Dazhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/54385506700","authid":"54385506700","orcid":"0000-0001-8822-6722","authname":"Liu D.","surname":"Liu","given-name":"Dujin","initials":"D.","afid": [{"@_fa": "true", "$" :"60092861"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57194183471","authid":"57194183471","authname":"Zhu H.","surname":"Zhu","given-name":"Huawei","initials":"H.","afid": [{"@_fa": "true", "$" :"60092861"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/58466078400","authid":"58466078400","authname":"Wang H.","surname":"Wang","given-name":"Haiyan","initials":"H.","afid": [{"@_fa": "true", "$" :"60092861"}]}],"article-number":"9447410","source-id":"13082","fund-no":"znzz2102","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}}]}}