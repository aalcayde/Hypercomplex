{"search-results":{"opensearch:totalResults":"214","opensearch:startIndex":"100","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "100"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=100&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2023&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2023&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=75&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2023&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2023&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=189&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2023&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85141926414"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85141926414?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85141926414&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85141926414&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0957417422022631"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85141926414","dc:identifier":"SCOPUS_ID:85141926414","eid":"2-s2.0-85141926414","dc:title":"Theory of reduced biquaternion sparse representation and its applications","dc:creator":"Gai S.","prism:publicationName":"Expert Systems with Applications","prism:issn":"09574174","prism:volume":"213","prism:pageRange":null,"prism:coverDate":"2023-03-01","prism:coverDisplayDate":"1 March 2023","prism:doi":"10.1016/j.eswa.2022.119245","pii":"S0957417422022631","dc:description":"Traditional sparse representation models treat color image either represent color channels independently using the monochromatic model or concatenate color channels using the concatenation model. However, these two strategies cannot make full use of the correlation among the three color channels. In this paper, we propose a novel sparse representation model for color image based on reduced biquaternion. The advances of the proposed model are in two aspects: 1) compared with quaternion algebra, reduced biquaternion algebra is commutative algebra which has a low computation cost; 2) benefited from reduced biquaternion representation, the proposed model can treat the color image as a whole. We firstly extend the singular value decomposition (SVD) to the reduced biquaternion domain (RBSVD). The framework of the proposed model contains two major stages: first, reduced biquaternion orthogonal matching pursuit (RBOMP) is proposed in the stage of sparse coding; second, generalized K-means clustering for RBSVD (K-RBSVD) is proposed in the stage of dictionary training. Afterward, a new color image denoising algorithm is developed to demonstrate the effectiveness of the proposed model. The experimental results demonstrate that the proposed sparse representation model achieves state-of-the-art denoising performance in terms of both quantitative metrics and visual quality.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018465","afid":"60018465","affilname":"Yanshan University","affiliation-city":"Qinhuangdao","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35748407200","authid":"35748407200","authname":"Gai S.","surname":"Gai","given-name":"Shan","initials":"S.","afid": [{"@_fa": "true", "$" :"60018465"}]}],"authkeywords":"Dictionary learning | Image denoising | K-RBSVD | Reduced biquaternion | Sparse representation","article-number":"119245","source-id":"24201","fund-acr":"NSFC","fund-no":"62061032","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85133206338"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85133206338?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85133206338&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85133206338&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85133206338","dc:identifier":"SCOPUS_ID:85133206338","eid":"2-s2.0-85133206338","dc:title":"Image classification based on quaternion-valued capsule network","dc:creator":"Zhou H.","prism:publicationName":"Applied Intelligence","prism:issn":"0924669X","prism:eIssn":"15737497","prism:volume":"53","prism:issueIdentifier":"5","prism:pageRange":"5587-5606","prism:coverDate":"2023-03-01","prism:coverDisplayDate":"March 2023","prism:doi":"10.1007/s10489-022-03849-x","dc:description":"In this paper, a novel quaternion-valued (QV) capsule module is designed to construct QV capsule networks for image classification. The quaternion algebra is introduced into the capsule networks to effectively capture the external dependencies and internal structural information. Moreover, the QV capsules can enhance the representation of complex information and alleviate the information loss of vanilla capsule networks. Particularly, a non-iterative quaternion routing algorithm is proposed to integrate QV capsules, considering both the membership and the consistency of QV capsules in two stages. Extensive experiments are conducted on classic image datasets, hyperspectral image datasets, and face datasets, which demonstrate that: firstly, the QV capsule network achieves higher classification accuracy, reaching 92.95% in UC Merced Land Use and 95.02% in CIFAR 10; secondly, the QV capsule module is more adaptable to different backbone networks than the vanilla capsule module; finally, the QV capsule network shows high performance with limited training samples.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023237","afid":"60023237","affilname":"Beijing Normal University","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013551","afid":"60013551","affilname":"China Agricultural University","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009409","afid":"60009409","affilname":"China University of Geosciences, Beijing","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/126149005","afid":"126149005","affilname":"Ltd.","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57216217214","authid":"57216217214","authname":"Zhou H.","surname":"Zhou","given-name":"Heng","initials":"H.","afid": [{"@_fa": "true", "$" :"60013551"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57223020406","authid":"57223020406","orcid":"0000-0002-6253-2446","authname":"Zhang C.","surname":"Zhang","given-name":"Chunlei","initials":"C.","afid": [{"@_fa": "true", "$" :"126149005"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57196396566","authid":"57196396566","authname":"Zhang X.","surname":"Zhang","given-name":"Xin","initials":"X.","afid": [{"@_fa": "true", "$" :"60023237"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57216152458","authid":"57216152458","authname":"Ma Q.","surname":"Ma","given-name":"Qiaoyu","initials":"Q.","afid": [{"@_fa": "true", "$" :"60009409"}]}],"authkeywords":"Capsule networks | Image classification | Quaternion | Routing algorithm","source-id":"23674","fund-acr":"NSFC","fund-no":"11871104","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85129624656"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85129624656?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85129624656&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85129624656&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85129624656","dc:identifier":"SCOPUS_ID:85129624656","eid":"2-s2.0-85129624656","dc:title":"Learning a Novel LiDAR Submap-Based Observation Model for Global Positioning in Long-Term Changing Environments","dc:creator":"Kong D.","prism:publicationName":"IEEE Transactions on Industrial Electronics","prism:issn":"02780046","prism:eIssn":"15579948","prism:volume":"70","prism:issueIdentifier":"3","prism:pageRange":"3147-3157","prism:coverDate":"2023-03-01","prism:coverDisplayDate":"1 March 2023","prism:doi":"10.1109/TIE.2022.3169849","dc:description":"In complex environments with long-term changes such as light, seasonal, and viewpoint changes, robust, accurate, and high-frequency global positioning based on light detection and ranging (LiDAR) map is still a challenge, which is crucial for autonomous vehicles or robots. To this end, a novel observation model that relies on the siamese multitask convolutional neural networks (CNNs) with multimodule cascaded is creatively presented in this article. In particular, a new pseudoimage representing LiDAR submap is designed to enrich scene texture and enhance rotation invariance. Besides, novel siamese CNNs that are coupled by NeXtVLAD and long short-term memory is designed for the first time, which can reliably predict similarity and quaternion at the same time. Finally, the predicted quaternion observation is integrated into the extended Kalman filter framework for multisensor fusion to achieve robust high-frequency global pose estimation. Extensive evaluations on KITTI, NCLT, and real-world datasets suggest that the proposed method not only obtains the remarkable precision-recall performance, but also effectively enhances and improves the robustness and accuracy of long-term positioning.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005244","afid":"60005244","affilname":"Southeast University","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57780827200","authid":"57780827200","orcid":"0000-0003-3002-7389","authname":"Kong D.","surname":"Kong","given-name":"Dong","initials":"D.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55273488000","authid":"55273488000","orcid":"0000-0003-2772-7114","authname":"Li X.","surname":"Li","given-name":"Xu","initials":"X.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57437080200","authid":"57437080200","orcid":"0000-0002-0566-811X","authname":"Hu Y.","surname":"Hu","given-name":"Yue","initials":"Y.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55948275400","authid":"55948275400","orcid":"0000-0002-7159-8666","authname":"Xu Q.","surname":"Xu","given-name":"Qimin","initials":"Q.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57192417267","authid":"57192417267","authname":"Wang A.","surname":"Wang","given-name":"Aimin","initials":"A.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57213687281","authid":"57213687281","orcid":"0000-0001-9483-5559","authname":"Hu W.","surname":"Hu","given-name":"Weiming","initials":"W.","afid": [{"@_fa": "true", "$" :"60005244"}]}],"authkeywords":"Fusion positioning | long short-term memory (LSTM) | place recognition (PR) | quaternion observation | siamese network","source-id":"26053","fund-acr":"NSFC","fund-no":"BE2019106","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85158815433"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85158815433?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85158815433&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85158815433&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85158815433","dc:identifier":"SCOPUS_ID:85158815433","eid":"2-s2.0-85158815433","dc:title":"Color image denoising method combining prue quaternion and dictionary learning","dc:creator":"Zeng Y.","prism:publicationName":"Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics","prism:issn":"1001506X","prism:volume":"45","prism:issueIdentifier":"2","prism:pageRange":"373-378","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.12305/j.issn.1001-506X.2023.02.06","dc:description":"The acquisition, transmission, and storage process of color images can corrupted by noise, which brings trouble to the subsequent image processing. The task of image denoising is of great significance. A model based on quaternion dictionary learning is proposed by using the method of constraining the real part of quaternion to zero to represent color images, so that the color information can be well preserved. The traditional sparse image models only regard color image pixels as the linear connection of vector or monochrome images, which ignore the correlation of RGB channels. The color image is represented as a pure quaternion, and the RGB channels of the color image are represented as the imaginary part of the quaternion matrix, which fits the image better. Compared with other advanced models, numerical experiments show that the constructed model can represent color images more accurately, and the model fitting error is relatively small in the process of processing color images, peak signal-to-noise ratio and visual effect are significantly improved, so it can better denoise the image.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069734","afid":"60069734","affilname":"Logistical Engineering University China","affiliation-city":"Chongqing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009400","afid":"60009400","affilname":"Nanjing University of Post and TeleCommunications","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7402981495","authid":"7402981495","authname":"Zeng Y.","surname":"Zeng","given-name":"Yonghua","initials":"Y.","afid": [{"@_fa": "true", "$" :"60069734"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58196013000","authid":"58196013000","authname":"Ma J.","surname":"Ma","given-name":"Junyao","initials":"J.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57238469700","authid":"57238469700","authname":"Huang C.","surname":"Huang","given-name":"Chaoyan","initials":"C.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57682545000","authid":"57682545000","authname":"Mao Z.","surname":"Mao","given-name":"Zhihui","initials":"Z.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57129572900","authid":"57129572900","authname":"Wu T.","surname":"Wu","given-name":"Tingting","initials":"T.","afid": [{"@_fa": "true", "$" :"60009400"}]}],"authkeywords":"color image denoising | dictionary learning method | quaternion","source-id":"15141","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85152197883"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85152197883?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85152197883&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85152197883&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85152197883","dc:identifier":"SCOPUS_ID:85152197883","eid":"2-s2.0-85152197883","dc:title":"Hypotheses Generation and Verification Based Framework for Crowd Anomaly Detection in Single-Scene Surveillance Videos","dc:creator":"Hanif M.S.","prism:publicationName":"Traitement du Signal","prism:issn":"07650019","prism:eIssn":"19585608","prism:volume":"40","prism:issueIdentifier":"1","prism:pageRange":"115-122","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.18280/ts.400110","dc:description":"A two-stage framework for crowd anomaly detection in single-scene or scene-dependent surveillance videos is proposed in this article. The first stage generates several hypotheses corresponding to potential anomalous regions in a video frame and the second stage verifies them to reduce false alarms and identifies crowd anomalies. In the hypotheses generation stage, spatial and temporal derivatives are computed for each video frame and a saliency detector employing Hypercomplex Fourier Transform (HFT) is used to generate a saliency map. A threshold is applied to the saliency map to generate potential anomalous regions in the form of connected components. For each connected component, a set of 4 statistical features are computed and fed to the second stage which employs a Gaussian Mixture Model (GMM) as a verification method to yield the final crowd anomalies in the frame. The effectiveness of the proposed framework has been shown through results obtained on the UCSD anomaly detection benchmark dataset which contains two subsets namely Ped1 and Ped2 with a total of 48 test videos (9210 frames). Both frame-level and pixel-level anomaly detection results are provided using the widely recognized evaluation criterion in the domain and compared with the state-of-the-art methods. The experimental results show that the proposed framework obtains comparable results against the state-of-the-art methods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004582","afid":"60004582","affilname":"King Abdulaziz University","affiliation-city":"Jeddah","affiliation-country":"Saudi Arabia"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57213496275","authid":"57213496275","authname":"Hanif M.S.","surname":"Hanif","given-name":"Muhammad Shehzad","initials":"M.S.","afid": [{"@_fa": "true", "$" :"60004582"},{"@_fa": "true", "$" :"60004582"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58530090700","authid":"58530090700","authname":"Bilal M.","surname":"Bilal","given-name":"Muhammad","initials":"M.","afid": [{"@_fa": "true", "$" :"60004582"},{"@_fa": "true", "$" :"60004582"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6506611878","authid":"6506611878","authname":"Balamash A.S.","surname":"Balamash","given-name":"Abdullah Saeed","initials":"A.S.","afid": [{"@_fa": "true", "$" :"60004582"},{"@_fa": "true", "$" :"60004582"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/6603087350","authid":"6603087350","authname":"Al-Saggaf U.M.","surname":"Al-Saggaf","given-name":"Ubaid M.","initials":"U.M.","afid": [{"@_fa": "true", "$" :"60004582"},{"@_fa": "true", "$" :"60004582"}]}],"authkeywords":"crowd anomaly detection | gaussian mixture model | hypercomplex Fourier transform | visual saliency detection","source-id":"21100212114","fund-acr":"KAU","fund-no":"MDP-IRI-11-2020","fund-sponsor":"King Abdulaziz University","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85150911266"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85150911266?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85150911266&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85150911266&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85150911266","dc:identifier":"SCOPUS_ID:85150911266","eid":"2-s2.0-85150911266","dc:title":"Sedenion Fractional-Order Chebyshev-Fourier Moments for Multi-View Color Images","dc:creator":"Wang C.P.","prism:publicationName":"Jisuanji Xuebao/Chinese Journal of Computers","prism:issn":"02544164","prism:volume":"46","prism:issueIdentifier":"2","prism:pageRange":"400-421","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.11897/SP.J.1016.2023.00400","dc:description":"Image moments have strong geometric invariance and global feature description capabilities and are excellent image features. In recent years, research on image moments has achieved fruitful results. However, traditional image moments have many problems, and the radial basis functions of some image moments are numerically unstable, which seriously affects their image reconstruction performance. In addition, traditional image moments can only be used to process grayscale images, but they are powerless for color images that are widely used and disseminated today. Although grayscale and sub-channel processing of color images can allow traditional image moments to play a role in processing color images to a certain extent, they destroy the integrity of color images. The introduction of fractional-order moments and hypercomplex moments has brought the research of image moments into a new stage. Fractional-order moments constructed based on traditional integer-order moments can effectively solve the problem of numerical instability of radial basis functions in traditional image moments and improve the reconstruction ability of image moments. The introduction of hypercomplex moments makes image moments adapt to complex application scenarios. Quaternion moments can process the color image as a whole, while ternary moments and octonion moments can process grayscale stereo images and color stereo images, respectively. However, the current research on fractional-order moments is still not comprehensive enough, and there are still no research results on the fractional-order structure of some traditional image moments with good properties. The mining of hypercomplex moments is still not sufficient. The combination of higher-dimensional hypercomplex numbers and image moments can make image moments adapt to more complex application scenarios. Based on the Chebyshev-Fourier moments (CHFMs), this paper proposes the fractional-order Chebyshev-Fourier moments (FrCHFMs) and solves the numerical instability of the radial basis function of CHFMs effectively. On this basis, combined with the sedenion theory, sedenion fractional-order Chebyshev-Fourier moments (SFrCHFMs) are constructed. The application of the hypercomplex moments is extended from color images and stereo images to multi-view color images. Multi-view color images are captured by moving a single camera or arranging multiple cameras in a certain position to form a camera array according to parallax requirements. The imaginary parts of sedenion are used to encode all color components of all views of multi-view color images, thus allowing internal correlations between the components to be preserved. By comparing the radial basis function characteristics of SFrCHFMs with different fractional parameters, the numerical stability of the SFrCHFMs is analyzed. The image reconstruction experiment further verifies the influence of SFrCHFMs with different fractional parameters on the image reconstruction performance, and we obtain the fractional parameters that give SFrCHFMs the best reconstruction performance. Since SFrCHFMs extract the low-frequency features of images and have good stability, and some conventional attacks such as noise attacks and filtering attacks are attacks on image high-frequency information, SFrCHFMs have strong robustness to various conventional attacks. The nature of SFrCHFMs makes them have good geometric invariance and can effectively resist various geometric attacks. The image reconstruction experiment verifies the reconstruction performance of SFrCHFMs for multi-view color images that have undergone various attacks. Through the zero-watermarking experiment, it is concluded that the zero-watermarking scheme based on SFrCHFMs is better than the previous zero-watermarking schemes for stereo images in the face of various attacks, which further verifies the stability of SFrCHFMs. It can be concluded that SFrCHFMs have good image reconstruction ability and stability.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011592","afid":"60011592","affilname":"Qilu University of Technology","affiliation-city":"Jinan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55318994100","authid":"55318994100","authname":"Wang C.P.","surname":"Wang","given-name":"Chun Peng","initials":"C.P.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57729718600","authid":"57729718600","authname":"Zhang Q.H.","surname":"Zhang","given-name":"Qing Hua","initials":"Q.H.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57204589541","authid":"57204589541","authname":"Ma B.","surname":"Ma","given-name":"Bin","initials":"B.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57188991071","authid":"57188991071","authname":"Xia Z.Q.","surname":"Xia","given-name":"Zhi Qiu","initials":"Z.Q.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56290438800","authid":"56290438800","authname":"Li J.","surname":"Li","given-name":"Jian","initials":"J.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57204177824","authid":"57204177824","authname":"Li Q.","surname":"Li","given-name":"Qi","initials":"Q.","afid": [{"@_fa": "true", "$" :"60011592"}]}],"authkeywords":"Chebyshev-Fourier moments | fractional-order moments | image reconstruction | multi-view color images | sedenion moments","source-id":"26131","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85148861240"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85148861240?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85148861240&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85148861240&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85148861240","dc:identifier":"SCOPUS_ID:85148861240","eid":"2-s2.0-85148861240","dc:title":"An Interplay of Wigner–Ville Distribution and 2D Hyper-Complex Quadratic-Phase Fourier Transform","dc:creator":"Bhat M.Y.","prism:publicationName":"Fractal and Fractional","prism:eIssn":"25043110","prism:volume":"7","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.3390/fractalfract7020159","dc:description":"Two-dimensional hyper-complex (Quaternion) quadratic-phase Fourier transforms (Q-QPFT) have gained much popularity in recent years because of their applications in many areas, including color image and signal processing. At the same time, the applications of Wigner–Ville distribution (WVD) in signal analysis and image processing cannot be ruled out. In this paper, we study the two-dimensional hyper-complex (Quaternion) Wigner–Ville distribution associated with the quadratic-phase Fourier transform (WVD-QQPFT) by employing the advantages of quaternion quadratic-phase Fourier transforms (Q-QPFT) and Wigner–Ville distribution (WVD). First, we propose the definition of the WVD-QQPFT and its relationship with the classical Wigner–Ville distribution in the quaternion setting. Next, we investigate the general properties of the newly defined WVD-QQPFT, including complex conjugate, symmetry-conjugation, nonlinearity, boundedness, reconstruction formula, Moyal’s formula, and Plancherel formula. Finally, we propose the convolution and correlation theorems associated with WVD-QQPFT.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60115213","afid":"60115213","affilname":"Islamic University of Science and Technology","affiliation-city":"Awantipora","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60063163","afid":"60063163","affilname":"Academia Militar","affiliation-city":"Lisbon","affiliation-country":"Portugal"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021543","afid":"60021543","affilname":"King Mongkut's Institute of Technology Ladkrabang","affiliation-city":"Ladkrabang Bangkok","affiliation-country":"Thailand"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56747301000","authid":"56747301000","orcid":"0000-0002-3369-0883","authname":"Bhat M.Y.","surname":"Bhat","given-name":"Mohammad Younus","initials":"M.Y.","afid": [{"@_fa": "true", "$" :"60115213"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57221082109","authid":"57221082109","orcid":"0000-0001-5124-2761","authname":"Dar A.H.","surname":"Dar","given-name":"Aamir Hamid","initials":"A.H.","afid": [{"@_fa": "true", "$" :"60115213"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57217129250","authid":"57217129250","orcid":"0000-0002-2655-949X","authname":"Nurhidayat I.","surname":"Nurhidayat","given-name":"Irfan","initials":"I.","afid": [{"@_fa": "true", "$" :"60021543"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/14830463700","authid":"14830463700","orcid":"0000-0002-0984-0159","authname":"Pinelas S.","surname":"Pinelas","given-name":"Sandra","initials":"S.","afid": [{"@_fa": "true", "$" :"60063163"}]}],"authkeywords":"boundedness | convolution | correlation | Moyals formula | quaternion quadratic-phase Fourier transform | Winger–Ville distribution","article-number":"159","source-id":"21101020132","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85147894151"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85147894151?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85147894151&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85147894151&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85147894151","dc:identifier":"SCOPUS_ID:85147894151","eid":"2-s2.0-85147894151","dc:title":"DPO: Direct Planar Odometry with Stereo Camera","dc:creator":"Lins F.C.A.","prism:publicationName":"Sensors","prism:issn":"14248220","prism:volume":"23","prism:issueIdentifier":"3","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.3390/s23031393","dc:description":"Nowadays, state-of-the-art direct visual odometry (VO) methods essentially rely on points to estimate the pose of the camera and reconstruct the environment. Direct Sparse Odometry (DSO) became the standard technique and many approaches have been developed from it. However, only recently, two monocular plane-based DSOs have been presented. The first one uses a learning-based plane estimator to generate coarse planes as input for optimization. When these coarse estimates are too far from the minimum, the optimization may fail. Thus, the entire system result is dependent on the quality of the plane predictions and restricted to the training data domain. The second one only detects planes in vertical and horizontal orientation as being more adequate to structured environments. To the best of our knowledge, we propose the first Stereo Plane-based VO inspired by the DSO framework. Differing from the above-mentioned methods, our approach purely uses planes as features in the sliding window optimization and uses a dual quaternion as pose parameterization. The conducted experiments showed that our method presents a similar performance to Stereo DSO, a point-based approach.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023857","afid":"60023857","affilname":"Universidade Federal do Rio Grande do Norte","affiliation-city":"Natal","affiliation-country":"Brazil"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008088","afid":"60008088","affilname":"Universidade de São Paulo","affiliation-city":"Sao Paulo","affiliation-country":"Brazil"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/117190055","afid":"117190055","affilname":"Agricultural Research Company of Rio Grande do Norte","affiliation-city":"Parnamirim","affiliation-country":"Brazil"}],"pubmed-id":"36772441","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57217970697","authid":"57217970697","orcid":"0000-0001-8360-4632","authname":"Lins F.C.A.","surname":"Lins","given-name":"Filipe C.A.","initials":"F.C.A.","afid": [{"@_fa": "true", "$" :"117190055"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57194021223","authid":"57194021223","orcid":"0000-0002-3511-090X","authname":"Rosa N.S.","surname":"Rosa","given-name":"Nicolas S.","initials":"N.S.","afid": [{"@_fa": "true", "$" :"60008088"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/12795251100","authid":"12795251100","orcid":"0000-0001-6753-139X","authname":"Grassi V.","surname":"Grassi","given-name":"Valdir","initials":"V.","afid": [{"@_fa": "true", "$" :"60008088"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7005447974","authid":"7005447974","orcid":"0000-0001-8520-1888","authname":"Medeiros A.A.D.","surname":"Medeiros","given-name":"Adelardo A.D.","initials":"A.A.D.","afid": [{"@_fa": "true", "$" :"60023857"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/6603627735","authid":"6603627735","orcid":"0000-0002-2882-5237","authname":"Alsina P.J.","surname":"Alsina","given-name":"Pablo J.","initials":"P.J.","afid": [{"@_fa": "true", "$" :"60023857"}]}],"authkeywords":"direct method | planar features | second-order optimization | stereo camera | visual odometry","article-number":"1393","source-id":"130124","fund-acr":"FAPESP","fund-no":"2014/50851-0","fund-sponsor":"Fundação de Amparo à Pesquisa do Estado de São Paulo","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85147834205"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85147834205?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85147834205&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85147834205&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85147834205","dc:identifier":"SCOPUS_ID:85147834205","eid":"2-s2.0-85147834205","dc:title":"A color image contrast enhancement method based on improved PSO","dc:creator":"Zhang X.","prism:publicationName":"PLoS ONE","prism:eIssn":"19326203","prism:volume":"18","prism:issueIdentifier":"2 February","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1371/journal.pone.0274054","dc:description":"Image contrast enhancement uses the object intensity transformation function to maximize the amount of information to enhance an image. In this paper, the image enhancement problem is regarded as an optimization problem, and the particle swarm algorithm is used to obtain the optimal solution. First, an improved particle swarm optimization algorithm is proposed. In this algorithm, individual optimization, local optimization, and global optimization are used to adjust the particle’s flight direction. In local optimization, the topology is used to induce comparison and communication between particles. The sparse penalty term in speed update formula is added to adjust the sparsity of the algorithm and the size of the solution space. Second, the three channels of the color images R, G, and B are represented by a quaternion matrix, and an improved particle swarm algorithm is used to optimize the transformation parameters. Finally, contrast and brightness elements are added to the fitness function. The fitness function is used to guide the particle swarm optimization algorithm to optimize the parameters in the transformation function. This paper verifies via two experiments. First, improved particle swarm algorithm is simulated and tested. By comparing the average values of the four algorithms under the three types of 6 test functions, the average value is increased by at least 15 times in the single-peak 2 test functions: in the multi-peak and multi-peak fixed-dimension 4 test functions, this paper can always search for the global optimal solution, and the average value is either the same or at least 1.3 times higher. Second, the proposed algorithm is compared with other evolutionary algorithms to optimize contrast enhancement, select images in two different data sets, and calculate various evaluation indicators of different algorithms under different images. The optimal value is the algorithm in this paper, and the performance indicators are at least a 5% increase and a minimum 15% increase in algorithm running time. Final results show that the effects the proposed algorithm have obvious advantages in both subjective and qualitative aspects.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001305","afid":"60001305","affilname":"North University of China","affiliation-city":"Taiyuan","affiliation-country":"China"}],"pubmed-id":"36757955","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/58098829800","authid":"58098829800","authname":"Zhang X.","surname":"Zhang","given-name":"Xiaowen","initials":"X.","afid": [{"@_fa": "true", "$" :"60001305"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/23019755100","authid":"23019755100","authname":"Ren Y.","surname":"Ren","given-name":"Yongfeng","initials":"Y.","afid": [{"@_fa": "true", "$" :"60001305"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/24077884000","authid":"24077884000","authname":"Zhen G.","surname":"Zhen","given-name":"Guoyong","initials":"G.","afid": [{"@_fa": "true", "$" :"60001305"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36461802600","authid":"36461802600","authname":"Shan Y.","surname":"Shan","given-name":"Yanhu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60001305"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56176875900","authid":"56176875900","authname":"Chu C.","surname":"Chu","given-name":"Chengqun","initials":"C.","afid": [{"@_fa": "true", "$" :"60001305"}]}],"article-number":"e0274054","source-id":"10600153309","fund-acr":"NSFC","fund-no":"6177012376","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85146282782"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85146282782?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85146282782&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85146282782&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0273117722009127"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85146282782","dc:identifier":"SCOPUS_ID:85146282782","eid":"2-s2.0-85146282782","dc:title":"Autonomous navigation for lunar final approach based on gravity gradient measurements","dc:creator":"Chen P.","prism:publicationName":"Advances in Space Research","prism:issn":"02731177","prism:eIssn":"18791948","prism:volume":"71","prism:issueIdentifier":"3","prism:pageRange":"1769-1783","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"1 February 2023","prism:doi":"10.1016/j.asr.2022.09.056","pii":"S0273117722009127","dc:description":"Lunar final approach navigation is critical for pin-point lunar landing in future missions. This study investigates the use of lunar gravity gradient measurements for autonomous navigation of a lunar probe during the final approach phase. As the spacecraft approaches the Moon, the strength of gravity gradient signals improves. A spaceborne gravity gradiometer can precisely measure local gravity gradients, and the latest lunar gravity model GL1500E is used to provide reference values. The employed truncation degree and order of the gravity model are increased stepwise considering the decreasing altitude of the spacecraft in order to reach a compromise between computational costs and model accuracy. An iterative Kalman filter is developed for coupled orbit and attitude estimation using gravity gradient measurements and attitude quaternions obtained from star sensors. A simulated spacecraft with a gradiometer noise level of 0.01 E is considered. Simulation results show that the spacecraft's position converges rapidly and achieves an accuracy of less than 100 m at the last epoch.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013789","afid":"60013789","affilname":"Beihang University","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113162590","afid":"113162590","affilname":"System Engineering Institute of Sichuan Aerospace","affiliation-city":"Chengdu","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55376097200","authid":"55376097200","authname":"Chen P.","surname":"Chen","given-name":"Pei","initials":"P.","afid": [{"@_fa": "true", "$" :"60013789"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57859885600","authid":"57859885600","authname":"Mao X.","surname":"Mao","given-name":"Xuejian","initials":"X.","afid": [{"@_fa": "true", "$" :"60013789"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55774251100","authid":"55774251100","authname":"Sun X.","surname":"Sun","given-name":"Xiucong","initials":"X.","afid": [{"@_fa": "true", "$" :"60013789"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/58065358500","authid":"58065358500","authname":"Lai Y.","surname":"Lai","given-name":"Yumin","initials":"Y.","afid": [{"@_fa": "true", "$" :"113162590"}]}],"authkeywords":"Autonomous navigation | Iterative Kalman filter | Lunar final approach | Lunar gravity gradient measurements","source-id":"12375","fund-acr":"NSFC","fund-no":"11902012","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85145774706"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85145774706?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85145774706&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85145774706&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0167865522003749"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85145774706","dc:identifier":"SCOPUS_ID:85145774706","eid":"2-s2.0-85145774706","dc:title":"Dual quaternion ambisonics array for six-degree-of-freedom acoustic representation","dc:creator":"Grassucci E.","prism:publicationName":"Pattern Recognition Letters","prism:issn":"01678655","prism:volume":"166","prism:pageRange":"24-30","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.patrec.2022.12.006","pii":"S0167865522003749","dc:description":"Spatial audio methods are gaining a growing interest due to the spread of immersive audio experiences and applications, such as virtual and augmented reality. For these purposes, 3D audio signals are often acquired through arrays of Ambisonics microphones, each comprising four capsules that decompose the sound field in spherical harmonics. In this paper, we propose a dual quaternion representation of the spatial sound field acquired through an array of two First Order Ambisonics (FOA) microphones. The audio signals are encapsulated in a dual quaternion that leverages quaternion algebra properties to exploit correlations among them. This augmented representation with 6 degrees of freedom (6DOF) involves a more accurate coverage of the sound field, resulting in a more precise sound localization and a more immersive audio experience. We evaluate our approach on a sound event localization and detection (SELD) benchmark. We show that our dual quaternion SELD model with temporal convolution blocks (DualQSELD-TCN) achieves better results with respect to real and quaternion-valued baselines thanks to our augmented representation of the sound field. Full code is available at: https://github.com/ispamm/DualQSELD-TCN.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032350","afid":"60032350","affilname":"Sapienza Università di Roma","affiliation-city":"Rome","affiliation-country":"Italy"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57218250258","authid":"57218250258","orcid":"0000-0003-4626-4506","authname":"Grassucci E.","surname":"Grassucci","given-name":"Eleonora","initials":"E.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57537137800","authid":"57537137800","authname":"Mancini G.","surname":"Mancini","given-name":"Gioia","initials":"G.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57190246173","authid":"57190246173","authname":"Brignone C.","surname":"Brignone","given-name":"Christian","initials":"C.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7005621339","authid":"7005621339","authname":"Uncini A.","surname":"Uncini","given-name":"Aurelio","initials":"A.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/36444807900","authid":"36444807900","authname":"Comminiello D.","surname":"Comminiello","given-name":"Danilo","initials":"D.","afid": [{"@_fa": "true", "$" :"60032350"}]}],"authkeywords":"Dual quaternion neural networks | Dual quaternions | Quaternion ambisonics signals | Quaternion neural networks","source-id":"24825","fund-no":"RTX 8000","fund-sponsor":"Sapienza Università di Roma","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85144023257"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85144023257?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85144023257&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85144023257&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0030402622016291"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85144023257","dc:identifier":"SCOPUS_ID:85144023257","eid":"2-s2.0-85144023257","dc:title":"Cross-scale feature fusion-based JND estimation for robust image watermarking in quaternion DWT domain","dc:creator":"Wang C.","prism:publicationName":"Optik","prism:issn":"00304026","prism:volume":"272","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.ijleo.2022.170371","pii":"S0030402622016291","dc:description":"Owing to the rapid development of just-noticeable difference (JND) and the high robustness of discrete wavelet transform (DWT) based watermarking, robust watermarking methods based on JND models have been extensively adopted in the area of image copyright protection. In general, in existing JND model-based methods, transform domain-based features play an important role during the quantization strength measurement. However, most existing methods only use the subband-specific features from the final multi-scale wavelet transform domain, ignoring the feature relevance among subband-specific features with different scales among RGB channels. To address this issue, in this study, we put forward a JND estimation based on cross-scale feature fusion (CFJnd) mechanism in quaternionic DWT domain for robust image watermarking. For the proposed CFJnd, we first design different quaternionic wavelet scales for the JND modeling, which can be used to measure the minimum distortion level of the embedding-specific subband relevance. Furthermore, the cross-scale features among different subbands are adopted to jointly generate the pattern, texture and color measurement, making the final perceptual masking more representative. In addition, we further develop a CFJnd-based robust image watermarking, and the watermark is embedded by quantifying the candidate quaternionic DWT coefficients of the embedding-specific subband on a level which is adaptively defined according to the proposed CFJnd. Experimental results based on the publicly available image database show that the proposed method can produce reliable and promising results, compared to other state-of-the-art image watermarking methods.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002210","afid":"60002210","affilname":"Shandong Normal University","affiliation-city":"Jinan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/14523808500","authid":"14523808500","authname":"Wang C.","surname":"Wang","given-name":"Chunxing","initials":"C.","afid": [{"@_fa": "true", "$" :"60002210"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58017208600","authid":"58017208600","authname":"Li S.","surname":"Li","given-name":"Shang","initials":"S.","afid": [{"@_fa": "true", "$" :"60002210"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57192566251","authid":"57192566251","authname":"Liu Y.","surname":"Liu","given-name":"Yan","initials":"Y.","afid": [{"@_fa": "true", "$" :"60002210"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55991979300","authid":"55991979300","authname":"Meng L.","surname":"Meng","given-name":"Lili","initials":"L.","afid": [{"@_fa": "true", "$" :"60002210"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56451954400","authid":"56451954400","authname":"Zhang K.","surname":"Zhang","given-name":"Kai","initials":"K.","afid": [{"@_fa": "true", "$" :"60002210"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/35328241700","authid":"35328241700","orcid":"0000-0003-1447-0524","authname":"Wan W.","surname":"Wan","given-name":"Wenbo","initials":"W.","afid": [{"@_fa": "true", "$" :"60002210"}]}],"authkeywords":"DWT | Feature fusion | Image watermarking | Quaternion domain | Robustness","article-number":"170371","source-id":"110152","fund-acr":"NSFC","fund-no":"61601268","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85142901152"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85142901152?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85142901152&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85142901152&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0030402622014711"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85142901152","dc:identifier":"SCOPUS_ID:85142901152","eid":"2-s2.0-85142901152","dc:title":"Wigner distribution and associated uncertainty principles in the framework of octonion linear canonical transform","dc:creator":"Dar A.H.","prism:publicationName":"Optik","prism:issn":"00304026","prism:volume":"272","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.ijleo.2022.170213","pii":"S0030402622014711","dc:description":"The most recent generalization of octonion Fourier transform (OFT) is the octonion linear canonical transform (OLCT) that has become popular in present era due to its applications in color image and signal processing. On the other hand the applications of Wigner distribution (WD) in signal and image analysis cannot be excluded. In this paper, we introduce novel integral transform coined as the Wigner distribution in the octonion linear canonical transform domain (WDOL). We first propose the definition of the one dimensional WDOL (1D-WDOL), we extend its relationship with 1D-OLCT and 1D-OFT. Then explore several important properties of 1D-WDOL, such as reconstruction formula, Rayleigh's theorem. Second, we introduce the definition of three dimensional WDOL (3D-WDOL) and establish its relationships with the WD associated with quaternion LCT (WD-QLCT) and 3D-WD in LCT domain (3D-WDLCT). Then we study properties like reconstruction formula, Rayleigh's theorem and Riemann–Lebesgue Lemma associated with 3D-WDOL. The crux of this paper lies in developing well known uncertainty principles (UPs) including Heisenberg's UP, Logarithmic UP and Hausdorff–Young inequality associated with WDOL.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60115213","afid":"60115213","affilname":"Islamic University of Science and Technology","affiliation-city":"Awantipora","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57221082109","authid":"57221082109","orcid":"0000-0001-5124-2761","authname":"Dar A.H.","surname":"Dar","given-name":"Aamir H.","initials":"A.H.","afid": [{"@_fa": "true", "$" :"60115213"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56747301000","authid":"56747301000","orcid":"0000-0002-3369-0883","authname":"Bhat M.Y.","surname":"Bhat","given-name":"M. Younus","initials":"M.Y.","afid": [{"@_fa": "true", "$" :"60115213"}]}],"authkeywords":"Octonion linear canonical transform(OLCT) | Rayleigh's theorem | Riemann–Lebesgue Lemma | Uncertainty principle (UP) | Wigner distribution (WD)","article-number":"170213","source-id":"110152","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85142759216"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85142759216?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85142759216&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85142759216&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0030402622014784"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85142759216","dc:identifier":"SCOPUS_ID:85142759216","eid":"2-s2.0-85142759216","dc:title":"Uncertainty principles and applications of quaternion windowed linear canonical transform","dc:creator":"Prasad A.","prism:publicationName":"Optik","prism:issn":"00304026","prism:volume":"272","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.ijleo.2022.170220","pii":"S0030402622014784","dc:description":"Quaternion signal processing is frequently used in color image processing. The quaternion windowed linear canonical transform (QWLCT), a generalization of the windowed linear canonical transform (WLCT), has a wide range of application domains, including signal processing and optics. In this paper, we study QWLCT-based characterization range, reproducing kernel, one-one map, Donoho-Stark inequality and Pitt's inequality. Some useful uncertainty principles (UP) like Heisenberg UP, Lieb UP, and local UP are discussed. Moreover, some applications associated with QWLCT in linear time-varying (TV) systems are explained in detail.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60118182","afid":"60118182","affilname":"SRM University-AP","affiliation-city":"Mangalagiri","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008898","afid":"60008898","affilname":"Indian Institute of Technology (Indian School of Mines), Dhanbad","affiliation-city":"Dhanbad","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7401882139","authid":"7401882139","authname":"Prasad A.","surname":"Prasad","given-name":"Akhilesh","initials":"A.","afid": [{"@_fa": "true", "$" :"60008898"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57221264907","authid":"57221264907","orcid":"0000-0002-5467-724X","authname":"Kundu M.","surname":"Kundu","given-name":"Manab","initials":"M.","afid": [{"@_fa": "true", "$" :"60118182"}]}],"authkeywords":"Quaternion linear canonical transform | Quaternion windowed linear canonical transform | Uncertainty principle | Windowed linear canonical transform","article-number":"170220","source-id":"110152","fund-acr":"SERB","fund-no":"MTR/2021/000193","fund-sponsor":"Science and Engineering Research Board","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140411214"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140411214?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140411214&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140411214&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165168422003541"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140411214","dc:identifier":"SCOPUS_ID:85140411214","eid":"2-s2.0-85140411214","dc:title":"Widely nonlinear quaternion-valued second-order Volterra recursive least squares filter","dc:creator":"Zhang Z.","prism:publicationName":"Signal Processing","prism:issn":"01651684","prism:volume":"203","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.sigpro.2022.108815","pii":"S0165168422003541","dc:description":"Recently, a family of the quaternion-valued second-order Volterra LMS (QSOV-LMS) algorithms were proposed to deal with 3d and 4d signals. However, it should be noted that the QSOV-LMS algorithms suffer from low convergence speed and high steady-state properties. To this end, a widely nonlinear quaternion recursive least square algorithm is proposed to train the second-order Volterra filter (WNL-QSOVRLS) for enhancing the performance of QSOV-LMS algorithms. Furthermore, to avoid the immense computation complexity, we also present a novel widely nonlinear quaternion Volterra recursive least square dichotomous coordinate descent filtering model (WNL-QSOVRLS-DCD) which introduce the quaternion dichotomous coordinate descent (QDCD) algorithm for the first time. Moreover, based on the augmented model of quaternion second-order Volterra filter, the two proposed algorithms can process quaternion-valued circular and non-circular signals well. Finally, experiments verify the performance of the proposed algorithms.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010421","afid":"60010421","affilname":"Southwest Jiaotong University","affiliation-city":"Chengdu","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57214826392","authid":"57214826392","authname":"Zhang Z.","surname":"Zhang","given-name":"Zhao","initials":"Z.","afid": [{"@_fa": "true", "$" :"60010421"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8942252100","authid":"8942252100","authname":"Zhang J.","surname":"Zhang","given-name":"Jiashu","initials":"J.","afid": [{"@_fa": "true", "$" :"60010421"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55488840900","authid":"55488840900","authname":"Li D.","surname":"Li","given-name":"Defang","initials":"D.","afid": [{"@_fa": "true", "$" :"60010421"}]}],"authkeywords":"QDCD | quaternion recursive least square | quaternion Volterra adaptive filter | Widely nonlinear","article-number":"108815","source-id":"25548","fund-acr":"NSFC","fund-no":"62071396","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140342063"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85140342063?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85140342063&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85140342063&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165168422003486"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85140342063","dc:identifier":"SCOPUS_ID:85140342063","eid":"2-s2.0-85140342063","dc:title":"Hypercomplex Low Rank Reconstruction for NMR Spectroscopy","dc:creator":"Guo Y.","prism:publicationName":"Signal Processing","prism:issn":"01651684","prism:volume":"203","prism:pageRange":null,"prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.sigpro.2022.108809","pii":"S0165168422003486","dc:description":"Nuclear magnetic resonance (NMR) spectroscopy serves as an important tool to analyze chemicals and proteins in bioengineering. Multi-dimensional NMR offers a major improvement in resolution with multi-dimensional spectrum, but significantly increases data acquisition time and produces hypercomplex data that is difficult to be handled. To reduce this time, non-uniformly sampling can be applied to obtain undersampled data and using a reconstruction approach, such as the state-of-the-art low rank method, to remove the spectral artifacts introduced by undersampling. However, only complex format of signal, including the real and imaginary parts, is considered in previous low rank approach, which is less efficient when dealing with hypercomplex data that has multiple components. To solve this problem, a hypercomplex low rank model is proposed by introducing an adjoint matrix operation and then solved with a fast matrix factorization algorithm. This method explores redundant information among all the components of hypercomplex signal. Using simulated data and real protein data, we demonstrate that the proposed method provides a fast and high-fidelity reconstruction of hypercomplex spectroscopy in fast NMR.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60092863","afid":"60092863","affilname":"Xiamen University of Technology","affiliation-city":"Xiamen","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019764","afid":"60019764","affilname":"China Mobile Communications","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018205","afid":"60018205","affilname":"Xiamen University","affiliation-city":"Xiamen","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016437","afid":"60016437","affilname":"Göteborgs Universitet","affiliation-city":"Gothenburg","affiliation-country":"Sweden"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "10", "$" :"10"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57222719236","authid":"57222719236","authname":"Guo Y.","surname":"Guo","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60092863"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57217286329","authid":"57217286329","authname":"Zhan J.","surname":"Zhan","given-name":"Jiaying","initials":"J.","afid": [{"@_fa": "true", "$" :"60092863"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57205546570","authid":"57205546570","authname":"Tu Z.","surname":"Tu","given-name":"Zhangren","initials":"Z.","afid": [{"@_fa": "true", "$" :"60018205"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57222585587","authid":"57222585587","authname":"Zhou Y.","surname":"Zhou","given-name":"Yirong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60018205"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57579196700","authid":"57579196700","authname":"Wu J.","surname":"Wu","given-name":"Jianfan","initials":"J.","afid": [{"@_fa": "true", "$" :"60092863"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57580227100","authid":"57580227100","authname":"Hong Q.","surname":"Hong","given-name":"Qing","initials":"Q.","afid": [{"@_fa": "true", "$" :"60019764"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/35490610500","authid":"35490610500","authname":"Huang Y.","surname":"Huang","given-name":"Yuqing","initials":"Y.","afid": [{"@_fa": "true", "$" :"60018205"}]},{"@_fa": "true", "@seq": "8", "author-url":"https://api.elsevier.com/content/author/author_id/7004326268","authid":"7004326268","orcid":"0000-0002-7892-6896","authname":"Orekhov V.","surname":"Orekhov","given-name":"Vladislav","initials":"V.","afid": [{"@_fa": "true", "$" :"60016437"}]},{"@_fa": "true", "@seq": "9", "author-url":"https://api.elsevier.com/content/author/author_id/22958150800","authid":"22958150800","authname":"Qu X.","surname":"Qu","given-name":"Xiaobo","initials":"X.","afid": [{"@_fa": "true", "$" :"60018205"}]},{"@_fa": "true", "@seq": "10", "author-url":"https://api.elsevier.com/content/author/author_id/26636947000","authid":"26636947000","orcid":"0000-0002-9910-5720","authname":"Guo D.","surname":"Guo","given-name":"Di","initials":"D.","afid": [{"@_fa": "true", "$" :"60092863"}]}],"authkeywords":"Hypercomplex | Low rank | NMR spectroscopy | Reconstruction","article-number":"108809","source-id":"25548","fund-acr":"STINT","fund-no":"2019-WJ-31","fund-sponsor":"Swedish Foundation for International Cooperation in Research and Higher Education","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139871182"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139871182?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139871182&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85139871182&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85139871182","dc:identifier":"SCOPUS_ID:85139871182","eid":"2-s2.0-85139871182","dc:title":"Generalization to unseen viewpoint images of objects via alleviated pose attentive capsule agreement","dc:creator":"Özcan B.","prism:publicationName":"Neural Computing and Applications","prism:issn":"09410643","prism:eIssn":"14333058","prism:volume":"35","prism:issueIdentifier":"4","prism:pageRange":"3521-3536","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1007/s00521-022-07900-3","dc:description":"Despite their achievements in object recognition, Convolutional Neural Networks (CNNs) particularly fail to generalize to unseen viewpoints of a learned object even with substantial samples. On the other hand, recently emerged capsule networks outperform CNNs in novel viewpoint generalization tasks even with significantly fewer parameters. Capsule networks group the neuron activations for representing higher level attributes and their interactions for achieving equivariance to visual transformations. However, capsule networks have a high computational cost for learning the interactions of capsules in consecutive layers via the, so called, routing algorithm. To address these issues, we propose a novel routing algorithm, Alleviated Pose Attentive Capsule Agreement (ALPACA) which is tailored for capsules that contain pose, feature and existence probability information together to enhance novel viewpoint generalization of capsules on 2D images. For this purpose, we have created a Novel ViewPoint Dataset (NVPD) a viewpoint-controlled texture-free dataset that has 8 different setups where training and test samples are formed by different viewpoints. In addition to NVPD, we have conducted experiments on iLab2M dataset where the dataset is split in terms of the object instances. Experimental results show that ALPACA outperforms its capsule network counterparts and state-of-the-art CNNs on iLab2M and NVPD datasets. Moreover, ALPACA is 10 times faster when compared to routing-based capsule networks. It also outperforms attention-based routing algorithms of the domain while keeping the inference and training times comparable. Lastly, our code, the NVPD dataset, test setups, and implemented models are freely available at https://github.com/Boazrciasn/ALPACA.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60086558","afid":"60086558","affilname":"Ozyegin University","affiliation-city":"Istanbul","affiliation-country":"Turkey"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190745168","authid":"57190745168","orcid":"0000-0001-8598-1239","authname":"Özcan B.","surname":"Özcan","given-name":"Barış","initials":"B.","afid": [{"@_fa": "true", "$" :"60086558"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57215970264","authid":"57215970264","authname":"Kınlı F.","surname":"Kınlı","given-name":"Furkan","initials":"F.","afid": [{"@_fa": "true", "$" :"60086558"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/15835061300","authid":"15835061300","authname":"Kıraç F.","surname":"Kıraç","given-name":"Furkan","initials":"F.","afid": [{"@_fa": "true", "$" :"60086558"}]}],"authkeywords":"Capsule networks | Neural networks | Novel viewpoint generalization | Quaternion neural networks","source-id":"24800","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139357163"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85139357163?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85139357163&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85139357163&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S156625352200149X"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85139357163","dc:identifier":"SCOPUS_ID:85139357163","eid":"2-s2.0-85139357163","dc:title":"A sensor fusion approach to MARG module orientation estimation for a real-time hand tracking application","dc:creator":"Ratchatanantakit N.","prism:publicationName":"Information Fusion","prism:issn":"15662535","prism:volume":"90","prism:pageRange":"298-315","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1016/j.inffus.2022.09.017","pii":"S156625352200149X","dc:description":"This paper introduces a new algorithm (Gravity & Magnetic North Vector correction — Double SLERP, or “GMV-D”) to estimate the orientation of a MEMS Magnetic/Angular-Rate/Gravity (MARG) sensor module using sensor fusion in the context of a real-time hand tracking application, for human–computer interaction purposes. Integrated MEMS MARG modules are affordable, small, light and consume minimal power. As such, there is interest in using them for monitoring the orientation of various body segments, to which they can be attached (e.g., the finger segments of a gloved hand). However, each of the 3 types of signals they provide has proven insufficient to yield robust orientation estimates, particularly in regions of space where the geomagnetic field is distorted. The significance (main contribution) of the approach we present is the computation of a final orientation estimate that uses all the signals generated by inexpensive (e.g., less than 20 USD, in large quantities) integrated MEMS MARG modules but weighs their contributions with simple, real-time-updatable parameters that prevent erroneous corrections when the pre-conditions for their valid use are not met. This will enable the use of inexpensive integrated MEMS MARG modules for hand tracking applications in human–computer interaction and other areas of work where tracking the orientation of body segments in real-time is important. In each iteration, GMV-D defines an initial orientation estimate from integration of gyroscopic signals (“dead reckoning”), and also calculates accelerometer-based and magnetometer-based corrections. These corrections are defined on the assumptions that the module is near static and affected by an undistorted geomagnetic field. Because these assumptions are seldom fully met simultaneously, the information fusion challenge is to apply each correction only to the extent that its corresponding pre-conditions are met, as inappropriate corrections will introduce significant error in the future orientation estimates. To achieve this, GMV-D develops an accelerometer correction trustworthiness parameter, 0 ≤α≤ 1, and a magnetometer correction trustworthiness parameter, 0 ≤μ≤ 1, both of which are updated on a sample-by-sample basis and are available at each iteration of the algorithm. The information fusion phase of the algorithm implements the corrections in a two-tiered application of Spherical Linear Interpolation (SLERP) of the quaternions representing the initial dead reckoning estimate and the available corrections, scaled according to their corresponding levels of trustworthiness. GMV-D was evaluated in comparison to 2 other orientation correction approaches (Kalman Filtering and GMV-S) and contrasted with 2 contemporary complementary filter approaches (Madgwick, Mahony). The results confirm that GMV-D displayed better orientation estimation performance when the algorithms operated in an area with known distortion of the geomagnetic field.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015206","afid":"60015206","affilname":"Florida International University","affiliation-city":"Miami","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57203136289","authid":"57203136289","orcid":"0000-0003-1891-2115","authname":"Ratchatanantakit N.","surname":"Ratchatanantakit","given-name":"Neeranut","initials":"N.","afid": [{"@_fa": "true", "$" :"60015206"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56902559100","authid":"56902559100","authname":"O-larnnithipong N.","surname":"O-larnnithipong","given-name":"Nonnarit","initials":"N.","afid": [{"@_fa": "true", "$" :"60015206"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56308078000","authid":"56308078000","authname":"Sonchan P.","surname":"Sonchan","given-name":"Pontakorn","initials":"P.","afid": [{"@_fa": "true", "$" :"60015206"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7004124475","authid":"7004124475","authname":"Adjouadi M.","surname":"Adjouadi","given-name":"Malek","initials":"M.","afid": [{"@_fa": "true", "$" :"60015206"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7007109179","authid":"7007109179","authname":"Barreto A.","surname":"Barreto","given-name":"Armando","initials":"A.","afid": [{"@_fa": "true", "$" :"60015206"}]}],"authkeywords":"Dead reckoning | Drift correction algorithm | Gyroscope drift | Hand motion tracking | Inertial measurement unit | Magnetic distortion | MARG | Quaternion correction","source-id":"26099","fund-no":"undefined","fund-sponsor":"Graduate School, Duke University","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137603489"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85137603489?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85137603489&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85137603489&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85137603489","dc:identifier":"SCOPUS_ID:85137603489","eid":"2-s2.0-85137603489","dc:title":"Dynam-SLAM: An Accurate, Robust Stereo Visual-Inertial SLAM Method in Dynamic Environments","dc:creator":"Yin H.","prism:publicationName":"IEEE Transactions on Robotics","prism:issn":"15523098","prism:eIssn":"19410468","prism:volume":"39","prism:issueIdentifier":"1","prism:pageRange":"289-308","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"1 February 2023","prism:doi":"10.1109/TRO.2022.3199087","dc:description":"Most existing vision-based simultaneous localization and mapping (SLAM) systems and their variants still assume that the observation is absolutely static and cannot work well in dynamic environments. Here, we present the Dynam-SLAM (Dynam), a stereo visual-inertial SLAM system capable of robust, accurate, and continuous work in high dynamic environments. Our approach is devoted to loosely coupling the stereo scene flow with an inertial measurement unit (IMU) for dynamic feature detection and tightly coupling the dynamic and static features with the IMU measurements for nonlinear optimization. First, the scene flow uncertainty caused by measurement noise is modeled to derive the accurate motion likelihood of landmarks. Meanwhile, to cope with highly dynamic environments, we additionally construct the virtual landmarks based on the detected dynamic features. Then, we build a tightly coupled, nonlinear optimization-based SLAM system to estimate the camera state by fusing IMU measurements and feature observations. Finally, we evaluate the proposed dynamic feature detection module (DFM) and the overall SLAM system in various benchmark datasets. Experimental results show that the Dynam is almost unaffected by DFM and performs well in static EuRoC datasets. Dynam outperforms the current state-of-the-art visual and visual-inertial SLAM implementations in terms of accuracy and robustness in self-collected dynamic datasets. The average absolute trajectory error of Dynam in the dynamic benchmark datasets is ∼90% lower than that of VINS-Fusion, ∼84% lower than that of ORB-SLAM3, and ∼88% lower than that of Kimera.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019616","afid":"60019616","affilname":"Harbin Institute of Technology","affiliation-city":"Harbin","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57211273398","authid":"57211273398","orcid":"0000-0003-3403-6231","authname":"Yin H.","surname":"Yin","given-name":"Hesheng","initials":"H.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57211274697","authid":"57211274697","orcid":"0000-0002-3236-658X","authname":"Li S.","surname":"Li","given-name":"Shaomiao","initials":"S.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57880673500","authid":"57880673500","orcid":"0000-0002-1466-476X","authname":"Tao Y.","surname":"Tao","given-name":"Yu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/42461450300","authid":"42461450300","orcid":"0000-0001-8846-5838","authname":"Guo J.","surname":"Guo","given-name":"Junlong","initials":"J.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57056793200","authid":"57056793200","orcid":"0000-0002-3025-0532","authname":"Huang B.","surname":"Huang","given-name":"Bo","initials":"B.","afid": [{"@_fa": "true", "$" :"60019616"}]}],"authkeywords":"Dynamic feature detection | simultaneous localization and mapping (SLAM) | state estimation | visual-inertial system","source-id":"95101","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85117080211"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85117080211?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85117080211&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85117080211&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85117080211","dc:identifier":"SCOPUS_ID:85117080211","eid":"2-s2.0-85117080211","dc:title":"Tool wear prediction based on multidomain feature fusion by attention-based depth-wise separable convolutional neural network in manufacturing","dc:creator":"Li G.","prism:publicationName":"International Journal of Advanced Manufacturing Technology","prism:issn":"02683768","prism:eIssn":"14333015","prism:volume":"124","prism:issueIdentifier":"11-12","prism:pageRange":"3857-3874","prism:coverDate":"2023-02-01","prism:coverDisplayDate":"February 2023","prism:doi":"10.1007/s00170-021-08119-7","dc:description":"Computer numerical control (CNC) machine tool is the foundation of the equipment manufacturing industry, and its technical level is an important indicator to measure the development level of a country’s equipment manufacturing industry. Tool wear during machining has a great impact on the important performance indicators of CNC machine tools, such as machining accuracy, machining efficiency and reliability. Tool wear monitoring is of great significance to improve the machining efficiency, machining accuracy and reliability of CNC machine tools. Multidomain features (time domain, frequency domain and time–frequency domain) can accurately characterise the degree of tool wear. However, manual feature fusion is time consuming and prevents the improvement of monitoring accuracy. A new tool wear prediction method based on multidomain feature fusion by attention-based depth-wise separable convolutional neural network is proposed to solve these problems. In this method, multidomain features of cutting force and vibration signals are extracted and recombined into feature tensors. The proposed hypercomplex position encoding and high-dimensional self-attention mechanism are used to calculate the new representation of input feature tensor, which emphasizes the tool wear sensitive information and suppresses large area background noise. The designed depth-wise separable convolutional neural network is used to adaptively extract high-level features that can characterise tool wear from the new representation, and the tool wear is predicted automatically. The proposed method is verified on three sets of tool run-to-failure data sets of three-flute ball nose cemented carbide tool in machining centre. Experimental results show that the prediction accuracy of the proposed method is remarkably higher than other state-of-art methods. Therefore, the proposed tool wear prediction method is beneficial to improve the prediction accuracy and provide effective guidance for decision making in processing.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007711","afid":"60007711","affilname":"Jilin University","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57198456846","authid":"57198456846","authname":"Li G.","surname":"Li","given-name":"Guofa","initials":"G.","afid": [{"@_fa": "true", "$" :"60007711"},{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57216566483","authid":"57216566483","authname":"Wang Y.","surname":"Wang","given-name":"Yanbo","initials":"Y.","afid": [{"@_fa": "true", "$" :"60007711"},{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/54586192800","authid":"54586192800","authname":"Wang J.","surname":"Wang","given-name":"Jili","initials":"J.","afid": [{"@_fa": "true", "$" :"60007711"},{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57214005012","authid":"57214005012","authname":"He J.","surname":"He","given-name":"Jialong","initials":"J.","afid": [{"@_fa": "true", "$" :"60007711"},{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57196374693","authid":"57196374693","authname":"Huo Y.","surname":"Huo","given-name":"Yongchao","initials":"Y.","afid": [{"@_fa": "true", "$" :"60007711"},{"@_fa": "true", "$" :"60007711"}]}],"authkeywords":"CNC machine tool | Depth-wise separable convolutional neural network | Feature fusion | Position encoding | Self-attention mechanism | Tool wear prediction","source-id":"20428","fund-acr":"NSFC","fund-no":"2020122332JC","fund-sponsor":"Natural Science Foundation of Jilin Province","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136640563"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85136640563?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85136640563&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85136640563&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85136640563","dc:identifier":"SCOPUS_ID:85136640563","eid":"2-s2.0-85136640563","dc:title":"The uncertainty principle for the octonion Fourier transform","dc:creator":"Zayed M.","prism:publicationName":"Mathematical Methods in the Applied Sciences","prism:issn":"01704214","prism:eIssn":"10991476","prism:volume":"46","prism:issueIdentifier":"2","prism:pageRange":"2651-2666","prism:coverDate":"2023-01-30","prism:coverDisplayDate":"30 January 2023","prism:doi":"10.1002/mma.8667","dc:description":"The octonion Fourier transform (OFT) is a hypercomplex Fourier transform that generalizes the quaternion Fourier transform. However, in octonion algebra, there are two major obstacles that are presented in the loss of associativity and commutativity. Researchers have been trying to extend the results of the Euclidean Fourier transform to quaternion-valued signals using special techniques to overcome these two problems. In this context, we intend to generalize the Heisenberg uncertainty principles associated with covariance and Hardy's uncertainty principle for octonion multivector valued signals over (Formula presented.) using the polar form of an octonion, the quaternion decomposition, and the relationship between the OFT and the three-dimensional (3D)-Clifford-Fourier transform.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027741","afid":"60027741","affilname":"King Khalid University","affiliation-city":"Abha","affiliation-country":"Saudi Arabia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015943","afid":"60015943","affilname":"Université Moulay Ismail","affiliation-city":"Meknes","affiliation-country":"Morocco"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/37089993400","authid":"37089993400","orcid":"0000-0002-3305-7340","authname":"Zayed M.","surname":"Zayed","given-name":"Mohra","initials":"M.","afid": [{"@_fa": "true", "$" :"60027741"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57196079800","authid":"57196079800","orcid":"0000-0002-0993-7217","authname":"El Haoui Y.","surname":"El Haoui","given-name":"Youssef","initials":"Y.","afid": [{"@_fa": "true", "$" :"60015943"}]}],"authkeywords":"clifford algebra | fourier transform | octonion algebra | uncertainty principle","source-id":"24594","fund-acr":"DSR, KFU","fund-no":"undefined","fund-sponsor":"Deanship of Scientific Research, King Faisal University","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85149153494"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85149153494?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85149153494&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85149153494&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85149153494","dc:identifier":"SCOPUS_ID:85149153494","eid":"2-s2.0-85149153494","dc:title":"Application of extended reality technology for real-time navigation in clinical operation","dc:creator":"Li R.","prism:publicationName":"Nan fang yi ke da xue xue bao = Journal of Southern Medical University","prism:issn":"16734254","prism:volume":"43","prism:issueIdentifier":"1","prism:pageRange":"128-132","prism:coverDate":"2023-01-20","prism:coverDisplayDate":"20 January 2023","prism:doi":"10.12122/j.issn.1673-4254.2023.01.18","dc:description":"OBJECTIVE: To explore the application of extended reality (XR) technology in clinical surgeries for improving the success rate of surgeries. METHODS: To assist the surgeons to better understand the location, size and geometric shape of the lesions and reduce potential radiation exposure in minimally invasive surgical navigation based on two-dimensional images, we constructed three-dimensional models based on CT data and used XR technology to achieve intraoperative navigation. An improved quaternion method was used to improve the accuracy of electromagnetic positioning, with which the system error of positioning accuracy was reduced to below 2 mm. A 5G network was used to optimize the server GPU programming algorithm, and real-time video stream coding strategy and network design were adopted to reduce data transmission jam and delay in the remote surgery network, which achieved an average delay of less than 60 ms. A Gaussian distribution deformation model was used to simulate collision detection and stress deformation of the tissues to achieve a tactile perception effect. RESULTS AND CONCLUSION: The intraoperative navigation system based on XR technology allowed more accurate determination of the location of the lesions, effectively reduced the surgical risk, and avoided the risk of intraoperative radiation exposure. The low latency and high fidelity of 5G network achieved real-time interaction during the surgery to provide a technical basis for multi-terminal remote cooperative surgery. The combination of force feedback technology and XR technology enables the surgeons to conduct deep immersion preoperative planning and virtual surgery to improve the success rate of surgery and shorten the learning curve.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60092443","afid":"60092443","affilname":"Dalian Ocean University","affiliation-city":"Dalian","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018702","afid":"60018702","affilname":"Luzhou Medical College","affiliation-city":"Luzhou","affiliation-country":"China"}],"pubmed-id":"36856221","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57198938331","authid":"57198938331","authname":"Li R.","surname":"Li","given-name":"R.","initials":"R.","afid": [{"@_fa": "true", "$" :"60092443"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58122784500","authid":"58122784500","authname":"Lou Y.","surname":"Lou","given-name":"Y.","initials":"Y.","afid": [{"@_fa": "true", "$" :"60018702"}]}],"authkeywords":"5G | clinical operation | extended reality technology | intraoperative navigation | tactile perception","source-id":"10600153369","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85146149874"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85146149874?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85146149874&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85146149874&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85146149874","dc:identifier":"SCOPUS_ID:85146149874","eid":"2-s2.0-85146149874","dc:title":"Neural Networks at a Fraction with Pruned Quaternions","dc:creator":"Iqbal S.M.","prism:publicationName":"ACM International Conference Proceeding Series","prism:isbn": [{"@_fa": "true", "$" :"9781450397988"}],"prism:pageRange":"19-27","prism:coverDate":"2023-01-04","prism:coverDisplayDate":"4 January 2023","prism:doi":"10.1145/3570991.3570997","dc:description":"Contemporary state-of-the-art neural networks have increasingly large numbers of parameters, which prevents their deployment on devices with limited computational power. Pruning is one technique to remove unnecessary weights and reduce resource requirements for training and inference. In addition, for ML tasks where the input data is multi-dimensional, using higher-dimensional data embeddings such as complex numbers or quaternions has been shown to reduce the parameter count while maintaining accuracy. In this work, we conduct pruning on real and quaternion-valued implementations of different architectures on classification tasks. We find that for some architectures, at very high sparsity levels, quaternion models provide higher accuracies than their real counterparts. For example, at the task of image classification on CIFAR-10 using Conv-4, at of the number of parameters as the original model, the pruned quaternion version outperforms the pruned real by more than . Experiments on various network architectures and datasets show that for deployment in extremely resource-constrained environments, a sparse quaternion network might be a better candidate than a real sparse model of similar architecture.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105512","afid":"60105512","affilname":"National Institute of Science Education and Research","affiliation-city":"Bhubaneswar","affiliation-country":"India"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/58061760800","authid":"58061760800","orcid":"0000-0001-5464-3632","authname":"Iqbal S.M.","surname":"Iqbal","given-name":"Sahel Mohammad","initials":"S.M.","afid": [{"@_fa": "true", "$" :"60105512"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56289643200","authid":"56289643200","orcid":"0000-0002-9910-7291","authname":"Mishra S.","surname":"Mishra","given-name":"Subhankar","initials":"S.","afid": [{"@_fa": "true", "$" :"60105512"}]}],"authkeywords":"network pruning | quaternion neural networks","source-id":"11600154611","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85169146658"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85169146658?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85169146658&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85169146658&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85169146658","dc:identifier":"SCOPUS_ID:85169146658","eid":"2-s2.0-85169146658","dc:title":"Quaternion Fourier Transform","dc:creator":"Hitzer E.","prism:publicationName":"Trends in Mathematics","prism:issn":"22970215","prism:eIssn":"2297024X","prism:volume":"Part F1249","prism:pageRange":"1-58","prism:coverDate":"2023-01-01","prism:coverDisplayDate":"2023","prism:doi":"10.1007/978-3-031-28375-8_1","dc:description":"This chapter first focusses on the theoretical foundations of quaternion Fourier transforms. Basically, in the complex Fourier transform the imaginary complex unit i is replaced by any constant unit pure quaternion squaring to −1. Since quaternion multiplication is generically non-commutative, a kernel factor can either be placed to the right or the left of the signal to be transformed, the signal itself may be scalar or quaternion valued as well. Furthermore, two kernel factors can be used, one on the left and one on the right, yielding a two-sided QFT. Due to quaternion non-commutativity it is not trivial to derive the properties of QFTs. A recent comprehensive treatment is given in E. Hitzer, Quaternion and Clifford Fourier Transforms, Chapman and Hall/CRC, London, 1st edition (September 22, 2021). The one-sided QFT had been implemented for quite a while in the Quaternion Toolbox for Matlab (QTFM) by S. Sangwine, and most recently he has expanded this in version 3.4 to include the two-sided QFT as well (https://sourceforge.net/projects/qtfm/ ).","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016348","afid":"60016348","affilname":"International Christian University","affiliation-city":"Mitaka","affiliation-country":"Japan"}],"prism:aggregationType":"Book Series","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8898269700","authid":"8898269700","authname":"Hitzer E.","surname":"Hitzer","given-name":"Eckhard","initials":"E.","afid": [{"@_fa": "true", "$" :"60016348"}]}],"source-id":"21100447813","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85169140252"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85169140252?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85169140252&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85169140252&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85169140252","dc:identifier":"SCOPUS_ID:85169140252","eid":"2-s2.0-85169140252","dc:title":"Quaternionic Moments","dc:creator":"Hitzer E.","prism:publicationName":"Trends in Mathematics","prism:issn":"22970215","prism:eIssn":"2297024X","prism:volume":"Part F1249","prism:pageRange":"151-167","prism:coverDate":"2023-01-01","prism:coverDisplayDate":"2023","prism:doi":"10.1007/978-3-031-28375-8_4","dc:description":"This short chapter surveys five papers containing a variety of quaternionic moment applications in fields like color image watermarking, image representation and recognition, bio-signal watermarking, and quaternionic fractional-order pseudo-Jacobi Fourier moments.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016348","afid":"60016348","affilname":"International Christian University","affiliation-city":"Mitaka","affiliation-country":"Japan"}],"prism:aggregationType":"Book Series","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8898269700","authid":"8898269700","authname":"Hitzer E.","surname":"Hitzer","given-name":"Eckhard","initials":"E.","afid": [{"@_fa": "true", "$" :"60016348"}]}],"source-id":"21100447813","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}