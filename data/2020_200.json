{"search-results":{"opensearch:totalResults":"235","opensearch:startIndex":"200","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "200"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=200&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=175&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=225&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=210&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85089354539"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85089354539?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85089354539&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85089354539&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85089354539","dc:identifier":"SCOPUS_ID:85089354539","eid":"2-s2.0-85089354539","dc:title":"RFID aided SINS integrated navigation system for lane applications","dc:creator":"Wang Q.","prism:publicationName":"International Journal of Embedded Systems","prism:issn":"17411068","prism:eIssn":"17411076","prism:volume":"13","prism:issueIdentifier":"1","prism:pageRange":"113-120","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1504/IJES.2020.108328","dc:description":"To improve the lane vehicle position accuracy, RFID technology is applied to correct the position of the SINS irregularly with label positioning. The acceleration data of the vehicle in three directions is measured by the accelerometers of the inertial measurement unit; the attitude matrix is updated in real time using the angular velocity of the gyroscope output space, and the acceleration component is transformed into the geographic coordinate system, and the acceleration of the inertial measurement unit. The data is subjected to an integral operation process to obtain a spatial displacement value of the vehicle. The real-time updating algorithm of the attitude matrix and the processing of the inertial measurement unit signal are presented. The quaternion-based algorithm is used to solve the attitude matrix as well as updating the coordinate system of the inertial navigation attitude matrix in real time. The Hilbert-Huang transform is used to filter the acceleration signal to solve the integrator saturation problem caused by the low-frequency component of the acceleration signal. The EMD algorithm based on the continuous root mean square error is applied in rejecting the low-frequency components in the signal. The simulation experiments show that the system can be reliable and high precision.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028244","afid":"60028244","affilname":"Ball State University","affiliation-city":"Muncie","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57199479176","authid":"57199479176","authname":"Wang Q.","surname":"Wang","given-name":"Qi","initials":"Q.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55604360000","authid":"55604360000","authname":"Yang C.S.","surname":"Yang","given-name":"Chang Song","initials":"C.S.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/13613225900","authid":"13613225900","authname":"Wu S.","surname":"Wu","given-name":"Shaoen","initials":"S.","afid": [{"@_fa": "true", "$" :"60028244"}]}],"authkeywords":"Attitude matrix | Radio frequency identification | RFID | Simulation experiments | SINS | Strapdown inertial navigation system","source-id":"12100157172","fund-acr":"PAPD","fund-no":"BK20160955","fund-sponsor":"Natural Science Foundation of Jiangsu Province","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85088775355"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85088775355?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85088775355&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85088775355&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85088775355","dc:identifier":"SCOPUS_ID:85088775355","eid":"2-s2.0-85088775355","dc:title":"Method for camera motion parameter estimation from a small number of corresponding points using quaternions","dc:creator":"Goshin Y.V.","prism:publicationName":"Computer Optics","prism:issn":"01342452","prism:eIssn":"24126179","prism:volume":"44","prism:issueIdentifier":"3","prism:pageRange":"446-453","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.18287/2412-6179-CO-683","dc:description":"In this paper, we study methods for determining parameters of camera movement from a set of corresponding points. Unlike the traditional approach, the corresponding points in this paper are not used to determine the fundamental matrix, but directly to determine motion parameters. In addition, in this work, we use a multi-angle image formation model based on the representation of three-dimensional images and motion parameters in the form of quaternions. We propose method for determining motion parameters, including the selection of the most noise-free matches using the RANSAC method. The study presents results of an experiment on the “Middlebury” and “ETH3D” test kits, which contains a set of images with known values of the motion parameters. Using a program written in Python, a comparative experiment was conducted to evaluate the accuracy and reliability of the estimates obtained using the proposed method under conditions of a small number of corresponding points and a shallow depth of the scene. In the course of experimental studies, it was shown that under the above-described conditions, the reliability of parameter determination using the proposed method significantly exceeds the reliability of traditional methods for estimating motion parameters based on the calculation of the fundamental matrix.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60114364","afid":"60114364","affilname":"Federal Scientific Research Center \"Crystallography and photonics\" of Russian Academy of Sciences","affiliation-city":"Moscow","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011415","afid":"60011415","affilname":"Samara National Research University","affiliation-city":"Samara","affiliation-country":"Russian Federation"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55241631500","authid":"55241631500","authname":"Goshin Y.V.","surname":"Goshin","given-name":"Ye V.","initials":"Y.V.","afid": [{"@_fa": "true", "$" :"60011415"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56511279100","authid":"56511279100","authname":"Kotov A.P.","surname":"Kotov","given-name":"A. P.","initials":"A.P.","afid": [{"@_fa": "true", "$" :"60011415"},{"@_fa": "true", "$" :"60114364"}]}],"authkeywords":"Epipolar geometry | Motion parameters | Quaternion","source-id":"21100203110","fund-acr":"РФФИ","fund-no":"17-29-03112","fund-sponsor":"Russian Foundation for Basic Research","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85087062228"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85087062228?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85087062228&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85087062228&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85087062228","dc:identifier":"SCOPUS_ID:85087062228","eid":"2-s2.0-85087062228","dc:title":"Medical image fusion based on quaternion wavelet transform","dc:creator":"Zhancheng Z.","prism:publicationName":"Journal of Algorithms and Computational Technology","prism:issn":"17483018","prism:eIssn":"17483026","prism:volume":"14","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1177/1748302620931297","dc:description":"Medical image fusion can combine multi-modal images into an integrated higher-quality image, which can provide more comprehensive and accurate pathological information than individual image does. Traditional transform domain-based image fusion methods usually ignore the dependencies between coefficients and may lead to the inaccurate representation of source image. To improve the quality of fused image, a medical image fusion method based on the dependencies of quaternion wavelet transform coefficients is proposed. First, the source images are decomposed into low-frequency component and high-frequency component by quaternion wavelet transform. Then, a clarity evaluation index based on quaternion wavelet transform amplitude and phase is constructed and a contextual activity measure is designed. These measures are utilized to fuse the high-frequency coefficients and the choose-max fusion rule is applied to the low-frequency components. Finally, the fused image can be obtained by inverse quaternion wavelet transform. The experimental results on some brain multi-modal medical images demonstrate that the proposed method has achieved advanced fusion result.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073673","afid":"60073673","affilname":"Suzhou University of Science and Technology","affiliation-city":"Suzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007029","afid":"60007029","affilname":"Jiangnan University","affiliation-city":"Wuxi","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57217308601","authid":"57217308601","orcid":"0000-0002-7729-6896","authname":"Zhancheng Z.","surname":"Zhancheng","given-name":"Zhang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60073673"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57217300918","authid":"57217300918","orcid":"0000-0001-8030-1660","authname":"Xiaoqing L.","surname":"Xiaoqing","given-name":"Luo","initials":"L.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57217303620","authid":"57217303620","authname":"Mengyu X.","surname":"Mengyu","given-name":"Xiong","initials":"X.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57217309536","authid":"57217309536","authname":"Zhiwen W.","surname":"Zhiwen","given-name":"Wang","initials":"W.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57217313068","authid":"57217313068","authname":"Kai L.","surname":"Kai","given-name":"Li","initials":"L.","afid": [{"@_fa": "true", "$" :"60007029"}]}],"authkeywords":"activity measure | context | Medical image fusion | quaternion wavelet transform","source-id":"19700200886","fund-acr":"NSFC","fund-no":"JUSRP51618B","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084856377"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084856377?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85084856377&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85084856377&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85084856377","dc:identifier":"SCOPUS_ID:85084856377","eid":"2-s2.0-85084856377","dc:title":"Hybrid watermarking algorithm using clifford algebra with arnold scrambling and chaotic encryption","dc:creator":"Bhatti U.A.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"76386-76398","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.2988298","dc:description":"With the widespread use of color images, the copyright protection of those images using watermarks is one of the latest research topics. The use of color images as watermarks has advantages over binary and irreplaceable grayscale images. Color images are intuitive, rich, and lively; they have large amounts of copyright protection information and more easily recognized by human vision. To improve the security of watermark information and embedding positions and improve the algorithm's robustness against various attacks, a Quaternion Fourier transform (QFT) based algorithm, based on Arnold transform and chaotic encryption, is proposed in this paper. Geometric algebra (GA) can deal with color images in vector form with each component of RGB handled individually. We used Quaternion, which is a sub-algebra of GA, and effectively handled color image processing by using Fourier transformation. After deriving the calculation process of the QFT with strong security by Arnold scrambling and chaotic encryption, this paper proposes a digital watermarking algorithm that resists geometric attacks by using color images as carriers. The robustness and quality of the proposed watermarking algorithm is tested with different with many statistical measures. Experimental outcomes show that the proposed approach is the best to solve conflict problems between quality and robustness. Also, the proposed approach exhibits worthy robustness against many attacks, such as, conventional attacks, and geometrical attacks.","citedby-count":"56","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60020258","afid":"60020258","affilname":"Nanjing Normal University","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017716","afid":"60017716","affilname":"Hainan University","affiliation-city":"Haikou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57194505499","authid":"57194505499","orcid":"0000-0002-8743-2783","authname":"Bhatti U.A.","surname":"Bhatti","given-name":"Uzair Aslam","initials":"U.A.","afid": [{"@_fa": "true", "$" :"60020258"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/23491178000","authid":"23491178000","authname":"Yu Z.","surname":"Yu","given-name":"Zhaoyuan","initials":"Z.","afid": [{"@_fa": "true", "$" :"60020258"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/58435381800","authid":"58435381800","authname":"Li J.","surname":"Li","given-name":"Jingbing","initials":"J.","afid": [{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57207104583","authid":"57207104583","authname":"Nawaz S.A.","surname":"Nawaz","given-name":"Saqib Ali","initials":"S.A.","afid": [{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57200864193","authid":"57200864193","authname":"Mehmood A.","surname":"Mehmood","given-name":"Anum","initials":"A.","afid": [{"@_fa": "true", "$" :"60017716"},{"@_fa": "true", "$" :"60017716"},{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/56335694300","authid":"56335694300","orcid":"0000-0001-9195-8000","authname":"Zhang K.","surname":"Zhang","given-name":"Kun","initials":"K.","afid": [{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/23490892300","authid":"23490892300","authname":"Yuan L.","surname":"Yuan","given-name":"Linwang","initials":"L.","afid": [{"@_fa": "true", "$" :"60020258"},{"@_fa": "true", "$" :"60020258"},{"@_fa": "true", "$" :"60020258"}]}],"authkeywords":"Arnold scrambling | chaotic encryption | Clifford algebra | QFT","article-number":"9069210","source-id":"21100374601","fund-acr":"NSFC","fund-no":"41625004 41971404","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084762576"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084762576?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85084762576&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85084762576&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85084762576","dc:identifier":"SCOPUS_ID:85084762576","eid":"2-s2.0-85084762576","dc:title":"Research on Transmitter of the Somatosensory Hand Gesture Recognition System","dc:creator":"Gao F.","prism:publicationName":"Lecture Notes in Electrical Engineering","prism:issn":"18761100","prism:eIssn":"18761119","prism:isbn": [{"@_fa": "true", "$" :"9789811394089"}],"prism:volume":"571 LNEE","prism:pageRange":"1376-1384","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-981-13-9409-6_165","dc:description":"A high-precision sensitive and portable “transmitter” of the hand gesture recognition system is designed in this paper. The MPU6050 sensor is used to collect the hand gesture data in real time. And the quaternion is obtained by the digital motion processing (DMP) unit of the sensor, and the Euler angle is obtained by the mathematical formulas operation. After that the complementary filtering correction algorithm is used to calculate the human hand gesture. Wireless modules are used to send data to the intelligent terminals and realize the function of wireless control of the intelligent terminals by hand gesture. Finally, the effectiveness and reliability of the scheme are verified by experiments. The experimental results show that compared with Euler angle method and direction cosine method, the attitude calculation method based on quaternion method and adding correction algorithm proposed by this scheme has the characteristics of less calculation, fast calculation speed and less drift error.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60108768","afid":"60108768","affilname":"Dalian Neusoft University of Information","affiliation-city":"Dalian","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003144","afid":"60003144","affilname":"Dalian Jiaotong University","affiliation-city":"Dalian","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55636219500","authid":"55636219500","authname":"Gao F.","surname":"Gao","given-name":"Fei","initials":"F.","afid": [{"@_fa": "true", "$" :"60003144"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24166131300","authid":"24166131300","authname":"Fei J.","surname":"Fei","given-name":"Jiyou","initials":"J.","afid": [{"@_fa": "true", "$" :"60003144"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57194787043","authid":"57194787043","authname":"Li H.","surname":"Li","given-name":"Hua","initials":"H.","afid": [{"@_fa": "true", "$" :"60003144"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57195056890","authid":"57195056890","authname":"Liu X.","surname":"Liu","given-name":"Xiaodong","initials":"X.","afid": [{"@_fa": "true", "$" :"60003144"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57193684501","authid":"57193684501","authname":"Han T.","surname":"Han","given-name":"Ti","initials":"T.","afid": [{"@_fa": "true", "$" :"60108768"}]}],"authkeywords":"Attitude algorithm | Complementary filtering correction | Hand gesture recognition | Somatosensory","source-id":"19700186822","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084430210"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084430210?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85084430210&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85084430210&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85084430210","dc:identifier":"SCOPUS_ID:85084430210","eid":"2-s2.0-85084430210","dc:title":"Image Quality Assessment Based on Quaternion Singular Value Decomposition","dc:creator":"Sang Q.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"75925-75935","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.2989312","dc:description":"We propose an image quality assessment metric based on quaternion singular value decomposition that represents a color image as a quaternion matrix, separates image noise information using singular value decomposition and extracts features from both the whole image and its noise information. In the proposed method, the color image and its local variance are represented by using quaternion and then performing singular value decomposition. Later, 75% of singular values are taken as image noise information. We extract a luminance comparison, contrast comparison, structure comparison, phase congruency and gradient magnitude from whole color images and extract the peak signal-to-noise ratio from image noise information as features. Finally, these features are used as the input to a kernel extreme learning machine to predict the quality of the tested images. Extensive experiments performed on four benchmark image quality assessment databases demonstrate that the proposed metric achieves high consistency with the subjective evaluations and outperforms state-of-the-art image quality assessment metrics.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007029","afid":"60007029","affilname":"Jiangnan University","affiliation-city":"Wuxi","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55254860700","authid":"55254860700","orcid":"0000-0002-9883-792X","authname":"Sang Q.","surname":"Sang","given-name":"Qingbing","initials":"Q.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57216748205","authid":"57216748205","authname":"Yang Y.","surname":"Yang","given-name":"Yunshuo","initials":"Y.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/26435997900","authid":"26435997900","authname":"Liu L.","surname":"Liu","given-name":"Lixiong","initials":"L.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/8304894200","authid":"8304894200","orcid":"0000-0002-3967-4497","authname":"Song X.","surname":"Song","given-name":"Xiaoning","initials":"X.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56191888600","authid":"56191888600","orcid":"0000-0002-0310-5778","authname":"Wu X.","surname":"Wu","given-name":"Xiaojun","initials":"X.","afid": [{"@_fa": "true", "$" :"60007029"}]}],"authkeywords":"image quality assessment | kernel extreme learning machine | Quaternion singular value decomposition","article-number":"9075250","source-id":"21100374601","fund-acr":"NSFC","fund-no":"BK20171142","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084395444"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084395444?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85084395444&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85084395444&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85084395444","dc:identifier":"SCOPUS_ID:85084395444","eid":"2-s2.0-85084395444","dc:title":"Quaternion Non-Negative Matrix Factorization: Definition, Uniqueness, and Algorithm","dc:creator":"Flamant J.","prism:publicationName":"IEEE Transactions on Signal Processing","prism:issn":"1053587X","prism:eIssn":"19410476","prism:volume":"68","prism:pageRange":"1870-1883","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/TSP.2020.2974651","dc:description":"This article introduces quaternion non-negative matrix factorization (QNMF), which generalizes the usual non-negative matrix factorization (NMF) to the case of polarized signals. Polarization information is represented by Stokes parameters, a set of 4 energetic parameters widely used in polarimetric imaging. QNMF relies on two key ingredients: (i) the algebraic representation of Stokes parameters thanks to quaternions and (ii) the exploitation of physical constraints on Stokes parameters. These constraints generalize non-negativity to the case of polarized signals, encoding positive semi-definiteness of the covariance matrix associated which each source. Uniqueness conditions for QNMF are presented. Remarkably, they encompass known sufficient uniqueness conditions from NMF. Meanwhile, QNMF further relaxes NMF uniqueness conditions requiring sources to exhibit a certain zero-pattern, by leveraging the complete polarization information. We introduce a simple yet efficient algorithm called quaternion alternating least squares (QALS) to solve the QNMF problem in practice. Closed-form quaternion updates are obtained using the recently introduced generalized HR calculus. Numerical experiments on synthetic data demonstrate the relevance of the approach. QNMF defines a promising generic low-rank approximation tool to handle polarization, notably for blind source separation problems arising in imaging applications.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073336","afid":"60073336","affilname":"CRAN Centre de Recherche en Automatique de Nancy","affiliation-city":"Vandoeouvre-les-Nancy","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57189218541","authid":"57189218541","orcid":"0000-0001-9994-173X","authname":"Flamant J.","surname":"Flamant","given-name":"Julien","initials":"J.","afid": [{"@_fa": "true", "$" :"60073336"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8345291500","authid":"8345291500","orcid":"0000-0003-4733-6698","authname":"Miron S.","surname":"Miron","given-name":"Sebastian","initials":"S.","afid": [{"@_fa": "true", "$" :"60073336"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55513010100","authid":"55513010100","orcid":"0000-0002-2373-3480","authname":"Brie D.","surname":"Brie","given-name":"David","initials":"D.","afid": [{"@_fa": "true", "$" :"60073336"}]}],"authkeywords":"blind source separation | Polarization | quaternion non-negative matrix factorization | Stokes parameters","article-number":"9001262","source-id":"17391","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084333265"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85084333265?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85084333265&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85084333265&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85084333265","dc:identifier":"SCOPUS_ID:85084333265","eid":"2-s2.0-85084333265","dc:title":"Quaternion Discrete Fourier Transform-Based Color Image Watermarking Method Using Quaternion QR Decomposition","dc:creator":"Li M.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"72308-72315","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.2987914","dc:description":"In this paper, a new Quaternion Discrete Fourier Transform (QDFT)-based digital color image watermarking method is presented. In addition, the Quaternion QR (QQR) decomposition is applied in digital watermarking technology for the first time. First of all, the QDFT and QQR decomposition are performed on the host image, respectively, to acquire the scalar part of the quaternion matrix for watermark information embedding. After that, we divide the scalar part of the quaternion matrix generated by the QQR decomposition into blocks and calculate the entropy. The block with high entropy is selected to embed the watermark information. Then the watermark information is embedded into the extracted block using the quantization index modulation method. We conducted a large number of tests and experimental results indicate that the presented approach obtains excellent robustness against Scaling, Rotation, Median filtering, 'Salt Pepper' noise, and JPEG Compression. Compared with the existing methods, the presented method achieves better performance.","citedby-count":"17","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60072902","afid":"60072902","affilname":"Macau University of Science and Technology","affiliation-city":"Taipa","affiliation-country":"Macao"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023237","afid":"60023237","affilname":"Beijing Normal University","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/124371791","afid":"124371791","affilname":"Zhuhai M.U.S.T. Science Research Academy","affiliation-city":null,"affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57193864492","authid":"57193864492","authname":"Li M.","surname":"Li","given-name":"Mianjie","initials":"M.","afid": [{"@_fa": "true", "$" :"60072902"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/36562860900","authid":"36562860900","orcid":"0000-0002-7490-6695","authname":"Yuan X.","surname":"Yuan","given-name":"Xiaochen","initials":"X.","afid": [{"@_fa": "true", "$" :"60072902"},{"@_fa": "true", "$" :"124371791"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57200210182","authid":"57200210182","authname":"Chen H.","surname":"Chen","given-name":"Hai","initials":"H.","afid": [{"@_fa": "true", "$" :"60023237"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57209630145","authid":"57209630145","orcid":"0000-0002-6768-1483","authname":"Li J.","surname":"Li","given-name":"Jianqing","initials":"J.","afid": [{"@_fa": "true", "$" :"60072902"}]}],"authkeywords":"quantization index modulation | quaternion discrete Fourier transform (QDFT) | quaternion QR (QQR) decomposition | scalar part | Watermarking technology","article-number":"9066976","source-id":"21100374601","fund-acr":"NSFC","fund-no":"0007/2018/ASC","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083731590"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083731590?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083731590&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85083731590&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85083731590","dc:identifier":"SCOPUS_ID:85083731590","eid":"2-s2.0-85083731590","dc:title":"4th International Conference on Computer Vision and Image Processing, CVIP 2019","prism:publicationName":"Communications in Computer and Information Science","prism:issn":"18650929","prism:eIssn":"18650937","prism:isbn": [{"@_fa": "true", "$" :"9789811540141"}],"prism:volume":"1147 CCIS","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","dc:description":"The proceedings contain 82 papers. The special focus in this conference is on Computer Vision and Image Processing. The topics include: A method to generate synthetically warped document image; delaunay triangulation based thinning algorithm for alphabet images; a reduced graph cut approach to interactive object segmentation with flexible user input; A new fuzzy clustering algorithm by incorporating constrained class uncertainty-based entropy for brain MR image segmentation; a novel saliency-based cascaded approach for moving object segmentation; a novel graph theoretic image segmentation technique; automated industrial quality control of pipe stacks using computer vision; extraction and recognition of numerals from machine-printed urdu documents; colour sensitive image segmentation using quaternion Algebra; multimodal query based approach for document image retrieval; transformed directional tri concomitant triplet patterns for image retrieval; encoder decoder based image semantic space creation for clothing items retrieval; feature learning for effective content-based image retrieval; two efficient image bag generators for multi-instance multi-label learning; a comparative study of big mart sales prediction; asymmetric wide tele camera fusion for high fidelity digital zoom; energy based convex set hyperspectral endmember extraction algorithm; fast semantic feature extraction using superpixels for soft segmentation; spatially variant laplacian pyramids for multi-frame exposure fusion; Traffic sign recognition using color and spatial transformer network on GPU embedded development board; unsupervised single-view depth estimation for real time inference; preface; towards ocular recognition through local image descriptors; a novel information theoretic cost measure for filtering based feature selection from hyperspectral images; CNN and RF based classification of brain tumors in MR neurological images.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"17700155007","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083728974"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083728974?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083728974&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85083728974&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85083728974","dc:identifier":"SCOPUS_ID:85083728974","eid":"2-s2.0-85083728974","dc:title":"Colour sensitive image segmentation using quaternion Algebra","dc:creator":"Maity S.K.","prism:publicationName":"Communications in Computer and Information Science","prism:issn":"18650929","prism:eIssn":"18650937","prism:isbn": [{"@_fa": "true", "$" :"9789811540141"}],"prism:volume":"1147 CCIS","prism:pageRange":"348-358","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-981-15-4015-8_31","dc:description":"In colour image segmentation, a few vector filters are useful, and they are not well applicable. The segmentation tools which are still available, not also colour sensitive. In this paper, we present an approach for color sensitive segmentation method by using the color sensitivity property of hyper complex or quaternion algebra. The filter is based on quaternion convolution and impulse response is determined using modified gray centered RGB color cube. This method demands that every color can be segmented by choosing suitable impulse response.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004750","afid":"60004750","affilname":"Indian Institute of Technology Kharagpur","affiliation-city":"Kharagpur","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/117020677","afid":"117020677","affilname":"ARC Document Solutions","affiliation-city":"Kolkata","affiliation-country":"India"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57201552311","authid":"57201552311","authname":"Maity S.K.","surname":"Maity","given-name":"Sandip Kumar","initials":"S.K.","afid": [{"@_fa": "true", "$" :"117020677"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7202443668","authid":"7202443668","authname":"Biswas P.","surname":"Biswas","given-name":"Prabir","initials":"P.","afid": [{"@_fa": "true", "$" :"60004750"}]}],"authkeywords":"Colour sensitive image segmentation | Gray-Centered RGB colour cube | Liniear quaternion convolution","source-id":"17700155007","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083725115"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083725115?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083725115&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85083725115&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85083725115","dc:identifier":"SCOPUS_ID:85083725115","eid":"2-s2.0-85083725115","dc:title":"Double JPEG Compression Detection Based on Markov Model","dc:creator":"Wang J.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030435745"}],"prism:volume":"12022 LNCS","prism:pageRange":"141-149","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-3-030-43575-2_11","dc:description":"In this paper, a feature based on the Markov model in quaternion discrete cosine transform (QDCT) domain is proposed for double JPEG compression detection. Firstly, a given JPEG image is extracted from blocked images to obtain amplitude and three angles (ψ, φ, and θ). Secondly, when extracting the Markov features, we process the transition probability matrix with the corresponding refinement. Our proposed refinement method not only reduces redundant features, but also makes the acquired features more efficient for detection. Finally, a support vector machine (SVM) is employed for NA-DJPEG compression detection. It is well known that detecting NA-DJPEG compressed images with (Formula Presented) is a challenging task, and when the images with small size (i.e., 64 × 64), the detection will be more difficult. The experimental result indicates that our method can still achieve a high classification accuracy in this case.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025578","afid":"60025578","affilname":"Xidian University","affiliation-city":"Xi'an","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022904","afid":"60022904","affilname":"New Jersey Institute of Technology","affiliation-city":"Newark","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019499","afid":"60019499","affilname":"Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113621902","afid":"113621902","affilname":"State Key Laboratory of Mathematical Engineering and Advanced Computing","affiliation-city":"Zhengzhou","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57192930875","authid":"57192930875","authname":"Wang J.","surname":"Wang","given-name":"Jinwei","initials":"J.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60025578"},{"@_fa": "true", "$" :"113621902"},{"@_fa": "true", "$" :"60019499"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57211362450","authid":"57211362450","authname":"Huang W.","surname":"Huang","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8976166200","authid":"8976166200","authname":"Luo X.","surname":"Luo","given-name":"Xiangyang","initials":"X.","afid": [{"@_fa": "true", "$" :"113621902"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/58324477200","authid":"58324477200","authname":"Shi Y.Q.","surname":"Shi","given-name":"Yung Qing","initials":"Y.Q.","afid": [{"@_fa": "true", "$" :"60022904"}]}],"authkeywords":"Color image forensics | Double JPEG compression detection | Markov model | Quaternion discrete cosine transform","source-id":"25674","fund-acr":"NSFC","fund-no":"61502241","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083088197"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083088197?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083088197&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85083088197&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85083088197","dc:identifier":"SCOPUS_ID:85083088197","eid":"2-s2.0-85083088197","dc:title":"5th International Conference on Electrical, Control and Computer Engineering, InECCE 2019","prism:publicationName":"Lecture Notes in Electrical Engineering","prism:issn":"18761100","prism:eIssn":"18761119","prism:isbn": [{"@_fa": "true", "$" :"9789811523168"}],"prism:volume":"632","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","dc:description":"The proceedings contain 74 papers. The special focus in this conference is on Electrical, Control and Computer Engineering. The topics include: A Diversity-Based Adaptive Synchronous-Asynchronous Switching Simulated Kalman Filter Optimizer; combinatorial Test Suite Generation Strategy Using Enhanced Sine Cosine Algorithm; classification of Lubricant Oil Geometrical Odor-Profile Using Cased-Based Reasoning; Optimization of Quaternion Based on Hybrid PID and Pw Control; elimination-Dispersal Sine Cosine Algorithm for a Dynamic Modelling of a Twin Rotor System; the Investigation of Meat Classification Based on Significant Authentication Features Using Odor-Profile Intelligent Signal Processing Approach; the Study of Raw Water Based on Quality Parameter Using Smell-Print Sensing Device; camera Orientation Determination Based on Copper Wire Spool Shape; a Modified Symbiotic Organism Search Algorithm with Lévy Flight for Software Module Clustering Problem; Effect of Excitation Frequency on Magnetic Response Induced by Front- and Back-Side Slits Measured by a Differential AMR Sensor Probe; Classification of Agarwood Types (Malaccensis and Crassna) Between Oil and Smoke Using E-Nose with CBR Classifier; SCAR-CNN: Secondary-Classification-After-Refinement Convolutional Neural Network for Fine-Grained Categorization; forecasting Road Deaths in Malaysia Using Support Vector Machine; investigation of Dimensionality Reduction on Numerical Attribute Features in a Finger Vein Identification System; intelligent Gender Recognition System for Classification of Gender in Malaysian Demographic; a Novel Approach Towards Tamper Detection of Digital Holy Quran Generation; A Comparative Study of AFM-Assisted Direct and Least-Square Attitude Determination Algorithm; design and Development of Wearable Human Activity Recognition for Healthcare Monitoring; region of Interest Extraction of Finger-Vein Image Using Watershed Segmentation with Distance Transform.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"19700186822","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082695456"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082695456?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082695456&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85082695456&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85082695456","dc:identifier":"SCOPUS_ID:85082695456","eid":"2-s2.0-85082695456","dc:title":"Non-orthogonal shafting laser sensor for trans-scale three-dimensional measurement","dc:creator":"Kang J.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510636569"}],"prism:volume":"11439","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1117/12.2543036","dc:description":"For the trans-scale three-dimensional (3D) measurement in regular-size space and industrial applications, there are many deficiencies and application limitations for traditional measurement methods. Reference to the three axes architecture of traditional instruments, a novel non-orthogonal shafting laser sensor is proposed. The novel sensor is mainly composed of two non-orthogonal shafting laser sensing modules, and each module is made up of two one-dimensional rotary tables and one collimated laser. In the novel laser sensing module, the three axes represent a non-orthogonal shafting architecture, with no orthogonal and intersecting requirements. The manufacturing and application costs are greatly reduced. A high-Accuracy calibration method based on coordinate measuring machine and image processing is introduced. An improved perspective projection transform model and attitude kinetic model described by quaternion are adopted to calculate the 3D coordinates of spatial points. The simulation and experimental results showed that a maximum error less than 0.1 mm was detected from 100 mm to 500 mm. It is proved that trans-scale 3D measurement is feasible with the proposed non-orthogonal shafting laser sensor.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019533","afid":"60019533","affilname":"Tianjin University","affiliation-city":"Tianjin","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55444698300","authid":"55444698300","authname":"Kang J.","surname":"Kang","given-name":"Jiehu","initials":"J.","afid": [{"@_fa": "true", "$" :"60019533"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56428272000","authid":"56428272000","authname":"Wu B.","surname":"Wu","given-name":"Bin","initials":"B.","afid": [{"@_fa": "true", "$" :"60019533"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57210893510","authid":"57210893510","authname":"Duan X.","surname":"Duan","given-name":"Xiaodeng","initials":"X.","afid": [{"@_fa": "true", "$" :"60019533"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57192634907","authid":"57192634907","authname":"Zhang Z.","surname":"Zhang","given-name":"Zhen","initials":"Z.","afid": [{"@_fa": "true", "$" :"60019533"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55985288300","authid":"55985288300","authname":"Xue T.","surname":"Xue","given-name":"Ting","initials":"T.","afid": [{"@_fa": "true", "$" :"60019533"}]}],"authkeywords":"Calibration method | Non-orthogonal shafting laser sensor | Perspective projection transform model | Trans-scale","article-number":"114390M","source-id":"40067","fund-no":"18JCZDJC38600","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082447972"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082447972?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082447972&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85082447972&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85082447972","dc:identifier":"SCOPUS_ID:85082447972","eid":"2-s2.0-85082447972","dc:title":"Deep learning analysis of human behaviour recognition based on convolutional neural network analysis","dc:creator":"Yao F.","prism:publicationName":"Behaviour and Information Technology","prism:issn":"0144929X","prism:eIssn":"13623001","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1080/0144929X.2020.1716390","dc:description":"With the rapid development of smart devices, the application range of human behaviour recognition has been expanding. Due to the problems of low efficiency and low accuracy of traditional artificial feature extraction behaviour recognition, human behaviour recognition based on deep learning has become a new direction of research. This paper proposes an adaptive feature recalibration residual network-AFRRNet model. In order to verify the effectiveness of the AFRRNet model, this paper trained the CNN model, RNN model, and AFRRNet model on the generated image data set SAImage Net. This paper further proposes a quaternion spatio-temporal convolutional neural network that is consistent with the understanding of human behaviour. The CNN’s spatial convolutional layer is extended to a quaternion spatial convolutional layer, so that the three components R, G, and B of the colour image as a whole can be used to extract the apparent features in the human behaviour space domain. The experimental results prove that QST-CNN improves the feature extraction capability and behaviour recognition accuracy of deep learning networks.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104086","afid":"60104086","affilname":"Chongqing University of Education","affiliation-city":"Chongqing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"tb","subtypeDescription":"Retracted","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/12344717000","authid":"12344717000","authname":"Yao F.","surname":"Yao","given-name":"Fuguang","initials":"F.","afid": [{"@_fa": "true", "$" :"60104086"}]}],"authkeywords":"AFRRNet model | convolutional neural network | deep learning | Human behaviour recognition | quaternion space convolution","source-id":"12125","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082306956"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082306956?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082306956&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85082306956&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85082306956","dc:identifier":"SCOPUS_ID:85082306956","eid":"2-s2.0-85082306956","dc:title":"Hand Gesture Recognition Based on Joint Rotation Feature and Fingertip Distance Feature","dc:creator":"Miao Y.W.","prism:publicationName":"Jisuanji Xuebao/Chinese Journal of Computers","prism:issn":"02544164","prism:volume":"43","prism:issueIdentifier":"1","prism:pageRange":"78-92","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"1 January 2020","prism:doi":"10.11897/SP.J.1016.2020.00078","dc:description":"As a mainstream and important interactive mode of human-computer interaction (HCI), due to its high degree of freedom, hand gesture interaction and gesture recognition become a hot research topic in the literature of Computer Graphics, Virtual Reality and HCI, etc. The traditional hand gesture recognition method which directly extracts the gesture contour or the position information of hand joints is usually difficult to represent the differences between hand gestures accurately. In order to solve the issues of high degree of freedom of different gestures and the inaccurate feature representation in gesture recognition due to low resolution of gesture images, messy image background, occlusive hands, different shape and size of fingers and also individual differences, a new feature representation of hand gesture and the corresponding gesture recognition method is proposed in this paper, which combines the joint rotation feature and fingertip distance feature. First, the 3D position information of 20 hand joints is calculated from the depth map of the underlying hand gesture by using hand template, and also considering the hand as a segment structures which consists of 19 segments. Then, the quaternion joint rotation feature and the fingertip distance features are extracted by using the position information of the hand joints, which constitutes the intrinsic representation of hand gesture feature. Finally, the hand gesture can be effectively recognized and classified by using one-to-one support vector machine (SVM) classifier. This paper not only presents a new feature representation and the corresponding feature extraction approach of static hand gesture, but also proves theoretically that the proposed gesture features can uniquely represent the 3D position information of hand joints. At the same time, a multi-classification strategy based on one-to-one SVM is also adopted to classify and recognize different hand gestures. We evaluate the proposed algorithm on the ASTAR dataset with annotated hand-depth images of static gestures, which including 8 kinds of Chinese digital gestures and 21 classes of American alphabet gestures. We compared our gesture recognition method with the existing methods from the following two aspects. One is for different feature representations of hand gesture, such as HOG (histogram of oriented gradients feature), SURF (speeded-up robust feature), Feature 1 (quaternions joint rotation with rotation axis+fingertip distance feature), Feature 2 (quaternions without rotation axis), and Feature 3 (quaternions without rotation axis+fingertip distance feature). The other is for different classifier selections for gesture classification and recognition, such as K-Nearest Neighbor (KNN), Naïve Bayes (NB), one-to-rest SVM, one-to-one SVM. Our experiments show the efficiency and advantage of our proposed static gesture recognition method by using the Feature 3+one-to-one SVM in terms of the accuracy of gesture classification and recognition. The accuracy of our hand gesture recognition method is 99.71% for Chinese digital gestures and 85.24% for American alphabet gestures, respectively. Experimental results demonstrate that the proposed feature representation based on joint rotation feature and fingertip distance feature can reflect the geometric properties of different hand gestures, and also can accurately represent the static gestures and effectively recognize different hand gestures.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60103821","afid":"60103821","affilname":"Zhejiang Sci-Tech University","affiliation-city":"Hangzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60026282","afid":"60026282","affilname":"Zhejiang University of Technology","affiliation-city":"Hangzhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8924022900","authid":"8924022900","authname":"Miao Y.W.","surname":"Miao","given-name":"Yong Wei","initials":"Y.W.","afid": [{"@_fa": "true", "$" :"60103821"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57215899258","authid":"57215899258","authname":"Li J.Y.","surname":"Li","given-name":"Jia Ying","initials":"J.Y.","afid": [{"@_fa": "true", "$" :"60103821"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57215897407","authid":"57215897407","authname":"Liu J.Z.","surname":"Liu","given-name":"Jia Zong","initials":"J.Z.","afid": [{"@_fa": "true", "$" :"60103821"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55974337900","authid":"55974337900","authname":"Chen J.Z.","surname":"Chen","given-name":"Jia Zhou","initials":"J.Z.","afid": [{"@_fa": "true", "$" :"60026282"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57215896599","authid":"57215896599","authname":"Sun S.S.","surname":"Sun","given-name":"Shu Sen","initials":"S.S.","afid": [{"@_fa": "true", "$" :"60103821"}]}],"authkeywords":"Hand gesture recognition | Human-computer interaction | Position of hand joints | Quaternion feature | Support vector machine","source-id":"26131","fund-acr":"NSFC","fund-no":"61972458","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082111527"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082111527?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082111527&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85082111527&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85082111527","dc:identifier":"SCOPUS_ID:85082111527","eid":"2-s2.0-85082111527","dc:title":"Proactive Fiber Break Detection Based on Quaternion Time Series and Automatic Variable Selection from Relational Data","dc:creator":"Lemaire V.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030390976"}],"prism:volume":"11986 LNAI","prism:pageRange":"26-42","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-3-030-39098-3_3","dc:description":"We address the problem of event classification for proactive fiber break detection in high-speed optical communication systems. The proposed approach is based on monitoring the State of Polarization (SOP) via digital signal processing in a coherent receiver. We describe in details the design of a classifier providing interpretable decision rules and enabling low-complexity real-time detection embedded in network elements. The proposed method operates on SOP time series, which define trajectories on the 3D sphere; SOP time series are low-pass filtered (to reduce measurement noise), pre-rotated (to provide invariance to the starting point of trajectories) and converted to quaternion domain. Then quaternion sequences are recoded to relational data for automatic variable construction and selection. We show that a naïve Bayes classifier using a limited subset of variables can achieve an event classification accuracy of more than 99% for the tested conditions.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104081","afid":"60104081","affilname":"Orange Labs","affiliation-city":"Issy-les-Moulineaux","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021378","afid":"60021378","affilname":"Nokia Bell Labs","affiliation-city":"Murray","affiliation-country":"United States"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7103308068","authid":"7103308068","authname":"Lemaire V.","surname":"Lemaire","given-name":"Vincent","initials":"V.","afid": [{"@_fa": "true", "$" :"60104081"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/26038887900","authid":"26038887900","authname":"Boitier F.","surname":"Boitier","given-name":"Fabien","initials":"F.","afid": [{"@_fa": "true", "$" :"60021378"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57188956207","authid":"57188956207","authname":"Pesic J.","surname":"Pesic","given-name":"Jelena","initials":"J.","afid": [{"@_fa": "true", "$" :"60021378"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/23090474600","authid":"23090474600","authname":"Bondu A.","surname":"Bondu","given-name":"Alexis","initials":"A.","afid": [{"@_fa": "true", "$" :"60104081"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/18042416800","authid":"18042416800","authname":"Ragot S.","surname":"Ragot","given-name":"Stéphane","initials":"S.","afid": [{"@_fa": "true", "$" :"60104081"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/55995258900","authid":"55995258900","authname":"Clérot F.","surname":"Clérot","given-name":"Fabrice","initials":"F.","afid": [{"@_fa": "true", "$" :"60104081"}]}],"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081959465"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081959465?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081959465&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85081959465&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85081959465","dc:identifier":"SCOPUS_ID:85081959465","eid":"2-s2.0-85081959465","dc:title":"An extrinsic calibration method for multiple RGB-D cameras in a limited field of view","dc:creator":"Chaochuan J.","prism:publicationName":"Measurement Science and Technology","prism:issn":"09570233","prism:eIssn":"13616501","prism:volume":"31","prism:issueIdentifier":"4","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1088/1361-6501/ab48b3","dc:description":"A 3D scanning system involving multiple RGB-D cameras has the potential to accelerate the reconstruction of an object and improve the measurement accuracy because it can capture an object in a comprehensive way. However, the extrinsic calibration of a multi-RGB-D-camera system is a fundamental and challenging problem, especially in a limited field of view. In this work, a system with four SR300 cameras on a platform with a size of approximately 0.64 m2 and an extrinsic calibration method assisted by a tower calibration pattern with circular markers in a limited field of view are proposed. The Hough transform algorithm is used to identify the centres of the circular markers in a colour image, and then the 3D coordinates are extracted by employing the alignment relationship between the colour image and the depth image. An improved adaptive cuckoo search (IACS) algorithm and unit quaternion are proposed to optimize the extrinsic parameters. The effectiveness of the IACS is verified by a comparison with the singular value decomposition (SVD), standard cuckoo search (CS) and two CS variant algorithms. In addition, the accuracy of the proposed extrinsic calibration method is verified by reconstructing and measuring a human foot and a cube box. The mean errors from the standard values of the length and width of the reconstructed foot mode are 0.18 cm and 0.13 cm, and the diameter of the yellow sphere are 0.17 cm, respectively. All of the experimental results show that the proposed extrinsic calibration method has a high calibration accuracy and good potential application prospects.","citedby-count":"10","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011052","afid":"60011052","affilname":"West AnHui University","affiliation-city":"Lu'an","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001429","afid":"60001429","affilname":"Shandong University of Science and Technology","affiliation-city":"Qingdao","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57215822326","authid":"57215822326","authname":"Chaochuan J.","surname":"Chaochuan","given-name":"Jia","initials":"J.","afid": [{"@_fa": "true", "$" :"60001429"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57215821379","authid":"57215821379","authname":"Ting Y.","surname":"Ting","given-name":"Yang","initials":"Y.","afid": [{"@_fa": "true", "$" :"60011052"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57160119400","authid":"57160119400","authname":"Chuanjiang W.","surname":"Chuanjiang","given-name":"Wang","initials":"W.","afid": [{"@_fa": "true", "$" :"60001429"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/39761057000","authid":"39761057000","orcid":"0000-0003-3393-7900","authname":"Binghui F.","surname":"Binghui","given-name":"Fan","initials":"F.","afid": [{"@_fa": "true", "$" :"60001429"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55437731600","authid":"55437731600","authname":"Fugui H.","surname":"Fugui","given-name":"He","initials":"H.","afid": [{"@_fa": "true", "$" :"60011052"}]}],"authkeywords":"extrinsic calibration | improved adaptive cuckoo search algorithm | multi RGB-D cameras | optimization | tower calibration pattern","article-number":"045901","source-id":"15526","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081689963"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081689963?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081689963&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85081689963&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85081689963","dc:identifier":"SCOPUS_ID:85081689963","eid":"2-s2.0-85081689963","dc:title":"Novel Multi-Channel Fractional-Order Radial Harmonic Fourier Moments for Color Image Analysis","dc:creator":"Hosny K.M.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"40732-40743","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.2976759","dc:description":"The classical radial harmonic Fourier moments (RHFMs) and the quaternion radial harmonic Fourier moments (QRHFMs) are gray-scale and color image descriptors. The radial harmonic functions with integer orders are not able to extract fine features from the input images. In this paper, the authors derived novel fractional-order radial harmonic functions in polar coordinates. The obtained functions are used to defined novel multi-channel fractional-order radial harmonic moments (FrMRHFMs) for color image description and analysis. The invariants to geometric transformations for these new moments are derived. A theoretical comparison between FrMRHFMs and QRHFMs is performed from the aspects of kernel function and the spectrum analysis. Numerical simulation is carried out to test these new moments in terms of image reconstruction capabilities, invariance to the similarity transformations, color image recognition and the CPU computational times. The obtained theoretical and numerical results clearly show that the proposed FrMRHFMs is superior to the QRHFMs and the existing fractional-order orthogonal moments.","citedby-count":"26","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60274165","afid":"60274165","affilname":"Faculty of Computers and Information","affiliation-city":"Zagazig","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60273131","afid":"60273131","affilname":"Faculty of Science","affiliation-city":"Asyut","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60239381","afid":"60239381","affilname":"Faculty of Computers and Informatics","affiliation-city":"Ismailia","affiliation-country":"Egypt"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205214086","authid":"57205214086","orcid":"0000-0001-8065-8977","authname":"Hosny K.M.","surname":"Hosny","given-name":"Khalid M.","initials":"K.M.","afid": [{"@_fa": "true", "$" :"60274165"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57205229124","authid":"57205229124","orcid":"0000-0003-3256-8728","authname":"Darwish M.M.","surname":"Darwish","given-name":"Mohamed M.","initials":"M.M.","afid": [{"@_fa": "true", "$" :"60273131"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35092321100","authid":"35092321100","orcid":"0000-0003-0205-2210","authname":"Eltoukhy M.M.","surname":"Eltoukhy","given-name":"Mohamed Meselhy","initials":"M.M.","afid": [{"@_fa": "true", "$" :"60239381"}]}],"authkeywords":"Color image analysis | fractional-order orthogonal moments | radial harmonic Fourier moments | rotation invariance","article-number":"9016026","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081551030"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081551030?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081551030&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85081551030&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85081551030","dc:identifier":"SCOPUS_ID:85081551030","eid":"2-s2.0-85081551030","dc:title":"A Novel Bayesian Patch-Based Approach for Image Denoising","dc:creator":"Ali R.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"38985-38994","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.2975892","dc:description":"Recently patch-based image denoising techniques have gained the attention of researchers as it is being used in numerous image denoising applications. This article is proposing a new Bayesian Patch-based image denoising algorithm using Quaternion Wavelet Transform (QWT) for grayscale images. In the proposed work, a patch model has been used instead of the Gibbs distribution based energy model. Experimental results indicate that the proposed algorithm effectively diminishes noise. The results of the developed approach are also compared with other efficient image denoising algorithms such as Expected Patch Log Likelihood (EPLL), Block-matching and 3D filtering (BM3D), Patch-Based Locally Optimal Wiener (PLOW), Weighted Nuclear Norm Minimization (WNNM), Hybrid Robust Bilateral Filter-Total Variation Filter (RBF-TVF) and Hybrid Total Variation Filter-Weighted Bilateral Filter (TVF-WBF) methods. The comparison revealed that the outcomes of the given approach are much sharper, clearer, and having the highest quality in comparison with other patch-based methods.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60042800","afid":"60042800","affilname":"University of Engineering and Technology Taxila","affiliation-city":"Taxila","affiliation-country":"Pakistan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018273","afid":"60018273","affilname":"University of Science and Technology Beijing","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57207832871","authid":"57207832871","orcid":"0000-0003-4194-6444","authname":"Ali R.","surname":"Ali","given-name":"Rashid","initials":"R.","afid": [{"@_fa": "true", "$" :"60018273"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55726486200","authid":"55726486200","orcid":"0000-0002-7179-9978","authname":"Yunfeng P.","surname":"Yunfeng","given-name":"Peng","initials":"P.","afid": [{"@_fa": "true", "$" :"60018273"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55752995400","authid":"55752995400","orcid":"0000-0003-2592-0383","authname":"Amin R.U.","surname":"Amin","given-name":"Rooh Ul","initials":"R.U.","afid": [{"@_fa": "true", "$" :"60042800"}]}],"authkeywords":"Bayesian patch-based method | Image denoising | PSNR | quaternion wavelet transform (QWT)","article-number":"9007380","source-id":"21100374601","fund-no":"2003008002","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081176853"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081176853?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081176853&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85081176853&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85081176853","dc:identifier":"SCOPUS_ID:85081176853","eid":"2-s2.0-85081176853","dc:title":"ICPS-net: An end-to-end RGB-based indoor camera positioning system using deep convolutional neural networks","dc:creator":"Ghofrani A.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510636439"}],"prism:volume":"11433","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1117/12.2559285","dc:description":"Indoor positioning and navigation inside an area with no GPS-data availability is a challenging problem. There are applications such as augmented reality, autonomous driving, navigation of drones inside tunnels, in which indoor positioning gets crucial. In this paper, a tandem architecture of deep network-based systems, for the first time to our knowledge, is developed to address this problem. This structure is trained on the scene images being obtained through scanning of the desired area segments using photogrammetry. A CNN structure based on EfficientNet is trained as a classifier of the scenes, followed by a MobileNet CNN structure which is trained to perform as a regressor. The proposed system achieves amazingly fine precisions for both Cartesian position and quaternion information of the camera.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/124035567","afid":"124035567","affilname":"AR/VR Solution Company","affiliation-city":null,"affiliation-country":null},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/106541998","afid":"106541998","affilname":"Iran Broadcasting University","affiliation-city":"Tehran","affiliation-country":"Iran"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57211940470","authid":"57211940470","authname":"Ghofrani A.","surname":"Ghofrani","given-name":"Ali","initials":"A.","afid": [{"@_fa": "true", "$" :"106541998"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56712794800","authid":"56712794800","authname":"Mahdian Toroghi R.","surname":"Mahdian Toroghi","given-name":"Rahil","initials":"R.","afid": [{"@_fa": "true", "$" :"106541998"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57215564444","authid":"57215564444","authname":"Tabatabaie S.M.","surname":"Tabatabaie","given-name":"Seyed Mojtaba","initials":"S.M.","afid": [{"@_fa": "true", "$" :"124035567"}]}],"authkeywords":"Camera positioning | EfficientNet | Indoor localization | Indoor navigation | MobileNetV2","article-number":"1143323","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081104825"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081104825?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081104825&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85081104825&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85081104825","dc:identifier":"SCOPUS_ID:85081104825","eid":"2-s2.0-85081104825","dc:title":"Robust Dual-Color Watermarking Based on Quaternion Singular Value Decomposition","dc:creator":"Chen Y.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"30628-30642","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.2973044","dc:description":"This paper proposes a robust dual-color watermarking based on quaternion singular value decomposition (QSVD), which can embed large payloads into color images with low distortion, and can obtain strong robustness to process color image in a holistic manner. First, two notes are proposed for designing the proposed watermarking scheme, one of which is about three strong correlations found in U that can be used for watermark embedding, and the other is analyzing the feasibility of V compensation for QSVD-based watermarking scheme. In addition, a fast structure-preserving algorithm is used to calculate the singular value decomposition (SVD) of a quaternion matrix, which makes the procedure computationally more flexible and efficient. Then a new watermarking scheme is proposed to protect the copyright of color images. This scheme uses quaternion to make the color image channels correlated so that the proposed watermarking scheme has strong anti-attack performance. Experimental results show that the proposed dual-color watermarking is not only imperceptible but also robust to some common attacks, and the performance of the proposed method outperforms other methods considered in this work.","citedby-count":"15","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023813","afid":"60023813","affilname":"Shanghai University","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004691","afid":"60004691","affilname":"Jiangsu Normal University","affiliation-city":"Xuzhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57216667311","authid":"57216667311","orcid":"0000-0002-9820-1614","authname":"Chen Y.","surname":"Chen","given-name":"Yong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60023813"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8264355300","authid":"8264355300","orcid":"0000-0001-9408-0942","authname":"Jia Z.","surname":"Jia","given-name":"Zhigang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60004691"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/36617766500","authid":"36617766500","authname":"Peng Y.","surname":"Peng","given-name":"Yan","initials":"Y.","afid": [{"@_fa": "true", "$" :"60023813"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55962184600","authid":"55962184600","orcid":"0000-0002-2983-555X","authname":"Peng Y.","surname":"Peng","given-name":"Yaxin","initials":"Y.","afid": [{"@_fa": "true", "$" :"60023813"}]}],"authkeywords":"image watermarking | QSVD | robustness | structure-preserving method","article-number":"8990155","source-id":"21100374601","fund-acr":"NSFC","fund-no":"11602133","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85080986015"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85080986015?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85080986015&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85080986015&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85080986015","dc:identifier":"SCOPUS_ID:85080986015","eid":"2-s2.0-85080986015","dc:title":"Ship Detection in Panchromatic Optical Remote Sensing Images Based on Visual Saliency and Multi-Dimensional Feature Description","dc:creator":"Nie T.","prism:publicationName":"Remote Sensing","prism:eIssn":"20724292","prism:volume":"12","prism:issueIdentifier":"1","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"January-1 2020","prism:doi":"10.3390/rs12010152","dc:description":"Ship detection in panchromatic optical remote sensing images is faced with two major challenges, locating candidate regions from complex backgrounds quickly and describing ships effectively to reduce false alarms. Here, a practical method was proposed to solve these issues. Firstly, we constructed a novel visual saliency detection method based on a hyper-complex Fourier transform of a quaternion to locate regions of interest (ROIs), which can improve the accuracy of the subsequent discrimination process for panchromatic images, compared with the phase spectrum quaternary Fourier transform (PQFT) method. In addition, the Gaussian filtering of different scales was performed on the transformed result to synthesize the best saliency map. An adaptive method based on GrabCut was then used for binary segmentation to extract candidate positions. With respect to the discrimination stage, a rotation-invariant modified local binary pattern (LBP) description was achieved by combining shape, texture, and moment invariant features to describe the ship targets more powerfully. Finally, the false alarms were eliminated through SVM training. The experimental results on panchromatic optical remote sensing images demonstrated that the presented saliency model under various indicators is superior, and the proposed ship detection method is accurate and fast with high robustness, based on detailed comparisons to existing efforts.","citedby-count":"28","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190755958","authid":"57190755958","authname":"Nie T.","surname":"Nie","given-name":"Ting","initials":"T.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57195983970","authid":"57195983970","authname":"Han X.","surname":"Han","given-name":"Xiyu","initials":"X.","afid": [{"@_fa": "true", "$" :"60004828"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35336904400","authid":"35336904400","authname":"He B.","surname":"He","given-name":"Bin","initials":"B.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57203730482","authid":"57203730482","authname":"Li X.","surname":"Li","given-name":"Xiansheng","initials":"X.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/54380181100","authid":"54380181100","authname":"Liu H.","surname":"Liu","given-name":"Hongxing","initials":"H.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/37119997600","authid":"37119997600","authname":"Bi G.","surname":"Bi","given-name":"Guoling","initials":"G.","afid": [{"@_fa": "true", "$" :"60004828"}]}],"authkeywords":"Hyper-complex Fourier transform | Panchromatic optical remote sensing images | Rotation-invariant modified LBP | Ship detection | Visual saliency","article-number":"152","source-id":"86430","fund-acr":"NSFC","fund-no":"61801455","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85080924873"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85080924873?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85080924873&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85080924873&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85080924873","dc:identifier":"SCOPUS_ID:85080924873","eid":"2-s2.0-85080924873","dc:title":"Improved color image watermarking using logistic maps and quaternion Legendre-Fourier moments","dc:creator":"Darwish M.M.","prism:publicationName":"Studies in Computational Intelligence","prism:issn":"1860949X","prism:eIssn":"18609503","prism:volume":"884","prism:pageRange":"137-158","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-3-030-38700-6_6","dc:description":"In this chapter, an improved color image watermarking method is presented where the logistic maps were utilized with the quaternion Legendre-Fourier moments (Logistic maps–QLFMs). An exact, highly accurate, fast and numerically stable method is used to compute the Logistic maps–QLFMs in polar coordinates. In the Logistic maps–QLFMs method, the radial and angular kernels are computed over circular pixels by using analytical integration. Based on the geometric invariance of QLFMs, the robustness of the Logistic maps–QLFMs method is improved against geometric attacks, and the logistic mapping is used to randomly select QLFMs coefficients. Therefore, selected QLFMs are quantized to embed the binary digital watermark in the host color image. Moreover, the Logistic maps–QLFMs watermarking method is compared with quaternion Legendre-Fourier moments and existing quaternion methods. The QLFMs method is computed by using the same computation of the Logistic maps–QLFMs method. Utilizing an efficient computational method, the radial kernels of existing quaternion are computed using the accurate Gaussian quadrature method while the angular kernel is computed using analytical integration with the same as Logistic maps–QLFMs and QLFMs methods. Numerical experiments are performed where the performance of Logistic maps–QLFMs method is compared with the existing quaternion moment-based watermarking methods in terms of visual imperceptibility and robustness against different attacks. The comparison clearly shows that the Logistic maps–QLFMs is outperformed than existing quaternion moment-based watermarking methods.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60274165","afid":"60274165","affilname":"Faculty of Computers and Information","affiliation-city":"Zagazig","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60273131","afid":"60273131","affilname":"Faculty of Science","affiliation-city":"Asyut","affiliation-country":"Egypt"}],"prism:aggregationType":"Book Series","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205229124","authid":"57205229124","authname":"Darwish M.M.","surname":"Darwish","given-name":"Mohamed M.","initials":"M.M.","afid": [{"@_fa": "true", "$" :"60273131"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57205214086","authid":"57205214086","authname":"Hosny K.M.","surname":"Hosny","given-name":"Khalid M.","initials":"K.M.","afid": [{"@_fa": "true", "$" :"60274165"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57215416161","authid":"57215416161","authname":"Kamal S.T.","surname":"Kamal","given-name":"Sara T.","initials":"S.T.","afid": [{"@_fa": "true", "$" :"60273131"}]}],"authkeywords":"Color image watermarking | Logistic maps | Quaternion Legendre-Fourier moments","source-id":"4900152708","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079506895"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079506895?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079506895&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85079506895&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85079506895","dc:identifier":"SCOPUS_ID:85079506895","eid":"2-s2.0-85079506895","dc:title":"Structured quaternion-based tight frame for multicomponent signal recovery","dc:creator":"Zhao Q.","prism:publicationName":"SEG International Exposition and Annual Meeting 2019","prism:pageRange":"2715-2719","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1190/segam2019-3216441.1","dc:description":"Traditional signal recovery models usually treat multicomponent data as three independent components, which easily cause difficult to preserve the subtle relationships between different components. We propose a structured quaternion-based tight frame (SQTF) for multicomponent signal recovery through combining dictionary learning and quaternion matrix analysis. In the quaternion-based sparse domain, we can conduct structured representation after transforming multicomponent signal into an orthogonal representation formula, which ensures that the subtle relationships between multicomponent signal can be preserved to a greater extent. We test the performance of proposed method on both synthetic and field multicomponent data, and use the results of conventional data-driven tight frame independently training on each component as comparisons. Results show that much more features, especially for the weak signals in each component, can be preserved using the proposed method than the conventional methods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60138680","afid":"60138680","affilname":"Pilot National Laboratory for Marine Science and Technology","affiliation-city":"Qingdao","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105111","afid":"60105111","affilname":"China University of Petroleum (East China)","affiliation-city":"Qingdao","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57193323513","authid":"57193323513","authname":"Zhao Q.","surname":"Zhao","given-name":"Qiang","initials":"Q.","afid": [{"@_fa": "true", "$" :"60105111"},{"@_fa": "true", "$" :"60138680"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57203877465","authid":"57203877465","authname":"Du Q.","surname":"Du","given-name":"Qizhen","initials":"Q.","afid": [{"@_fa": "true", "$" :"60105111"},{"@_fa": "true", "$" :"60138680"}]}],"source-id":"21100945241","fund-acr":"NKRDPC","fund-no":"2017YFB0202903","fund-sponsor":"National Key Research and Development Program of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079485054"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079485054?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079485054&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85079485054&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85079485054","dc:identifier":"SCOPUS_ID:85079485054","eid":"2-s2.0-85079485054","dc:title":"Vector-valued seismic data denoising via widely-linear autoregressive models","dc:creator":"Bahia B.","prism:publicationName":"SEG International Exposition and Annual Meeting 2019","prism:pageRange":"4565-4569","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1190/segam2019-3214183.1","dc:description":"Processing vector-valued seismic datasets is a challenging task. The data are usually composed of correlated components, which are corrupted by uncorrelated random noise. Random noise reduction is, therefore, a primary goal in its processing workflow. We seek to exploit both, the correlation between data components and the uncorrelated character of noise samples, to achieve further mitigation of random noise in multicomponent datasets. We represent the data through quaternion arrays and process it via quaternion algebra. We show how to exploit the correlation between the components of vector-valued datasets by proposing the extension of the frequency-space deconvolution (FXDECON) to its hypercomplex version, the QFXDECON. This rather straightforward extension does not guarantee that the complete vectorial information is taken into consideration. We also show how widely-linear models can exploit this correlation. The widely-linear scheme, named WL-QFXDECON, produces longer prediction filters which have enhanced signal preservation capabilities shown through synthetic and field vector-valued data examples.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030835","afid":"60030835","affilname":"University of Alberta","affiliation-city":"Edmonton","affiliation-country":"Canada"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205750370","authid":"57205750370","authname":"Bahia B.","surname":"Bahia","given-name":"Breno","initials":"B.","afid": [{"@_fa": "true", "$" :"60030835"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57203080832","authid":"57203080832","authname":"Sacchi M.D.","surname":"Sacchi","given-name":"Mauricio D.","initials":"M.D.","afid": [{"@_fa": "true", "$" :"60030835"}]}],"source-id":"21100974952","fund-acr":"UofA","fund-no":"undefined","fund-sponsor":"University of Alberta","openaccess":"0","openaccessFlag":false}]}}