{"abstracts-retrieval-response": {
    "item": {
        "ait:process-info": {
            "ait:status": {
                "@state": "new",
                "@type": "core",
                "@stage": "S300"
            },
            "ait:date-delivered": {
                "@day": "19",
                "@timestamp": "2021-09-19T22:53:17.000017-04:00",
                "@year": "2021",
                "@month": "09"
            },
            "ait:date-sort": {
                "@day": "01",
                "@year": "2021",
                "@month": "01"
            }
        },
        "bibrecord": {
            "head": {
                "author-group": {
                    "affiliation": {
                        "country": "United States",
                        "@afid": "60026415",
                        "@country": "usa",
                        "organization": [
                            {"$": "Department of Computer Science"},
                            {"$": "Stony Brook University"}
                        ],
                        "affiliation-id": {
                            "@afid": "60026415",
                            "@dptid": "112963493"
                        },
                        "state": "NY",
                        "ce:source-text": "Department of Computer Science, Stony Brook University, NY, USA",
                        "@dptid": "112963493"
                    },
                    "author": [
                        {
                            "ce:given-name": "Aneesh",
                            "preferred-name": {
                                "ce:given-name": "Aneesh",
                                "ce:initials": "A.",
                                "ce:surname": "Muppidi",
                                "ce:indexed-name": "Muppidi A."
                            },
                            "@seq": "1",
                            "ce:initials": "A.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Muppidi",
                            "@auid": "57216523770",
                            "ce:indexed-name": "Muppidi A."
                        },
                        {
                            "ce:given-name": "Martin",
                            "preferred-name": {
                                "ce:given-name": "Martin",
                                "ce:initials": "M.",
                                "ce:surname": "Radfar",
                                "ce:indexed-name": "Radfar M."
                            },
                            "@seq": "2",
                            "ce:initials": "M.",
                            "@_fa": "true",
                            "@type": "auth",
                            "ce:surname": "Radfar",
                            "@auid": "8403329000",
                            "ce:indexed-name": "Radfar M."
                        }
                    ]
                },
                "citation-title": "Speech emotion recognition using quaternion convolutional neural networks",
                "abstracts": "Â© 2021 IEEE.Although speech recognition has become a widespread technology, inferring emotion from speech signals remains a challenge. Our paper addresses this problem by proposing a quaternion convolutional neural network (QCNN) based speech emotion recognition (SER) model in which Mel-spectrogram features of speech signals are encoded in an RGB quaternion domain. We demonstrate that our QCNN based SER model outperforms other real-valued methods in the Ryerson Audio- Visual Database of Emotional Speech and Song (RAVDESS, 8-classes) dataset, achieving, to the best of our knowledge, state-of-the-art results. The QCNN model also achieves comparable results with state-of-the-art methods in the Interactive Emotional Dyadic Motion Capture (IEMOCAP 4-classes) and Berlin EMO-DB (7-classes) datasets. Specifically, the model achieves an accuracy of 77.87%, 70.46%, and 88.78% for the RAVDESS, IEMOCAP, and EMO-DB datasets, respectively. Additionally, model size results reveal that the quaternion unit structure is significantly better able to encode internal dependencies than real-valued structures.",
                "citation-info": {
                    "author-keywords": {"author-keyword": [
                        {
                            "$": "Convolutional Neural Networks",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Quaternion Deep Learning",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Signal Processing",
                            "@xml:lang": "eng",
                            "@original": "y"
                        },
                        {
                            "$": "Speech Emotion Recognition",
                            "@xml:lang": "eng",
                            "@original": "y"
                        }
                    ]},
                    "citation-type": {"@code": "cp"},
                    "citation-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    },
                    "abstract-language": {
                        "@language": "English",
                        "@xml:lang": "eng"
                    }
                },
                "source": {
                    "translated-sourcetitle": {
                        "$": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
                        "@xml:lang": "eng"
                    },
                    "volisspag": {
                        "voliss": {"@volume": "2021-June"},
                        "pagerange": {
                            "@first": "6309",
                            "@last": "6313"
                        }
                    },
                    "@type": "p",
                    "additional-srcinfo": {"conferenceinfo": {
                        "confpublication": {"procpartno": "1 of 1"},
                        "confevent": {
                            "confname": "2021 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2021",
                            "confsponsors": {
                                "confsponsor": "The Institute of Electrical and Electronics Engineers Signal Processing Society",
                                "@complete": "n"
                            },
                            "confcatnumber": "CFP21ICA-ART",
                            "confseriestitle": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                            "conflocation": {
                                "@country": "can",
                                "city": "Virtual, Toronto",
                                "state": "ON"
                            },
                            "confcode": "169955",
                            "confdate": {
                                "enddate": {
                                    "@day": "11",
                                    "@year": "2021",
                                    "@month": "06"
                                },
                                "startdate": {
                                    "@day": "06",
                                    "@year": "2021",
                                    "@month": "06"
                                }
                            }
                        }
                    }},
                    "sourcetitle": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
                    "publicationdate": {
                        "year": "2021",
                        "date-text": {
                            "@xfab-added": "true",
                            "$": "2021"
                        }
                    },
                    "codencode": "IPROD",
                    "sourcetitle-abbrev": "ICASSP IEEE Int Conf Acoust Speech Signal Process Proc",
                    "@country": "usa",
                    "issn": {
                        "$": "15206149",
                        "@type": "print"
                    },
                    "publicationyear": {"@first": "2021"},
                    "publisher": {"publishername": "Institute of Electrical and Electronics Engineers Inc."},
                    "@srcid": "110544"
                },
                "enhancement": {"classificationgroup": {"classifications": [
                    {
                        "@type": "CPXCLASS",
                        "classification": [
                            {
                                "classification-code": "716.1",
                                "classification-description": "Information Theory and Signal Processing"
                            },
                            {
                                "classification-code": "751.5",
                                "classification-description": "Speech"
                            }
                        ]
                    },
                    {
                        "@type": "FLXCLASS",
                        "classification": {
                            "classification-code": "902",
                            "classification-description": "FLUIDEX; Related Topics"
                        }
                    },
                    {
                        "@type": "ASJC",
                        "classification": [
                            {"$": "1712"},
                            {"$": "1711"},
                            {"$": "2208"}
                        ]
                    },
                    {
                        "@type": "SUBJABBR",
                        "classification": [
                            {"$": "COMP"},
                            {"$": "ENGI"}
                        ]
                    }
                ]}}
            },
            "item-info": {
                "copyright": {
                    "$": "Copyright 2021 Elsevier B.V., All rights reserved.",
                    "@type": "Elsevier"
                },
                "dbcollection": [
                    {"$": "CPX"},
                    {"$": "REAXYSCAR"},
                    {"$": "SCOPUS"},
                    {"$": "Scopusbase"}
                ],
                "history": {"date-created": {
                    "@day": "19",
                    "@timestamp": "BST 07:02:42",
                    "@year": "2021",
                    "@month": "09"
                }},
                "itemidlist": {
                    "itemid": [
                        {
                            "$": "635978359",
                            "@idtype": "PUI"
                        },
                        {
                            "$": "935606837",
                            "@idtype": "CAR-ID"
                        },
                        {
                            "$": "20213810908249",
                            "@idtype": "CPX"
                        },
                        {
                            "$": "20213353826",
                            "@idtype": "REAXYSCAR"
                        },
                        {
                            "$": "20213120957",
                            "@idtype": "SCOPUS"
                        },
                        {
                            "$": "85114965941",
                            "@idtype": "SCP"
                        },
                        {
                            "$": "85114965941",
                            "@idtype": "SGR"
                        }
                    ],
                    "ce:doi": "10.1109/ICASSP39728.2021.9414248"
                }
            },
            "tail": {"bibliography": {
                "@refcount": "30",
                "reference": [
                    {
                        "ref-fulltext": "D. Rethage, J. Pons, and X. Serra, \"A wavenet for speech denoising,\" in 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018, pp. 5069-5073.",
                        "@id": "1",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "A wavenet for speech denoising"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85054257597",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "5069",
                                "@last": "5073"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Rethage",
                                    "ce:indexed-name": "Rethage D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Pons",
                                    "ce:indexed-name": "Pons J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Serra",
                                    "ce:indexed-name": "Serra X."
                                }
                            ]},
                            "ref-sourcetitle": "2018 Ieee International Conference on Acoustics, Speech and Signal Processing (ICASSP). Ieee"
                        },
                        "ce:source-text": "D. Rethage, J. Pons, and X. Serra, \"A wavenet for speech denoising,\" in 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018, pp. 5069-5073."
                    },
                    {
                        "ref-fulltext": "M. Benzeghiba, R. De Mori, O. Deroo, S. Dupont, T. Erbes, D. Jouvet, L. Fissore, P. Laface, A. Mertins, C. Ris et al., \"Automatic speech recognition and speech variability: A review,\" Speech communication, vol. 49, no. 10-11, pp. 763-786, 2007.",
                        "@id": "2",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2007"},
                            "ref-title": {"ref-titletext": "Automatic speech recognition and speech variability: A review"},
                            "refd-itemidlist": {"itemid": {
                                "$": "34547941599",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "49",
                                    "@issue": "10-11"
                                },
                                "pagerange": {
                                    "@first": "763",
                                    "@last": "786"
                                }
                            },
                            "ref-authors": {
                                "author": [
                                    {
                                        "@seq": "1",
                                        "ce:initials": "M.",
                                        "@_fa": "true",
                                        "ce:surname": "Benzeghiba",
                                        "ce:indexed-name": "Benzeghiba M."
                                    },
                                    {
                                        "@seq": "2",
                                        "ce:initials": "R.",
                                        "@_fa": "true",
                                        "ce:surname": "De Mori",
                                        "ce:indexed-name": "De Mori R."
                                    },
                                    {
                                        "@seq": "3",
                                        "ce:initials": "O.",
                                        "@_fa": "true",
                                        "ce:surname": "Deroo",
                                        "ce:indexed-name": "Deroo O."
                                    },
                                    {
                                        "@seq": "4",
                                        "ce:initials": "S.",
                                        "@_fa": "true",
                                        "ce:surname": "Dupont",
                                        "ce:indexed-name": "Dupont S."
                                    },
                                    {
                                        "@seq": "5",
                                        "ce:initials": "T.",
                                        "@_fa": "true",
                                        "ce:surname": "Erbes",
                                        "ce:indexed-name": "Erbes T."
                                    },
                                    {
                                        "@seq": "6",
                                        "ce:initials": "D.",
                                        "@_fa": "true",
                                        "ce:surname": "Jouvet",
                                        "ce:indexed-name": "Jouvet D."
                                    },
                                    {
                                        "@seq": "7",
                                        "ce:initials": "L.",
                                        "@_fa": "true",
                                        "ce:surname": "Fissore",
                                        "ce:indexed-name": "Fissore L."
                                    },
                                    {
                                        "@seq": "8",
                                        "ce:initials": "P.",
                                        "@_fa": "true",
                                        "ce:surname": "Laface",
                                        "ce:indexed-name": "Laface P."
                                    },
                                    {
                                        "@seq": "9",
                                        "ce:initials": "A.",
                                        "@_fa": "true",
                                        "ce:surname": "Mertins",
                                        "ce:indexed-name": "Mertins A."
                                    },
                                    {
                                        "@seq": "10",
                                        "ce:initials": "C.",
                                        "@_fa": "true",
                                        "ce:surname": "Ris",
                                        "ce:indexed-name": "Ris C."
                                    }
                                ],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Speech Communication"
                        },
                        "ce:source-text": "M. Benzeghiba, R. De Mori, O. Deroo, S. Dupont, T. Erbes, D. Jouvet, L. Fissore, P. Laface, A. Mertins, C. Ris et al., \"Automatic speech recognition and speech variability: A review,\" Speech communication, vol. 49, no. 10-11, pp. 763-786, 2007."
                    },
                    {
                        "ref-fulltext": "S. Ramakrishnan and I. M. El Emary, \"Speech emotion recognition approaches in human computer interaction,\" Telecommunication Systems, vol. 52, no. 3, pp. 1467-1478, 2013.",
                        "@id": "3",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2013"},
                            "ref-title": {"ref-titletext": "Speech emotion recognition approaches in human computer interaction"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84879797312",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "52",
                                    "@issue": "3"
                                },
                                "pagerange": {
                                    "@first": "1467",
                                    "@last": "1478"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Ramakrishnan",
                                    "ce:indexed-name": "Ramakrishnan S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "I.M.",
                                    "@_fa": "true",
                                    "ce:surname": "El Emary",
                                    "ce:indexed-name": "El Emary I.M."
                                }
                            ]},
                            "ref-sourcetitle": "Telecommunication Systems"
                        },
                        "ce:source-text": "S. Ramakrishnan and I. M. El Emary, \"Speech emotion recognition approaches in human computer interaction,\" Telecommunication Systems, vol. 52, no. 3, pp. 1467-1478, 2013."
                    },
                    {
                        "ref-fulltext": "A. Ashar, M. S. Bhatti, and U. Mushtaq, \"Speaker identification using a hybrid cnn-mfcc approach,\" in 2020 International Conference on Emerging Trends in Smart Technologies (ICETST). IEEE, 2020, pp. 1-4.",
                        "@id": "4",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Speaker identification using a hybrid cnn-mfcc approach"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85084947536",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "4"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Ashar",
                                    "ce:indexed-name": "Ashar A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.S.",
                                    "@_fa": "true",
                                    "ce:surname": "Bhatti",
                                    "ce:indexed-name": "Bhatti M.S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "U.",
                                    "@_fa": "true",
                                    "ce:surname": "Mushtaq",
                                    "ce:indexed-name": "Mushtaq U."
                                }
                            ]},
                            "ref-sourcetitle": "2020 International Conference on Emerging Trends in Smart Technologies (ICETST). Ieee"
                        },
                        "ce:source-text": "A. Ashar, M. S. Bhatti, and U. Mushtaq, \"Speaker identification using a hybrid cnn-mfcc approach,\" in 2020 International Conference on Emerging Trends in Smart Technologies (ICETST). IEEE, 2020, pp. 1-4."
                    },
                    {
                        "ref-fulltext": "S. An, Z. Ling, and L. Dai, \"Emotional statistical parametric speech synthesis using lstm-rnns,\" in 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE, 2017, pp. 1613-1616.",
                        "@id": "5",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Emotional statistical parametric speech synthesis using lstm-rnns"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85050485102",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1613",
                                "@last": "1616"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "An",
                                    "ce:indexed-name": "An S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Ling",
                                    "ce:indexed-name": "Ling Z."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "L.",
                                    "@_fa": "true",
                                    "ce:surname": "Dai",
                                    "ce:indexed-name": "Dai L."
                                }
                            ]},
                            "ref-sourcetitle": "2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). Ieee"
                        },
                        "ce:source-text": "S. An, Z. Ling, and L. Dai, \"Emotional statistical parametric speech synthesis using lstm-rnns,\" in 2017 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC). IEEE, 2017, pp. 1613-1616."
                    },
                    {
                        "ref-fulltext": "S. Pascual, A. Bonafonte, and J. Serra, \"Segan: Speech enhancement generative adversarial network,\" arXiv preprint arXiv:1703.09452, 2017.",
                        "@id": "6",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "1703.09452",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85029798988",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Pascual",
                                    "ce:indexed-name": "Pascual S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Bonafonte",
                                    "ce:indexed-name": "Bonafonte A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Serra",
                                    "ce:indexed-name": "Serra J."
                                }
                            ]},
                            "ref-sourcetitle": "Segan: Speech Enhancement Generative Adversarial Network"
                        },
                        "ce:source-text": "S. Pascual, A. Bonafonte, and J. Serra, \"Segan: Speech enhancement generative adversarial network,\" arXiv preprint arXiv:1703.09452, 2017."
                    },
                    {
                        "ref-fulltext": "E. J. Humphrey, T. Cho, and J. P. Bello, \"Learning a robust tonnetz-space transform for automatic chord recognition,\" in 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2012, pp. 453-456.",
                        "@id": "7",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2012"},
                            "ref-title": {"ref-titletext": "Learning a robust tonnetz-space transform for automatic chord recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84867602860",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "453",
                                "@last": "456"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "E.J.",
                                    "@_fa": "true",
                                    "ce:surname": "Humphrey",
                                    "ce:indexed-name": "Humphrey E.J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Cho",
                                    "ce:indexed-name": "Cho T."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "J.P.",
                                    "@_fa": "true",
                                    "ce:surname": "Bello",
                                    "ce:indexed-name": "Bello J.P."
                                }
                            ]},
                            "ref-sourcetitle": "2012 Ieee International Conference on Acoustics, Speech and Signal Processing (ICASSP). Ieee"
                        },
                        "ce:source-text": "E. J. Humphrey, T. Cho, and J. P. Bello, \"Learning a robust tonnetz-space transform for automatic chord recognition,\" in 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2012, pp. 453-456."
                    },
                    {
                        "ref-fulltext": "D. Palaz, M. M. Doss, and R. Collobert, \"Convolutional neural networks-based continuous speech recognition using raw speech signal,\" in 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015, pp. 4295-4299.",
                        "@id": "8",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Convolutional neural networks-based continuous speech recognition using raw speech signal"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84946023646",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "4295",
                                "@last": "4299"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Palaz",
                                    "ce:indexed-name": "Palaz D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.M.",
                                    "@_fa": "true",
                                    "ce:surname": "Doss",
                                    "ce:indexed-name": "Doss M.M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Collobert",
                                    "ce:indexed-name": "Collobert R."
                                }
                            ]},
                            "ref-sourcetitle": "2015 Ieee International Conference on Acoustics, Speech and Signal Processing (ICASSP). Ieee"
                        },
                        "ce:source-text": "D. Palaz, M. M. Doss, and R. Collobert, \"Convolutional neural networks-based continuous speech recognition using raw speech signal,\" in 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015, pp. 4295-4299."
                    },
                    {
                        "ref-fulltext": "Y. Miao, M. Gowayyed, and F. Metze, \"Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding,\" in 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2015, pp. 167-174.",
                        "@id": "9",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2015"},
                            "ref-title": {"ref-titletext": "Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84964489732",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "167",
                                "@last": "174"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Miao",
                                    "ce:indexed-name": "Miao Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Gowayyed",
                                    "ce:indexed-name": "Gowayyed M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Metze",
                                    "ce:indexed-name": "Metze F."
                                }
                            ]},
                            "ref-sourcetitle": "2015 Ieee Workshop on Automatic Speech Recognition and Understanding (ASRU). Ieee"
                        },
                        "ce:source-text": "Y. Miao, M. Gowayyed, and F. Metze, \"Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding,\" in 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2015, pp. 167-174."
                    },
                    {
                        "ref-fulltext": "A. Graves, N. Jaitly, and A.-r. Mohamed, \"Hybrid speech recognition with deep bidirectional lstm,\" in 2013 IEEE workshop on automatic speech recognition and understanding. IEEE, 2013, pp. 273-278.",
                        "@id": "10",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2013"},
                            "ref-title": {"ref-titletext": "Hybrid speech recognition with deep bidirectional lstm"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84893701254",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "273",
                                "@last": "278"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Graves",
                                    "ce:indexed-name": "Graves A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Jaitly",
                                    "ce:indexed-name": "Jaitly N."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "A.-R.",
                                    "@_fa": "true",
                                    "ce:surname": "Mohamed",
                                    "ce:indexed-name": "Mohamed A.-R."
                                }
                            ]},
                            "ref-sourcetitle": "2013 Ieee Workshop on Automatic Speech Recognition and Understanding. Ieee"
                        },
                        "ce:source-text": "A. Graves, N. Jaitly, and A.-r. Mohamed, \"Hybrid speech recognition with deep bidirectional lstm,\" in 2013 IEEE workshop on automatic speech recognition and understanding. IEEE, 2013, pp. 273-278."
                    },
                    {
                        "ref-fulltext": "M. W\"ollmer, B. Schuller, F. Eyben, and G. Rigoll, \"Combining long short-term memory and dynamic bayesian networks for incremental emotion-sensitive artificial listening,\" IEEE Journal of selected topics in signal processing, vol. 4, no. 5, pp. 867-881, 2010.",
                        "@id": "11",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2010"},
                            "ref-title": {"ref-titletext": "Combining long short-term memory and dynamic bayesian networks for incremental emotion-sensitive artificial listening"},
                            "refd-itemidlist": {"itemid": {
                                "$": "77956721304",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "4",
                                    "@issue": "5"
                                },
                                "pagerange": {
                                    "@first": "867",
                                    "@last": "881"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "W\"ollmer",
                                    "ce:indexed-name": "W\"ollmer M."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Schuller",
                                    "ce:indexed-name": "Schuller B."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Eyben",
                                    "ce:indexed-name": "Eyben F."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Rigoll",
                                    "ce:indexed-name": "Rigoll G."
                                }
                            ]},
                            "ref-sourcetitle": "Ieee Journal of Selected Topics in Signal Processing"
                        },
                        "ce:source-text": "M. W\"ollmer, B. Schuller, F. Eyben, and G. Rigoll, \"Combining long short-term memory and dynamic bayesian networks for incremental emotion-sensitive artificial listening,\" IEEE Journal of selected topics in signal processing, vol. 4, no. 5, pp. 867-881, 2010."
                    },
                    {
                        "ref-fulltext": "T. Isokawa, T. Kusakabe, N. Matsui, and F. Peper, \"Quaternion neural network and its application,\" in International conference on knowledge-based and intelligent information and engineering systems. Springer, 2003, pp. 318-324.",
                        "@id": "12",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2003"},
                            "ref-title": {"ref-titletext": "Quaternion neural network and its application"},
                            "refd-itemidlist": {"itemid": {
                                "$": "8344264584",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "318",
                                "@last": "324"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Isokawa",
                                    "ce:indexed-name": "Isokawa T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Kusakabe",
                                    "ce:indexed-name": "Kusakabe T."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Matsui",
                                    "ce:indexed-name": "Matsui N."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Peper",
                                    "ce:indexed-name": "Peper F."
                                }
                            ]},
                            "ref-sourcetitle": "International Conference on Knowledge-based and Intelligent Information and Engineering Systems. Springer"
                        },
                        "ce:source-text": "T. Isokawa, T. Kusakabe, N. Matsui, and F. Peper, \"Quaternion neural network and its application,\" in International conference on knowledge-based and intelligent information and engineering systems. Springer, 2003, pp. 318-324."
                    },
                    {
                        "ref-fulltext": "X. Zhu, Y. Xu, H. Xu, and C. Chen, \"Quaternion convolutional neural networks,\" in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 631-647.",
                        "@id": "13",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "Quaternion convolutional neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85062333525",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "631",
                                "@last": "647"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhu",
                                    "ce:indexed-name": "Zhu X."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Xu",
                                    "ce:indexed-name": "Xu Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Xu",
                                    "ce:indexed-name": "Xu H."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Chen",
                                    "ce:indexed-name": "Chen C."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the European Conference on Computer Vision (ECCV)"
                        },
                        "ce:source-text": "X. Zhu, Y. Xu, H. Xu, and C. Chen, \"Quaternion convolutional neural networks,\" in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 631-647."
                    },
                    {
                        "ref-fulltext": "D. Issa, M. F. Demirci, and A. Yazici, \"Speech emotion recognition with deep convolutional neural networks,\" Biomedical Signal Processing and Control, vol. 59, p. 101894, 2020.",
                        "@id": "14",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "Speech emotion recognition with deep convolutional neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85079857593",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "59"},
                                "pagerange": {"@first": "101894"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Issa",
                                    "ce:indexed-name": "Issa D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.F.",
                                    "@_fa": "true",
                                    "ce:surname": "Demirci",
                                    "ce:indexed-name": "Demirci M.F."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Yazici",
                                    "ce:indexed-name": "Yazici A."
                                }
                            ]},
                            "ref-sourcetitle": "Biomedical Signal Processing and Control"
                        },
                        "ce:source-text": "D. Issa, M. F. Demirci, and A. Yazici, \"Speech emotion recognition with deep convolutional neural networks,\" Biomedical Signal Processing and Control, vol. 59, p. 101894, 2020."
                    },
                    {
                        "ref-fulltext": "W. Lim, D. Jang, and T. Lee, \"Speech emotion recognition using convolutional and recurrent neural networks,\" in 2016 Asia-Pacific signal and information processing association annual summit and conference (APSIPA). IEEE, 2016, pp. 1-4.",
                        "@id": "15",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "ref-title": {"ref-titletext": "Speech emotion recognition using convolutional and recurrent neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85013832571",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "4"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "W.",
                                    "@_fa": "true",
                                    "ce:surname": "Lim",
                                    "ce:indexed-name": "Lim W."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Jang",
                                    "ce:indexed-name": "Jang D."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee T."
                                }
                            ]},
                            "ref-sourcetitle": "2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA). Ieee"
                        },
                        "ce:source-text": "W. Lim, D. Jang, and T. Lee, \"Speech emotion recognition using convolutional and recurrent neural networks,\" in 2016 Asia-Pacific signal and information processing association annual summit and conference (APSIPA). IEEE, 2016, pp. 1-4."
                    },
                    {
                        "ref-fulltext": "A. Satt, S. Rozenberg, and R. Hoory, \"Efficient emotion recognition from speech using deep learning on spectrograms, \" in Interspeech, 2017, pp. 1089-1093.",
                        "@id": "16",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2017"},
                            "ref-title": {"ref-titletext": "Efficient emotion recognition from speech using deep learning on spectrograms"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85039149720",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1089",
                                "@last": "1093"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Satt",
                                    "ce:indexed-name": "Satt A."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Rozenberg",
                                    "ce:indexed-name": "Rozenberg S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Hoory",
                                    "ce:indexed-name": "Hoory R."
                                }
                            ]},
                            "ref-sourcetitle": "Interspeech"
                        },
                        "ce:source-text": "A. Satt, S. Rozenberg, and R. Hoory, \"Efficient emotion recognition from speech using deep learning on spectrograms, \" in Interspeech, 2017, pp. 1089-1093."
                    },
                    {
                        "ref-fulltext": "T. Parcollet, Y. Zhang, M. Morchid, C. Trabelsi, G. Linar'es, R. De Mori, and Y. Bengio, \"Quaternion convolutional neural networks for end-to-end automatic speech recognition,\" arXiv preprint arXiv:1806.07789, 2018.",
                        "@id": "17",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "1806.07789",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85061857388",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Parcollet",
                                    "ce:indexed-name": "Parcollet T."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhang",
                                    "ce:indexed-name": "Zhang Y."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Morchid",
                                    "ce:indexed-name": "Morchid M."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Trabelsi",
                                    "ce:indexed-name": "Trabelsi C."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Linar'es",
                                    "ce:indexed-name": "Linar'es G."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "De Mori",
                                    "ce:indexed-name": "De Mori R."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Bengio",
                                    "ce:indexed-name": "Bengio Y."
                                }
                            ]},
                            "ref-sourcetitle": "Quaternion Convolutional Neural Networks for End-to-end Automatic Speech Recognition"
                        },
                        "ce:source-text": "T. Parcollet, Y. Zhang, M. Morchid, C. Trabelsi, G. Linar'es, R. De Mori, and Y. Bengio, \"Quaternion convolutional neural networks for end-to-end automatic speech recognition,\" arXiv preprint arXiv:1806.07789, 2018."
                    },
                    {
                        "ref-fulltext": "X. Glorot and Y. Bengio, \"Understanding the difficulty of training deep feedforward neural networks,\" in Proceedings of the thirteenth international conference on artificial intelligence and statistics, 2010, pp. 249-256.",
                        "@id": "18",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2010"},
                            "ref-title": {"ref-titletext": "Understanding the difficulty of training deep feedforward neural networks"},
                            "refd-itemidlist": {"itemid": {
                                "$": "84862277874",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "249",
                                "@last": "256"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "X.",
                                    "@_fa": "true",
                                    "ce:surname": "Glorot",
                                    "ce:indexed-name": "Glorot X."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Bengio",
                                    "ce:indexed-name": "Bengio Y."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics"
                        },
                        "ce:source-text": "X. Glorot and Y. Bengio, \"Understanding the difficulty of training deep feedforward neural networks,\" in Proceedings of the thirteenth international conference on artificial intelligence and statistics, 2010, pp. 249-256."
                    },
                    {
                        "ref-fulltext": "S. R. Livingstone and F. A. Russo, \"The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english,\" PloS one, vol. 13, no. 5, p. e0196391, 2018.",
                        "@id": "19",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2018"},
                            "ref-title": {"ref-titletext": "The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85047203203",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "13",
                                    "@issue": "5"
                                },
                                "pagerange": {"@first": "e0196391"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.R.",
                                    "@_fa": "true",
                                    "ce:surname": "Livingstone",
                                    "ce:indexed-name": "Livingstone S.R."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "F.A.",
                                    "@_fa": "true",
                                    "ce:surname": "Russo",
                                    "ce:indexed-name": "Russo F.A."
                                }
                            ]},
                            "ref-sourcetitle": "PloS. One"
                        },
                        "ce:source-text": "S. R. Livingstone and F. A. Russo, \"The ryerson audio-visual database of emotional speech and song (ravdess): A dynamic, multimodal set of facial and vocal expressions in north american english,\" PloS one, vol. 13, no. 5, p. e0196391, 2018."
                    },
                    {
                        "ref-fulltext": "J. Parry, D. Palaz, G. Clarke, P. Lecomte, R. Mead, M. Berger, and G. Hofer, \"Analysis of deep learning architectures for crosscorpus speech emotion recognition, \" in INTERSPEECH, 2019, pp. 1656-1660.",
                        "@id": "20",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Analysis of deep learning architectures for crosscorpus speech emotion recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074687799",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1656",
                                "@last": "1660"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Parry",
                                    "ce:indexed-name": "Parry J."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Palaz",
                                    "ce:indexed-name": "Palaz D."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Clarke",
                                    "ce:indexed-name": "Clarke G."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Lecomte",
                                    "ce:indexed-name": "Lecomte P."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Mead",
                                    "ce:indexed-name": "Mead R."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Berger",
                                    "ce:indexed-name": "Berger M."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "G.",
                                    "@_fa": "true",
                                    "ce:surname": "Hofer",
                                    "ce:indexed-name": "Hofer G."
                                }
                            ]},
                            "ref-sourcetitle": "Interspeech"
                        },
                        "ce:source-text": "J. Parry, D. Palaz, G. Clarke, P. Lecomte, R. Mead, M. Berger, and G. Hofer, \"Analysis of deep learning architectures for crosscorpus speech emotion recognition, \" in INTERSPEECH, 2019, pp. 1656-1660."
                    },
                    {
                        "ref-fulltext": "P. Shegokar and P. Sircar, \"Continuous wavelet transform based speech emotion recognition,\" in 2016 10th International Conference on Signal Processing and Communication Systems (ICSPCS). IEEE, 2016, pp. 1-8.",
                        "@id": "21",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2016"},
                            "ref-title": {"ref-titletext": "Continuous wavelet transform based speech emotion recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85015253945",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "1",
                                "@last": "8"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Shegokar",
                                    "ce:indexed-name": "Shegokar P."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "P.",
                                    "@_fa": "true",
                                    "ce:surname": "Sircar",
                                    "ce:indexed-name": "Sircar P."
                                }
                            ]},
                            "ref-sourcetitle": "2016 10th International Conference on Signal Processing and Communication Systems (ICSPCS). Ieee"
                        },
                        "ce:source-text": "P. Shegokar and P. Sircar, \"Continuous wavelet transform based speech emotion recognition,\" in 2016 10th International Conference on Signal Processing and Communication Systems (ICSPCS). IEEE, 2016, pp. 1-8."
                    },
                    {
                        "ref-fulltext": "Y. Zeng, H. Mao, D. Peng, and Z. Yi, \"Spectrogram based multitask audio classification,\" Multimedia Tools and Applications, vol. 78, no. 3, pp. 3705-3722, 2019.",
                        "@id": "22",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Spectrogram based multitask audio classification"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85039064595",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "78",
                                    "@issue": "3"
                                },
                                "pagerange": {
                                    "@first": "3705",
                                    "@last": "3722"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Zeng",
                                    "ce:indexed-name": "Zeng Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Mao",
                                    "ce:indexed-name": "Mao H."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Peng",
                                    "ce:indexed-name": "Peng D."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Yi",
                                    "ce:indexed-name": "Yi Z."
                                }
                            ]},
                            "ref-sourcetitle": "Multimedia Tools and Applications"
                        },
                        "ce:source-text": "Y. Zeng, H. Mao, D. Peng, and Z. Yi, \"Spectrogram based multitask audio classification,\" Multimedia Tools and Applications, vol. 78, no. 3, pp. 3705-3722, 2019."
                    },
                    {
                        "ref-fulltext": "C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, \"Iemocap: Interactive emotional dyadic motion capture database,\" Language resources and evaluation, vol. 42, no. 4, p. 335, 2008.",
                        "@id": "23",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2008"},
                            "ref-title": {"ref-titletext": "Iemocap: Interactive emotional dyadic motion capture database"},
                            "refd-itemidlist": {"itemid": {
                                "$": "59849093076",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "42",
                                    "@issue": "4"
                                },
                                "pagerange": {"@first": "335"}
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Busso",
                                    "ce:indexed-name": "Busso C."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Bulut",
                                    "ce:indexed-name": "Bulut M."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "C.-C.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee C.-C."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Kazemzadeh",
                                    "ce:indexed-name": "Kazemzadeh A."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Mower",
                                    "ce:indexed-name": "Mower E."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Kim",
                                    "ce:indexed-name": "Kim S."
                                },
                                {
                                    "@seq": "7",
                                    "ce:initials": "J.N.",
                                    "@_fa": "true",
                                    "ce:surname": "Chang",
                                    "ce:indexed-name": "Chang J.N."
                                },
                                {
                                    "@seq": "8",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Lee",
                                    "ce:indexed-name": "Lee S."
                                },
                                {
                                    "@seq": "9",
                                    "ce:initials": "S.S.",
                                    "@_fa": "true",
                                    "ce:surname": "Narayanan",
                                    "ce:indexed-name": "Narayanan S.S."
                                }
                            ]},
                            "ref-sourcetitle": "Language Resources and Evaluation"
                        },
                        "ce:source-text": "C. Busso, M. Bulut, C.-C. Lee, A. Kazemzadeh, E. Mower, S. Kim, J. N. Chang, S. Lee, and S. S. Narayanan, \"Iemocap: Interactive emotional dyadic motion capture database,\" Language resources and evaluation, vol. 42, no. 4, p. 335, 2008."
                    },
                    {
                        "ref-fulltext": "N. Majumder, S. Poria, D. Hazarika, R. Mihalcea, A. Gelbukh, and E. Cambria, \"Dialoguernn: An attentive rnn for emotion detection in conversations,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 6818-6825.",
                        "@id": "24",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Dialoguernn: An attentive rnn for emotion detection in conversations"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85090801279",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {"@volume": "33"},
                                "pagerange": {
                                    "@first": "6818",
                                    "@last": "6825"
                                }
                            },
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Majumder",
                                    "ce:indexed-name": "Majumder N."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Poria",
                                    "ce:indexed-name": "Poria S."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Hazarika",
                                    "ce:indexed-name": "Hazarika D."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "R.",
                                    "@_fa": "true",
                                    "ce:surname": "Mihalcea",
                                    "ce:indexed-name": "Mihalcea R."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Gelbukh",
                                    "ce:indexed-name": "Gelbukh A."
                                },
                                {
                                    "@seq": "6",
                                    "ce:initials": "E.",
                                    "@_fa": "true",
                                    "ce:surname": "Cambria",
                                    "ce:indexed-name": "Cambria E."
                                }
                            ]},
                            "ref-sourcetitle": "Proceedings of the Aaai Conference on Artificial Intelligence"
                        },
                        "ce:source-text": "N. Majumder, S. Poria, D. Hazarika, R. Mihalcea, A. Gelbukh, and E. Cambria, \"Dialoguernn: An attentive rnn for emotion detection in conversations,\" in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 6818-6825."
                    },
                    {
                        "ref-fulltext": "C. Li, J. Jiao, Y. Zhao, and Z. Zhao, \"Combining gated convolutional networks and self-attention mechanism for speech emotion recognition,\" in 2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW). IEEE, 2019, pp. 105-109.",
                        "@id": "25",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Combining gated convolutional networks and self-attention mechanism for speech emotion recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85077818420",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "105",
                                "@last": "109"
                            }},
                            "ref-text": "IEEE",
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "C.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li C."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "J.",
                                    "@_fa": "true",
                                    "ce:surname": "Jiao",
                                    "ce:indexed-name": "Jiao J."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhao",
                                    "ce:indexed-name": "Zhao Y."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "Z.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhao",
                                    "ce:indexed-name": "Zhao Z."
                                }
                            ]},
                            "ref-sourcetitle": "2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)."
                        },
                        "ce:source-text": "C. Li, J. Jiao, Y. Zhao, and Z. Zhao, \"Combining gated convolutional networks and self-attention mechanism for speech emotion recognition,\" in 2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW). IEEE, 2019, pp. 105-109."
                    },
                    {
                        "ref-fulltext": "D. Ghosal, N. Majumder, S. Poria, N. Chhaya, and A. Gelbukh, \"Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation,\" arXiv preprint arXiv:1908.11540, 2019.",
                        "@id": "26",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "1908.11540",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85088318789",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "D.",
                                    "@_fa": "true",
                                    "ce:surname": "Ghosal",
                                    "ce:indexed-name": "Ghosal D."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Majumder",
                                    "ce:indexed-name": "Majumder N."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Poria",
                                    "ce:indexed-name": "Poria S."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "N.",
                                    "@_fa": "true",
                                    "ce:surname": "Chhaya",
                                    "ce:indexed-name": "Chhaya N."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Gelbukh",
                                    "ce:indexed-name": "Gelbukh A."
                                }
                            ]},
                            "ref-sourcetitle": "Dialoguegcn: A Graph Convolutional Neural Network for Emotion Recognition in Conversation"
                        },
                        "ce:source-text": "D. Ghosal, N. Majumder, S. Poria, N. Chhaya, and A. Gelbukh, \"Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation,\" arXiv preprint arXiv:1908.11540, 2019."
                    },
                    {
                        "ref-fulltext": "Y. Li, T. Zhao, and T. Kawahara, \"Improved end-to-end speech emotion recognition using self attention mechanism and multitask learning, \" in Interspeech, 2019, pp. 2803-2807.",
                        "@id": "27",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2019"},
                            "ref-title": {"ref-titletext": "Improved end-to-end speech emotion recognition using self attention mechanism and multitask learning"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85074693859",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {"pagerange": {
                                "@first": "2803",
                                "@last": "2807"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "Y.",
                                    "@_fa": "true",
                                    "ce:surname": "Li",
                                    "ce:indexed-name": "Li Y."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Zhao",
                                    "ce:indexed-name": "Zhao T."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "T.",
                                    "@_fa": "true",
                                    "ce:surname": "Kawahara",
                                    "ce:indexed-name": "Kawahara T."
                                }
                            ]},
                            "ref-sourcetitle": "Interspeech"
                        },
                        "ce:source-text": "Y. Li, T. Zhao, and T. Kawahara, \"Improved end-to-end speech emotion recognition using self attention mechanism and multitask learning, \" in Interspeech, 2019, pp. 2803-2807."
                    },
                    {
                        "ref-fulltext": "S. Kwon et al., \"A cnn-assisted enhanced audio signal processing for speech emotion recognition,\" Sensors, vol. 20, no. 1, p. 183, 2020.",
                        "@id": "28",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "ref-title": {"ref-titletext": "A cnn-assisted enhanced audio signal processing for speech emotion recognition"},
                            "refd-itemidlist": {"itemid": {
                                "$": "85077495339",
                                "@idtype": "SGR"
                            }},
                            "ref-volisspag": {
                                "voliss": {
                                    "@volume": "20",
                                    "@issue": "1"
                                },
                                "pagerange": {"@first": "183"}
                            },
                            "ref-authors": {
                                "author": [{
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Kwon",
                                    "ce:indexed-name": "Kwon S."
                                }],
                                "et-al": null
                            },
                            "ref-sourcetitle": "Sensors"
                        },
                        "ce:source-text": "S. Kwon et al., \"A cnn-assisted enhanced audio signal processing for speech emotion recognition,\" Sensors, vol. 20, no. 1, p. 183, 2020."
                    },
                    {
                        "ref-fulltext": "F. Burkhardt, A. Paeschke, M. Rolfes, W. F. Sendlmeier, and B. Weiss, \"A database of german emotional speech,\" in Ninth European Conference on Speech Communication and Technology, 2005.",
                        "@id": "29",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2005"},
                            "ref-title": {"ref-titletext": "A database of german emotional speech"},
                            "refd-itemidlist": {"itemid": {
                                "$": "33745202280",
                                "@idtype": "SGR"
                            }},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "F.",
                                    "@_fa": "true",
                                    "ce:surname": "Burkhardt",
                                    "ce:indexed-name": "Burkhardt F."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "A.",
                                    "@_fa": "true",
                                    "ce:surname": "Paeschke",
                                    "ce:indexed-name": "Paeschke A."
                                },
                                {
                                    "@seq": "3",
                                    "ce:initials": "M.",
                                    "@_fa": "true",
                                    "ce:surname": "Rolfes",
                                    "ce:indexed-name": "Rolfes M."
                                },
                                {
                                    "@seq": "4",
                                    "ce:initials": "W.F.",
                                    "@_fa": "true",
                                    "ce:surname": "Sendlmeier",
                                    "ce:indexed-name": "Sendlmeier W.F."
                                },
                                {
                                    "@seq": "5",
                                    "ce:initials": "B.",
                                    "@_fa": "true",
                                    "ce:surname": "Weiss",
                                    "ce:indexed-name": "Weiss B."
                                }
                            ]},
                            "ref-sourcetitle": "Ninth European Conference on Speech Communication and Technology"
                        },
                        "ce:source-text": "F. Burkhardt, A. Paeschke, M. Rolfes, W. F. Sendlmeier, and B. Weiss, \"A database of german emotional speech,\" in Ninth European Conference on Speech Communication and Technology, 2005."
                    },
                    {
                        "ref-fulltext": "S. Goel and H. Beigi, \"Cross lingual cross corpus speech emotion recognition,\" arXiv preprint arXiv:2003.07996, 2020.",
                        "@id": "30",
                        "ref-info": {
                            "ref-publicationyear": {"@first": "2020"},
                            "refd-itemidlist": {"itemid": [
                                {
                                    "$": "2003.07996",
                                    "@idtype": "ARXIV"
                                },
                                {
                                    "$": "85092676232",
                                    "@idtype": "SGR"
                                }
                            ]},
                            "ref-authors": {"author": [
                                {
                                    "@seq": "1",
                                    "ce:initials": "S.",
                                    "@_fa": "true",
                                    "ce:surname": "Goel",
                                    "ce:indexed-name": "Goel S."
                                },
                                {
                                    "@seq": "2",
                                    "ce:initials": "H.",
                                    "@_fa": "true",
                                    "ce:surname": "Beigi",
                                    "ce:indexed-name": "Beigi H."
                                }
                            ]},
                            "ref-sourcetitle": "Cross Lingual Cross Corpus Speech Emotion Recognition"
                        },
                        "ce:source-text": "S. Goel and H. Beigi, \"Cross lingual cross corpus speech emotion recognition,\" arXiv preprint arXiv:2003.07996, 2020."
                    }
                ]
            }}
        }
    },
    "affiliation": {
        "affiliation-city": "Stony Brook",
        "@id": "60026415",
        "affilname": "Stony Brook University",
        "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60026415",
        "affiliation-country": "United States"
    },
    "coredata": {
        "srctype": "p",
        "eid": "2-s2.0-85114965941",
        "dc:description": "Although speech recognition has become a widespread technology, inferring emotion from speech signals remains a challenge. Our paper addresses this problem by proposing a quaternion convolutional neural network (QCNN) based speech emotion recognition (SER) model in which Mel-spectrogram features of speech signals are encoded in an RGB quaternion domain. We demonstrate that our QCNN based SER model outperforms other real-valued methods in the Ryerson Audio- Visual Database of Emotional Speech and Song (RAVDESS, 8-classes) dataset, achieving, to the best of our knowledge, state-of-the-art results. The QCNN model also achieves comparable results with state-of-the-art methods in the Interactive Emotional Dyadic Motion Capture (IEMOCAP 4-classes) and Berlin EMO-DB (7-classes) datasets. Specifically, the model achieves an accuracy of 77.87%, 70.46%, and 88.78% for the RAVDESS, IEMOCAP, and EMO-DB datasets, respectively. Additionally, model size results reveal that the quaternion unit structure is significantly better able to encode internal dependencies than real-valued structures.",
        "prism:coverDate": "2021-01-01",
        "prism:aggregationType": "Conference Proceeding",
        "prism:url": "https://api.elsevier.com/content/abstract/scopus_id/85114965941",
        "dc:creator": {"author": [{
            "ce:given-name": "Aneesh",
            "preferred-name": {
                "ce:given-name": "Aneesh",
                "ce:initials": "A.",
                "ce:surname": "Muppidi",
                "ce:indexed-name": "Muppidi A."
            },
            "@seq": "1",
            "ce:initials": "A.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60026415",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60026415"
            },
            "ce:surname": "Muppidi",
            "@auid": "57216523770",
            "author-url": "https://api.elsevier.com/content/author/author_id/57216523770",
            "ce:indexed-name": "Muppidi A."
        }]},
        "link": [
            {
                "@_fa": "true",
                "@rel": "self",
                "@href": "https://api.elsevier.com/content/abstract/scopus_id/85114965941"
            },
            {
                "@_fa": "true",
                "@rel": "scopus",
                "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85114965941&origin=inward"
            },
            {
                "@_fa": "true",
                "@rel": "scopus-citedby",
                "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85114965941&origin=inward"
            }
        ],
        "source-id": "110544",
        "citedby-count": "18",
        "prism:volume": "2021-June",
        "subtype": "cp",
        "dc:title": "Speech emotion recognition using quaternion convolutional neural networks",
        "openaccess": "2",
        "prism:issn": "15206149",
        "publishercopyright": "Â© 2021 IEEE.",
        "subtypeDescription": "Conference Paper",
        "prism:publicationName": "ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings",
        "prism:pageRange": "6309-6313",
        "prism:endingPage": "6313",
        "openaccessFlag": null,
        "prism:doi": "10.1109/ICASSP39728.2021.9414248",
        "prism:startingPage": "6309",
        "dc:identifier": "SCOPUS_ID:85114965941",
        "dc:publisher": "Institute of Electrical and Electronics Engineers Inc."
    },
    "idxterms": {"mainterm": [
        {
            "$": "Audio-visual database",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Emotional speech",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Spectrograms",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Speech emotion recognition",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Speech signals",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "State of the art",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "State-of-the-art methods",
            "@weight": "b",
            "@candidate": "n"
        },
        {
            "$": "Unit structure",
            "@weight": "b",
            "@candidate": "n"
        }
    ]},
    "language": {"@xml:lang": "eng"},
    "authkeywords": {"author-keyword": [
        {
            "@_fa": "true",
            "$": "Convolutional Neural Networks"
        },
        {
            "@_fa": "true",
            "$": "Quaternion Deep Learning"
        },
        {
            "@_fa": "true",
            "$": "Signal Processing"
        },
        {
            "@_fa": "true",
            "$": "Speech Emotion Recognition"
        }
    ]},
    "subject-areas": {"subject-area": [
        {
            "@_fa": "true",
            "$": "Software",
            "@code": "1712",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Signal Processing",
            "@code": "1711",
            "@abbrev": "COMP"
        },
        {
            "@_fa": "true",
            "$": "Electrical and Electronic Engineering",
            "@code": "2208",
            "@abbrev": "ENGI"
        }
    ]},
    "authors": {"author": [
        {
            "ce:given-name": "Aneesh",
            "preferred-name": {
                "ce:given-name": "Aneesh",
                "ce:initials": "A.",
                "ce:surname": "Muppidi",
                "ce:indexed-name": "Muppidi A."
            },
            "@seq": "1",
            "ce:initials": "A.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60026415",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60026415"
            },
            "ce:surname": "Muppidi",
            "@auid": "57216523770",
            "author-url": "https://api.elsevier.com/content/author/author_id/57216523770",
            "ce:indexed-name": "Muppidi A."
        },
        {
            "ce:given-name": "Martin",
            "preferred-name": {
                "ce:given-name": "Martin",
                "ce:initials": "M.",
                "ce:surname": "Radfar",
                "ce:indexed-name": "Radfar M."
            },
            "@seq": "2",
            "ce:initials": "M.",
            "@_fa": "true",
            "affiliation": {
                "@id": "60026415",
                "@href": "https://api.elsevier.com/content/affiliation/affiliation_id/60026415"
            },
            "ce:surname": "Radfar",
            "@auid": "8403329000",
            "author-url": "https://api.elsevier.com/content/author/author_id/8403329000",
            "ce:indexed-name": "Radfar M."
        }
    ]}
}}