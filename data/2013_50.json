{"search-results":{"opensearch:totalResults":"166","opensearch:startIndex":"50","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "50"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=50&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=25&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=75&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=141&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84890742802"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84890742802?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84890742802&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84890742802&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84890742802","dc:identifier":"SCOPUS_ID:84890742802","eid":"2-s2.0-84890742802","dc:title":"Blind signal estimation based on JADE algorithm for an vector hydrophone array","dc:creator":"Xiao D.","prism:publicationName":"Wuhan Ligong Daxue Xuebao (Jiaotong Kexue Yu Gongcheng Ban)/Journal of Wuhan University of Technology (Transportation Science and Engineering)","prism:issn":"20953844","prism:volume":"37","prism:issueIdentifier":"5","prism:pageRange":"1012-1016","prism:coverDate":"2013-10-01","prism:coverDisplayDate":"October 2013","prism:doi":"10.3963/j.issn.2095-3844.2013.05.026","dc:description":"The traditional hydrophone array is unable to estimate the 2-D direction of arrival angle of sources, and fail to estimate the sources when they impinging from an identical direction. In response to this situation, the theory of blind signal processing is introduced in this paper. A new algorithm combining the JADE (joint approximate diagonalization of eigen-matrices) algorithm and the technique of vector hydrophone array is proposed to estimate the array signal. With no prior assumption about the structure of steering vector, the array manifold is estimated. And then, the frequency and direction of sources can be estimated by the proposed algorithm. Meanwhile, sources can be identified even if they impinging from an identical direction. Simulation results verify the efficacy of the proposed algorithm.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069736","afid":"60069736","affilname":"Naval University of Engineering","affiliation-city":"Wuhan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55157282800","authid":"55157282800","authname":"Xiao D.","surname":"Xiao","given-name":"Dawei","initials":"D.","afid": [{"@_fa": "true", "$" :"60069736"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/13103978500","authid":"13103978500","authname":"Cheng J.","surname":"Cheng","given-name":"Jinfang","initials":"J.","afid": [{"@_fa": "true", "$" :"60069736"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55789490800","authid":"55789490800","authname":"Zhang J.","surname":"Zhang","given-name":"Jingzhuo","initials":"J.","afid": [{"@_fa": "true", "$" :"60069736"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57197435506","authid":"57197435506","authname":"Li N.","surname":"Li","given-name":"Nan","initials":"N.","afid": [{"@_fa": "true", "$" :"60069736"}]}],"authkeywords":"Blind signal processing | Estimation of direction of arrival | JADE algorithm | Quaternion | Vector hydrophone array","source-id":"18038","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84888111136"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84888111136?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84888111136&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84888111136&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84888111136","dc:identifier":"SCOPUS_ID:84888111136","eid":"2-s2.0-84888111136","dc:title":"Low-cost AHRS design based on extending Kalman filter","dc:creator":"Sheng H.","prism:publicationName":"Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics","prism:issn":"1001506X","prism:volume":"35","prism:issueIdentifier":"10","prism:pageRange":"2158-2164","prism:coverDate":"2013-10-01","prism:coverDisplayDate":"October 2013","prism:doi":"10.3969/j.issn.1001-506X.2013.10.23","dc:description":"A low-cost, high-accuracy attitude and heading reference system (AHRS) is proposed for the problem of high cost, big volume and high power consumption on the traditional AHRS which is applied in micro unmanned aerial vehicle (MUAV) and robots. Using a digital signal processor (DSP) as a hardware platform, 9-degree of freedom micro-electro-mechanical system (MEMS) sensors including gyroscope, accelerator and compass are integrated. An attitude estimation method based on quaternion is adopted. Sensor model and state space model are built. The impact of acceleration on the system accuracy is considered. The singularity problem of quaternion covariance is solved, and the accurate output of attitude and heading by applying an extending Kalman filter to data fusion is acquired. The result indicates that the static accuracy and dynamic accuracy of the attitude angle are better than 0.5° and 2°, respectively. The system is also tested on the MUAV and the outcome meets the application demand of MUAV.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55936130000","authid":"55936130000","authname":"Sheng H.","surname":"Sheng","given-name":"Han Lin","initials":"H.L.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57203238239","authid":"57203238239","authname":"Zhang T.","surname":"Zhang","given-name":"Tian Hong","initials":"T.H.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55603970500","authid":"55603970500","authname":"Liu D.","surname":"Liu","given-name":"Dong Dong","initials":"D.D.","afid": [{"@_fa": "true", "$" :"60021666"}]}],"authkeywords":"Attitude and heading reference system (AHRS) | Extending Kalman filter | Instrumentation technology | Micro-electro-mechanical system (MEMS) sensor | Quaternion","source-id":"15141","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84888086427"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84888086427?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84888086427&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84888086427&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84888086427","dc:identifier":"SCOPUS_ID:84888086427","eid":"2-s2.0-84888086427","dc:title":"Multiple multifocus color image fusion using quaternion curvelet transform","dc:creator":"Zhu M.","prism:publicationName":"Guangxue Jingmi Gongcheng/Optics and Precision Engineering","prism:issn":"1004924X","prism:volume":"21","prism:issueIdentifier":"10","prism:pageRange":"2671-2678","prism:coverDate":"2013-10-01","prism:coverDisplayDate":"October 2013","prism:doi":"10.3788/OPE.20132110.2671","dc:description":"To solve the image blur problem existed in multiple sources and multi-focus color image fusion algorithms, a novel fusion algorithm based on the quaternion curvelet transform was proposed. First, the traditional curvelet transform was generalized to a quaternion algebra from a real and complex number, and the definition of quaternion curvelet transform and its discrete algorithm were given. Then, the original color image was molded in a quaternion matrix form, and the quaternion-value of the image was analyzed in a multiresolution through quaternion curvelet transform. Furthermore, the \"min, max\" selection rule was adopted to form a multiresolution of the fused color image. Finally, the fused color image was obtained from the inverse quaternion curvelet transform. The competing multiple multifocus color image fusion methods and the proposed method were compared by the subjective and objective analysis. The experimental results indicate that the proposed method significantly solve the image blur problem, and its Image Sharpness Metric(ISM), Image Contrast Metric (ICM) and Color Colorfulness Metric(CCM) are raised considerably as compared with those of Bidimensional Empirical Mode Decomposition(BEMD)).","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073486","afid":"60073486","affilname":"Aviation University of Air Force","affiliation-city":"Changchun","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/9238980500","authid":"9238980500","authname":"Zhu M.","surname":"Zhu","given-name":"Ming","initials":"M.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55558376200","authid":"55558376200","authname":"Sun J.","surname":"Sun","given-name":"Ji Gang","initials":"J.G.","afid": [{"@_fa": "true", "$" :"60004828"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57198709408","authid":"57198709408","authname":"Liang W.","surname":"Liang","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60073486"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36450684500","authid":"36450684500","authname":"Guo L.","surname":"Guo","given-name":"Li Qiang","initials":"L.Q.","afid": [{"@_fa": "true", "$" :"60004828"}]}],"authkeywords":"Color image | Image fusion | Quaternion | Quaternion curvelet transform","source-id":"144897","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84878922686"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84878922686?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84878922686&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84878922686&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0304399113001150"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84878922686","dc:identifier":"SCOPUS_ID:84878922686","eid":"2-s2.0-84878922686","dc:title":"Boundary identification in EBSD data with a generalization of fast multiscale clustering","dc:creator":"McMahon C.","prism:publicationName":"Ultramicroscopy","prism:issn":"03043991","prism:eIssn":"18792723","prism:volume":"133","prism:pageRange":"16-25","prism:coverDate":"2013-10-01","prism:coverDisplayDate":"October 2013","prism:doi":"10.1016/j.ultramic.2013.04.009","pii":"S0304399113001150","dc:description":"Electron backscatter diffraction (EBSD) studies of cellular or subgrain microstructures present problems beyond those in the study of coarse-grained polycrystalline aggregates. In particular, identification of boundaries delineating some subgrain structures, such as microbands, cannot be accomplished simply with pixel-to-pixel misorientation thresholding because many of the boundaries are gradual transitions in crystallographic orientation. Fast multiscale clustering (FMC) is an established data segmentation technique that is combined here with quaternion representation of orientation to segment EBSD data with gradual transitions. This implementation of FMC addresses a common problem with segmentation algorithms, handling data sets with both high and low magnitude boundaries, by using a novel distance function that is a modification of Mahalanobis distance. It accommodates data representations, such as quaternions, whose features are not necessarily linearly correlated but have known distance functions. To maintain the linear run time of FMC with such data, the method requires a novel variance update rule. Although FMC was originally an algorithm for two-dimensional data segmentation, it can be generalized to analyze three-dimensional data sets. As examples, several segmentations of quaternion EBSD data sets are presented. © 2013 Elsevier B.V.","citedby-count":"21","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028333","afid":"60028333","affilname":"UNSW Sydney","affiliation-city":"Sydney","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000812","afid":"60000812","affilname":"Harvey Mudd College","affiliation-city":"Claremont","affiliation-country":"United States"}],"pubmed-id":"23751208","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56678962800","authid":"56678962800","authname":"McMahon C.","surname":"McMahon","given-name":"Cullen","initials":"C.","afid": [{"@_fa": "true", "$" :"60000812"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/37016821000","authid":"37016821000","authname":"Soe B.","surname":"Soe","given-name":"Brian","initials":"B.","afid": [{"@_fa": "true", "$" :"60000812"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55762572300","authid":"55762572300","authname":"Loeb A.","surname":"Loeb","given-name":"Andrew","initials":"A.","afid": [{"@_fa": "true", "$" :"60000812"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55763295900","authid":"55763295900","authname":"Vemulkar A.","surname":"Vemulkar","given-name":"Ayyappa","initials":"A.","afid": [{"@_fa": "true", "$" :"60000812"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7005135028","authid":"7005135028","authname":"Ferry M.","surname":"Ferry","given-name":"Michael","initials":"M.","afid": [{"@_fa": "true", "$" :"60028333"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/6603643806","authid":"6603643806","authname":"Bassman L.","surname":"Bassman","given-name":"Lori","initials":"L.","afid": [{"@_fa": "true", "$" :"60000812"}]}],"authkeywords":"Clustering | Electron backscatter diffraction | Fast multiscale clustering | Mahalanobis distance | Quaternions","source-id":"20941","fund-acr":"NSF","fund-no":"CE-05611574","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84884277222"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84884277222?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84884277222&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84884277222&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84884277222","dc:identifier":"SCOPUS_ID:84884277222","eid":"2-s2.0-84884277222","dc:title":"Low-cost MEMS-based pedestrian navigation technique for GPS-denied areas","dc:creator":"Ali A.","prism:publicationName":"Journal of Sensors","prism:issn":"1687725X","prism:eIssn":"16877268","prism:volume":"2013","prism:pageRange":null,"prism:coverDate":"2013-09-23","prism:coverDisplayDate":"2013","prism:doi":"10.1155/2013/197090","dc:description":"The progress in the micro electro mechanical system (MEMS) sensors technology in size, cost, weight, and power consumption allows for new research opportunities in the navigation field. Today, most of smartphones, tablets, and other handheld devices are fully packed with the required sensors for any navigation system such as GPS, gyroscope, accelerometer, magnetometer, and pressure sensors. For seamless navigation, the sensors' signal quality and the sensors availability are major challenges. Heading estimation is a fundamental challenge in the GPS-denied environments; therefore, targeting accurate attitude estimation is considered significant contribution to the overall navigation error. For that end, this research targets an improved pedestrian navigation by developing sensors fusion technique to exploit the gyroscope, magnetometer, and accelerometer data for device attitude estimation in the different environments based on quaternion mechanization. Results indicate that the improvement in the traveled distance and the heading estimations is capable of reducing the overall position error to be less than 15 m in the harsh environments. © 2013 Abdelrahman Ali and Naser El-Sheimy.","citedby-count":"44","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002306","afid":"60002306","affilname":"University of Calgary","affiliation-city":"Calgary","affiliation-country":"Canada"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57203757784","authid":"57203757784","authname":"Ali A.","surname":"Ali","given-name":"Abdelrahman","initials":"A.","afid": [{"@_fa": "true", "$" :"60002306"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6701545030","authid":"6701545030","authname":"El-Sheimy N.","surname":"El-Sheimy","given-name":"Naser","initials":"N.","afid": [{"@_fa": "true", "$" :"60002306"}]}],"article-number":"197090","source-id":"17700156304","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883659785"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883659785?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84883659785&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84883659785&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84883659785","dc:identifier":"SCOPUS_ID:84883659785","eid":"2-s2.0-84883659785","dc:title":"Robust gesture detection and recognition using dynamic time warping and multi-class probability estimates","dc:creator":"Pisharady P.","prism:publicationName":"Proceedings of the 2013 IEEE Symposium on Computational Intelligence for Multimedia, Signal and Vision Processing, CIMSIVP 2013 - 2013 IEEE Symposium Series on Computational Intelligence, SSCI 2013","prism:isbn": [{"@_fa": "true", "$" :"9781467359177"}],"prism:pageRange":"30-36","prism:coverDate":"2013-09-16","prism:coverDisplayDate":"2013","prism:doi":"10.1109/CIMSIVP.2013.6583844","dc:description":"A robust hand gesture detection and recognition algorithm using dynamic time warping and multi-class probability estimates is proposed. Quaternion based directional features of the hand are extracted using the color-depth camera Kinect. The directional features utilized have position and orientation invariance. Dynamic time warping of the signal sequence is done to achieve gesture size and speed invariance, and to enhance the gesture detection capability. The gestures are detected by hierarchical thresholding of the gesture probability and warping distance. Classification of gestures is done by multi-class probability estimates. The proposed algorithm is tested using a 12 class alphabet gesture database having variations in size, orientation, and speed. The algorithm provided 97.72% detection and 96.85% recognition accuracies respectively. A comparison of the proposed method with existing approaches (for detection as well as recognition) shows its better performance. © 2013 IEEE.","citedby-count":"13","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004678","afid":"60004678","affilname":"A-Star, Institute of High Performance Computing","affiliation-city":"Singapore City","affiliation-country":"Singapore"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55342672200","authid":"55342672200","authname":"Pisharady P.","surname":"Pisharady","given-name":"Pramod Kumar","initials":"P.K.","afid": [{"@_fa": "true", "$" :"60004678"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24503741600","authid":"24503741600","authname":"Saerbeck M.","surname":"Saerbeck","given-name":"Martin","initials":"M.","afid": [{"@_fa": "true", "$" :"60004678"}]}],"authkeywords":"alphabet recognition | directional features | dynamic time warping | Hand gesture recognition | hierarchical thresholding | probability estimates | quaternions","article-number":"6583844","source-id":"21100256907","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883435481"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883435481?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84883435481&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84883435481&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84883435481","dc:identifier":"SCOPUS_ID:84883435481","eid":"2-s2.0-84883435481","dc:title":"Demosaicking of Color Filter Array patterns using Quaternion Fourier Transform and low pass filter","dc:creator":"Pei S.","prism:publicationName":"Proceedings - IEEE International Symposium on Circuits and Systems","prism:issn":"02714310","prism:isbn": [{"@_fa": "true", "$" :"9781467357609"}],"prism:pageRange":"2800-2803","prism:coverDate":"2013-09-09","prism:coverDisplayDate":"2013","prism:doi":"10.1109/ISCAS.2013.6572460","dc:description":"Recently, Color Filter Array (CFA) patterns are applied popularly in a digital camera. The CFA is a mosaic-like filter which only allows one primary color to be passed and captured by the sensor at each pixel, in order to save the cost. CFA will produce a mosaic-like color image and we have to use demosaicking algorithm to recover the original color image. In this paper, we propose a new method which uses Quaternion Fourier Transform (QFT) and low pass filter to do color image demosaicking. The proposed method is tested on several common CFA patterns and the efficacy of the proposed method is also demonstrated. © 2013 IEEE.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005429","afid":"60005429","affilname":"National Taiwan University","affiliation-city":"Taipei","affiliation-country":"Taiwan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7202463605","authid":"7202463605","authname":"Pei S.","surname":"Pei","given-name":"Soo Chang","initials":"S.C.","afid": [{"@_fa": "true", "$" :"60005429"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35191694600","authid":"35191694600","authname":"Hsiao Y.","surname":"Hsiao","given-name":"Yu Zhe","initials":"Y.Z.","afid": [{"@_fa": "true", "$" :"60005429"}]}],"article-number":"6572460","source-id":"56190","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883348886"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883348886?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84883348886&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84883348886&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84883348886","dc:identifier":"SCOPUS_ID:84883348886","eid":"2-s2.0-84883348886","dc:title":"A visual attention model for news video","dc:creator":"Wu B.","prism:publicationName":"Proceedings - IEEE International Symposium on Circuits and Systems","prism:issn":"02714310","prism:isbn": [{"@_fa": "true", "$" :"9781467357609"}],"prism:pageRange":"941-944","prism:coverDate":"2013-09-09","prism:coverDisplayDate":"2013","prism:doi":"10.1109/ISCAS.2013.6572003","dc:description":"In this paper, a novel method is proposed to perform saliency detection in news video. This method comprises bottom-up attention model which considers low level features to produce bottom-up saliency map and top-down attention model which utilizes high level factors to generate top-down saliency map. In bottom-up attention model, color image is represented as quaternion. Then the quaternion discrete cosine transform is used to detect static saliency in multi-scale and two color spaces. Meanwhile, the multi-scale local and global motion conspicuity maps are computed. To suppress the background motion noise, a novel histogram of average optical flow is proposed to calculate motion contrast. Then, the static saliency map and motion saliency map are fused after normalization. In top-down attention model, we explore high level factors of news video and generate the top-down saliency map based on these factors. Finally, the bottom-up and top-down saliency maps are integrated after normalization. Experiment results show that our method outperforms several state-of-the-art methods in saliency detection of news videos. © 2013 IEEE.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029943","afid":"60029943","affilname":"Henan Normal University","affiliation-city":"Xinxiang","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005465","afid":"60005465","affilname":"University of Electronic Science and Technology of China","affiliation-city":"Chengdu","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57199977678","authid":"57199977678","authname":"Wu B.","surname":"Wu","given-name":"Bo","initials":"B.","afid": [{"@_fa": "true", "$" :"60005465"},{"@_fa": "true", "$" :"60029943"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55748551700","authid":"55748551700","authname":"Xu L.","surname":"Xu","given-name":"Linfeng","initials":"L.","afid": [{"@_fa": "true", "$" :"60005465"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55706555700","authid":"55706555700","authname":"Liu G.","surname":"Liu","given-name":"Guanghui","initials":"G.","afid": [{"@_fa": "true", "$" :"60005465"}]}],"article-number":"6572003","source-id":"56190","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883312897"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883312897?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84883312897&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84883312897&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84883312897","dc:identifier":"SCOPUS_ID:84883312897","eid":"2-s2.0-84883312897","dc:title":"Unscented Kalman filtering for attitude determination using MEMS sensors","dc:creator":"Shiau J.K.","prism:publicationName":"Journal of Applied Science and Engineering","prism:issn":"15606686","prism:volume":"16","prism:issueIdentifier":"2","prism:pageRange":"165-176","prism:coverDate":"2013-09-09","prism:coverDisplayDate":"2013","prism:doi":"10.6180/jase.2013.16.2.08","dc:description":"This paper presents the results of a quaternion-based unscented Kalman filtering for attitude estimation using low cost MEMS sensors. The unscented Kalman filter uses the pitch and roll angles computed from gravity force decomposition as the measurement for the filter. The immeasurable gravity accelerations are deduced from the outputs of the three axes accelerometers, the relative accelerations, and the accelerations due to body rotation. The constraint of the four elements of the quaternion method is treated as a perfect measurement and is integrated into the system to form a constrained unscented Kalman filter. The heading angle is obtained from a complimentary filter which uses the heading signal derived from the magnetic force information from an electronic magnetic sensor and the GPS-derived heading as the inputs. An experiment using an in-house designed motion platform is conducted to evaluate the proposed algorithm. The noise characteristics of the sensor signals are examined using the laboratory data. Approximations of the time-varying noise variances of the measured signals are obtained through Taylor series expansions. The algorithm is intuitive and easy to implement. Moreover, the proposed algorithm and the filter design are successfully demonstrated through a complete set of flight test data.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018405","afid":"60018405","affilname":"Tamkang University","affiliation-city":"New Taipei City","affiliation-country":"Taiwan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7005542972","authid":"7005542972","authname":"Shiau J.K.","surname":"Shiau","given-name":"Jaw Kuen","initials":"J.K.","afid": [{"@_fa": "true", "$" :"60018405"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55843779100","authid":"55843779100","authname":"Wang I.C.","surname":"Wang","given-name":"I. Chiang","initials":"I.C.","afid": [{"@_fa": "true", "$" :"60018405"}]}],"authkeywords":"Complementary Filter | Flight Information Measurement | Nonlinear Kalman Filter | Quaternion","source-id":"14086","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883142688"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883142688?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84883142688&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84883142688&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84883142688","dc:identifier":"SCOPUS_ID:84883142688","eid":"2-s2.0-84883142688","dc:title":"Mars science laboratory frame manager for centralized frame tree database and target pointing","dc:creator":"Kim W.S.","prism:publicationName":"Proceedings of 2013 8th International Conference on System of Systems Engineering: SoSE in Cloud Computing and Emerging Information Technology Applications, SoSE 2013","prism:isbn": [{"@_fa": "true", "$" :"9781467355971"}],"prism:pageRange":"111-116","prism:coverDate":"2013-09-03","prism:coverDisplayDate":"2013","prism:doi":"10.1109/SYSoSE.2013.6575252","dc:description":"The FM (Frame Manager) flight software module is responsible for maintaining the frame tree database containing coordinate transforms between frames. The frame tree is a proper tree structure of directed links, consisting of surface and rover subtrees. Actual frame transforms are updated by their owner. FM updates site and saved frames for the surface tree. As the rover drives to a new area, a new site frame with an incremented site index can be created. Several clients including ARM and RSM (Remote Sensing Mast) update their related rover frames that they own. Through the onboard centralized FM frame tree database, client modules can query transforms between any two frames. Important applications include target image pointing for RSM-mounted cameras and frame-referenced arm moves. The use of frame tree eliminates cumbersome, error-prone calculations of coordinate entries for commands and thus simplifies flight operations significantly. © 2013 IEEE.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009037","afid":"60009037","affilname":"Jet Propulsion Laboratory","affiliation-city":"Pasadena","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005248","afid":"60005248","affilname":"Johns Hopkins University","affiliation-city":"Baltimore","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35078954300","authid":"35078954300","authname":"Kim W.S.","surname":"Kim","given-name":"Won S.","initials":"W.S.","afid": [{"@_fa": "true", "$" :"60009037"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7006401114","authid":"7006401114","authname":"Leger C.","surname":"Leger","given-name":"Chris","initials":"C.","afid": [{"@_fa": "true", "$" :"60009037"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7201537153","authid":"7201537153","authname":"Peters S.","surname":"Peters","given-name":"Stephen","initials":"S.","afid": [{"@_fa": "true", "$" :"60009037"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/21741813700","authid":"21741813700","authname":"Carsten J.","surname":"Carsten","given-name":"Joseph","initials":"J.","afid": [{"@_fa": "true", "$" :"60009037"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55957412700","authid":"55957412700","authname":"Diaz-Calderon A.","surname":"Diaz-Calderon","given-name":"Antonio","initials":"A.","afid": [{"@_fa": "true", "$" :"60005248"}]}],"authkeywords":"Coordinate transform | flight software | Frame tree | quaternion | target pointing","article-number":"6575252","source-id":"21100255402","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84885066901"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84885066901?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84885066901&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84885066901&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84885066901","dc:identifier":"SCOPUS_ID:84885066901","eid":"2-s2.0-84885066901","dc:title":"Objective color image fusion performance index","dc:creator":"Pang H.","prism:publicationName":"Guangxue Jingmi Gongcheng/Optics and Precision Engineering","prism:issn":"1004924X","prism:volume":"21","prism:issueIdentifier":"9","prism:pageRange":"2348-2353","prism:coverDate":"2013-09-01","prism:coverDisplayDate":"September 2013","prism:doi":"10.3788/OPE.20132109.2348","dc:description":"As existing objective evaluation index for color image fusion is inconsistent with the human vision perception, a non-reference index based on quaternion convolution was proposed. First, a color image was modeled in a holistic manner, in which the color information of the color image was considered fully as a whole. Then, the quaternion-valued edge detection template and the color image were used to do a convolution operation and to get the detailed color information. Furthermore, the image definition and useful information from the fusion were measured and they were given by weight modes. Finally, a set of quantitative computations for the fusion images were performed and objective evaluation results were given. The experimental results show that the proposed method can utilize the color information and other detail information obtained by human vision. It works better than the traditional methods, and shows a better stability in the color image fusion evaluation. The evaluation results of proposed method are consistent with the human vision perception, and fulfill the needs of objective color image fusion.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35234570300","authid":"35234570300","authname":"Pang H.","surname":"Pang","given-name":"Hao Chen","initials":"H.C.","afid": [{"@_fa": "true", "$" :"60004828"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/9238980500","authid":"9238980500","authname":"Zhu M.","surname":"Zhu","given-name":"Ming","initials":"M.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/36450684500","authid":"36450684500","authname":"Guo L.","surname":"Guo","given-name":"Li Qiang","initials":"L.Q.","afid": [{"@_fa": "true", "$" :"60004828"}]}],"authkeywords":"Color image | Image fusion | Objective evaluation index | Quaternion convolution","source-id":"144897","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883816735"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84883816735?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84883816735&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84883816735&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84883816735","dc:identifier":"SCOPUS_ID:84883816735","eid":"2-s2.0-84883816735","dc:title":"A fast calculation strategy of density function in ISAF reconstruction algorithm","dc:creator":"Wang G.M.","prism:publicationName":"Science China Information Sciences","prism:issn":"1674733X","prism:volume":"56","prism:issueIdentifier":"9","prism:pageRange":"1-12","prism:coverDate":"2013-09-01","prism:coverDisplayDate":"September 2013","prism:doi":"10.1007/s11432-011-4429-y","dc:description":"The ISAF reconstruction algorithm is a new method for reconstructing icosahedral molecules from their projections. This algorithm works in spherical coordinate system and can achieve higher resolution than the traditional Fourier-Bessel algorithm in cylindrical coordinate system; however this method needs huge computations, which limits its application in reality. The main bottleneck lies in the calculation of density function as it occupies 90% running time of the whole algorithm. A fast calculation strategy of density function is proposed to solve this problem. This strategy is composed of three components: the fast calculation method of density function of mesh point in spherical coordinate system, the transformation method of density function of mesh point from spherical coordinate system to Cartesian coordinate system and the fast two-phase mapping method. The time complexity of calculating density function is decreased from O[(LM)8] to O[(LM)7] in our strategy. The experimental results on Psv-F simulated data indicate that the speed of calculating density function is increased almost two orders of magnitude and the speedup of the whole algorithm could reach 30 times. In addition, the speedup could go up with the increase in the number of images and the requirement of accuracy. © 2012 Science China Press and Springer-Verlag Berlin Heidelberg.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030904","afid":"60030904","affilname":"Institute of Computing Technology Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022933","afid":"60022933","affilname":"IBM Research - China","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013625","afid":"60013625","affilname":"Institute of Biophysics Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55738590200","authid":"55738590200","authname":"Wang G.M.","surname":"Wang","given-name":"Gong Ming","initials":"G.M.","afid": [{"@_fa": "true", "$" :"60030904"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35340251400","authid":"35340251400","authname":"Zhang F.","surname":"Zhang","given-name":"Fa","initials":"F.","afid": [{"@_fa": "true", "$" :"60030904"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/37013210700","authid":"37013210700","authname":"Chu Q.","surname":"Chu","given-name":"Qi","initials":"Q.","afid": [{"@_fa": "true", "$" :"60030904"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36023348300","authid":"36023348300","authname":"Fan L.Y.","surname":"Fan","given-name":"Li Ya","initials":"L.Y.","afid": [{"@_fa": "true", "$" :"60022933"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55681446000","authid":"55681446000","authname":"Sun F.","surname":"Sun","given-name":"Fei","initials":"F.","afid": [{"@_fa": "true", "$" :"60013625"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/56118218400","authid":"56118218400","authname":"Liu Z.Y.","surname":"Liu","given-name":"Zhi Yong","initials":"Z.Y.","afid": [{"@_fa": "true", "$" :"60030904"}]}],"authkeywords":"3D reconstruction | density function | ISAF | quaternion interpolation | spherical coordinate system","source-id":"19600161832","fund-acr":"CAS","fund-no":"61003164","fund-sponsor":"Chinese Academy of Sciences","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877990916"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877990916?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84877990916&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84877990916&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165168413000649"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84877990916","dc:identifier":"SCOPUS_ID:84877990916","eid":"2-s2.0-84877990916","dc:title":"Unsupervised color-texture segmentation based on multiscale quaternion Gabor filters and splitting strategy","dc:creator":"Li L.","prism:publicationName":"Signal Processing","prism:issn":"01651684","prism:volume":"93","prism:issueIdentifier":"9","prism:pageRange":"2559-2572","prism:coverDate":"2013-09-01","prism:coverDisplayDate":"September 2013","prism:doi":"10.1016/j.sigpro.2013.02.010","pii":"S0165168413000649","dc:description":"This paper proposes a new method for color-texture segmentation based on a splitting framework with graph cut technique. To process the scale difference of quaternion Gabor filter (QGF) features of a color textured image, a new multiscale QGF (MQGF) is introduced to describe texture attributes of the given image. Then, the segmentation is formulated in terms of energy minimization gradually obtained using binary graph cuts, where color and MQGF features are modeled with a multivariate finite mixture model, and minimum description length (MDL) principle is integrated into this framework as a splitting criterion. In contrast to previous approaches, our method finds an optimal segmentation by balancing energy cost and coding length, and the segmentation result is determined during the splitting process automatically. Experimental results on both synthetic and real natural color textured images demonstrate the good performance of the proposed method. © 2013 Elsevier B.V. All rights reserved.","citedby-count":"25","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025761","afid":"60025761","affilname":"Huazhong University of Science and Technology","affiliation-city":"Wuhan","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001604","afid":"60001604","affilname":"Ministry of Education China","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56104314900","authid":"56104314900","authname":"Li L.","surname":"Li","given-name":"Lei","initials":"L.","afid": [{"@_fa": "true", "$" :"60025761"},{"@_fa": "true", "$" :"60001604"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/15922652500","authid":"15922652500","authname":"Jin L.","surname":"Jin","given-name":"Lianghai","initials":"L.","afid": [{"@_fa": "true", "$" :"60025761"},{"@_fa": "true", "$" :"60001604"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55706250100","authid":"55706250100","authname":"Xu X.","surname":"Xu","given-name":"Xiangyang","initials":"X.","afid": [{"@_fa": "true", "$" :"60025761"},{"@_fa": "true", "$" :"60001604"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/23767272300","authid":"23767272300","authname":"Song E.","surname":"Song","given-name":"Enmin","initials":"E.","afid": [{"@_fa": "true", "$" :"60025761"},{"@_fa": "true", "$" :"60001604"}]}],"authkeywords":"Color-texture segmentation | Graph cuts | Minimum description length | Multiscale quaternion Gabor filter","source-id":"25548","fund-acr":"NSFC","fund-no":"60972098","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877017249"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877017249?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84877017249&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84877017249&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165168413000601"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84877017249","dc:identifier":"SCOPUS_ID:84877017249","eid":"2-s2.0-84877017249","dc:title":"Prediction of wide-sense stationary quaternion random signals","dc:creator":"Navarro-Moreno J.","prism:publicationName":"Signal Processing","prism:issn":"01651684","prism:volume":"93","prism:issueIdentifier":"9","prism:pageRange":"2573-2580","prism:coverDate":"2013-09-01","prism:coverDisplayDate":"September 2013","prism:doi":"10.1016/j.sigpro.2013.02.007","pii":"S0165168413000601","dc:description":"An efficient widely linear prediction algorithm is introduced for the class of wide-sense stationary quaternion signals. Specifically, using second order statistics information in the quaternion domain, a multivariate Durbin-Levison-like algorithm is derived. The proposed solution can be applied under a very general formulation of the problem, allowing for the estimation of a function of the quaternion signal which is observed through a system with both additive/multiplicative noises. © 2013 Elsevier B.V. All rights reserved.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021097","afid":"60021097","affilname":"University of Surrey","affiliation-city":"Guildford","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015150","afid":"60015150","affilname":"Imperial College London","affiliation-city":"London","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60014586","afid":"60014586","affilname":"Universidad de Jaén","affiliation-city":"Jaen","affiliation-country":"Spain"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6602299200","authid":"6602299200","authname":"Navarro-Moreno J.","surname":"Navarro-Moreno","given-name":"Jesús","initials":"J.","afid": [{"@_fa": "true", "$" :"60014586"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6506232550","authid":"6506232550","authname":"Fernández-Alcalá R.","surname":"Fernández-Alcalá","given-name":"Rosa M.","initials":"R.M.","afid": [{"@_fa": "true", "$" :"60014586"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56614550100","authid":"56614550100","authname":"Cheong Took C.","surname":"Cheong Took","given-name":"Clive","initials":"C.","afid": [{"@_fa": "true", "$" :"60021097"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7006513328","authid":"7006513328","authname":"Mandic D.","surname":"Mandic","given-name":"Danilo P.","initials":"D.P.","afid": [{"@_fa": "true", "$" :"60015150"}]}],"authkeywords":"Quaternion random signals | Widely linear prediction","source-id":"25548","fund-acr":"EPSRC","fund-no":"EP/H026266/1","fund-sponsor":"Engineering and Physical Sciences Research Council","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881319947"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881319947?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84881319947&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84881319947&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84881319947","dc:identifier":"SCOPUS_ID:84881319947","eid":"2-s2.0-84881319947","dc:title":"Correcting Smartphone orientation for accelerometer-based analysis","dc:creator":"Tundo M.D.","prism:publicationName":"MeMeA 2013 - IEEE International Symposium on Medical Measurements and Applications, Proceedings","prism:isbn": [{"@_fa": "true", "$" :"9781467351966"}],"prism:pageRange":"58-62","prism:coverDate":"2013-08-15","prism:coverDisplayDate":"2013","prism:doi":"10.1109/MeMeA.2013.6549706","dc:description":"A method was developed for rotating a Smartphone accelerometer coordinate system from an offset to a predetermined three-dimensional position to improve accelerometer-based activity identification. A quaternion-based rotation matrix was constructed from an axis-angle pair, produced via algebraic manipulations of the gravity acceleration components in the device's body-fixed frame of reference with the desired position of the vector. The rotation matrix is constructed during quiet standing and then applied to all subsequent accelerometer readings thereafter, transforming their values in this new fixed frame. This method provides a consistent accelerometer orientation between people, thereby reducing Smartphone orientation variability that can adversely affect activity classification algorithms. © 2013 IEEE.","citedby-count":"34","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028897","afid":"60028897","affilname":"University of Ottawa","affiliation-city":"Ottawa","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002173","afid":"60002173","affilname":"Ottawa Hospital Research Institute","affiliation-city":"Ottawa","affiliation-country":"Canada"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55817805000","authid":"55817805000","authname":"Tundo M.D.","surname":"Tundo","given-name":"Marco D.","initials":"M.D.","afid": [{"@_fa": "true", "$" :"60028897"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7006574087","authid":"7006574087","authname":"Lemaire E.","surname":"Lemaire","given-name":"Edward","initials":"E.","afid": [{"@_fa": "true", "$" :"60002173"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57216001833","authid":"57216001833","authname":"Baddour N.","surname":"Baddour","given-name":"Natalie","initials":"N.","afid": [{"@_fa": "true", "$" :"60028897"}]}],"authkeywords":"accelerometer | calibration | orientation | quaterion | rotation","article-number":"6549706","source-id":"21100248836","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881186288"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881186288?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84881186288&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84881186288&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84881186288","dc:identifier":"SCOPUS_ID:84881186288","eid":"2-s2.0-84881186288","dc:title":"Multi-camera rigid body pose estimation using higher order dynamic models","dc:creator":"Forsman A.E.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9780819495358"}],"prism:volume":"8744","prism:pageRange":null,"prism:coverDate":"2013-08-12","prism:coverDisplayDate":"2013","prism:doi":"10.1117/12.2015539","dc:description":"We describe a Bayesian filtering process that estimates the pose (3-D position and orientation) of a moving rigid body using multiple cameras. The estimator also produces an arbitrary number of pose derivatives. We first discuss various ways to represent 3-D orientation. Unfortunately all 3-parameter representations have areas of instability. Higher dimensional representations are stable but require unwieldy constraints. Our combination of an axis-angle vector with a unit quaternion represents orientation minimally while remaining stable under realistic circumstances. Our dynamic model of rigid body motion can include an arbitrary number of derivatives, and we explicitly develop it up to the third order. Our observation model takes a predicted pose and produces the 2-D locations in each camera's image plane of the visible features on the body's surface. We provide noise terms for both the dynamic and observation models. We describe how our models are used in extended and unscented Kalman filters, and also in a particle filter. As a baseline we also describe a non-linear least squares method that uses just our observation model. We construct a synthetic testing scenario, and use root-mean-square error analysis to grade the relative performance of each model/filter combination. We derive the Cramer-Rao lower bound that gives the best achievable performance for our particular scenario. Our results show that adding derivatives to the state vector significantly improves the accuracy of pose estimates, and we also show that an unscented Kalman filter with a second order dynamic model is best suited to the task. © 2013 SPIE.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022054","afid":"60022054","affilname":"Johns Hopkins University Applied Physics Laboratory","affiliation-city":"Laurel","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004306","afid":"60004306","affilname":"Naval Air Warfare Center Aircraft Division","affiliation-city":"Patuxent River","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57225830108","authid":"57225830108","authname":"Forsman A.E.","surname":"Forsman","given-name":"Alec E.","initials":"A.E.","afid": [{"@_fa": "true", "$" :"60004306"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56700123300","authid":"56700123300","authname":"Schug D.A.","surname":"Schug","given-name":"David A.","initials":"D.A.","afid": [{"@_fa": "true", "$" :"60004306"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7102013560","authid":"7102013560","authname":"Haug A.J.","surname":"Haug","given-name":"Anton J.","initials":"A.J.","afid": [{"@_fa": "true", "$" :"60022054"}]}],"authkeywords":"Bayesian estimation | Tracking","article-number":"874407","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881163693"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881163693?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84881163693&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84881163693&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84881163693","dc:identifier":"SCOPUS_ID:84881163693","eid":"2-s2.0-84881163693","dc:title":"Performance analysis of adaptive DOA estimation algorithms for mobile applications","dc:creator":"Prasanna Kumar A.M.","prism:publicationName":"Lecture Notes in Electrical Engineering","prism:issn":"18761100","prism:eIssn":"18761119","prism:isbn": [{"@_fa": "true", "$" :"9788132215233"}],"prism:volume":"258 LNEE","prism:pageRange":"413-422","prism:coverDate":"2013-08-12","prism:coverDisplayDate":"2013","prism:doi":"10.1007/978-81-322-1524-0_49","dc:description":"Spatial filtering for mobile communications has attracted a lot of attention over the last decade and is currently considered a very promising technique that will help future cellular networks achieve their ambitious goals. One way to accomplish this is via array signal processing with algorithms which estimate the direction-of-arrival (DOA) of the received waves from the mobile users. This paper evaluates the performance of a number of DOA estimation algorithms. In all cases, a linear antenna array at the base station is assumed to be operating typical cellular environment. © 2013 Springer.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60114492","afid":"60114492","affilname":"Dayananda Sagar College of Engineering","affiliation-city":"Bengaluru","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105239","afid":"60105239","affilname":"ACS College of Engineering","affiliation-city":"Bengaluru","affiliation-country":"India"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55814185600","authid":"55814185600","authname":"Prasanna Kumar A.M.","surname":"Prasanna Kumar","given-name":"A. M.","initials":"A.M.","afid": [{"@_fa": "true", "$" :"60105239"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58142529100","authid":"58142529100","authname":"Suresh K.","surname":"Suresh","given-name":"K.","initials":"K.","afid": [{"@_fa": "true", "$" :"60114492"}]}],"authkeywords":"Direction-of-arrival | ESPRIT | MUSIC | Quaternion MUSIC","source-id":"19700186822","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881129642"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84881129642?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84881129642&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84881129642&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84881129642","dc:identifier":"SCOPUS_ID:84881129642","eid":"2-s2.0-84881129642","dc:title":"Progress in multi-channel image fusion for face image matching","dc:creator":"DelMarco S.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9780819495464"}],"prism:volume":"8755","prism:pageRange":null,"prism:coverDate":"2013-08-12","prism:coverDisplayDate":"2013","prism:doi":"10.1117/12.2014281","dc:description":"Fusion techniques have proven to be very useful for many signal and image processing applications including image recognition, image registration, and biometric matching. Along with standard fusion techniques, hypercomplex image processing techniques have been developed recently. These techniques represent a form of image fusion in which several image components are combined to form a multi-channel image. The multi-channel imagery may be processed using hypercomplex transforms, such as the hypercomplex Fourier transform, for image matching and registration. In this paper we investigate performance of multi-channel image fusion for face image matching. We use 3-D color face imagery and investigate fusion of various combinations of grayscale intensity, color, and range information. We conduct a theoretical investigation to identify conditions under which matchers using image channel fusion provide superior matching performance relative to matchers fusing single channel image matching results. We present numerical performance results in the form of Receiver Operating Characteristics curves quantifying matching performance for verification hypothesis testing problems. © 2013 SPIE.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017016","afid":"60017016","affilname":"BAE Systems Inc.","affiliation-city":"Arlington","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8835566600","authid":"8835566600","authname":"DelMarco S.","surname":"DelMarco","given-name":"Stephen","initials":"S.","afid": [{"@_fa": "true", "$" :"60017016"}]}],"authkeywords":"Face matching | Hypercomplex | Phase correlation | Quaternion","article-number":"87550H","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880548178"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880548178?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880548178&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880548178&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880548178","dc:identifier":"SCOPUS_ID:84880548178","eid":"2-s2.0-84880548178","dc:title":"Families of hadamard Z<inf>2Z4</inf>Z<inf>8</inf>-codes","dc:creator":"Del Rio A.","prism:publicationName":"IEEE Transactions on Information Theory","prism:issn":"00189448","prism:volume":"59","prism:issueIdentifier":"8","prism:pageRange":"5140-5151","prism:coverDate":"2013-07-29","prism:coverDisplayDate":"2013","prism:doi":"10.1109/TIT.2013.2258373","dc:description":"A Z2Z4Q8-code is the binary image, after a Gray map, of a subgroup of BBZ2k-1×\\BBZ4k 2× Q8 k3, where Q8 is the quaternion group on eight elements. Such BBZ2\\BBZ4Q8-codes are translation invariant propelinear codes as are the well known BBZ 4-linear or BBZ2BBZ4-linear codes. In this paper, we show that there exist 'pure' BBZ-2 BBZ4Q 8-codes, that is, codes that do not admit any abelian translation invariant propelinear structure. We study the dimension of the kernel and rank of the BBZ 2\\BBZ4Q8-codes, and we give upper and lower bounds for these parameters. We give tools to construct a new class of Hadamard codes formed by several families of BBZ2\\BBZ 4Q8-codes; we classify such codes from an algebraic point of view and we improve the upper and lower bounds for the rank and the dimension of the kernel when the codes are Hadamard. © 2013 IEEE.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023020","afid":"60023020","affilname":"Universitat Autònoma de Barcelona","affiliation-city":"Cerdanyola del Valles","affiliation-country":"Spain"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000130","afid":"60000130","affilname":"Universidad de Murcia","affiliation-city":"Murcia","affiliation-country":"Spain"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7005001527","authid":"7005001527","authname":"Del Rio A.","surname":"Del Rio","given-name":"Angel","initials":"A.","afid": [{"@_fa": "true", "$" :"60000130"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003423531","authid":"7003423531","authname":"Rifa J.","surname":"Rifa","given-name":"Josep","initials":"J.","afid": [{"@_fa": "true", "$" :"60023020"}]}],"authkeywords":"1-perfect codes | BBZ BBZ Q  -codes 2 4 8 | Hadamard codes | propelinear codes | translation invariant codes","article-number":"6508950","source-id":"15107","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880534060"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880534060?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880534060&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880534060&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880534060","dc:identifier":"SCOPUS_ID:84880534060","eid":"2-s2.0-84880534060","dc:title":"New feature extraction approach for bank note classification using Quaternion Wavelets","dc:creator":"Gai S.","prism:publicationName":"Journal of Intelligent and Fuzzy Systems","prism:issn":"10641246","prism:eIssn":"18758967","prism:volume":"25","prism:issueIdentifier":"3","prism:pageRange":"685-694","prism:coverDate":"2013-07-29","prism:coverDisplayDate":"2013","prism:doi":"10.3233/IFS-120675","dc:description":"In order to improve the performance of the banknote image classification, new feature extraction method based on quaternion wavelet transform (QWT) is proposed in this article. The QWT yields one shift-invariant magnitude and three phases by the quaternion algebra. The statistical characteristics such as mean, standard deviation and entropy are used as feature vector in the banknote image classification. The experimental results show that the proposed method by the QWT obtains better classification results than the conventional methods. © 2013 - IOS Press and the authors. All rights reserved.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/106924141","afid":"106924141","affilname":"Hangkong University","affiliation-city":"Nanchang","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35748407200","authid":"35748407200","authname":"Gai S.","surname":"Gai","given-name":"Shan","initials":"S.","afid": [{"@_fa": "true", "$" :"106924141"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7405754282","authid":"7405754282","authname":"Yang G.","surname":"Yang","given-name":"Guowei","initials":"G.","afid": [{"@_fa": "true", "$" :"106924141"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57770769500","authid":"57770769500","authname":"Zhang S.","surname":"Zhang","given-name":"Sheng","initials":"S.","afid": [{"@_fa": "true", "$" :"106924141"}]}],"authkeywords":"banknote classification | Feature extraction | quaternion algebra | quaternion wavelet transform","source-id":"23917","fund-acr":"NSFC","fund-no":"61202319","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880414910"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880414910?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880414910&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880414910&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880414910","dc:identifier":"SCOPUS_ID:84880414910","eid":"2-s2.0-84880414910","dc:title":"Performance analysis for interference and noise canceller based on hypercomplex and spatiotemporal-polarisation processes","dc:creator":"Tao J.","prism:publicationName":"IET Radar, Sonar and Navigation","prism:issn":"17518784","prism:volume":"7","prism:issueIdentifier":"3","prism:pageRange":"277-286","prism:coverDate":"2013-07-26","prism:coverDisplayDate":"2013","prism:doi":"10.1049/iet-rsn.2012.0151","dc:description":"In this study, the problem of spatio-temporal-polarisation filtering based on hypercomplex processes is considered for an electromagnetic (EM) vector-sensor array. The quaternion domain facilitates modelling and processing of four-dimensional real signals (or two-dimensional complex signals). Based on the quaternion model of linear symmetric array with twocomponents EM vector-sensors, an interference and noise canceller (INC) is presented for polarised signals. Then, the output signal to interference-plus-noise ratio (SINR) expression of INC is derived and its performance is analysed. The performance analysis reveal explicitly the fact that even though no separation between the direction of arrival (DOAs) of the desired signal and interference, the maximum value of output SINR can be obtained employing the orthogonality between the polarisations of the desired signal and interference. Simulation results show that if sample size N is large enough, the INC has larger output SINR and better robustness against the DOA mismatch.","citedby-count":"23","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073486","afid":"60073486","affilname":"Aviation University of Air Force","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8534150300","authid":"8534150300","authname":"Tao J.","surname":"Tao","given-name":"Jian Wu","initials":"J.W.","afid": [{"@_fa": "true", "$" :"60073486"}]}],"source-id":"5700165202","fund-acr":"NSFC","fund-no":"60872088","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880474637"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880474637?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880474637&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880474637&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880474637","dc:identifier":"SCOPUS_ID:84880474637","eid":"2-s2.0-84880474637","dc:title":"Texture feature extraction for color images based on quaternion representation","dc:creator":"Huang C.","prism:publicationName":"Advanced Materials Research","prism:issn":"10226680","prism:isbn": [{"@_fa": "true", "$" :"9783037857243"}],"prism:volume":"712-715","prism:pageRange":"2336-2340","prism:coverDate":"2013-07-25","prism:coverDisplayDate":"2013","prism:doi":"10.4028/www.scientific.net/AMR.712-715.2336","dc:description":"In order to get texture features of color image, we proposed a new algorithm which is adapted to extract the texture features for color images in this paper. Firstly, the proposed method adopt quaternion to color image processing that can represent the color image in a holistic manner and parallel processing the R, G and B components. Secondly, we can obtain the directional information and texture features by Quaternion Gabor Filter. The experimental results show that texture feature obtained by our method has good the discrimination power and classifing performance. © (2013) Trans Tech Publications, Switzerland.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60082832","afid":"60082832","affilname":"Shangqiu Normal University","affiliation-city":"Shangqiu","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002980","afid":"60002980","affilname":"Southwest University of Science and Technology","affiliation-city":"Mianyang","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/25927888600","authid":"25927888600","authname":"Huang C.","surname":"Huang","given-name":"Chuan Bo","initials":"C.B.","afid": [{"@_fa": "true", "$" :"60002980"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55799952800","authid":"55799952800","authname":"Zhou Z.","surname":"Zhou","given-name":"Zi Ping","initials":"Z.P.","afid": [{"@_fa": "true", "$" :"60082832"}]}],"authkeywords":"Quaternion | Quaternion gabor filter | Texture features","source-id":"4700151906","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880283140"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880283140?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880283140&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880283140&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0094576513002129"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880283140","dc:identifier":"SCOPUS_ID:84880283140","eid":"2-s2.0-84880283140","dc:title":"Relative position and attitude estimation of spacecrafts based on dual quaternion for rendezvous and docking","dc:creator":"Qiao B.","prism:publicationName":"Acta Astronautica","prism:issn":"00945765","prism:volume":"91","prism:pageRange":"237-244","prism:coverDate":"2013-07-23","prism:coverDisplayDate":"2013","prism:doi":"10.1016/j.actaastro.2013.06.022","pii":"S0094576513002129","dc:description":"The capacity to acquire the relative position and attitude information between the chaser and the target satellites in real time is one of the necessary prerequisites for the successful implementation of autonomous rendezvous and docking. This paper addresses a vision based relative position and attitude estimation algorithm for the final phase of spacecraft rendezvous and docking. By assuming that the images of feature points on the target satellite lie within the convex regions, the estimation of the relative position and attitude is converted into solving a convex optimization problem in which the dual quaternion method is employed to represent the rotational and translational transformation between the chaser body frame and the target body frame. Due to the point-to-region correspondence instead of the point-to-point correspondence is used, the proposed estimation algorithm shows good performance in robustness which is verified through computer simulations. © 2013 IAA.","citedby-count":"41","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113193302","afid":"113193302","affilname":"Aerospace System Engineering Shanghai","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006923558","authid":"7006923558","authname":"Qiao B.","surname":"Qiao","given-name":"Bing","initials":"B.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24465858900","authid":"24465858900","authname":"Tang S.","surname":"Tang","given-name":"Shuren","initials":"S.","afid": [{"@_fa": "true", "$" :"113193302"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/53664017000","authid":"53664017000","authname":"Ma K.","surname":"Ma","given-name":"Kexin","initials":"K.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55796451600","authid":"55796451600","authname":"Liu Z.","surname":"Liu","given-name":"Zhenya","initials":"Z.","afid": [{"@_fa": "true", "$" :"60021666"}]}],"authkeywords":"Autonomous on-orbit servicing | Dual quaternion | Relative position and attitude estimation | Rendezvous and docking | Spacecraft","source-id":"12372","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880265150"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880265150?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880265150&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880265150&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0096300313006462"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880265150","dc:identifier":"SCOPUS_ID:84880265150","eid":"2-s2.0-84880265150","dc:title":"On solutions of the quaternion matrix equation AX = B and their applications in color image restoration","dc:creator":"Yuan S.","prism:publicationName":"Applied Mathematics and Computation","prism:issn":"00963003","prism:volume":"221","prism:pageRange":"10-20","prism:coverDate":"2013-07-23","prism:coverDisplayDate":"2013","prism:doi":"10.1016/j.amc.2013.05.069","pii":"S0096300313006462","dc:description":"By using the complex representation of quaternion matrices, and the Moore-Penrose generalized inverse, we derive the expressions of the least squares solution with the least norm, the least squares pure imaginary solution with the least norm, and the least squares real solution with the least norm for the quaternion matrix equation AX=B, respectively. Finally, we discuss their applications in color image restoration. © 2013 Elsevier Inc. All rights reserved.","citedby-count":"39","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023813","afid":"60023813","affilname":"Shanghai University","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021751","afid":"60021751","affilname":"Wuyi University","affiliation-city":"Wuyishan","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008919","afid":"60008919","affilname":"Guilin University of Electronic Technology","affiliation-city":"Guilin","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55455311900","authid":"55455311900","authname":"Yuan S.","surname":"Yuan","given-name":"Shi Fang","initials":"S.F.","afid": [{"@_fa": "true", "$" :"60021751"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55780759900","authid":"55780759900","authname":"Wang Q.","surname":"Wang","given-name":"Qing Wen","initials":"Q.W.","afid": [{"@_fa": "true", "$" :"60023813"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/23984647900","authid":"23984647900","authname":"Duan X.","surname":"Duan","given-name":"Xue Feng","initials":"X.F.","afid": [{"@_fa": "true", "$" :"60008919"}]}],"authkeywords":"Image restoration | Kronecker product | Least squares solution | Matrix equation | Moore-Penrose generalized inverse | Quaternion matrices","source-id":"25170","fund-acr":"NSFC","fund-no":"LYM10128","fund-sponsor":"Natural Science Foundation of Shanghai","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880180253"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84880180253?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84880180253&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84880180253&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84880180253","dc:identifier":"SCOPUS_ID:84880180253","eid":"2-s2.0-84880180253","dc:title":"Appearance-based color face recognition with 3D model","dc:creator":"Wang C.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9780819495662"}],"prism:volume":"8768","prism:pageRange":null,"prism:coverDate":"2013-07-19","prism:coverDisplayDate":"2013","prism:doi":"10.1117/12.2003304","dc:description":"Appearance-based face recognition approaches explore color cues of face images, i.e. grey or color information for recognition task. They first encode color face images, and then extract facial features for classification. Similar to conventional singular value decomposition, hypercomplex matrix also exists singular value decomposition on hypercomplex field. In this paper, a novel color face recognition approach based on hypercomplex singular value decomposition is proposed. The approach employs hypercomplex to encode color face information of different channels simultaneously. Hypercomplex singular value decomposition is utilized then to compute the basis vectors of the color face subspace. To improve learning efficiency of the algorithm, 3D active deformable model is exploited to generate virtual face images. Color face samples are projected onto the subspace and projection coefficients are utilized as facial features. Experimental results on CMU PIE face database verify the effectiveness of the proposed approach. © 2013 SPIE.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60014337","afid":"60014337","affilname":"Capital University of EcoNomics and Business","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013131","afid":"60013131","affilname":"Central University of Finance and Economics","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55768087200","authid":"55768087200","authname":"Wang C.","surname":"Wang","given-name":"Chengzhang","initials":"C.","afid": [{"@_fa": "true", "$" :"60013131"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55767641100","authid":"55767641100","authname":"Bai X.","surname":"Bai","given-name":"Xiaoming","initials":"X.","afid": [{"@_fa": "true", "$" :"60014337"}]}],"authkeywords":"Color face | Face recognition | Hypercomplex singular value decomposition","article-number":"87680J","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}