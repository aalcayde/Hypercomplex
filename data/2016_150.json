{"search-results":{"opensearch:totalResults":"203","opensearch:startIndex":"150","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "150"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=150&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2016&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2016&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2016&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=175&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2016&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=178&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2016&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85047185405"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85047185405?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85047185405&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85047185405&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85047185405","dc:identifier":"SCOPUS_ID:85047185405","eid":"2-s2.0-85047185405","dc:title":"IET Seminar Digest","prism:publicationName":"IET Seminar Digest","prism:volume":"2016","prism:issueIdentifier":"6","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","dc:description":"The proceedings contain 26 papers. The topics discussed include: learning a similarity measure for striated toolmarks using convolutional neural networks; on-line normality modeling and anomaly event detection using spatio-temporal motion patterns; detecting acceleration for gait and crime scene analysis; an efficient approach to enhance the performance of fingerprint recognition; designing a facial spoofing database for processed image attacks; disguised face identification using multi-modal features in a quaternionic form; detecting sensor level spoof attacks using joint encoding of temporal and spatial features; and using keystroke and mouse dynamics for user identification in the online collaborative game league of legends.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"5100154507","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046058245"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046058245?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046058245&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85046058245&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85046058245","dc:identifier":"SCOPUS_ID:85046058245","eid":"2-s2.0-85046058245","dc:title":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","dc:description":"The proceedings contain 24 papers. The topics discussed include: combined full-reference image visual quality metrics; automatic face anonymization in visual data: are we really well protected?; non photorealistic rendering in frequency domain; comparison study of Gaussian mixture models for fingerprint image duplication with a new model; image stitching by means of adaptive normalization; video inpainting of complex scenes based on local statistical model; spatio-temporal video background inpainting; video segmentation in presence of static and dynamic textures; refractory neural nets and vision – a deeper look; prostate cancer detection using photoacoustic imaging and deep learning; approximate subgraph isomorphism for image localization; 2-D left-side quaternion discrete Fourier transform: fast algorithm; intelligent image filtering using multilayer neural network with multi-valued neurons; optimal transparent wavelength and arrangement for multispectral filter array; edge-directional interpolation algorithm using structure tensor; zonal-alpha-rooting color image enhancement by the two-side 2d quaternion discrete Fourier transform; jpeg compression with recursive group coding; and video quality of experience metric for streaming services.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"21100846961","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046057774"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046057774?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046057774&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85046057774&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85046057774","dc:identifier":"SCOPUS_ID:85046057774","eid":"2-s2.0-85046057774","dc:title":"2-D left-Side quaternion discrete fourier transform: Fast algorithm","dc:creator":"Grigoryan A.M.","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.2352/ISSN.2470-1173.2016.15.IPAS-192","dc:description":"Two-dimension discrete Fourier transform (2-D DFT) is a fundamental tool in grays-scale image processing. In color imaging, this transform is used to process separately color channels and such processing does not consider interactions between the color channels. The concept of the quaternion discrete Fourier transform (QDFT) became a very popular topic in color imaging. The color image from one of the color model, for instance the RGB model, can be transformed into the quaternion Algebra and be represented as one quaternion image which allows to process simultaneously of all color components of the image. In this work, we describe the algorithm for the 2-D left-side QDFT which is based on the concept of the tensor representation when the color or quaternion image is described by a set of 1-D quaternion signals and the 1-D left-side QDFTs over these signals determine values of the 2-D left-side QDFT at corresponding subset of frequency-points. The efficiency of the tensor algorithm for calculating the fast left-side 2-D QDFT is described and compared with the existent methods.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003212","afid":"60003212","affilname":"The University of Texas at San Antonio","affiliation-city":"San Antonio","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006123399","authid":"7006123399","authname":"Grigoryan A.M.","surname":"Grigoryan","given-name":"Artyom M.","initials":"A.M.","afid": [{"@_fa": "true", "$" :"60003212"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003395533","authid":"7003395533","authname":"Agaian S.S.","surname":"Agaian","given-name":"Sos S.","initials":"S.S.","afid": [{"@_fa": "true", "$" :"60003212"}]}],"source-id":"21100846961","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046054858"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046054858?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046054858&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85046054858&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85046054858","dc:identifier":"SCOPUS_ID:85046054858","eid":"2-s2.0-85046054858","dc:title":"Zonal-Alpha-Rooting color image enhancement by the two-Side 2D quaternion discrete fourier transform","dc:creator":"Grigoryan A.","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.2352/ISSN.2470-1173.2016.15.IPAS-195","dc:description":"The purpose of image enhancement is to improve the quality of a digital image, so as to support the human perception. In this paper, new methods of image enhancement are proposed for enhancement of color images, which are based on application of the concept of the two-dimensional quaternion discrete Fourier transform (QDFT) together with the well-known method of the alpha-rooting. The application of the alpha-rooting method which is based on the traditional two-dimensional discrete Fourier transform (2-D DFT) results in high quality images, when comparing with other transforms, such as Hadamard, Hartley, cosine, and heap transforms. The image enhancement technique of alpha-rooting can be used for enhancing even low contrast images. In zonal alpha-rooting method, the modification of frequency is different for different frequency zones. Optimization of alpha value is done with genetic algorithm.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003212","afid":"60003212","affilname":"The University of Texas at San Antonio","affiliation-city":"San Antonio","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006123399","authid":"7006123399","authname":"Grigoryan A.","surname":"Grigoryan","given-name":"Artyom M.","initials":"A.M.","afid": [{"@_fa": "true", "$" :"60003212"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57194467413","authid":"57194467413","authname":"John A.","surname":"John","given-name":"Aparna","initials":"A.","afid": [{"@_fa": "true", "$" :"60003212"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7003395533","authid":"7003395533","authname":"Agaian S.","surname":"Agaian","given-name":"Sos","initials":"S.","afid": [{"@_fa": "true", "$" :"60003212"}]}],"source-id":"21100846961","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85026198583"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85026198583?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85026198583&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85026198583&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85026198583","dc:identifier":"SCOPUS_ID:85026198583","eid":"2-s2.0-85026198583","dc:title":"2nd International Conference on Cloud Computing and Security, ICCCS 2016","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783319486734"}],"prism:volume":"10040 LNCS","prism:pageRange":"1-635","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","dc:description":"The proceedings contain 55 papers. The special focus in this conference is on IOT Applications, Multimedia Applications, Multimedia Security and Forensics. The topics include: A lifetime-aware network maintenance method for wireless sensor networks; an efficient task assignment mechanism for crowdsensing systems; fast pre-distribution authentication protocol for V2I; a context-aware communication approach based on the underwater acoustic sensor network; non-technical loss fraud targeting time-based pricing in smart grid; social influence analysis based on modeling interactions in dynamic social networks; automated vulnerability modeling and verification for penetration testing using Petri nets; integrating visible light with radio frequency communications for safety applications; temperature error correction based on BP Neural network in meteorological wireless sensor network; an energy-efficient data gathering based on compressive sensing; profit concerning and truthful online spectrum double auction mechanism; non-technical loss fraud in advanced metering infrastructure in smart grid; compressive sensing based on energy-efficient communication; the optimal trajectory planning for UAV in UAV-aided networks; an energy-efficient routing protocol for WSNs with single mobile sink; a method for electric load data verification and repair in home environment; a survey on the research of indoor RFID positioning system; color image quality assessment with quaternion moments; original image tracing with image relational graph for near-duplicate image elimination; palmprint matching by minutiae and ridge distance; anomaly detection algorithm for helicopter rotor based on STFT and SVDD and an efficient passive authentication scheme for copy-move forgery based on dct.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85023760606"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85023760606?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85023760606&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85023760606&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85023760606","dc:identifier":"SCOPUS_ID:85023760606","eid":"2-s2.0-85023760606","dc:title":"A distributed quaternion kalman filter with applications to smart grid and target tracking","dc:creator":"Talebi S.","prism:publicationName":"IEEE Transactions on Signal and Information Processing over Networks","prism:eIssn":"2373776X","prism:volume":"2","prism:issueIdentifier":"4","prism:pageRange":"477-488","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1109/TSIPN.2016.2618321","dc:description":"Recent advances in sensor and communication technologies have made the deployment of sensor networks in a variety of roles feasible, including smart grid management applications and collaborative target tracking solutions. While most research in distributed adaptive signal processing is conducted in the real and complex domains, inherently in many real-world applications the data sources are three-dimensional. This scenario is ideally suited for quaternions in terms of both convenience of representation and mathematical tractability. In this paper, we expand the concept of distributed Kalman filtering to the quaternion domain in order to develop a robust distributed quaternion Kalman filtering algorithm for data fusion over sensor networks dealing with three-dimensional data. For rigor, the mean and mean square behavior of the algorithm are analyzed. Finally, the developed algorithm is used to estimate the nominal system frequency in power distribution networks and for collaborative target tracking applications.","citedby-count":"44","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015150","afid":"60015150","affilname":"Imperial College London","affiliation-city":"London","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56297174200","authid":"56297174200","authname":"Talebi S.","surname":"Talebi","given-name":"Sayed Pouria","initials":"S.P.","afid": [{"@_fa": "true", "$" :"60015150"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56135784800","authid":"56135784800","authname":"Kanna S.","surname":"Kanna","given-name":"Sithan","initials":"S.","afid": [{"@_fa": "true", "$" :"60015150"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7006513328","authid":"7006513328","authname":"Mandic D.","surname":"Mandic","given-name":"Danilo P.","initials":"D.P.","afid": [{"@_fa": "true", "$" :"60015150"}]}],"authkeywords":"Distributed estimation | frequency estimation | quaternion-valued signal processing | smart grid | target tracking","article-number":"7592428","source-id":"21100854641","fund-acr":"EPSRC","fund-no":"EP/H026266/1","fund-sponsor":"Engineering and Physical Sciences Research Council","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85020503031"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85020503031?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85020503031&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85020503031&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85020503031","dc:identifier":"SCOPUS_ID:85020503031","eid":"2-s2.0-85020503031","dc:title":"In-orbit performance of attitude control system in DubaiSat-2","dc:creator":"Koh D.","prism:publicationName":"SpaceOps 2016 Conference","prism:isbn": [{"@_fa": "true", "$" :"9781624104268"}],"prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.2514/6.2016-2600","dc:description":"The Dubaisat-2 is a 1-m resolution remote sensing satellite system developed jointly by Satrec Initiative and Muhammed Bin Rashid Space Centre of UAE and it is fully operational since its successful launch on November 2013. The primary mission objectives are to provide high resolution images of earth observation. This paper represents the attitude control performance of Dubaisat-2 in space focusing on the launch & early operation results. The Dubaisat-2 has implemented reaction wheels, gyros, star trackers, sun sensors, magnetometers and magnetic torquer for agile and accurate attitude control purposes. The attitude control hardware and flight control software support various operations and maneuvers for efficient and advanced imaging missions. The required attitude pointing accuracy of 0.12 deg (3 sigma) and the stability of 0.009 deg/sec (3 sigma) are verified by in-orbit performance analysis. For 3-axis attitude control and stabilization of a rigid spacecraft, quaternion feedback law is applied in Dubaisat-2 and settling time to set PD gain is auto-scheduled in on-board software. The conservative pyramidal configuration of four reaction wheel and additional one reaction wheel is applied and continuous wheel momentum dumping is performed by using magnetic torquer. The control torque distribution optimization is based on a null space solution. Dubaisat-2 is designed to support the imaging functions such as single, multi strip and single-pass stereo imaging. For the geometric and radiometric calibration, stars and moon imaging operations are also performed for value-added image product. In this paper, the overview of the DubaiSat-2 attitude control system is described with focusing on the launch & early operation results. Lessons learned from flying experiences and analysis results will contributes to sustainable development in Satrec Initiative.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60114150","afid":"60114150","affilname":"Mohammed bin Rashid Space Centre","affiliation-city":"Dubai","affiliation-country":"United Arab Emirates"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/117077968","afid":"117077968","affilname":"Systems Department","affiliation-city":"Daejeon","affiliation-country":"South Korea"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/100347035","afid":"100347035","affilname":"Satrec Initiative","affiliation-city":"Daejeon","affiliation-country":"South Korea"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190438731","authid":"57190438731","authname":"Koh D.","surname":"Koh","given-name":"Dongwook","initials":"D.","afid": [{"@_fa": "true", "$" :"117077968"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57190438631","authid":"57190438631","authname":"Alsayegh A.","surname":"Alsayegh","given-name":"Amer","initials":"A.","afid": [{"@_fa": "true", "$" :"60114150"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55706773900","authid":"55706773900","authname":"Lee H.","surname":"Lee","given-name":"Hyunwoo","initials":"H.","afid": [{"@_fa": "true", "$" :"100347035"}]}],"article-number":"AIAA 2016-2600","source-id":"21100818700","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019272751"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019272751?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019272751&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019272751&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019272751","dc:identifier":"SCOPUS_ID:85019272751","eid":"2-s2.0-85019272751","dc:title":"Reconstruction of color biomedical images by means of quaternion generic Jacobi-Fourier moments in the framework of polar pixels","dc:creator":"Camacho-Bello C.","prism:publicationName":"Journal of Medical Imaging","prism:issn":"23294302","prism:eIssn":"23294310","prism:volume":"3","prism:issueIdentifier":"1","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"1 January 2016","prism:doi":"10.1117/1.JMI.3.1.014004","dc:description":"A detailed analysis of the quaternion generic Jacobi-Fourier moments (QGJFMs) for color image description is presented. In order to reach numerical stability, a recursive approach is used during the computation of the generic Jacobi radial polynomials. Moreover, a search criterion is performed to establish the best values for the parameters α and β of the radial Jacobi polynomial families. Additionally, a polar pixel approach is taken into account to increase the numerical accuracy in the calculation of the QGJFMs. To prove the mathematical theory, some color images from optical microscopy and human retina are used. Experiments and results about color image reconstruction are presented.","citedby-count":"19","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60095116","afid":"60095116","affilname":"Universidad Politécnica de Tulancingo Hidalgo","affiliation-city":"Huapalcalco","affiliation-country":"Mexico"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030699","afid":"60030699","affilname":"Instituto Nacional de Astrofisica Optica y Electronica","affiliation-city":"Puebla","affiliation-country":"Mexico"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55102936300","authid":"55102936300","authname":"Camacho-Bello C.","surname":"Camacho-Bello","given-name":"César","initials":"C.","afid": [{"@_fa": "true", "$" :"60095116"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55915081400","authid":"55915081400","authname":"Padilla-Vivanco A.","surname":"Padilla-Vivanco","given-name":"Alfonso","initials":"A.","afid": [{"@_fa": "true", "$" :"60095116"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8247648700","authid":"8247648700","authname":"Toxqui-Quitl C.","surname":"Toxqui-Quitl","given-name":"Carina","initials":"C.","afid": [{"@_fa": "true", "$" :"60095116"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55989692200","authid":"55989692200","authname":"Báez-Rojas J.J.","surname":"Báez-Rojas","given-name":"José Javier","initials":"J.J.","afid": [{"@_fa": "true", "$" :"60030699"}]}],"authkeywords":"color image | color microscopy images | Jacobi polynomial | polar pixels | quaternion moments","article-number":"014004","source-id":"21100829270","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019167755"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019167755?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019167755&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019167755&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019167755","dc:identifier":"SCOPUS_ID:85019167755","eid":"2-s2.0-85019167755","dc:title":"Fully automatic image colorization based on Convolutional Neural Network","dc:creator":"Varga D.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:issn":"10514651","prism:isbn": [{"@_fa": "true", "$" :"9781509048472"}],"prism:volume":"0","prism:pageRange":"3691-3696","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"PUBDATE","prism:doi":"10.1109/ICPR.2016.7900208","dc:description":"This paper deals with automatic image colorization. This is a very difficult task, since it is an ill-posed problem that usually requires user intervention to achieve high quality. A fully automatic approach is proposed that is able to produce realistic colorization of an input grayscale image. Motivated by the recent success of deep learning techniques in image processing, we propose a feed-forward, two-stage architecture based on Convolutional Neural Network that predicts the U and V color channels. Unlike most of the previous works, this paper presents a fully automatic colorization which is able to produce high-quality and realistic colorization even of complex scenes. Comprehensive experiments and qualitative and quantitative evaluations were conducted on the images of SUN database and on other images. We have found that Quaternion Structural Similarity (QSSIM) gives in some degree a good base for quantitative evaluation, that is why we chose QSSIM as an index-number for the quality of colorization.","citedby-count":"24","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030035","afid":"60030035","affilname":"Budapest University of Technology and Economics","affiliation-city":"Budapest","affiliation-country":"Hungary"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024855","afid":"60024855","affilname":"Számítástechnikai és Automatizálási Kutatóintézet","affiliation-city":"Budapest","affiliation-country":"Hungary"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55842599000","authid":"55842599000","authname":"Varga D.","surname":"Varga","given-name":"Domonkos","initials":"D.","afid": [{"@_fa": "true", "$" :"60024855"},{"@_fa": "true", "$" :"60030035"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7004036382","authid":"7004036382","authname":"Sziranyi T.","surname":"Sziranyi","given-name":"Tamas","initials":"T.","afid": [{"@_fa": "true", "$" :"60024855"},{"@_fa": "true", "$" :"60030035"}]}],"article-number":"7900208","source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019136358"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019136358?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019136358&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019136358&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019136358","dc:identifier":"SCOPUS_ID:85019136358","eid":"2-s2.0-85019136358","dc:title":"Quaternion-type moments combining both color and depth information for RGB-D object recognition","dc:creator":"Chen B.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:issn":"10514651","prism:isbn": [{"@_fa": "true", "$" :"9781509048472"}],"prism:volume":"0","prism:pageRange":"704-708","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"PUBDATE","prism:doi":"10.1109/ICPR.2016.7899717","dc:description":"The existing quaternion-type moments (QTMs) are based on the quaternion representation (QR) of color images. However, this representation creates redundancy when using four-dimensional quaternions to represent color images with three components. In this paper, for RGB-D images, the QR is improved by combining both color and depth information, which is invariant to lighting and color variations. The improved QR fully utilizes the four-dimensional quaternion domain. The new QTMs (NQTMs) are defined using the improved QR. They are combined with the quaternion back-propagation neural network (QBPNN) for RGB-D object recognition. The experimental results demonstrate that the NQTMs outperform our previous QTMs considering only color information.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023813","afid":"60023813","affilname":"Shanghai University","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009400","afid":"60009400","affilname":"Nanjing University of Post and TeleCommunications","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36805188500","authid":"36805188500","authname":"Chen B.","surname":"Chen","given-name":"Beijing","initials":"B.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57195995772","authid":"57195995772","authname":"Yang J.","surname":"Yang","given-name":"Jianhao","initials":"J.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57194180119","authid":"57194180119","authname":"Ding M.","surname":"Ding","given-name":"Mengru","initials":"M.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55809303800","authid":"55809303800","authname":"Liu T.","surname":"Liu","given-name":"Tianliang","initials":"T.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56034166800","authid":"56034166800","authname":"Zhang X.","surname":"Zhang","given-name":"Xinpeng","initials":"X.","afid": [{"@_fa": "true", "$" :"60023813"}]}],"authkeywords":"Color image | Depth information | Quaternion moment | RGB-D object recognition","article-number":"7899717","source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019083784"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019083784?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019083784&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019083784&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019083784","dc:identifier":"SCOPUS_ID:85019083784","eid":"2-s2.0-85019083784","dc:title":"Multi-focus image fusion using quaternion wavelet transform","dc:creator":"Zheng X.N.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:issn":"10514651","prism:isbn": [{"@_fa": "true", "$" :"9781509048472"}],"prism:volume":"0","prism:pageRange":"883-888","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"PUBDATE","prism:doi":"10.1109/ICPR.2016.7899747","dc:description":"To avoid the introduction of false information during the fusion progress, a novel multi-focus image fusion method is proposed in quaternion wavelet transform domain. To obtain the dependency in different high frequency subbands, a quaternion wavelet contextual hidden Markov model (Q-CHMM) is established for modeling quaternion wavelet coefficients. And for better image representations, several features are proposed by analyzing the transform coefficients, phases of coefficients and the statistical attribution of coefficients. Different from the traditional fusion methods basing on a single feature, a comprehensive feature is constructed by using quaternion matrix to fuse the high frequency subbands. Experimental results demonstrate that the proposed method possess good fusion performance.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073673","afid":"60073673","affilname":"Suzhou University of Science and Technology","affiliation-city":"Suzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007029","afid":"60007029","affilname":"Jiangnan University","affiliation-city":"Wuxi","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57194187512","authid":"57194187512","authname":"Zheng X.N.","surname":"Zheng","given-name":"Xue Ni","initials":"X.N.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/23985472800","authid":"23985472800","authname":"Luo X.Q.","surname":"Luo","given-name":"Xiao Qing","initials":"X.Q.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57219233537","authid":"57219233537","authname":"Zhang Z.C.","surname":"Zhang","given-name":"Zhan Cheng","initials":"Z.C.","afid": [{"@_fa": "true", "$" :"60073673"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56191888600","authid":"56191888600","authname":"Wu X.J.","surname":"Wu","given-name":"Xiao Jun","initials":"X.J.","afid": [{"@_fa": "true", "$" :"60007029"}]}],"authkeywords":"Contextual hidden Markov model | Image fusion | Phase | Quaternion matrix | Quaternion wavelet","article-number":"7899747","source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019054882"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019054882?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019054882&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019054882&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019054882","dc:identifier":"SCOPUS_ID:85019054882","eid":"2-s2.0-85019054882","dc:title":"Gaze estimation using EEG signals for HCI in augmented and virtual reality headsets","dc:creator":"Montenegro J.M.F.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:issn":"10514651","prism:isbn": [{"@_fa": "true", "$" :"9781509048472"}],"prism:volume":"0","prism:pageRange":"1159-1164","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"PUBDATE","prism:doi":"10.1109/ICPR.2016.7899793","dc:description":"Augmented and virtual reality have evolved significantly over the last few years providing new ways of entertainment and interaction with the environment. Although many systems and solutions are currently available, still there is much left unsettled and some technologies are missing from many VR/AR devices, such as foveated rendering and HCI. In this paper, a novel approach for coarse gaze estimation using EEG sensors with applications in items selection for HCI or foveated rendering for VR/AR devices is proposed. The suggested method requires only few electroencephalogram sensors that can be easily added to the current virtual and augmented reality headsets. A supervised machine leaning approach was suggested utilising novel features, based on quaternions allowing gaze estimation. Experiments were performed to evaluate the proposed method and a new dataset was designed and captured. Finally, the introduced learning framework was compared with other similar techniques demonstrating further the gain of the proposed descriptors.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60033359","afid":"60033359","affilname":"Kingston University","affiliation-city":"Kingston Upon Thames","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57188851647","authid":"57188851647","authname":"Montenegro J.M.F.","surname":"Montenegro","given-name":"Juan Manuel Fernandez","initials":"J.M.F.","afid": [{"@_fa": "true", "$" :"60033359"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/13806485100","authid":"13806485100","authname":"Argyriou V.","surname":"Argyriou","given-name":"Vasileios","initials":"V.","afid": [{"@_fa": "true", "$" :"60033359"}]}],"article-number":"7899793","source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85017632979"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85017632979?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85017632979&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85017632979&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85017632979","dc:identifier":"SCOPUS_ID:85017632979","eid":"2-s2.0-85017632979","dc:title":"Application of holomorphic functions in two and higher dimensions","dc:creator":"Gürlebeck K.","prism:publicationName":"Application of Holomorphic Functions in Two and Higher Dimensions","prism:isbn": [{"@_fa": "true", "$" :"9783034809641"},{"@_fa": "true", "$" :"9783034809627"}],"prism:pageRange":"1-390","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"1 January 2016","prism:doi":"10.1007/978-3-0348-0964-1","dc:description":"This book presents applications of hypercomplex analysis to boundary value and initial-boundary value problems from various areas of mathematical physics. Given that quaternion and Clifford analysis offer natural and intelligent ways to enter into higher dimensions, it starts with quaternion and Clifford versions of complex function theory including series expansions with Appell polynomials, as well as Taylor and Laurent series. Several necessary function spaces are introduced, and an operator calculus based on modifications of the Dirac, Cauchy-Fueter, and Teodorescu operators and different decompositions of quaternion Hilbert spaces are proved. Finally, hypercomplex Fourier transforms are studied in detail. All this is then applied to first-order partial differential equations such as the Maxwell equations, the Carleman-Bers-Vekua system, the Schrödinger equation, and the Beltrami equation. The higher-order equations start with Riccati-type equations. Further topics include spatial fluid flow problems, image and multi-channel processing, image diffusion, linear scale invariant filtering, and others. One of the highlights is the derivation of the three-dimensional Kolosov-Mushkelishvili formulas in linear elasticity. Throughout the book the authors endeavor to present historical references and important personalities. The book is intended for a wide audience in the mathematical and engineering sciences and is accessible to readers with a basic grasp of real, complex, and functional analysis.","citedby-count":"52","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028637","afid":"60028637","affilname":"Bauhaus-Universität Weimar","affiliation-city":"Weimar","affiliation-country":"Germany"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016653","afid":"60016653","affilname":"Rheinisch-Westfälische Technische Hochschule Aachen","affiliation-city":"Aachen","affiliation-country":"Germany"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008988","afid":"60008988","affilname":"Technische Universität Bergakademie Freiberg","affiliation-city":"Freiberg","affiliation-country":"Germany"}],"prism:aggregationType":"Book","subtype":"bk","subtypeDescription":"Book","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6602218979","authid":"6602218979","authname":"Gürlebeck K.","surname":"Gürlebeck","given-name":"Klaus","initials":"K.","afid": [{"@_fa": "true", "$" :"60028637"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56000051200","authid":"56000051200","authname":"Habetha K.","surname":"Habetha","given-name":"Klaus","initials":"K.","afid": [{"@_fa": "true", "$" :"60016653"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6508331953","authid":"6508331953","authname":"Sprößig W.","surname":"Sprößig","given-name":"Wolfgang","initials":"W.","afid": [{"@_fa": "true", "$" :"60008988"}]}],"source-id":"21100807880","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016812894"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016812894?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85016812894&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85016812894&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85016812894","dc:identifier":"SCOPUS_ID:85016812894","eid":"2-s2.0-85016812894","dc:title":"A novel upper limb training system based on UR5 using sEMG and IMU sensors","dc:creator":"Liu Z.","prism:publicationName":"2016 IEEE International Conference on Robotics and Biomimetics, ROBIO 2016","prism:isbn": [{"@_fa": "true", "$" :"9781509043644"}],"prism:pageRange":"1069-1074","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1109/ROBIO.2016.7866467","dc:description":"This paper intends to design a system which acquires the trainer's motion and force information in order to manipulate a robot arm applied for rehabilitations. Patients who suffering physical disability also can receive the professorial guiding and cheirapsis even excellent trainers are very busy and insufficient. The key point of this article is data acquisition and reconstruction of the movement of the upper limb by controlling the UR5 robot arm. Upper limb's postures are sensed by Inertial Measurement Unit (IMU) and transferred to STM32 microcontroller using I2C communication protocol. We employed the STM32 microcontroller to calculate attitude angles of both the upper arm and the forearm. And the method with using quaternions to calculate attitude angles is detailedly expounded in this paper. Besides, we employed the MYO armband to acquire upper limb's surface electromyography (sEMG) signals for estimating the muscle force of the upper limb. To verify the feasibility of the proposed system, we make three experiments including analyzing fluctuation range of the attitude angles from IMU signals, classifying muscle force using sEMG signals, and evaluating the effect of motion reconstruction. And the results show that the fluctuation range of acquired data are less than 1 degree, 4 typical motions of upper limb can be reconstructed. The proposed system can be used to reconstruct some upper limb's movement.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104220","afid":"60104220","affilname":"Maebashi Institute of Technology","affiliation-city":"Maebashi","affiliation-country":"Japan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60078086","afid":"60078086","affilname":"Universiti Teknikal Malaysia Melaka","affiliation-city":"Malacca","affiliation-country":"Malaysia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021005","afid":"60021005","affilname":"Universiti Teknologi Malaysia","affiliation-city":"Johor Bahru","affiliation-country":"Malaysia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018038","afid":"60018038","affilname":"Nankai University","affiliation-city":"Tianjin","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "8", "$" :"8"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57193806919","authid":"57193806919","authname":"Liu Z.","surname":"Liu","given-name":"Zhenqiang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60018038"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57072188800","authid":"57072188800","authname":"Chang W.","surname":"Chang","given-name":"Wennan","initials":"W.","afid": [{"@_fa": "true", "$" :"60018038"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57072706700","authid":"57072706700","authname":"Sheng S.","surname":"Sheng","given-name":"Shili","initials":"S.","afid": [{"@_fa": "true", "$" :"60018038"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55730961000","authid":"55730961000","authname":"Li L.","surname":"Li","given-name":"Liang","initials":"L.","afid": [{"@_fa": "true", "$" :"60018038"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/24765785200","authid":"24765785200","authname":"Soo Y.G.","surname":"Soo","given-name":"Yew Guan","initials":"Y.G.","afid": [{"@_fa": "true", "$" :"60078086"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/35147090800","authid":"35147090800","authname":"Yeong C.F.","surname":"Yeong","given-name":"Che Fai","initials":"C.F.","afid": [{"@_fa": "true", "$" :"60021005"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/9735252300","authid":"9735252300","authname":"Odagaki M.","surname":"Odagaki","given-name":"Masato","initials":"M.","afid": [{"@_fa": "true", "$" :"60104220"}]},{"@_fa": "true", "@seq": "8", "author-url":"https://api.elsevier.com/content/author/author_id/24537140100","authid":"24537140100","authname":"Duan F.","surname":"Duan","given-name":"Feng","initials":"F.","afid": [{"@_fa": "true", "$" :"60018038"}]}],"article-number":"7866467","source-id":"21100836251","fund-acr":"NSFC","fund-no":"14ZCZDSY00008","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016732303"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016732303?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85016732303&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85016732303&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85016732303","dc:identifier":"SCOPUS_ID:85016732303","eid":"2-s2.0-85016732303","dc:title":"3D evolutionary pose tracking experiments of eye-vergence visual servoing in lateral motion and arc swing motion","dc:creator":"Tian H.","prism:publicationName":"2016 IEEE International Conference on Robotics and Biomimetics, ROBIO 2016","prism:isbn": [{"@_fa": "true", "$" :"9781509043644"}],"prism:pageRange":"577-582","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1109/ROBIO.2016.7866384","dc:description":"The moving target visual servoing with hand eye cameras fixed at hand is inevitably affected by dynamic oscillatory, so that it's difficult to remain target position at the center of the camera's view, because the tracing ability of the system is influenced by non-linear dynamics of the entire manipulator. To overcome this defect of the fixed hand-eye system, hand-eye-vergence system in which left and right cameras' directions could be rotated to observe and keep the target object to be seen at the center of camera images to reduce the influences of aberration of camera lens. This paper analyses the performance of 3D-object position and orientation tracking experiments of hand-eye-vergence system. They both show good tracking performance. In this paper an orientation recognition method using quaternion is put forward. And quaternion is incorporated into chromosomes and participates in the evolution of Genetic Algorithms (GA). The dynamical superiorities of the proposed system are verified by comparing hand tracking performances and the proposed eye-vergence tracking performances in two experiments of lateral and arc swing motion respectively.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023147","afid":"60023147","affilname":"Okayama University","affiliation-city":"Okayama","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191252625","authid":"57191252625","authname":"Tian H.","surname":"Tian","given-name":"Hongzhi","initials":"H.","afid": [{"@_fa": "true", "$" :"60023147"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57193643707","authid":"57193643707","authname":"Funakubo R.","surname":"Funakubo","given-name":"Ryuki","initials":"R."},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57193649493","authid":"57193649493","authname":"Kou Y.","surname":"Kou","given-name":"Yejun","initials":"Y."},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7402907499","authid":"7402907499","authname":"Minami M.","surname":"Minami","given-name":"Mamoru","initials":"M."}],"article-number":"7866384","source-id":"21100836251","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016153808"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016153808?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85016153808&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85016153808&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85016153808","dc:identifier":"SCOPUS_ID:85016153808","eid":"2-s2.0-85016153808","dc:title":"Quaternion singular spectrum analysis of electroencephalogram with application in sleep analysis","dc:creator":"Enshaeifar S.","prism:publicationName":"IEEE Transactions on Neural Systems and Rehabilitation Engineering","prism:issn":"15344320","prism:volume":"24","prism:issueIdentifier":"1","prism:pageRange":"57-67","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"January 2016","prism:doi":"10.1109/TNSRE.2015.2465177","dc:description":"A novel quaternion-valued singular spectrum analysis (SSA) is introduced for multichannel analysis of electroencephalogram (EEG). The analysis of EEG typically requires the decomposition of data channels into meaningful components despite the notoriously noisy nature of EEG - which is the aim of SSA. However, the singular value decomposition involved in SSA implies the strict orthogonality of the decomposed components, which may not reflect accurately the sources which exhibit similar neural activities. To allow for the modelling of such co-channel coupling, the quaternion domain is considered for the first time to formulate the SSA using the augmented statistics. As an application, we demonstrate how the augmented quaternion-valued SSA (AQSSA) can be used to extract the sources, even at a signal-to-noise ratio as low as 10 dB. To illustrate the usefulness of our quaternion-valued SSA in a rehabilitation setting, we employ the proposed SSA for sleep analysis to extract statistical descriptors for five-stage classification (Awake, N1, N2, N3 and REM). The level of agreement using these descriptors was 74% as quantified by the Cohen's kappa.","citedby-count":"41","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021097","afid":"60021097","affilname":"University of Surrey","affiliation-city":"Guildford","affiliation-country":"United Kingdom"}],"pubmed-id":"26276995","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56266552400","authid":"56266552400","authname":"Enshaeifar S.","surname":"Enshaeifar","given-name":"Shirin","initials":"S.","afid": [{"@_fa": "true", "$" :"60021097"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55486118200","authid":"55486118200","authname":"Kouchaki S.","surname":"Kouchaki","given-name":"Samaneh","initials":"S.","afid": [{"@_fa": "true", "$" :"60021097"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56614550100","authid":"56614550100","authname":"Cheong Took C.","surname":"Cheong Took","given-name":"Clive","initials":"C.","afid": [{"@_fa": "true", "$" :"60021097"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56212338600","authid":"56212338600","authname":"Sanei S.","surname":"Sanei","given-name":"Saeid","initials":"S.","afid": [{"@_fa": "true", "$" :"60021097"}]}],"authkeywords":"Electroencephalogram (EEG) | Quaternion | Singular spectrum analysis (SSA) | Sleep analysis | Source extraction","article-number":"7192654","source-id":"16321","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015319827"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015319827?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85015319827&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85015319827&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85015319827","dc:identifier":"SCOPUS_ID:85015319827","eid":"2-s2.0-85015319827","dc:title":"Color image quality assessment with quaternion moments","dc:creator":"Zhang W.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:volume":"10040","prism:pageRange":"301-312","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1007/978-3-319-48674-1_27","dc:description":"Color information is important to image quality assessment (IQA). However, most image quality assessment methods transform color image into gray scale, which fail to consider color information. In recent years, color image processing by using the algebra of quaternions has been attracting tremendous attention. Extensive moments based on quaternion have been introduced to deal with the red, green and blue channels of color images in a holistic manner, which have been proved more effective in color processing. With these inspirations, this paper presents a full-reference color image quality assessment metric based on Quaternion Tchebichef Moments (QTMs). QTMs are first employed to measure color and structure distortions simultaneously. Considering that moments are insensitive to weak distortions in high-quality images, gradient is incorporated as a complementary feature. Luminance is also considered as an auxiliary feature. Finally, a QTM-feature-based weighting map is proposed to conduct the pooling, producing an overall quality score. The experimental results on five public image quality databases demonstrate that the proposed method outperforms the state-of-the-arts.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073460","afid":"60073460","affilname":"China University of Mining and Technology","affiliation-city":"Xuzhou","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56278457100","authid":"56278457100","authname":"Zhang W.","surname":"Zhang","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60073460"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56883547100","authid":"56883547100","authname":"Hu B.","surname":"Hu","given-name":"Bo","initials":"B.","afid": [{"@_fa": "true", "$" :"60073460"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/37014105300","authid":"37014105300","authname":"Xu Z.","surname":"Xu","given-name":"Zhao","initials":"Z.","afid": [{"@_fa": "true", "$" :"60073460"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55839736400","authid":"55839736400","authname":"Li L.","surname":"Li","given-name":"Leida","initials":"L.","afid": [{"@_fa": "true", "$" :"60073460"}]}],"authkeywords":"Full-reference | Image gradient | Image quality assessment | Quaternion moment","source-id":"25674","fund-acr":"NSFC","fund-no":"61379143","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85014857927"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85014857927?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85014857927&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85014857927&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85014857927","dc:identifier":"SCOPUS_ID:85014857927","eid":"2-s2.0-85014857927","dc:title":"A strategy of phonesat attitude determination based on smartphone sensors","dc:creator":"Zhao J.","prism:publicationName":"Proceedings of the IASTED International Conference on Modelling, Identification and Control","prism:issn":"10258973","prism:isbn": [{"@_fa": "true", "$" :"9780889869790"}],"prism:volume":"830","prism:pageRange":"37-43","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.2316/P.2016.830-011","dc:description":"This paper details the research and development of a new robust attitude determination strategy which is differenfrom the traditional strategies applied in the PhoneSats and processes the advantages both in size and price by using a satellite payload smartphone. Observation models are given, and we achieve the attitude information by using a smartphone's gyroscope, accelerometer and GPS. Assuming that the biased measurements are caused by the random drift of the sensors, an error model is proposed to estimate the bias. To improve the precision of the output, a quaternion-based Kalman Filter is derived. The results of experiments show that the proposed strategy in this paper is considerable in Obtaining PhoneSat attitude determination.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025256","afid":"60025256","affilname":"Institute of Software Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190880754","authid":"57190880754","authname":"Zhao J.","surname":"Zhao","given-name":"Jingjing","initials":"J.","afid": [{"@_fa": "true", "$" :"60025256"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/36811032700","authid":"36811032700","authname":"Zhao J.","surname":"Zhao","given-name":"Junsuo","initials":"J.","afid": [{"@_fa": "true", "$" :"60025256"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8262906200","authid":"8262906200","authname":"Wu F.","surname":"Wu","given-name":"Fengge","initials":"F.","afid": [{"@_fa": "true", "$" :"60025256"}]}],"authkeywords":"Attitude determination | Kalman Filter | PhoneSat | Smartphone","source-id":"200147116","fund-acr":"NSFC","fund-no":"6120218","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85014513069"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85014513069?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85014513069&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85014513069&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85014513069","dc:identifier":"SCOPUS_ID:85014513069","eid":"2-s2.0-85014513069","dc:title":"An improved feature extraction-based colour image matching method using quaternion matrix","dc:creator":"Zou H.","prism:publicationName":"International Journal of Communication Networks and Distributed Systems","prism:issn":"17543916","prism:eIssn":"17543924","prism:volume":"16","prism:issueIdentifier":"4","prism:pageRange":"388-411","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1504/IJCNDS.2016.077672","dc:description":"Specific to the problem of feature description for colour image, a novel speeded-up robust features (SURF) descriptor of colour image-based quaternion (CSURF-Q) is proposed in this paper. Firstly, in order to represent the colour information of colour image effectively, the colour information among three channels is expressed by the three imaginary parts of quaternion. This can transform colour image to a pure quaternion matrix, which simplifies the representation process of image colour information. Secondly, the SURF features among three channels of colour image are extracted by using quaternion matrix. Because of the rotation invariance of quaternion norm, feature description vectors are generated as the form of quaternion norm. Finally, comparing CSURF-Q with SURF, FAIR-SURF, CSIFT, SIFT-CCH, colour-SURF and CHSIFT, the experiments prove that, when image appears affine changes, the correct matching of feature point pairs and time complexity are superior.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073726","afid":"60073726","affilname":"Ludong University","affiliation-city":"Yantai","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/27868241600","authid":"27868241600","authname":"Zou H.","surname":"Zou","given-name":"Hailin","initials":"H.","afid": [{"@_fa": "true", "$" :"60073726"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/43461231600","authid":"43461231600","authname":"Liu C.","surname":"Liu","given-name":"Chanjuan","initials":"C.","afid": [{"@_fa": "true", "$" :"60073726"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57112964600","authid":"57112964600","authname":"Shen Q.","surname":"Shen","given-name":"Qian","initials":"Q.","afid": [{"@_fa": "true", "$" :"60073726"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36189232700","authid":"36189232700","authname":"Zhou S.","surname":"Zhou","given-name":"Shusen","initials":"S.","afid": [{"@_fa": "true", "$" :"60073726"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/53364663100","authid":"53364663100","authname":"Zang M.","surname":"Zang","given-name":"Mujun","initials":"M.","afid": [{"@_fa": "true", "$" :"60073726"}]}],"authkeywords":"Affine variations | Colour image | Feature description | Feature extraction | Image matching | Interest points | Local features | Object recognition | Quaternion matrix | Scale invariant feature transform | SIFT | Speeded-up robust features | SURF","source-id":"21100198205","fund-acr":"NSFC","fund-no":"61170161","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85007342458"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85007342458?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85007342458&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85007342458&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85007342458","dc:identifier":"SCOPUS_ID:85007342458","eid":"2-s2.0-85007342458","dc:title":"Attitude determination and control of ITASAT CubeSat","dc:creator":"Carrara V.","prism:publicationName":"Advances in the Astronautical Sciences","prism:issn":"00653438","prism:isbn": [{"@_fa": "true", "$" :"9780877036333"}],"prism:volume":"158","prism:pageRange":"53-70","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","dc:description":"The ITASAT CubeSat is a satellite being developed at Aeronautic Technological Institute in Brazil, to be launched in mid-2016. This work addresses the ADCS (Attitude Determination and Control Subsystem) of ITASAT, and the computer simulation done so far to assure that the mission requirements were accomplished. The formulation of a Kalman filter will be presented to estimate the attitude quaternion along with the gyro bias, having as inputs the raw measurements of the magnetometer and gyroscopes, and a preprocessed vector of coarse cosine sun sensors. The formulation shown here was taken from an algorithm of a similar Kalman filter, but adapted for employment on on-board computers in which unnecessary computations were eliminated. Attitude is estimated during the illuminated part of the orbit, based on measurements of the angular sensors. During eclipse attitude estimation procedure relies only on the magnetometer and gyros measurements, but the estimation error increases with the time the satellite remains in the shadow due to the lack of sun sensor readings necessary for full attitude estimation. Preliminary results indicate that the Kalman filter can track the bias of the gyroscope and its drift, significantly decreasing the noise level present in the angular sensors. However, the angular velocity remains with high noise levels, which restricts the use of the gyroscope to drive the control signal without previous filtering. The ITASAT should be stabilized and controlled in three-axis, with geocentric pointing. A set of three reaction wheels and three magnetorquers provide torques for attitude control. Simulations indicated that the pointing accuracy is particularly affected by the Kalman filter estimation error, when the reaction wheels are used as main actuators. However, due to the high power consumption of the wheels they can not be used during the whole orbit, and therefore a purely three-axis magnetic stabilization and control will also be required. The magnetorquer's inability to generate torques in all directions limits the attitude stabilization of this control. Coupled to the poor resolution of the angular velocity from gyros, pointing errors bellow 20 degrees are difficult to achieve, except when the angular velocity is estimated by other means such as, for example, by gyro filtering, or by numeric attitude derivative. The ITASAT attitude control modes will be presented, together with some simulation results.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021657","afid":"60021657","affilname":"Instituto Tecnologico de Aeronautica","affiliation-city":"Sao Jose dos Campos","affiliation-country":"Brazil"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6603063350","authid":"6603063350","authname":"Carrara V.","surname":"Carrara","given-name":"Valdemir","initials":"V.","afid": [{"@_fa": "true", "$" :"60021657"}]}],"source-id":"12376","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006046019"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006046019?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85006046019&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85006046019&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85006046019","dc:identifier":"SCOPUS_ID:85006046019","eid":"2-s2.0-85006046019","dc:title":"A New Double Color Image Watermarking Algorithm Based on the SVD and Arnold Scrambling","dc:creator":"Li Y.","prism:publicationName":"Journal of Applied Mathematics","prism:issn":"1110757X","prism:eIssn":"16870042","prism:volume":"2016","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1155/2016/2497379","dc:description":"We propose a new image watermarking scheme based on the real SVD and Arnold scrambling to embed a color watermarking image into a color host image. Before embedding watermark, the color watermark image W with size of M×M is scrambled by Arnold transformation to obtain a meaningless image W. Then, the color host image A with size of N×N is divided into nonoverlapping N/M×N/M pixel blocks. In each (i,j) pixel block Ai,j, we form a real matrix Ci,j with the red, green, and blue components of Ai,j and perform the SVD of Ci,j. We then replace the three smallest singular values of Ci,j by the red, green, and blue values of Wij with scaling factor, to form a new watermarked host image Aij. With the reserve procedure, we can extract the watermark from the watermarked host image. In the process of the algorithm, we only need to perform real number algebra operations, which have very low computational complexity and are more effective than the one using the quaternion SVD of color image.","citedby-count":"12","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030274","afid":"60030274","affilname":"Liaocheng University","affiliation-city":"Liaocheng","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022279","afid":"60022279","affilname":"Shanghai Normal University","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56086640300","authid":"56086640300","orcid":"0000-0003-1829-7327","authname":"Li Y.","surname":"Li","given-name":"Ying","initials":"Y.","afid": [{"@_fa": "true", "$" :"60030274"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7202184397","authid":"7202184397","authname":"Wei M.","surname":"Wei","given-name":"Musheng","initials":"M.","afid": [{"@_fa": "true", "$" :"60030274"},{"@_fa": "true", "$" :"60022279"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55376173400","authid":"55376173400","authname":"Zhang F.","surname":"Zhang","given-name":"Fengxia","initials":"F.","afid": [{"@_fa": "true", "$" :"60030274"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36867981700","authid":"36867981700","authname":"Zhao J.","surname":"Zhao","given-name":"Jianli","initials":"J.","afid": [{"@_fa": "true", "$" :"60030274"}]}],"article-number":"2497379","source-id":"144917","fund-acr":"NSFC","fund-no":"318011318","fund-sponsor":"Department of Education of Shandong Province","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85003030702"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85003030702?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85003030702&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85003030702&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85003030702","dc:identifier":"SCOPUS_ID:85003030702","eid":"2-s2.0-85003030702","dc:title":"Maximum Likelihood estimation of monocular optical flow field for mobile robot ego-motion","dc:creator":"Liu H.","prism:publicationName":"International Journal of Advanced Robotic Systems","prism:issn":"17298806","prism:eIssn":"17298814","prism:volume":"13","prism:issueIdentifier":"1","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.5772/62157","dc:description":"This paper presents an optimized scheme of monocular ego-motion estimation to provide location and pose information for mobile robots with one fixed camera. First, a multi-scale hyper-complex wavelet phase-derived optical flow is applied to estimate micro motion of image blocks. Optical flow computation overcomes the difficulties of unreliable feature selection and feature matching of outdoor scenes; at the same time, the multi-scale strategy overcomes the problem of road surface self-similarity and local occlusions. Secondly, a support probability of flow vector is defined to evaluate the validity of the candidate image motions, and a Maximum Likelihood Estimation (MLE) optical flow model is constructed based not only on image motion residuals but also their distribution of inliers and outliers, together with their support probabilities, to evaluate a given transform. This yields an optimized estimation of inlier parts of optical flow. Thirdly, a sampling and consensus strategy is designed to estimate the ego-motion parameters. Our model and algorithms are tested on real datasets collected from an intelligent vehicle. The experimental results demonstrate the estimated egomotion parameters closely follow the GPS/INS ground truth in complex outdoor road scenarios.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010080","afid":"60010080","affilname":"Nanjing University of Science and Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009400","afid":"60009400","affilname":"Nanjing University of Post and TeleCommunications","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191738993","authid":"57191738993","authname":"Liu H.","surname":"Liu","given-name":"Huajun","initials":"H.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35367319800","authid":"35367319800","authname":"Wang C.","surname":"Wang","given-name":"Cailing","initials":"C.","afid": [{"@_fa": "true", "$" :"60009400"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55547138819","authid":"55547138819","authname":"Lu J.","surname":"Lu","given-name":"Jianfeng","initials":"J.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55570666400","authid":"55570666400","authname":"Tang Z.","surname":"Tang","given-name":"Zhenmin","initials":"Z.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/12773171100","authid":"12773171100","authname":"Yang J.","surname":"Yang","given-name":"Jingyu","initials":"J.","afid": [{"@_fa": "true", "$" :"60010080"}]}],"authkeywords":"Maximum Likelihood | Mobile robot | Monocular ego-motion | Optical flow","article-number":"62157","source-id":"144749","fund-acr":"NSFC","fund-no":"2015AA8106043","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85000384183"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85000384183?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85000384183&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85000384183&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85000384183","dc:identifier":"SCOPUS_ID:85000384183","eid":"2-s2.0-85000384183","dc:title":"A robust method for infrared small target based on saliency detection","dc:creator":"Bai T.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510605039"}],"prism:volume":"10033","prism:pageRange":null,"prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1117/12.2245173","dc:description":"Infrared small-target detection plays an important role in image processing for infrared remote sensing. In this paper, we formulate this problem as salient region detection, which is inspired by the fact that a small target can often attract attention of human eyes in infrared images. We show that the convolution of the image amplitude spectrum with a low pass Gaussian kernel of an appropriate scale is equivalent to an image saliency detector. In this paper, we present a quaternion representation of an image which is composed of its intensity after denoising, the horizontal gradient and the vertical gradient. Therefore, a new method for infrared small target based on hyper complex Fourier transform (HFT) is proposed. The saliency map is obtained by reconstructing the 2D signal using the original phase and the amplitude spectrum, filtered at an appropriate scale. Experimental results demonstrate that the proposed algorithm is able to predict salient regions on which people focus their attention.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025761","afid":"60025761","affilname":"Huazhong University of Science and Technology","affiliation-city":"Wuhan","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57192179165","authid":"57192179165","authname":"Bai T.","surname":"Bai","given-name":"Ting","initials":"T.","afid": [{"@_fa": "true", "$" :"60025761"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7401635999","authid":"7401635999","authname":"Tian J.","surname":"Tian","given-name":"Jinwen","initials":"J.","afid": [{"@_fa": "true", "$" :"60025761"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55967548200","authid":"55967548200","authname":"Sun X.","surname":"Sun","given-name":"Xiao","initials":"X.","afid": [{"@_fa": "true", "$" :"60025761"}]}],"authkeywords":"Hypercomplex Fourier Transform | Infrared image | Saliency | Target detection | Visual attention","article-number":"100330O","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84995584910"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84995584910?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84995584910&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84995584910&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84995584910","dc:identifier":"SCOPUS_ID:84995584910","eid":"2-s2.0-84995584910","dc:title":"Comparison of automatic image registration uncertainty for three IGRT systems using a male pelvis phantom","dc:creator":"Barber J.","prism:publicationName":"Journal of Applied Clinical Medical Physics","prism:eIssn":"15269914","prism:volume":"17","prism:issueIdentifier":"5","prism:pageRange":"283-292","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1120/jacmp.v17i5.6332","dc:description":"A series of phantom images using the CIRS Virtual Human Male Pelvis was acquired across available dose ranges for three image-guided radiotherapy (IGRT) imaging systems: Elekta XVI CBCT, Varian TrueBeam CBCT, and TomoTherapy MV CT. Each image was registered to a fan-beam CT within the XVI software 100 times with random initial offsets. The residual registration error was analyzed to assess the role of imaging hardware and reconstruction in the uncertainty of the IGRT process. Residual translation errors were similar for all systems and < 0.5 mm. Over the clinical dose range for prostate IGRT images (10-25 mGy), all imaging systems provided acceptable matches in > 90% of registrations when incorporating residual rotational error using a dual quaternion derived distance metric. Outside normal dose settings, large uncertainties were observed at very low and very high dose levels. No trend between initial offset and residual registration error was observed. Patient images may incur higher uncertainties than this phantom study; however, these results encourage automatic matching for standard dose settings with review by treatment staff.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60111268","afid":"60111268","affilname":"Ingham Institute for Applied Medical Research","affiliation-city":"Liverpool","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025709","afid":"60025709","affilname":"The University of Sydney","affiliation-city":"Sydney","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/108858352","afid":"108858352","affilname":"Liverpool and Macarthur Cancer Therapy Centres","affiliation-city":"Sydney","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/101707758","afid":"101707758","affilname":"Nepean Cancer Care Centre","affiliation-city":"Sydney","affiliation-country":"Australia"}],"pubmed-id":"27685137","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191442591","authid":"57191442591","authname":"Barber J.","surname":"Barber","given-name":"Jeffrey","initials":"J.","afid": [{"@_fa": "true", "$" :"101707758"},{"@_fa": "true", "$" :"60025709"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55433565600","authid":"55433565600","authname":"Sykes J.R.","surname":"Sykes","given-name":"Jonathan R.","initials":"J.R.","afid": [{"@_fa": "true", "$" :"60025709"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7102473157","authid":"7102473157","authname":"Holloway L.","surname":"Holloway","given-name":"Lois","initials":"L.","afid": [{"@_fa": "true", "$" :"60025709"},{"@_fa": "true", "$" :"60111268"},{"@_fa": "true", "$" :"108858352"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7006384833","authid":"7006384833","authname":"Thwaites D.I.","surname":"Thwaites","given-name":"David I.","initials":"D.I.","afid": [{"@_fa": "true", "$" :"60025709"}]}],"authkeywords":"Automatic image registration | IGRT","source-id":"27214","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84994460658"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84994460658?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84994460658&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84994460658&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84994460658","dc:identifier":"SCOPUS_ID:84994460658","eid":"2-s2.0-84994460658","dc:title":"Quaternion linear color edge-glowing filter using genetic algorithm","dc:creator":"Yasmin S.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783319486796"}],"prism:volume":"10016 LNCS","prism:pageRange":"616-625","prism:coverDate":"2016-01-01","prism:coverDisplayDate":"2016","prism:doi":"10.1007/978-3-319-48680-2_54","dc:description":"This paper presents a quaternion linear color edge-glowing filter, based on a zooming technique using a genetic algorithm (GA) and quaternion (hypercomplex) convolution, to create a mask of the proposed filter. The zooming technique helps to produce the glowing color edges in all directions, with only one mask, and the GA helps to find the coefficients of the filter mask. This was a challenge with previous mathematical frameworks. The proposed filter employs linear color vector filtering operations on images. This converts the areas of smoothly-varying colors into black and generates glowing color edges in regions where color (but not intensity) edges occur in the image. The filter has been tested on different types of color images; the experimental results show that the proposed filter is a great advance towards the development of linear color vector image filtering. The computation time for the GA is about 1 h, which is very reasonable. The novelty of this filter is that one mask is enough for producing glowing color edges in all directions.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001359","afid":"60001359","affilname":"University of Essex","affiliation-city":"Colchester","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191874642","authid":"57191874642","authname":"Yasmin S.","surname":"Yasmin","given-name":"Shagufta","initials":"S.","afid": [{"@_fa": "true", "$" :"60001359"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003346836","authid":"7003346836","authname":"Sangwine S.","surname":"Sangwine","given-name":"Stephen J.","initials":"S.J.","afid": [{"@_fa": "true", "$" :"60001359"}]}],"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}