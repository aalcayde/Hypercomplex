{"search-results":{"opensearch:totalResults":"206","opensearch:startIndex":"125","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "125"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2017&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2017&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=100&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2017&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=150&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2017&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=181&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2017&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85021077962"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85021077962?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85021077962&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85021077962&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85021077962","dc:identifier":"SCOPUS_ID:85021077962","eid":"2-s2.0-85021077962","dc:title":"Multi-source dynamic attitude combination measurement for near-bit drilling tool","dc:creator":"Gao Y.","prism:publicationName":"Zhongguo Guanxing Jishu Xuebao/Journal of Chinese Inertial Technology","prism:issn":"10056734","prism:volume":"25","prism:issueIdentifier":"2","prism:pageRange":"146-150","prism:coverDate":"2017-04-01","prism:coverDisplayDate":"1 April 2017","prism:doi":"10.13695/j.cnki.12-1222/o3.2017.02.002","dc:description":"In the process of the attitude measurement for steering drilling system, the measurement of the attitude parameters may be uncertainty and unpredictable due to the influence of near-bit's strong vibration. In order to eliminate the regular interference's and vibration's influences on the measurement and quickly obtain the accurate attitude parameters of steering drilling tool, a new method of multi-source dynamic attitude combination measurement is presented. By using three-axis accelerometer, three-axis magnetic flux gate and angular rate gyro measurement system, the nonlinear model based on the quaternion is established. The relationship between the steering drilling tool motion state and the vibration acceleration is studied, and according to the model and the noise characteristics, the vibration disturbance signal is eliminated by the Unscented Kalman filtering based on the Quaternary. Experimental results and comparison analysis demonstrate that the proposed multi-source dynamic attitude combination measurement method can eliminate the near-bit interference's influences on the attitude parameters measurement, and effectively improve the accuracy of the attitude dynamic measurement of steering drilling tool. The deviation angle can be controlled to about 5.2°, and the tool face angle error is less than 10°.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025279","afid":"60025279","affilname":"Xi'an Shiyou University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55731336700","authid":"55731336700","authname":"Gao Y.","surname":"Gao","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60025279"},{"@_fa": "true", "$" :"60025279"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8686500600","authid":"8686500600","authname":"Cheng W.","surname":"Cheng","given-name":"Wei Bin","initials":"W.B.","afid": [{"@_fa": "true", "$" :"60025279"},{"@_fa": "true", "$" :"60025279"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/24067954700","authid":"24067954700","authname":"Wang Y.","surname":"Wang","given-name":"Yue Long","initials":"Y.L.","afid": [{"@_fa": "true", "$" :"60025279"},{"@_fa": "true", "$" :"60025279"}]}],"authkeywords":"Dynamic measurement | Multi-sensor fusion | Near-bit vibration | Steering drilling | Unscented Kalman filter","source-id":"19700186905","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85018513184"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85018513184?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85018513184&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85018513184&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85018513184","dc:identifier":"SCOPUS_ID:85018513184","eid":"2-s2.0-85018513184","dc:title":"Design, Implementation, and Evaluation of a Point Cloud Codec for Tele-Immersive Video","dc:creator":"Mekuria R.","prism:publicationName":"IEEE Transactions on Circuits and Systems for Video Technology","prism:issn":"10518215","prism:volume":"27","prism:issueIdentifier":"4","prism:pageRange":"828-842","prism:coverDate":"2017-04-01","prism:coverDisplayDate":"April 2017","prism:doi":"10.1109/TCSVT.2016.2543039","dc:description":"We present a generic and real-time time-varying point cloud codec for 3D immersive video. This codec is suitable for mixed reality applications in which 3D point clouds are acquired at a fast rate. In this codec, intra frames are coded progressively in an octree subdivision. To further exploit inter-frame dependencies, we present an inter-prediction algorithm that partitions the octree voxel space in N × N × N macroblocks ( N=8,16,32 ). The algorithm codes points in these blocks in the predictive frame as a rigid transform applied to the points in the intra-coded frame. The rigid transform is computed using the iterative closest point algorithm and compactly represented in a quaternion quantization scheme. To encode the color attributes, we defined a mapping of color per vertex attributes in the traversed octree to an image grid and use legacy image coding method based on JPEG. As a result, a generic compression framework suitable for real-time 3D tele-immersion is developed. This framework has been optimized to run in real time on commodity hardware for both the encoder and decoder. Objective evaluation shows that a higher rate-distortion performance is achieved compared with available point cloud codecs. A subjective study in a state-of-the-art mixed reality system shows that introduced prediction distortions are negligible compared with the original reconstructed point clouds. In addition, it shows the benefit of reconstructed point cloud video as a representation in the 3D virtual world. The codec is available as open source for integration in immersive and augmented communication applications and serves as a base reference software platform in JTC1/SC29/WG11 (MPEG) for the further development of standardized point-cloud compression solutions.","citedby-count":"244","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011575","afid":"60011575","affilname":"Centrum Wiskunde &amp; Informatica","affiliation-city":"Amsterdam","affiliation-country":"Netherlands"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008734","afid":"60008734","affilname":"Vrije Universiteit Amsterdam","affiliation-city":"Amsterdam","affiliation-country":"Netherlands"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36700010400","authid":"36700010400","orcid":"0000-0002-5581-6352","authname":"Mekuria R.","surname":"Mekuria","given-name":"Rufael","initials":"R.","afid": [{"@_fa": "true", "$" :"60008734"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56337591200","authid":"56337591200","authname":"Blom K.","surname":"Blom","given-name":"Kees","initials":"K.","afid": [{"@_fa": "true", "$" :"60011575"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/16237880000","authid":"16237880000","authname":"Cesar P.","surname":"Cesar","given-name":"Pablo","initials":"P.","afid": [{"@_fa": "true", "$" :"60011575"}]}],"authkeywords":"Data compression | Point clouds | Teleconferencing | Video codecs | Virtual reality","article-number":"7434610","source-id":"26027","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85017148020"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85017148020?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85017148020&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85017148020&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85017148020","dc:identifier":"SCOPUS_ID:85017148020","eid":"2-s2.0-85017148020","dc:title":"Adopting Quaternion Wavelet Transform to Fuse Multi-Modal Medical Images","dc:creator":"Geng P.","prism:publicationName":"Journal of Medical and Biological Engineering","prism:issn":"16090985","prism:eIssn":"21994757","prism:volume":"37","prism:issueIdentifier":"2","prism:pageRange":"230-239","prism:coverDate":"2017-04-01","prism:coverDisplayDate":"1 April 2017","prism:doi":"10.1007/s40846-016-0200-6","dc:description":"Medical image fusion plays an important role in clinical applications such as image-guided surgery, image-guided radiotherapy, noninvasive diagnosis, and treatment planning. In this paper, we propose a novel multi-modal medical image fusion method based on simplified pulse-coupled neural network and quaternion wavelet transform. The proposed fusion algorithm is capable of combining not only pairs of computed tomography (CT) and magnetic resonance (MR) images, but also pairs of CT and proton-density-weighted MR images, and multi-spectral MR images such as T1 and T2. Experiments on six pairs of multi-modal medical images are conducted to compare the proposed scheme with four existing methods. The performances of various methods are investigated using mutual information metrics and comprehensive fusion performance characterization (total fusion performance, fusion loss, and modified fusion artifacts criteria). The experimental results show that the proposed algorithm not only extracts more important visual information from source images, but also effectively avoids introducing artificial information into fused medical images. It significantly outperforms existing medical image fusion methods in terms of subjective performance and objective evaluation metrics.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60268352","afid":"60268352","affilname":"Zhangjiakou University","affiliation-city":"Zhangjiakou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032274","afid":"60032274","affilname":"Shijiazhuang Tiedao University","affiliation-city":"Shijiazhuang","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35843974800","authid":"35843974800","authname":"Geng P.","surname":"Geng","given-name":"Peng","initials":"P.","afid": [{"@_fa": "true", "$" :"60032274"},{"@_fa": "true", "$" :"60032274"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57221082729","authid":"57221082729","authname":"Sun X.","surname":"Sun","given-name":"Xiuming","initials":"X.","afid": [{"@_fa": "true", "$" :"60268352"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55851920200","authid":"55851920200","authname":"Liu J.","surname":"Liu","given-name":"Jianhua","initials":"J.","afid": [{"@_fa": "true", "$" :"60032274"}]}],"authkeywords":"Image fusion | Multi-modal medical image | Pulse-coupled neural network (PCNN) | Quaternion wavelet transform","source-id":"15949","fund-acr":"NSFC","fund-no":"61401308","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherhybridgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Hybrid Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84994752034"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84994752034?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84994752034&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84994752034&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84994752034","dc:identifier":"SCOPUS_ID:84994752034","eid":"2-s2.0-84994752034","dc:title":"Relaxed quaternionic Gabor expansions at critical density","dc:creator":"Hartmann S.","prism:publicationName":"Mathematical Methods in the Applied Sciences","prism:issn":"01704214","prism:eIssn":"10991476","prism:volume":"40","prism:issueIdentifier":"5","prism:pageRange":"1666-1678","prism:coverDate":"2017-03-30","prism:coverDisplayDate":"30 March 2017","prism:doi":"10.1002/mma.4087","dc:description":"Shifted and modulated Gaussian functions play a vital role in the representation of signals. We extend the theory into a quaternionic setting, using two exponential kernels with two complex numbers. As a final result, we show that every continuous and quaternion-valued signal f in the Wiener space can be expanded into a unique ℓ2 series on a lattice at critical density 1, provided one more point is added in the middle of a cell. We call that a relaxed Gabor expansion. Copyright © 2016 John Wiley & Sons, Ltd.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024825","afid":"60024825","affilname":"Universidade de Aveiro","affiliation-city":"Aveiro","affiliation-country":"Portugal"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56781045600","authid":"56781045600","authname":"Hartmann S.","surname":"Hartmann","given-name":"Stefan","initials":"S.","afid": [{"@_fa": "true", "$" :"60024825"}]}],"authkeywords":"critical density | hypercomplex signal | quaternionic windowed Fourier transform | quaternionic Zak transform | relaxed Gabor expansion","source-id":"24594","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006132127"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006132127?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85006132127&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85006132127&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0925231216312747"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85006132127","dc:identifier":"SCOPUS_ID:85006132127","eid":"2-s2.0-85006132127","dc:title":"Image splicing detection based on Markov features in QDCT domain","dc:creator":"Li C.","prism:publicationName":"Neurocomputing","prism:issn":"09252312","prism:eIssn":"18728286","prism:volume":"228","prism:pageRange":"29-36","prism:coverDate":"2017-03-08","prism:coverDisplayDate":"8 March 2017","prism:doi":"10.1016/j.neucom.2016.04.068","pii":"S0925231216312747","dc:description":"Image splicing is very common and fundamental in image tampering. Therefore, image splicing detection has attracted more and more attention recently in digital forensics. Gray images are used directly, or color images are converted to gray images before be processed in previous image splicing detection algorithms. However, most forgery images are color images. In order to make use of the color information in images, a classification algorithm is put forward which can use color images directly. In this paper, an algorithm based on Markov in quaternion discrete cosine transform (QDCT) domain is proposed for image splicing detection. First of all, color information is extracted from blocked images to construct quaternion in a whole manner, and the QDCT coefficients of quaternion blocked images can be obtained. Secondly, the expanded Markov features generated from the transition probability matrices in QDCT domain can not only capture the intra-block, but also the inter-block correlation between block QDCT coefficients. Finally, support vector machine (SVM) is exploited to classify the Markov feature vector. The experiment results demonstrate that the proposed algorithm not only make use of color information of images, but also can yield considerably better detection performance compared with the state-of-the-art splicing detection methods tested on the same dataset.","citedby-count":"73","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025945","afid":"60025945","affilname":"Lanzhou University of Technology","affiliation-city":"Lanzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018308","afid":"60018308","affilname":"Xi'an Jiaotong University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36699960500","authid":"36699960500","authname":"Li C.","surname":"Li","given-name":"Ce","initials":"C.","afid": [{"@_fa": "true", "$" :"60018308"},{"@_fa": "true", "$" :"60025945"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56912708600","authid":"56912708600","authname":"Ma Q.","surname":"Ma","given-name":"Qiang","initials":"Q.","afid": [{"@_fa": "true", "$" :"60025945"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/48261661600","authid":"48261661600","authname":"Xiao L.","surname":"Xiao","given-name":"Limei","initials":"L.","afid": [{"@_fa": "true", "$" :"60025945"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56994171900","authid":"56994171900","authname":"Li M.","surname":"Li","given-name":"Ming","initials":"M.","afid": [{"@_fa": "true", "$" :"60025945"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55731270200","authid":"55731270200","authname":"Zhang A.","surname":"Zhang","given-name":"Aihua","initials":"A.","afid": [{"@_fa": "true", "$" :"60025945"}]}],"authkeywords":"Color image for detection | Image splicing | Markov model | Quaternion discrete cosine transform","source-id":"24807","fund-acr":"NSFC","fund-no":"61365003,61302116","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85021672586"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85021672586?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85021672586&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85021672586&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85021672586","dc:identifier":"SCOPUS_ID:85021672586","eid":"2-s2.0-85021672586","dc:title":"Accurate computation of quaternion polar complex exponential transform for color images in different coordinate systems","dc:creator":"Hosny K.M.","prism:publicationName":"Journal of Electronic Imaging","prism:issn":"10179909","prism:eIssn":"1560229X","prism:volume":"26","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.1117/1.JEI.26.2.023021","dc:description":"Quaternion polar complex exponential transform (QPCET) moments and their invariants are widely used as powerful tools in many image processing and pattern recognition applications. However, the accuracy of the conventional approximated method for computing QPCET moments suffers from geometric and numerical errors. This approximated method is very time-consuming. Moreover, computing the high orders of approximated QPCET moments suffers from numerical instability. Computational methods are proposed for fast and accurate computation of the QPCET moments for color images in two coordinate systems. In the first method, the Gaussian quadrature method is applied to compute higher-order moments of QPCET in the Cartesian coordinates. On the other side, an exact kernel-based method is employed to compute the higher-order moments of QPCET in the polar coordinates. A set of numerical experiments is conducted and the obtained results clearly show that the conventional approximated method is unstable, where the numerical instability encountered with moment order ≥10, while the first proposed method is unstable for moment order =60. On the other side, the second proposed method is stable for all orders. The comparison clearly shows the superiority of the second proposed method in terms of image reconstruction capability, numerical stability, fast computation, rotation invariances, and robustness to different kinds of noises.","citedby-count":"12","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60274165","afid":"60274165","affilname":"Faculty of Computers and Information","affiliation-city":"Zagazig","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60273131","afid":"60273131","affilname":"Faculty of Science","affiliation-city":"Asyut","affiliation-country":"Egypt"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205214086","authid":"57205214086","authname":"Hosny K.M.","surname":"Hosny","given-name":"Khalid M.","initials":"K.M.","afid": [{"@_fa": "true", "$" :"60274165"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57205229124","authid":"57205229124","authname":"Darwish M.M.","surname":"Darwish","given-name":"Mohamed M.","initials":"M.M.","afid": [{"@_fa": "true", "$" :"60273131"}]}],"authkeywords":"Cartesian coordinates | Polar coordinates | Quaternion polar complex exponential transform | Reconstruction of color images | Rotational invariance","article-number":"023021","source-id":"25978","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019686461"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019686461?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019686461&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019686461&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019686461","dc:identifier":"SCOPUS_ID:85019686461","eid":"2-s2.0-85019686461","dc:title":"Color Image Detail Enhancement Based on Quaternion Guided Filter","dc:creator":"Wu K.","prism:publicationName":"Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics","prism:issn":"10039775","prism:volume":"29","prism:issueIdentifier":"3","prism:pageRange":"419-427","prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","dc:description":"To make the detail of color images outstanding, highly visible, an image enhancement method based on the quaternion guided filter was proposed. First, the traditional guided filter was extended to quaternion field, and the guided filter based on quaternion was obtained. Then, the original color image was modeled in a quaternion matrix form, and the quaternion-value of the image was processed through quaternion guided filter. Furthermore, image layering was adopted to decompose a source image into a base image and a detail image, and the detail image was enhanced by self-adaptive enhancement transform. Finally, the base image and the detail-enhanced image were reconstructed to obtain an enhanced image. Experimental results show that the proposed method can produce high-quality detail enhancement. It not only makes image's edges more prominent and textures clearer, but also keeps color fidelity. Comparing with the existing enhancement methods, our proposed method improves the visual quality significantly and the objective evaluating indicators are also greatly improved.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57194327094","authid":"57194327094","authname":"Wu K.","surname":"Wu","given-name":"Kun","initials":"K.","afid": [{"@_fa": "true", "$" :"60004828"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55558630500","authid":"55558630500","authname":"Li G.","surname":"Li","given-name":"Guiju","initials":"G.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7202923446","authid":"7202923446","authname":"Han G.","surname":"Han","given-name":"Guangliang","initials":"G.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55322098100","authid":"55322098100","authname":"Yang H.","surname":"Yang","given-name":"Hang","initials":"H.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57203768643","authid":"57203768643","authname":"Wang Y.","surname":"Wang","given-name":"Yuqing","initials":"Y.","afid": [{"@_fa": "true", "$" :"60004828"}]}],"authkeywords":"Detail enhancement | Guided filter | Quaternion | Self-adaptive enhancement transform","source-id":"25574","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019378344"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85019378344?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85019378344&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85019378344&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85019378344","dc:identifier":"SCOPUS_ID:85019378344","eid":"2-s2.0-85019378344","dc:title":"Transferring pre-trained deep CNNs for remote scene classification with general features learned from linear PCA network","dc:creator":"Wang J.","prism:publicationName":"Remote Sensing","prism:eIssn":"20724292","prism:volume":"9","prism:issueIdentifier":"3","prism:pageRange":null,"prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.3390/rs9030225","dc:description":"Deep convolutional neural networks (CNNs) have been widely used to obtain high-level representation in various computer vision tasks. However, in the field of remote sensing, there are not sufficient images to train a useful deep CNN. Instead, we tend to transfer successful pre-trained deep CNNs to remote sensing tasks. In the transferring process, generalization power of features in pre-trained deep CNNs plays the key role. In this paper, we propose two promising architectures to extract general features from pre-trained deep CNNs for remote scene classification. These two architectures suggest two directions for improvement. First, before the pre-trained deep CNNs, we design a linear PCA network (LPCANet) to synthesize spatial information of remote sensing images in each spectral channel. This design shortens the spatial \"distance\" of target and source datasets for pre-trained deep CNNs. Second, we introduce quaternion algebra to LPCANet, which further shortens the spectral \"distance\" between remote sensing images and images used to pre-train deep CNNs. With five well-known pre-trained deep CNNs, experimental results on three independent remote sensing datasets demonstrate that our proposed framework obtains state-of-the-art results without fine-tuning and feature fusing. This paper also provides baseline for transferring fresh pre-trained deep CNNs to other remote sensing tasks.","citedby-count":"55","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069720","afid":"60069720","affilname":"Air Force Engineering University China","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55969122900","authid":"55969122900","authname":"Wang J.","surname":"Wang","given-name":"Jie","initials":"J.","afid": [{"@_fa": "true", "$" :"60069720"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57189042360","authid":"57189042360","authname":"Luo C.","surname":"Luo","given-name":"Chang","initials":"C.","afid": [{"@_fa": "true", "$" :"60069720"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57215153156","authid":"57215153156","authname":"Huang H.","surname":"Huang","given-name":"Hanqiao","initials":"H.","afid": [{"@_fa": "true", "$" :"60069720"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57192951225","authid":"57192951225","authname":"Zhao H.","surname":"Zhao","given-name":"Huizhen","initials":"H.","afid": [{"@_fa": "true", "$" :"60069720"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/54418099700","authid":"54418099700","authname":"Wang S.","surname":"Wang","given-name":"Shiqiang","initials":"S.","afid": [{"@_fa": "true", "$" :"60069720"}]}],"authkeywords":"Convolutional neural network | Deep learning | General feature | Principle component analysis | Remote scene classification","article-number":"225","source-id":"86430","fund-acr":"NSFC","fund-no":"61601499","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016289037"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016289037?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85016289037&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85016289037&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85016289037","dc:identifier":"SCOPUS_ID:85016289037","eid":"2-s2.0-85016289037","dc:title":"Quaternion structured paranormal distributions","dc:creator":"Woodbridge Y.","prism:publicationName":"Conference Record - Asilomar Conference on Signals, Systems and Computers","prism:issn":"10586393","prism:isbn": [{"@_fa": "true", "$" :"9781538639542"}],"prism:pageRange":"815-819","prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.1109/ACSSC.2016.7869160","dc:description":"Quaternions, a four dimensional extension of complex numbers, are increasingly being used in various signal processing applications. At the same time, there are few probabilistic representations for capturing such random variables. In this work we present a new copula-based distribution over quaternions. The distribution extends the classical Gaussian and independent distributions, while maintaining the circular symmetry conditions required by such applications, namely properness. Importantly, the new distribution allows for flexible control of both the marginals and the correlations. We develop methods for estimating the parameters of the new distribution, and demonstrate its potential advantages via numerical experiments.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57189600174","authid":"57189600174","authname":"Woodbridge Y.","surname":"Woodbridge","given-name":"Yonatan","initials":"Y."},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8899019300","authid":"8899019300","authname":"Elidan G.","surname":"Elidan","given-name":"Gal","initials":"G."},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6603672752","authid":"6603672752","authname":"Wiesel A.","surname":"Wiesel","given-name":"Ami","initials":"A."}],"article-number":"7869160","source-id":"12222","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85014308304"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85014308304?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85014308304&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85014308304&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85014308304","dc:identifier":"SCOPUS_ID:85014308304","eid":"2-s2.0-85014308304","dc:title":"Comparison of two SVD-based color image compression schemes","dc:creator":"Li Y.","prism:publicationName":"PLoS ONE","prism:eIssn":"19326203","prism:volume":"12","prism:issueIdentifier":"3","prism:pageRange":null,"prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.1371/journal.pone.0172746","dc:description":"Color image compression is a commonly used process to represent image data as few bits as possible, which removes redundancy in the data while maintaining an appropriate level of quality for the user. Color image compression algorithms based on quaternion are very common in recent years. In this paper, we propose a color image compression scheme, based on the real SVD, named real compression scheme. First, we form a new real rectangular matrix C according to the red, green and blue components of the original color image and perform the real SVD for C. Then we select several largest singular values and the corresponding vectors in the left and right unitary matrices to compress the color image. We compare the real compression scheme with quaternion compression scheme by performing quaternion SVD using the real structure-preserving algorithm. We compare the two schemes in terms of operation amount, assignment number, operation speed, PSNR and CR. The experimental results show that with the same numbers of selected singular values, the real compression scheme offers higher CR, much less operation time, but a little bit smaller PSNR than the quaternion compression scheme. When these two schemes have the same CR, the real compression scheme shows more prominent advantages both on the operation time and PSNR.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030274","afid":"60030274","affilname":"Liaocheng University","affiliation-city":"Liaocheng","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022279","afid":"60022279","affilname":"Shanghai Normal University","affiliation-city":"Shanghai","affiliation-country":"China"}],"pubmed-id":"28257451","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56086640300","authid":"56086640300","authname":"Li Y.","surname":"Li","given-name":"Ying","initials":"Y.","afid": [{"@_fa": "true", "$" :"60030274"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7202184397","authid":"7202184397","authname":"Wei M.","surname":"Wei","given-name":"Musheng","initials":"M.","afid": [{"@_fa": "true", "$" :"60030274"},{"@_fa": "true", "$" :"60022279"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55376173400","authid":"55376173400","authname":"Zhang F.","surname":"Zhang","given-name":"Fengxia","initials":"F.","afid": [{"@_fa": "true", "$" :"60030274"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36867981700","authid":"36867981700","authname":"Zhao J.","surname":"Zhao","given-name":"Jianli","initials":"J.","afid": [{"@_fa": "true", "$" :"60030274"}]}],"article-number":"e0172746","source-id":"10600153309","fund-acr":"ED","fund-no":"J15LI10","fund-sponsor":"U.S. Department of Education","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84988329725"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84988329725?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84988329725&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84988329725&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84988329725","dc:identifier":"SCOPUS_ID:84988329725","eid":"2-s2.0-84988329725","dc:title":"Frequency response experiments of eye-vergence visual servoing in lateral motion with 3D evolutionary pose tracking","dc:creator":"Tian H.","prism:publicationName":"Artificial Life and Robotics","prism:issn":"14335298","prism:eIssn":"16147456","prism:volume":"22","prism:issueIdentifier":"1","prism:pageRange":"36-43","prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.1007/s10015-016-0319-0","dc:description":"Visual servoing towards moving target with hand-eye cameras fixed at hand is inevitably affected by hand dynamical oscillations. Therefore, it is difficult to make target position keep always at the center of camera’s view, as nonlinear dynamical effects of whole manipulator stand against tracking ability. To overcome this defect of the hand-eye fixed camera system, an eye-vergence system has been put forward, where the cameras could rotate to observe the target object. The visual servoing controllers of hand and eye-vergence are installed independently, so that it can observe the target object at the center of camera images through eye-vergence function. The dynamical superiorities of eye-vergence system are verified through frequency response experiments, comparing with hand tracking performances and the proposed eye-vergence tracking performances. This paper analyzes the performance of 3D-object position and orientation tracking, in which orientation representation method is based on quaternion, and the orientation tracking results are shown with more comprehensive analysis of system performance.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023147","afid":"60023147","affilname":"Okayama University","affiliation-city":"Okayama","affiliation-country":"Japan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/112700548","afid":"112700548","affilname":"Kawasaki College of Allied Health Professions","affiliation-city":"Kawasaki","affiliation-country":"Japan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191252625","authid":"57191252625","authname":"Tian H.","surname":"Tian","given-name":"Hongzhi","initials":"H.","afid": [{"@_fa": "true", "$" :"60023147"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57191251756","authid":"57191251756","authname":"Cui Y.","surname":"Cui","given-name":"Yu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60023147"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7402907499","authid":"7402907499","authname":"Minami M.","surname":"Minami","given-name":"Mamoru","initials":"M.","afid": [{"@_fa": "true", "$" :"60023147"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57189022378","authid":"57189022378","authname":"Yanou A.","surname":"Yanou","given-name":"Akira","initials":"A.","afid": [{"@_fa": "true", "$" :"112700548"}]}],"authkeywords":"Eye-vergence | Model-based matching | Quaternion | Visual servoing","source-id":"144653","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84982293163"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84982293163?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84982293163&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84982293163&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84982293163","dc:identifier":"SCOPUS_ID:84982293163","eid":"2-s2.0-84982293163","dc:title":"A novel combination of second-order statistical features and segmentation using multi-layer superpixels for salient object detection","dc:creator":"Arya R.","prism:publicationName":"Applied Intelligence","prism:issn":"0924669X","prism:eIssn":"15737497","prism:volume":"46","prism:issueIdentifier":"2","prism:pageRange":"254-271","prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.1007/s10489-016-0819-6","dc:description":"Salient object detection is one of the outstanding capabilities of the human visual system (HVS). The researcher community aims at developing a salient object detection model that matches the detection accuracy as well as computation time taken by the humans. These models can be developed in either spatial domain or frequency domain. Spatial domain models provide good detection accuracy at the cost of high computational time while frequency domain models offer fast computational speed to meet real-time requirements at the cost of poor detection accuracy. In order to induce a trade-off between computational time and accuracy, we propose a model which provides high detection accuracy without taking much of computation time. To detect the salient object with an accurate shape, we first segment the given image by utilizing a bipartite graph partitioning approach which aggregates multi-layer superpixels in a principled and effective manner. Second, the saliency of each segmented region is computed based on a hypercomplex Fourier transform (HFT) saliency map reconstructed using amplitude spectrum, filtered at an appropriate scale chosen using statistical features extracted from grey- level co-occurrence matrix and original phase spectrum. Finally, a saliency map is generated by taking average of the HFT coefficients of each region in the segmented image and then using the average HFT intensity value of the entire image as a threshold to clearly separate salient object from the background. The performance of the proposed model is evaluated in terms of F–measure, area under curve (AUC), and computation time using six publicly available image datasets. Both qualitative and quantitative evaluations on six publicly available datasets demonstrate the robustness and efficiency of the proposed model against twenty popular state-of-the-art methods.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60107387","afid":"60107387","affilname":"National Institute of Technology, Uttarakhand","affiliation-city":"Sumari","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030622","afid":"60030622","affilname":"Jawaharlal Nehru University","affiliation-city":"New Delhi","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55940327800","authid":"55940327800","authname":"Arya R.","surname":"Arya","given-name":"Rinki","initials":"R.","afid": [{"@_fa": "true", "$" :"60030622"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57214659061","authid":"57214659061","authname":"Singh N.","surname":"Singh","given-name":"Navjot","initials":"N.","afid": [{"@_fa": "true", "$" :"60030622"},{"@_fa": "true", "$" :"60107387"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35291228900","authid":"35291228900","authname":"Agrawal R.K.","surname":"Agrawal","given-name":"R. K.","initials":"R.K.","afid": [{"@_fa": "true", "$" :"60030622"}]}],"authkeywords":"Bipartite graph | Gray-level Co-occurrence Matrix (GLCM) | Hypercomplex fourier transform (HFT) | Saliency map | Salient object detection | Segmentation | Superpixel | Visual saliency","source-id":"23674","fund-acr":"UGC","fund-no":"undefined","fund-sponsor":"University Grants Commission","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84966697281"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84966697281?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84966697281&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84966697281&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84966697281","dc:identifier":"SCOPUS_ID:84966697281","eid":"2-s2.0-84966697281","dc:title":"General two-sided quaternion Fourier transform, convolution and Mustard convolution","dc:creator":"Hitzer E.","prism:publicationName":"Advances in Applied Clifford Algebras","prism:issn":"01887009","prism:eIssn":"16614909","prism:volume":"27","prism:issueIdentifier":"1","prism:pageRange":"381-395","prism:coverDate":"2017-03-01","prism:coverDisplayDate":"1 March 2017","prism:doi":"10.1007/s00006-016-0684-8","dc:description":"In this paper we use the general two-sided quaternion Fourier transform (QFT), and relate the classical convolution of quaternion-valued signals over R2 with the Mustard convolution. A Mustard convolution can be expressed in the spectral domain as the point wise product of the QFTs of the factor functions. In full generality do we express the classical convolution of quaternion signals in terms of finite linear combinations of Mustard convolutions, and vice versa the Mustard convolution of quaternion signals in terms of finite linear combinations of classical convolutions.","citedby-count":"22","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8898269700","authid":"8898269700","authname":"Hitzer E.","surname":"Hitzer","given-name":"Eckhard","initials":"E."}],"authkeywords":"Convolution | Frequency domain | Mustard convolution | Quaternion signals | Spatial domain | Two-sided quaternion Fourier transform","source-id":"4900152804","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016056359"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016056359?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85016056359&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85016056359&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85016056359","dc:identifier":"SCOPUS_ID:85016056359","eid":"2-s2.0-85016056359","dc:title":"Two-dimensional analytic signal construction","dc:creator":"Ge G.","prism:publicationName":"Proceedings - 2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2016","prism:isbn": [{"@_fa": "true", "$" :"9781509037100"}],"prism:pageRange":"883-887","prism:coverDate":"2017-02-13","prism:coverDisplayDate":"13 February 2017","prism:doi":"10.1109/CISP-BMEI.2016.7852835","dc:description":"This paper provides a brief overview of the approaches for two-dimensional analytic signal construction. According to the basis of definition for one-dimensional analytic signal, a set of desirable properties is determined as the guideline to measure a new definition for two-dimensional analytic signal. To appreciate this guideline, several important definitions are brought out, such as total analytic signal, partial analytic signal and Hahn's twodimensional analytic signal, etc. It is a pity that these definitions cannot satisfy the main properties in the guideline. A chance to solve this problem is provided by the quaternion theory. Based on the Quaternionic Fourier Transform (QFT), a novel definition called quaternionic analytic signal is introduced. This novel definition fulfills most properties in the guideline.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60012581","afid":"60012581","affilname":"Zhejiang Gongshang University","affiliation-city":"Hangzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004538","afid":"60004538","affilname":"Dalian University of Technology","affiliation-city":"Dalian","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/100666584","afid":"100666584","affilname":"Dalian Shipbuilding Industry Co. Ltd.","affiliation-city":"Dalian","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/24824490600","authid":"24824490600","authname":"Ge G.","surname":"Ge","given-name":"Guangtao","initials":"G.","afid": [{"@_fa": "true", "$" :"60012581"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58423575700","authid":"58423575700","authname":"Lou Y.","surname":"Lou","given-name":"Yichao","initials":"Y.","afid": [{"@_fa": "true", "$" :"60012581"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/54785560400","authid":"54785560400","authname":"Wang X.","surname":"Wang","given-name":"Xiuping","initials":"X.","afid": [{"@_fa": "true", "$" :"60012581"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/58449017100","authid":"58449017100","authname":"Xue L.","surname":"Xue","given-name":"Lei","initials":"L.","afid": [{"@_fa": "true", "$" :"60004538"},{"@_fa": "true", "$" :"100666584"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/15753223100","authid":"15753223100","authname":"Dai D.","surname":"Dai","given-name":"Dashuang","initials":"D.","afid": [{"@_fa": "true", "$" :"60004538"}]}],"authkeywords":"Analytic Signal | Quaternion | Quaternionic Fourier Transform (QFT)","article-number":"7852835","source-id":"21100803188","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016039274"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85016039274?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85016039274&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85016039274&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85016039274","dc:identifier":"SCOPUS_ID:85016039274","eid":"2-s2.0-85016039274","dc:title":"Camera image quality assessment without reference information","dc:creator":"Tang L.","prism:publicationName":"Proceedings - 2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2016","prism:isbn": [{"@_fa": "true", "$" :"9781509037100"}],"prism:pageRange":"666-670","prism:coverDate":"2017-02-13","prism:coverDisplayDate":"13 February 2017","prism:doi":"10.1109/CISP-BMEI.2016.7852793","dc:description":"Blur plays an key part in evaluating of camera image quality. It leads to decrease of high frequency information and accordingly changes the image energy. Recent researches in quaternion singular value decomposition show that the quaternion's singular values and associated vectors can capture the distortion of color images, and thus singular values can be utilized to assess the sharpness of camera image. Based on this, a novel blind quality assessment method considering the integral color information and singular values of the blurred camera image is proposed for evaluating the sharpness of camera image. Pure quaternion is utilized to represent pixels of the blurred camera image and the energy of every block are obtained. Results confirm the superiority of the proposed blind algorithm in assessing camera images.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60106849","afid":"60106849","affilname":"Nanjing Institute of Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005510","afid":"60005510","affilname":"Nanyang Technological University","affiliation-city":"Singapore City","affiliation-country":"Singapore"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113311552","afid":"113311552","affilname":"Jiangsu Vocational College of Business","affiliation-city":"Nantong","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190384121","authid":"57190384121","authname":"Tang L.","surname":"Tang","given-name":"Lijuan","initials":"L.","afid": [{"@_fa": "true", "$" :"113311552"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55729837600","authid":"55729837600","authname":"Lu H.","surname":"Lu","given-name":"Hong","initials":"H.","afid": [{"@_fa": "true", "$" :"60106849"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55265130000","authid":"55265130000","authname":"Gu K.","surname":"Gu","given-name":"Ke","initials":"K.","afid": [{"@_fa": "true", "$" :"60005510"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57193716650","authid":"57193716650","authname":"Sun K.","surname":"Sun","given-name":"Kezheng","initials":"K.","afid": [{"@_fa": "true", "$" :"113311552"}]}],"article-number":"7852793","source-id":"21100803188","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015715929"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015715929?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85015715929&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85015715929&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85015715929","dc:identifier":"SCOPUS_ID:85015715929","eid":"2-s2.0-85015715929","dc:title":"Quaternion decomposition based discriminant analysis for color face recognition","dc:creator":"Lan R.","prism:publicationName":"2016 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2016 - Conference Proceedings","prism:isbn": [{"@_fa": "true", "$" :"9781509018970"}],"prism:pageRange":"1833-1837","prism:coverDate":"2017-02-06","prism:coverDisplayDate":"6 February 2017","prism:doi":"10.1109/SMC.2016.7844504","dc:description":"In this paper, we propose a novel quaternion decomposition based discriminant analysis (QDDA) method for color face recognition. Unlike traditional approaches that handle color face images by vector representation or by each color channel individually, QDDA makes use of the quaternion to encode all color channels such that we can process all these channels in a holistic way and consider their relations simultaneously. In order to extract more discriminant color information from the image, a decomposition operation is performed to the quaternion matrix. A linear discriminant analysis is finally implemented to the obtained subcomponents for feature extraction. Experimental results have demonstrated the effectiveness of QDDA by comparing with other quaternion based methods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022317","afid":"60022317","affilname":"University of Macau","affiliation-city":"Taipa","affiliation-country":"Macao"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35146229200","authid":"35146229200","authname":"Lan R.","surname":"Lan","given-name":"Rushi","initials":"R.","afid": [{"@_fa": "true", "$" :"60022317"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24175343600","authid":"24175343600","authname":"Zhou Y.","surname":"Zhou","given-name":"Yicong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60022317"}]}],"article-number":"7844504","source-id":"21100802687","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85027582090"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85027582090?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85027582090&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85027582090&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85027582090","dc:identifier":"SCOPUS_ID:85027582090","eid":"2-s2.0-85027582090","dc:title":"Quaternionic Weber Local Descriptor of Color Images","dc:creator":"Lan R.","prism:publicationName":"IEEE Transactions on Circuits and Systems for Video Technology","prism:issn":"10518215","prism:volume":"27","prism:issueIdentifier":"2","prism:pageRange":"261-274","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"February 2017","prism:doi":"10.1109/TCSVT.2015.2492839","dc:description":"This paper proposes a simple but effective framework named quaternionic Weber local descriptor (QWLD) for color image feature extraction. Integrating quaternionic representation (QR) of the color image and Weber's law (WL), QWLD possesses both their superiorities. It uses QR to handle all color channels of the image in a holistic way while preserving their relations, and applies WL to ensure that the derived descriptors are robust and discriminative. Using the QWLD framework, we further develop the quaternionic-increment-based Weber descriptor and quaternionic-distance-based Weber descriptor in terms of different perspectives. Extensive experiments on different color image recognition problems demonstrate that the proposed framework and descriptors outperform state-of-the-art local descriptors.","citedby-count":"37","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022317","afid":"60022317","affilname":"University of Macau","affiliation-city":"Taipa","affiliation-country":"Macao"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35146229200","authid":"35146229200","authname":"Lan R.","surname":"Lan","given-name":"Rushi","initials":"R.","afid": [{"@_fa": "true", "$" :"60022317"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24175343600","authid":"24175343600","orcid":"0000-0002-4487-6384","authname":"Zhou Y.","surname":"Zhou","given-name":"Yicong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60022317"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7404591899","authid":"7404591899","authname":"Tang Y.Y.","surname":"Tang","given-name":"Yuan Yan","initials":"Y.Y.","afid": [{"@_fa": "true", "$" :"60022317"}]}],"authkeywords":"Color image descriptor | local feature | quaternionic representation (QR) | Weber's law (WL)","source-id":"26027","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015231840"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015231840?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85015231840&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85015231840&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85015231840","dc:identifier":"SCOPUS_ID:85015231840","eid":"2-s2.0-85015231840","dc:title":"Quaternion based joint DOA and polarization parameters estimation with stretched three-component electromagnetic vector sensor array","dc:creator":"Zhao J.","prism:publicationName":"Journal of Systems Engineering and Electronics","prism:issn":"16711793","prism:volume":"28","prism:issueIdentifier":"1","prism:pageRange":"1-9","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"February 2017","prism:doi":"10.21629/JSEE.2017.01.01","dc:description":"The three-component electromagnetic vector sensor (EMVS) consisting of co-centered orthogonally oriented x-dipole, z-dipole and z-loop is considered. In order to make full use of the spatial aperture of each component, the original uniform linear three-component EMVS array (ULTEA) is stretched into one half-wavelength spaced uniform linear loop subarray (ULLSA) along the z axis, and one sparse uniform linear co-centered orthogonally oriented dual-dipole (CODD) subarray (SULCSA) along the x axis. Then, a generalized rotation invariance based quaternion multiple signal classification (GRIQ-MUSIC) algorithm is presented for direction of arrival (DOA) and polarization parameters estimation. According to the proposed algorithm, the elevation angles are firstly estimated based on the half-wavelength spaced ULLSA. Then the polarization phase differences and azimuth angles are obtained based on the coupling relationship between the angle domain and polarization domain, but the azimuth angles are in coarse-resolution since the array aperture is not utilized. Next, the SULCSA is used to re-estimate the azimuth angles in fine-resolution, and the ambiguity problem can be resolved by the least square method. Finally, based on the estimated elevation angles, azimuth angles and polarization phase differences, the corresponding auxiliary polarization angles can be estimated by N times one-dimensional parameter search, where N is the sources number, and the parameters are matched automatically. Based on the GRIQ-MUSIC algorithm, the high dimensional parameters search problem of the conventional Q-MUSIC algorithm is simplified to a one-dimensional parameter search problem, thus the proposed algorithm not only reduces the computation complexity considerably, but also avoids the performance degradation caused by the failure in parameters pairing. The simulation examples demonstrate the effectiveness and feasibility of the proposed algorithm.","citedby-count":"12","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025578","afid":"60025578","affilname":"Xidian University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56729271200","authid":"56729271200","authname":"Zhao J.","surname":"Zhao","given-name":"Jichao","initials":"J.","afid": [{"@_fa": "true", "$" :"60025578"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7202328081","authid":"7202328081","authname":"Tao H.","surname":"Tao","given-name":"Haihong","initials":"H.","afid": [{"@_fa": "true", "$" :"60025578"}]}],"authkeywords":"direction of arrival (DOA) | electromagnetic vector sensor (EMVS) array | generalized rotational invariance based quaternion multiple signal classification (GRIQ-MUSIC) | polarization","article-number":"7870503","source-id":"58655","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85010219998"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85010219998?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85010219998&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85010219998&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85010219998","dc:identifier":"SCOPUS_ID:85010219998","eid":"2-s2.0-85010219998","dc:title":"A software package for evaluating the performance of a star sensor operation","dc:creator":"Sarpotdar M.","prism:publicationName":"Experimental Astronomy","prism:issn":"09226435","prism:eIssn":"15729508","prism:volume":"43","prism:issueIdentifier":"1","prism:pageRange":"99-117","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"1 February 2017","prism:doi":"10.1007/s10686-016-9522-1","dc:description":"We have developed a low-cost off-the-shelf component star sensor (StarSense) for use in minisatellites and CubeSats to determine the attitude of a satellite in orbit. StarSense is an imaging camera with a limiting magnitude of 6.5, which extracts information from star patterns it records in the images. The star sensor implements a centroiding algorithm to find centroids of the stars in the image, a Geometric Voting algorithm for star pattern identification, and a QUEST algorithm for attitude quaternion calculation. Here, we describe the software package to evaluate the performance of these algorithms as a star sensor single operating system. We simulate the ideal case where sky background and instrument errors are omitted, and a more realistic case where noise and camera parameters are added to the simulated images. We evaluate such performance parameters of the algorithms as attitude accuracy, calculation time, required memory, star catalog size, sky coverage, etc., and estimate the errors introduced by each algorithm. This software package is written for use in MATLAB. The testing is parametrized for different hardware parameters, such as the focal length of the imaging setup, the field of view (FOV) of the camera, angle measurement accuracy, distortion effects, etc., and therefore, can be applied to evaluate the performance of such algorithms in any star sensor. For its hardware implementation on our StarSense, we are currently porting the codes in form of functions written in C. This is done keeping in view its easy implementation on any star sensor electronics hardware.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007654","afid":"60007654","affilname":"Indian Institute of Astrophysics","affiliation-city":"Bengaluru","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "8", "$" :"8"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191746583","authid":"57191746583","orcid":"0000-0003-1555-958X","authname":"Sarpotdar M.","surname":"Sarpotdar","given-name":"Mayuresh","initials":"M.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56678969000","authid":"56678969000","authname":"Mathew J.","surname":"Mathew","given-name":"Joice","initials":"J.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55671867600","authid":"55671867600","authname":"Sreejith A.","surname":"Sreejith","given-name":"A. G.","initials":"A.G.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57192081430","authid":"57192081430","authname":"Nirmal K.","surname":"Nirmal","given-name":"K.","initials":"K.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57192663194","authid":"57192663194","authname":"Ambily S.","surname":"Ambily","given-name":"S.","initials":"S.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57192079834","authid":"57192079834","authname":"Prakash A.","surname":"Prakash","given-name":"Ajin","initials":"A.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/6602852259","authid":"6602852259","authname":"Safonova M.","surname":"Safonova","given-name":"Margarita","initials":"M.","afid": [{"@_fa": "true", "$" :"60007654"}]},{"@_fa": "true", "@seq": "8", "author-url":"https://api.elsevier.com/content/author/author_id/7102462509","authid":"7102462509","authname":"Murthy J.","surname":"Murthy","given-name":"Jayant","initials":"J.","afid": [{"@_fa": "true", "$" :"60007654"}]}],"authkeywords":"Attitude control system | Centroiding algorithm | Cubesats | Geometric voting algorithm | QUEST algorithm | Star sensor","source-id":"27195","fund-acr":"डीएसटी","fund-no":"IR/S2/PU-006/2012","fund-sponsor":"Department of Science and Technology, Ministry of Science and Technology, India","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006819435"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006819435?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85006819435&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85006819435&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0967066116302519"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85006819435","dc:identifier":"SCOPUS_ID:85006819435","eid":"2-s2.0-85006819435","dc:title":"A low-cost high-fidelity ultrasound simulator with the inertial tracking of the probe pose","dc:creator":"Farsoni S.","prism:publicationName":"Control Engineering Practice","prism:issn":"09670661","prism:volume":"59","prism:pageRange":"183-193","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"1 February 2017","prism:doi":"10.1016/j.conengprac.2016.11.002","pii":"S0967066116302519","dc:description":"The authors developed a versatile ultrasound simulator. The proposed system achieves the main features of a high-fidelity device exploiting low-cost rapid prototyping hardware. The hand-guided ultrasound simulator probe includes a RFID reader, a 9-DOF inertial sensor unit, consisting of an accelerometer, a magnetometer and a gyroscope, and a microcontroller that performs the real-time data acquisition, the processing and the transmission of the estimated pose information to the visualization system, so that the proper ultrasound view can be generated. Since the probe orientation is the main information involved in the pose reconstruction, this work presents and investigates several tracking methods for the probe orientation, exploiting a sensor fusion technique to filter the noisy measurements coming from inertial sensors. The performances of a Kalman filter, a nonlinear complementary filter and a quaternion-based filter as inertial trackers have been tested by means of a robot manipulator, in terms of readiness, accuracy and stability of the estimated orientation signal. The results show that the nonlinear complementary filter and the quaternion-based filter match all the application requirements (RMSE <3deg, variance <1deg2, and settling time <0.3s), and they involve a lower computational time with respect to the Kalman filter.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024690","afid":"60024690","affilname":"University of Ferrara","affiliation-city":"Ferrara","affiliation-country":"Italy"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56102599900","authid":"56102599900","authname":"Farsoni S.","surname":"Farsoni","given-name":"Saverio","initials":"S.","afid": [{"@_fa": "true", "$" :"60024690"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6602978139","authid":"6602978139","authname":"Bonfè M.","surname":"Bonfè","given-name":"Marcello","initials":"M.","afid": [{"@_fa": "true", "$" :"60024690"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8655129800","authid":"8655129800","authname":"Astolfi L.","surname":"Astolfi","given-name":"Luca","initials":"L.","afid": [{"@_fa": "true", "$" :"60024690"}]}],"authkeywords":"Inertial tracking | Medical training | Real-time algorithms | Sensor fusion | Ultrasound simulator","source-id":"18174","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006802873"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006802873?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85006802873&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85006802873&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0893608016300338"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85006802873","dc:identifier":"SCOPUS_ID:85006802873","eid":"2-s2.0-85006802873","dc:title":"Neurons the decision makers, Part I: The firing function of a single neuron","dc:creator":"Saaty T.","prism:publicationName":"Neural Networks","prism:issn":"08936080","prism:eIssn":"18792782","prism:volume":"86","prism:pageRange":"102-114","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"1 February 2017","prism:doi":"10.1016/j.neunet.2016.04.003","pii":"S0893608016300338","dc:description":"This paper is concerned with understanding synthesis of electric signals in the neural system based on making pairwise comparisons. Fundamentally, every person and every animal are born with the talent to compare stimuli from things that share properties in space or over time. Comparisons always need experience to distinguish among things. Pairwise comparisons are numerically reciprocal. If a value is assigned to the larger of two elements that have a given property when compared with the smaller one, then the smaller has the reciprocal of that value when compared with the larger. Because making comparisons requires the reciprocal property, we need mathematics that can cope with division. There are four division algebras that would allow us to use our reciprocals arising from comparisons: The real numbers, the complex numbers, the non-commutative quaternions and the non-associative octonions. Rather than inferring function as from electric flow in a network, in this paper we infer the flow from function. Neurons fire in response to stimuli and their firings vary relative to the intensities of the stimuli. We believe neurons use some kind of pairwise comparison mechanism to determine when to fire based on the stimuli they receive. The ideas we develop here about flows are used to deduce how a system based on this kind of firing determination works and can be described. Furthermore the firing of neurons requires continuous comparisons. To develop a formula describing the output of these pairwise comparisons requires solving Fredholm's equation of the second kind which is satisfied if and only if a simple functional equation has solutions. The Fourier transform of the real solution of this equation leads to inverse square laws like those that are common in physics. The Fourier transform applied to a complex valued solution leads to Dirac type of firings. Such firings are dense in the very general fields of functions known as Sobolev spaces and thus can be used to represent the very diverse phenomena in and around us. The non-commutative solution in quaternions can be interpreted as rotations in space. The also non-commutative and non-associative solution in octonions has yet to be adequately interpreted outside physics.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015543","afid":"60015543","affilname":"University of Pittsburgh","affiliation-city":"Pittsburgh","affiliation-country":"United States"}],"pubmed-id":"27292267","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7004006121","authid":"7004006121","orcid":"0000-0002-1304-7663","authname":"Saaty T.","surname":"Saaty","given-name":"Thomas","initials":"T.","afid": [{"@_fa": "true", "$" :"60015543"}]}],"authkeywords":"Complex | Fredholm's equation | Functional equation of proportionality | Octonions | Quaternions | Real","source-id":"24804","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84996799401"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84996799401?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84996799401&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84996799401&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0952197616302056"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84996799401","dc:identifier":"SCOPUS_ID:84996799401","eid":"2-s2.0-84996799401","dc:title":"Discriminant quaternion local binary pattern embedding for person re-identification through prototype formation and color categorization","dc:creator":"Chahla C.","prism:publicationName":"Engineering Applications of Artificial Intelligence","prism:issn":"09521976","prism:volume":"58","prism:pageRange":"27-33","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"1 February 2017","prism:doi":"10.1016/j.engappai.2016.11.004","pii":"S0952197616302056","dc:description":"Re-identifying objects is one of the fundamental elements for visual surveillance, in the sense that images of the same object at different time or places should be assigned with the same label. In this work, we propose a new embedding scheme for person re-identification under nonoverlapping target cameras. Inspired by the prototype approach derived from cognition field, we propose to use prototype images as a reference set to achieve a discriminative representation of a person's appearance. To enhance the discrimination between different persons, we learn a linear subspace in a training phase during which person correspondences are assumed to be known. The robustness of the algorithm against results that are counterintuitive to a human operator is improved by proposing the Color Categorization procedure. By doing so, our method becomes very flexible when tracing a person in a camera network even under large illumination changes. The proposed framework was tested on VIPeR, the most challenging dataset for person re-identification. Results confirm that our method outperforms the state of the art techniques.","citedby-count":"17","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104285","afid":"60104285","affilname":"Ikerbasque, Basque Foundation for Science","affiliation-city":"Bilbao","affiliation-country":"Spain"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60068774","afid":"60068774","affilname":"Université Libanaise","affiliation-city":"Beirut","affiliation-country":"Lebanon"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027856","afid":"60027856","affilname":"Universidad del Pais Vasco","affiliation-city":"Leioa","affiliation-country":"Spain"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023736","afid":"60023736","affilname":"Université de Technologie de Troyes","affiliation-city":"Troyes","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57160103400","authid":"57160103400","authname":"Chahla C.","surname":"Chahla","given-name":"C.","initials":"C.","afid": [{"@_fa": "true", "$" :"60023736"},{"@_fa": "true", "$" :"60068774"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/16176538800","authid":"16176538800","authname":"Snoussi H.","surname":"Snoussi","given-name":"H.","initials":"H.","afid": [{"@_fa": "true", "$" :"60023736"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57210156007","authid":"57210156007","authname":"Abdallah F.","surname":"Abdallah","given-name":"F.","initials":"F.","afid": [{"@_fa": "true", "$" :"60068774"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55967501800","authid":"55967501800","authname":"Dornaika F.","surname":"Dornaika","given-name":"F.","initials":"F.","afid": [{"@_fa": "true", "$" :"60027856"},{"@_fa": "true", "$" :"60104285"}]}],"authkeywords":"Color categorization | Discrimination | Person re-identification | Prototype formation | Quaternion local binary pattern","source-id":"24182","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84995489246"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84995489246?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84995489246&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84995489246&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84995489246","dc:identifier":"SCOPUS_ID:84995489246","eid":"2-s2.0-84995489246","dc:title":"Compressed Sensing for Quaternionic Signals","dc:creator":"Gomes N.","prism:publicationName":"Complex Analysis and Operator Theory","prism:issn":"16618254","prism:eIssn":"16618262","prism:volume":"11","prism:issueIdentifier":"2","prism:pageRange":"417-455","prism:coverDate":"2017-02-01","prism:coverDisplayDate":"1 February 2017","prism:doi":"10.1007/s11785-016-0607-7","dc:description":"We study the problem of compressed sensing for quaternionic Fourier matrices as arising in color representation of images. We will show that such matrices are allowing a sparse reconstruction by means of an l1-minimization with high probability. Examples of sparse sampling of color images are provided.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60139088","afid":"60139088","affilname":"Universidade de Cabo Verde","affiliation-city":"Praia","affiliation-country":"Cape Verde"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024825","afid":"60024825","affilname":"Universidade de Aveiro","affiliation-city":"Aveiro","affiliation-country":"Portugal"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191953232","authid":"57191953232","authname":"Gomes N.","surname":"Gomes","given-name":"Narciso","initials":"N.","afid": [{"@_fa": "true", "$" :"60139088"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56781045600","authid":"56781045600","authname":"Hartmann S.","surname":"Hartmann","given-name":"Stefan","initials":"S.","afid": [{"@_fa": "true", "$" :"60024825"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/36191790900","authid":"36191790900","orcid":"0000-0002-9066-1819","authname":"Kähler U.","surname":"Kähler","given-name":"Uwe","initials":"U.","afid": [{"@_fa": "true", "$" :"60024825"}]}],"authkeywords":"Compressed sensing | Quaternionic signals | Sparsity constrains","source-id":"5700165206","fund-acr":"FCT","fund-no":"UID/MAT/ 0416/2013","fund-sponsor":"Fundação para a Ciência e a Tecnologia","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015314569"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85015314569?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85015314569&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85015314569&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85015314569","dc:identifier":"SCOPUS_ID:85015314569","eid":"2-s2.0-85015314569","dc:title":"Quaternion linear colour edge-sharpening filter using genetic algorithm","dc:creator":"Yasmin S.","prism:publicationName":"2016 8th Computer Science and Electronic Engineering Conference, CEEC 2016 - Conference Proceedings","prism:isbn": [{"@_fa": "true", "$" :"9781509020508"}],"prism:pageRange":"124-129","prism:coverDate":"2017-01-27","prism:coverDisplayDate":"27 January 2017","prism:doi":"10.1109/CEEC.2016.7835900","dc:description":"A quaternion linear colour edge-sharpening filter is presented. A quaternion convolution mask is created using a genetic algorithm (GA) and a zooming technique. When the new filter is applied to colour images, it produces sharpened colour edges in all directions in regions where colour (but not intensity) edges occur in the image. The methodology of the proposed filter depends on the zooming technique and fitness function. The new filter is tested on different kind of colour images and the experimental results show that the proposed scheme is needed for sharpening colour edges in all directions with only one mask. This proposed filter is a great achievement for developing linear colour vector image filters because it is difficult to design manually/mathematically. This new filter is an example of a linear colour vector image filter developed using genetic algorithm and zooming techniques.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001359","afid":"60001359","affilname":"University of Essex","affiliation-city":"Colchester","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57191874642","authid":"57191874642","authname":"Yasmin S.","surname":"Yasmin","given-name":"Shagufta","initials":"S.","afid": [{"@_fa": "true", "$" :"60001359"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003346836","authid":"7003346836","authname":"Sangwine S.","surname":"Sangwine","given-name":"Stephen J.","initials":"S.J.","afid": [{"@_fa": "true", "$" :"60001359"}]}],"article-number":"7835900","source-id":"21100801719","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006940224"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85006940224?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85006940224&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85006940224&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0021929016311289"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85006940224","dc:identifier":"SCOPUS_ID:85006940224","eid":"2-s2.0-85006940224","dc:title":"Interpolation of three dimensional kinematics with dual-quaternions","dc:creator":"Goodsitt J.","prism:publicationName":"Journal of Biomechanics","prism:issn":"00219290","prism:eIssn":"18732380","prism:volume":"51","prism:pageRange":"105-110","prism:coverDate":"2017-01-25","prism:coverDisplayDate":"25 January 2017","prism:doi":"10.1016/j.jbiomech.2016.10.028","pii":"S0021929016311289","dc:description":"Devising patient-specific kinematic assessment techniques are critical for both patient diagnosis and treatment evaluation of complex biomechanical joints within the body. New non-invasive kinematic assessment techniques, such as bi-planar fluoroscopic registration, provide improved insight on joint biomechanics compared to traditional techniques, but at the expense of higher radiation exposure to the patient. The purpose of this study was to minimize the x-ray sample size required for evaluating spine kinematics, ultimately reducing radiation exposure, while maintaining a high degree of accuracy by improving upon existing 3D kinematic interpolation techniques. Existing interpolation methods were improved to account for non-uniformly sampled control points and applied to new motion descriptors, thus creating a new approach to 3D kinematic interpolation utilizing dual-quaternions. Interpolation reconstruction methods were applied to decimated gold standard ex vivo spinal kinematic data originally acquired at 30 Hz. The effects of interpolation method and variables (motion descriptor, sample spacing, sampling correction factors) on accuracy were compared. Dual-quaternion interpolation methods and equal interval angular sampling showed superior reconstruction results. Accuracy also improved when using temporal correction factors. Less than 1% normalized root-mean-squared error and less than 2% normalized maximum error were achieved from 0.36% of the original data set. The new approach also demonstrated its scalability for larger movements. However, accuracy may vary when interpolating more complex motion patterns. Overall, multiple interpolation methods and factors were evaluated in reconstructing 3D spine kinematics. High accuracy at low sample sizes and advantageous scalability to motions with larger total displacement illustrate its viability for bi-planar fluoroscopy.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017216","afid":"60017216","affilname":"Loyola University Medical Center","affiliation-city":"Maywood","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60014521","afid":"60014521","affilname":"Edward Hines Jr. VA Hospital","affiliation-city":"Hines","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000745","afid":"60000745","affilname":"University of Illinois Urbana-Champaign","affiliation-city":"Urbana","affiliation-country":"United States"}],"pubmed-id":"27829494","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56743231900","authid":"56743231900","authname":"Goodsitt J.","surname":"Goodsitt","given-name":"Jeremy E.","initials":"J.E.","afid": [{"@_fa": "true", "$" :"60000745"},{"@_fa": "true", "$" :"60014521"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7004176274","authid":"7004176274","authname":"Havey R.","surname":"Havey","given-name":"Robert M.","initials":"R.M.","afid": [{"@_fa": "true", "$" :"60014521"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56743194200","authid":"56743194200","authname":"Khayatzadeh S.","surname":"Khayatzadeh","given-name":"Saeed","initials":"S.","afid": [{"@_fa": "true", "$" :"60014521"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/6603835154","authid":"6603835154","authname":"Voronov L.","surname":"Voronov","given-name":"Leonard I.","initials":"L.I.","afid": [{"@_fa": "true", "$" :"60014521"},{"@_fa": "true", "$" :"60017216"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7102069417","authid":"7102069417","authname":"Patwardhan A.","surname":"Patwardhan","given-name":"Avinash G.","initials":"A.G.","afid": [{"@_fa": "true", "$" :"60014521"},{"@_fa": "true", "$" :"60017216"}]}],"authkeywords":"3-D Motion | Dual | Dual-quaternions | Helical axes of motion | Interpolation | Joint | Kinematics | Lumbar | Quaternions | Spine","source-id":"15846","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}