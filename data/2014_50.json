{"search-results":{"opensearch:totalResults":"179","opensearch:startIndex":"50","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "50"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=50&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=25&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=75&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=154&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84903454494"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84903454494?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84903454494&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84903454494&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84903454494","dc:identifier":"SCOPUS_ID:84903454494","eid":"2-s2.0-84903454494","dc:title":"Multi-focus image fusion based on quaternion wavelet","dc:creator":"Yin M.","prism:publicationName":"Journal of Information and Computational Science","prism:issn":"15487741","prism:volume":"11","prism:issueIdentifier":"9","prism:pageRange":"3187-3198","prism:coverDate":"2014-06-10","prism:coverDisplayDate":"10 June 2014","prism:doi":"10.12733/jics20103882","dc:description":"For the characteristics of multi-focus image and the shortcomings of traditional wavelet in image fusion multiscale analysis, we propose multi-focus image fusion method based on QuaternionWavelet Transform (QWT) in this paper. First, the original images are processed by quaternion wavelet transformthe local region energy is adopted for the low frequency sub-bands, while a Novel Sum-modified-Laplacian (NSML) is employed for the high frequency sub-bands. Then the fused image is achieved by the inverse quaternion wavelet transform, the algorithm has a certain effectiveness and practicality. Experiments show that comparing with traditional methods, the fusion result of this method is better in subjective vision effect and objective evaluation index. Copyright © 2014 Binary Information Press.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002836","afid":"60002836","affilname":"Hefei University of Technology","affiliation-city":"Hefei","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8611278700","authid":"8611278700","authname":"Yin M.","surname":"Yin","given-name":"Ming","initials":"M.","afid": [{"@_fa": "true", "$" :"60002836"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56093986900","authid":"56093986900","authname":"Wu J.","surname":"Wu","given-name":"Jiangmin","initials":"J.","afid": [{"@_fa": "true", "$" :"60002836"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56236903100","authid":"56236903100","authname":"Chu B.","surname":"Chu","given-name":"Biao","initials":"B.","afid": [{"@_fa": "true", "$" :"60002836"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56237254000","authid":"56237254000","authname":"Kong R.","surname":"Kong","given-name":"Ranran","initials":"R.","afid": [{"@_fa": "true", "$" :"60002836"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55376612000","authid":"55376612000","authname":"Wang Z.","surname":"Wang","given-name":"Zhicheng","initials":"Z.","afid": [{"@_fa": "true", "$" :"60002836"}]}],"authkeywords":"Image fusion | Local region energy | Novel sum-modified-Laplacian | Quaternion wavelet transform","source-id":"144748","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85017390746"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85017390746?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85017390746&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85017390746&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85017390746","dc:identifier":"SCOPUS_ID:85017390746","eid":"2-s2.0-85017390746","dc:title":"Quaternion Fourier Transforms for Signal and Image Processing","dc:creator":"Ell T.A.","prism:publicationName":"Quaternion Fourier Transforms for Signal and Image Processing","prism:isbn": [{"@_fa": "true", "$" :"9781118930908"},{"@_fa": "true", "$" :"9781848214781"}],"prism:pageRange":"1-136","prism:coverDate":"2014-06-03","prism:coverDisplayDate":"3 June 2014","prism:doi":"10.1002/9781118930908","dc:description":"Based on updates to signal and image processing technology made in the last two decades, this text examines the most recent research results pertaining to Quaternion Fourier Transforms. QFT is a central component of processing color images and complex valued signals. The book's attention to mathematical concepts, imaging applications, and Matlab compatibility render it an irreplaceable resource for students, scientists, researchers, and engineers.","citedby-count":"108","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/116719107","afid":"116719107","affilname":"Colchester","affiliation-city":null,"affiliation-country":"United Kingdom"}],"prism:aggregationType":"Book","subtype":"bk","subtypeDescription":"Book","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6603651371","authid":"6603651371","authname":"Ell T.A.","surname":"Ell","given-name":"Todd A.","initials":"T.A."},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6507015909","authid":"6507015909","authname":"Bihan N.L.","surname":"Bihan","given-name":"Nicolas Le","initials":"N.L."},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7003346836","authid":"7003346836","authname":"Sangwine S.J.","surname":"Sangwine","given-name":"Stephen J.","initials":"S.J.","afid": [{"@_fa": "true", "$" :"116719107"}]}],"source-id":"21100806078","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899986596"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899986596?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84899986596&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84899986596&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84899986596","dc:identifier":"SCOPUS_ID:84899986596","eid":"2-s2.0-84899986596","dc:title":"Two Sample Tests for Mean 3D Projective Shapes from Digital Camera Images","dc:creator":"Patrangenaru V.","prism:publicationName":"Methodology and Computing in Applied Probability","prism:issn":"13875841","prism:eIssn":"15737713","prism:volume":"16","prism:issueIdentifier":"2","prism:pageRange":"485-506","prism:coverDate":"2014-06-01","prism:coverDisplayDate":"June 2014","prism:doi":"10.1007/s11009-013-9363-6","dc:description":"In this article, we extend mean 3D projective shape change in matched pairs to independent samples. We provide a brief introduction of projective shapes of spatial configurations obtained from their digital camera images, building on previous results of Crane and Patrangenaru (J Multivar Anal 102:225-237, 2011). The manifold of projective shapes of k-ads in 3D containing a projective frame at five given landmark indices has a natural Lie group structure, which is inherited from the quaternion multiplication. Here, given the small sample size, one estimates the mean 3D projective shape change in two populations, based on independent random samples of possibly different sizes using Efron's nonparametric bootstrap. This methodology is applied in three relevant applications of analysis of 3D scenes from digital images: visual quality control, face recognition, and scene recognition. © 2013 Springer Science+Business Media New York.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002092","afid":"60002092","affilname":"Florida State University","affiliation-city":"Tallahassee","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/109584241","afid":"109584241","affilname":"Brain Corporation","affiliation-city":"San Diego","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6603108043","authid":"6603108043","authname":"Patrangenaru V.","surname":"Patrangenaru","given-name":"Vic","initials":"V.","afid": [{"@_fa": "true", "$" :"60002092"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55816442000","authid":"55816442000","authname":"Qiu M.","surname":"Qiu","given-name":"Mingfei","initials":"M.","afid": [{"@_fa": "true", "$" :"60002092"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/23767885500","authid":"23767885500","authname":"Buibas M.","surname":"Buibas","given-name":"Marius","initials":"M.","afid": [{"@_fa": "true", "$" :"109584241"}]}],"authkeywords":"3D projective shape | 3D scene reconstruction from a pair of uncalibrated camera views | Asymptotic statistics on manifolds | Computational statistics | Extrinsic mean change on a Lie group | Face recognition | Fréchet means | Nonparametric bootstrap on manifolds | Quaternions | Visual quality control","source-id":"144816","fund-acr":"NSF","fund-no":"DMS-0805977","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84893372421"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84893372421?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84893372421&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84893372421&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0143816614000098"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84893372421","dc:identifier":"SCOPUS_ID:84893372421","eid":"2-s2.0-84893372421","dc:title":"Quaternion higher-order spectra and their invariants for color image recognition","dc:creator":"Jia X.","prism:publicationName":"Optics and Lasers in Engineering","prism:issn":"01438166","prism:volume":"57","prism:pageRange":"28-39","prism:coverDate":"2014-06-01","prism:coverDisplayDate":"June 2014","prism:doi":"10.1016/j.optlaseng.2014.01.008","pii":"S0143816614000098","dc:description":"This paper describes an invariants generation method for color images, which could be a useful tool in color object recognition tasks. First, by using the algebra of quaternions, we introduce the definition of quaternion higher-order spectra (QHOS) in the spatial domain and derive its equivalent form in the frequency domain. Then, QHOS invariants with respect to rotation, translation, and scaling transformations for color images are constructed using the central slice theorem and quaternion bispectral analysis. The feature data are further reduced to a smaller set using quaternion principal component analysis. The proposed method can deal with color images in a holistic manner, and the constructed QHOS invariants are highly immune to background noise. Experimental results show that the extracted QHOS invariants form compact and isolated clusters, and that a simple minimum distance classifier can yield high recognition accuracy. © 2014 Elsevier Ltd. All rights reserved.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007711","afid":"60007711","affilname":"Jilin University","affiliation-city":"Changchun","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56023746400","authid":"56023746400","authname":"Jia X.","surname":"Jia","given-name":"Xiaoning","initials":"X.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55322098100","authid":"55322098100","authname":"Yang H.","surname":"Yang","given-name":"Hang","initials":"H.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8982588800","authid":"8982588800","authname":"Ma S.","surname":"Ma","given-name":"Siliang","initials":"S.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56024642200","authid":"56024642200","authname":"Song D.","surname":"Song","given-name":"Dongzhe","initials":"D.","afid": [{"@_fa": "true", "$" :"60007711"}]}],"authkeywords":"Bispectrum | Color image recognition | Higher-order spectra invariant | Quaternion | Quaternion principal component analysis","source-id":"12348","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84901386244"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84901386244?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84901386244&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84901386244&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84901386244","dc:identifier":"SCOPUS_ID:84901386244","eid":"2-s2.0-84901386244","dc:title":"Concurrent validity of accelerations measured using a tri-axial inertial measurement unit while walking on firm, compliant and uneven surfaces","dc:creator":"Cole M.H.","prism:publicationName":"PLoS ONE","prism:eIssn":"19326203","prism:volume":"9","prism:issueIdentifier":"5","prism:pageRange":null,"prism:coverDate":"2014-05-27","prism:coverDisplayDate":"27 May 2014","prism:doi":"10.1371/journal.pone.0098395","dc:description":"Although accelerometers are extensively used for assessing gait, limited research has evaluated the concurrent validity of these devices on less predictable walking surfaces or the comparability of different methods used for gravitational acceleration compensation. This study evaluated the concurrent validity of trunk accelerations derived from a tri-axial inertial measurement unit while walking on firm, compliant and uneven surfaces and contrasted two methods used to remove gravitational accelerations; i) subtraction of the best linear fit from the data (detrending); and ii) use of orientation information (quaternions) from the inertial measurement unit. Twelve older and twelve younger adults walked at their preferred speed along firm, compliant and uneven walkways. Accelerations were evaluated for the thoracic spine (T12) using a tri-axial inertial measurement unit and an eleven-camera Vicon system. The findings demonstrated excellent agreement between accelerations derived from the inertial measurement unit and motion analysis system, including while walking on uneven surfaces that better approximate a real-world setting (all differences <0.16 m.s-2). Detrending produced slightly better agreement between the inertial measurement unit and Vicon system on firm surfaces (delta range: -0.05 to 0.06 vs. 0.00 to 0.14 m.s-2), whereas the quaternion method performed better when walking on compliant and uneven walkways (delta range: -0.16 to -0.02 vs. -0.07 to 0.07 m.s-2). The technique used to compensate for gravitational accelerations requires consideration in future research, particularly when walking on compliant and uneven surfaces. These findings demonstrate trunk accelerations can be accurately measured using a wireless inertial measurement unit and are appropriate for research that evaluates healthy populations in complex environments. © 2014 Cole et al.","citedby-count":"23","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032987","afid":"60032987","affilname":"Griffith University","affiliation-city":"Brisbane","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031004","afid":"60031004","affilname":"The University of Queensland","affiliation-city":"Brisbane","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011019","afid":"60011019","affilname":"Queensland University of Technology","affiliation-city":"Brisbane","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010679","afid":"60010679","affilname":"Australian Catholic University","affiliation-city":"Sydney","affiliation-country":"Australia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007652","afid":"60007652","affilname":"Old Dominion University","affiliation-city":"Norfolk","affiliation-country":"United States"}],"pubmed-id":"24866262","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/25958682200","authid":"25958682200","authname":"Cole M.H.","surname":"Cole","given-name":"Michael H.","initials":"M.H.","afid": [{"@_fa": "true", "$" :"60010679"},{"@_fa": "true", "$" :"60011019"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/25723934200","authid":"25723934200","authname":"Van Den Hoorn W.","surname":"Van Den Hoorn","given-name":"Wolbert","initials":"W.","afid": [{"@_fa": "true", "$" :"60031004"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/9734434300","authid":"9734434300","authname":"Kavanagh J.K.","surname":"Kavanagh","given-name":"Justin K.","initials":"J.K.","afid": [{"@_fa": "true", "$" :"60032987"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7201672373","authid":"7201672373","authname":"Morrison S.","surname":"Morrison","given-name":"Steven","initials":"S.","afid": [{"@_fa": "true", "$" :"60007652"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7005834883","authid":"7005834883","authname":"Hodges P.W.","surname":"Hodges","given-name":"Paul W.","initials":"P.W.","afid": [{"@_fa": "true", "$" :"60031004"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/6701890314","authid":"6701890314","authname":"Smeathers J.E.","surname":"Smeathers","given-name":"James E.","initials":"J.E.","afid": [{"@_fa": "true", "$" :"60011019"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/7102158133","authid":"7102158133","authname":"Kerr G.K.","surname":"Kerr","given-name":"Graham K.","initials":"G.K.","afid": [{"@_fa": "true", "$" :"60011019"},{"@_fa": "true", "$" :"60011019"}]}],"article-number":"e98395","source-id":"10600153309","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899939557"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899939557?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84899939557&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84899939557&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84899939557","dc:identifier":"SCOPUS_ID:84899939557","eid":"2-s2.0-84899939557","dc:title":"Bundle block adjustment of airborne three-line array imagery based on rotation angles","dc:creator":"Zhang Y.","prism:publicationName":"Sensors (Switzerland)","prism:issn":"14248220","prism:volume":"14","prism:issueIdentifier":"5","prism:pageRange":"8189-8202","prism:coverDate":"2014-05-07","prism:coverDisplayDate":"7 May 2014","prism:doi":"10.3390/s140508189","dc:description":"In the midst of the rapid developments in electronic instruments and remote sensing technologies, airborne three-line array sensors and their applications are being widely promoted and plentiful research related to data processing and high precision geo-referencing technologies is under way. The exterior orientation parameters (EOPs), which are measured by the integrated positioning and orientation system (POS) of airborne three-line sensors, however, have inevitable systematic errors, so the level of precision of direct geo-referencing is not sufficiently accurate for surveying and mapping applications. Consequently, a few ground control points are necessary to refine the exterior orientation parameters, and this paper will discuss bundle block adjustment models based on the systematic error compensation and the orientation image, considering the principle of an image sensor and the characteristics of the integrated POS. Unlike the models available in the literature, which mainly use a quaternion to represent the rotation matrix of exterior orientation, three rotation angles are directly used in order to effectively model and eliminate the systematic errors of the POS observations. Very good experimental results have been achieved with several real datasets that verify the correctness and effectiveness of the proposed adjustment models. © 2014 by the authors; licensee MDPI, Basel, Switzerland.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029306","afid":"60029306","affilname":"Wuhan University","affiliation-city":"Wuhan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55577971100","authid":"55577971100","authname":"Zhang Y.","surname":"Zhang","given-name":"Yongjun","initials":"Y.","afid": [{"@_fa": "true", "$" :"60029306"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55457399500","authid":"55457399500","authname":"Zheng M.","surname":"Zheng","given-name":"Maoteng","initials":"M.","afid": [{"@_fa": "true", "$" :"60029306"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/36816004500","authid":"36816004500","authname":"Huang X.","surname":"Huang","given-name":"Xu","initials":"X.","afid": [{"@_fa": "true", "$" :"60029306"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36836445400","authid":"36836445400","authname":"Xiong J.","surname":"Xiong","given-name":"Jinxin","initials":"J.","afid": [{"@_fa": "true", "$" :"60029306"}]}],"authkeywords":"Airborne three-line array imagery | Block adjustment | Orientation image | Rotation angle | Systematic error compensation","source-id":"130124","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84890859684"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84890859684?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84890859684&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84890859684&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84890859684","dc:identifier":"SCOPUS_ID:84890859684","eid":"2-s2.0-84890859684","dc:title":"Region-of-interest extraction based on frequency domain analysis and salient region detection for remote sensing image","dc:creator":"Zhang L.","prism:publicationName":"IEEE Geoscience and Remote Sensing Letters","prism:issn":"1545598X","prism:volume":"11","prism:issueIdentifier":"5","prism:pageRange":"916-920","prism:coverDate":"2014-05-01","prism:coverDisplayDate":"May 2014","prism:doi":"10.1109/LGRS.2013.2281827","dc:description":"Traditional approaches for detecting visually salient regions or targets in remote sensing images are inaccurate and prohibitively computationally complex. In this letter, a fast, efficient region-of-interest extraction method based on frequency domain analysis and salient region detection (FDA-SRD) is proposed. First, the HSI transform is used to preprocess the remote sensing image from RGB space to HSI space. Second, a frequency domain analysis strategy based on quaternion Fourier transform was employed to rapidly generate the saliency map. Finally, the salient regions are described by an adaptive threshold segmentation algorithm based on Gaussian Pyramids. Compared with existing models, the new algorithm is computationally more efficient and provides more visually accurate detection results. © 2004-2012 IEEE.","citedby-count":"83","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023237","afid":"60023237","affilname":"Beijing Normal University","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35325855000","authid":"35325855000","authname":"Zhang L.","surname":"Zhang","given-name":"Libao","initials":"L.","afid": [{"@_fa": "true", "$" :"60023237"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55353851800","authid":"55353851800","authname":"Yang K.","surname":"Yang","given-name":"Kaina","initials":"K.","afid": [{"@_fa": "true", "$" :"60023237"}]}],"authkeywords":"Frequency domain analysis (FDA) | quaternion Fourier transform | region of interest (ROI) | remote sensing image processing","article-number":"6670051","source-id":"17259","fund-acr":"NSFC","fund-no":"61071103","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84892698809"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84892698809?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84892698809&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84892698809&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0167865513005126"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84892698809","dc:identifier":"SCOPUS_ID:84892698809","eid":"2-s2.0-84892698809","dc:title":"Color Fourier-Mellin descriptors for image recognition","dc:creator":"Mennesson J.","prism:publicationName":"Pattern Recognition Letters","prism:issn":"01678655","prism:volume":"40","prism:issueIdentifier":"1","prism:pageRange":"27-35","prism:coverDate":"2014-04-15","prism:coverDisplayDate":"15 April 2014","prism:doi":"10.1016/j.patrec.2013.12.014","pii":"S0167865513005126","dc:description":"We propose new sets of Fourier-Mellin descriptors for color images. They are constructed using the Clifford Fourier transform of Batard et al. (2010) [4] and are an extension of the classical Fourier-Mellin descriptors for grayscale images. These are invariant under direct similarity transformations (translations, rotations, scale) and marginal treatment of colors images is avoided. An implementation of these features is given and the choice of the bivector (a distinguished color plane which parameterizes the Clifford Fourier transform) is discussed. The proposed formalism extends and clarifies the notion of direction of analysis as introduced for the quaternionic Fourier-Mellin moments (Guo and Zhu, 2011). Thus, another set of descriptors invariant under this parameter is defined. Our proposals are tested with the purpose of object recognition on well-known color image databases. Their retrieval rates are favorably compared to standard feature descriptors. © 2014 Elsevier B.V. All rights reserved.","citedby-count":"37","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60122456","afid":"60122456","affilname":"Mathématiques, Image et Applications (MIA)","affiliation-city":"La Rochelle","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60122064","afid":"60122064","affilname":"Centre de Recherche en Informatique, Signal et Automatique de Lille ( CRISTAL )","affiliation-city":"Villeneuve-d'Ascq","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36844459600","authid":"36844459600","authname":"Mennesson J.","surname":"Mennesson","given-name":"J.","initials":"J.","afid": [{"@_fa": "true", "$" :"60122064"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/12800377500","authid":"12800377500","authname":"Saint-Jean C.","surname":"Saint-Jean","given-name":"C.","initials":"C.","afid": [{"@_fa": "true", "$" :"60122456"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6602823419","authid":"6602823419","authname":"Mascarilla L.","surname":"Mascarilla","given-name":"L.","initials":"L.","afid": [{"@_fa": "true", "$" :"60122456"}]}],"authkeywords":"Clifford algebra | Frequency methods | Image retrieval | Invariant color descriptors | Object recognition","source-id":"24825","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84903521255"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84903521255?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84903521255&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84903521255&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84903521255","dc:identifier":"SCOPUS_ID:84903521255","eid":"2-s2.0-84903521255","dc:title":"Camera calibration effects of rotation matrix expression","dc:creator":"Xu F.","prism:publicationName":"Journal of Geomatics","prism:issn":"10073817","prism:volume":"39","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2014-04-05","prism:coverDisplayDate":"5 April 2014","dc:description":"Because the initial values of the position and attitude are unable to get, in the big inclination angle images of camera calibration, it may lead to non-convergence iterations by classical collinearity equation of rotation matrix of Euler angle. In collinearity equation, rotation matrix can also be expressed by the direction cosine or unit quaternion. Then the camera calibration can not rely on the initial values of the position and attitude. This paper uses the same data, the same initial values and the same convergence conditions. The experimental results show that the direction cosine method is better than the unit quaternion method. It mainly reflected in the convergence case and the calculate value corresponds closely to the method of Euler angle. In the non-metric camera calibration, we recommend that the best choice is the rotation matrix expressed by direction cosine in collinearity equation.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029306","afid":"60029306","affilname":"Wuhan University","affiliation-city":"Wuhan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/51666033800","authid":"51666033800","authname":"Xu F.","surname":"Xu","given-name":"Fang","initials":"F.","afid": [{"@_fa": "true", "$" :"60029306"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/34975765100","authid":"34975765100","authname":"Mei W.","surname":"Mei","given-name":"Wensheng","initials":"W.","afid": [{"@_fa": "true", "$" :"60029306"}]}],"authkeywords":"Collinearity equation | Direction cosine | Euler angle | Unit quaternion","source-id":"144674","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899859346"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899859346?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84899859346&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84899859346&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84899859346","dc:identifier":"SCOPUS_ID:84899859346","eid":"2-s2.0-84899859346","dc:title":"Global observer-based attitude controller using direct inertial measurements","dc:creator":"Bouhired S.","prism:publicationName":"International Journal of Advanced Robotic Systems","prism:issn":"17298806","prism:eIssn":"17298814","prism:volume":"11","prism:issueIdentifier":"1","prism:pageRange":null,"prism:coverDate":"2014-04-02","prism:coverDisplayDate":"2 April 2014","prism:doi":"10.5772/56861","dc:description":"In this work, we address the problem of global attitude control using direct inertial measurements. When using direct inertial measurement to observe the rigid body attitude, it is shown that due to a geometrical obstruction, it is impossible to achieve global asymptotic stability. In fact, for a particular initial condition the tracking error quaternion converges to a pure imaginary quaternion formed by an eigenvector of a characteristic matrix related to the inertial constant and known vectors. Our proposition consists of adding a dynamic signal to force the rigid body to escape from such a situation. The proposed observer-based controller is synthesized based on a single Lyapunov function and a stability analysis shows that the controller stabilizes globally and asymptotically the rigid body attitude at the desired one. The effectiveness of the proposed observer-based controller is confirmed by simulation results. © 2014 The Author(s).","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105433","afid":"60105433","affilname":"École Militaire Polytechnique","affiliation-city":"Bordj El Bahri","affiliation-country":"Algeria"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60068739","afid":"60068739","affilname":"Ecole Nationale Polytechnique","affiliation-city":"Algiers","affiliation-country":"Algeria"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56078531300","authid":"56078531300","authname":"Bouhired S.","surname":"Bouhired","given-name":"Saâdi","initials":"S.","afid": [{"@_fa": "true", "$" :"60105433"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/15762077400","authid":"15762077400","authname":"Bouchoucha M.","surname":"Bouchoucha","given-name":"Mouloud","initials":"M.","afid": [{"@_fa": "true", "$" :"60105433"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6701425808","authid":"6701425808","authname":"Tadjine M.","surname":"Tadjine","given-name":"Mohamed","initials":"M.","afid": [{"@_fa": "true", "$" :"60068739"}]}],"authkeywords":"Attitude control | Global stability | Inertial measurements | Quaternion","article-number":"54","source-id":"144749","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84949928277"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84949928277?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84949928277&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84949928277&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84949928277","dc:identifier":"SCOPUS_ID:84949928277","eid":"2-s2.0-84949928277","dc:title":"Moment preserving technique for color feature extraction in content based image retrieval","dc:creator":"Kottawar V.","prism:publicationName":"International Conference on Computing and Communication Technologies, ICCCT 2014","prism:isbn": [{"@_fa": "true", "$" :"9781479981502"}],"prism:pageRange":null,"prism:coverDate":"2014-03-23","prism:coverDisplayDate":"23 March 2014","prism:doi":"10.1109/ICCCT2.2014.7066745","dc:description":"Interest in the digital images has increased a lot over the last few years, but the process of locating a desired image in such a large and diverse image collection becomes very difficult. Traditionally text in different languages is used for efficient retrieval of images; it has several drawbacks such as language constraint and subjectivity of human perception. Content-based image retrieval is a technique which uses visual contents such as color texture and shape to search images from large image databases according to user's desire. Color is the most commonly used feature for content based image retrieval. In many applications color histogram is used to represent extracted color features. The important drawback of usual color histogram based method is that, it does not take image color distribution into consideration and inflexibly partition the color spaces into a fixed number of bins. In this paper we propose a moment-preserving technique based on binary quaternion space for feature extraction. It aims to extract color features according to the image color distribution that effectively reduces the distortion incurred in the feature extraction process. We also propose an efficient clustering based algorithm to compare similarity between two histograms. It is observed that minimizing the distortion incurred in the extraction process can improve the accuracy of retrieval. Our experimental results show that the proposed extraction methods can improve the average retrieval precision rate by a factor of 25% over that of a color histogram based feature extraction method (binning method). It is also observed that, this technique effectively reduces the average retrieval time.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/109487619","afid":"109487619","affilname":"M.G.M's College of Engineering","affiliation-city":"Nanded","affiliation-country":"India"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56703460200","authid":"56703460200","authname":"Kottawar V.","surname":"Kottawar","given-name":"Vinayak Gajanan","initials":"V.G.","afid": [{"@_fa": "true", "$" :"109487619"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24778396700","authid":"24778396700","authname":"Rajurkar A.","surname":"Rajurkar","given-name":"A. M.","initials":"A.M.","afid": [{"@_fa": "true", "$" :"109487619"}]}],"authkeywords":"Clustering based histogram comparison | Content based image retrieval | Histogram | Quaternion moment","article-number":"7066745","source-id":"21100397326","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84896847181"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84896847181?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84896847181&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84896847181&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84896847181","dc:identifier":"SCOPUS_ID:84896847181","eid":"2-s2.0-84896847181","dc:title":"Secondary multiplication in tate cohomology of generalized quaternion groups","dc:creator":"Langer M.","prism:publicationName":"Homology, Homotopy and Applications","prism:issn":"15320073","prism:eIssn":"15320081","prism:volume":"16","prism:issueIdentifier":"1","prism:pageRange":"27-47","prism:coverDate":"2014-03-17","prism:coverDisplayDate":"2014","prism:doi":"10.4310/HHA.2014.v16.n1.a2","dc:description":"Let k be a field, and let G be a finite group. By a theorem of D. Benson, H. Krause, and S. Schwede, there is a canonical element in the Hochschild cohomology of the Tate cohomology γG ∈ HH3,-1Ĥ*(G) with the following property: Given any graded Ĥ*(G)-module X, the image of γG in Ext3,-1Ĥ*(G)(X;X)is zero if and only if X is isomorphic to a direct summand of Ĥ*(G, M)for some kG-module M. In particular, if γG = 0 then every module is a direct summand of a realizable Ĥ*(G)-module. We prove that the converse of that last statement is not true by studying in detail the case of generalized quaternion groups. Suppose that k is a field of characteristic 2 and G is generalized quaternion of order 2n with n ≥ 3. We show that γG is non-trivial for all n, but there is an Ĥ*(G)-module detecting this non-triviality if and only if n = 3. © 2014, International Press.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000401","afid":"60000401","affilname":"Westfälische Wilhelms-Universität Münster","affiliation-city":"Munster","affiliation-country":"Germany"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57198078523","authid":"57198078523","authname":"Langer M.","surname":"Langer","given-name":"Martin","initials":"M.","afid": [{"@_fa": "true", "$" :"60000401"}]}],"authkeywords":"Higher multiplication | Tate cohomology","source-id":"145269","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84897713265"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84897713265?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84897713265&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84897713265&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84897713265","dc:identifier":"SCOPUS_ID:84897713265","eid":"2-s2.0-84897713265","dc:title":"Video segmentation of multiresolution dynamic spatiotemporal model based on quaternion wavelet transform","dc:creator":"Hu W.","prism:publicationName":"Applied Mechanics and Materials","prism:issn":"16609336","prism:eIssn":"16627482","prism:isbn": [{"@_fa": "true", "$" :"9783038350125"}],"prism:volume":"513-517","prism:pageRange":"3822-3829","prism:coverDate":"2014-03-12","prism:coverDisplayDate":"2014","prism:doi":"10.4028/www.scientific.net/AMM.513-517.3822","dc:description":"How to achieve a meaningful video representation is an important problem in various research communities. Automatically segmenting non-specific objects is an open problem. To deal with the error segmentation problem of the existing video algorithms under dynamic scenes, we propose a dynamic spatiotemporal saliency model based on the quaternion wavelet transform for video segmentation in this paper, which has the capability of segmenting the salient objects from moving background automatically. The model is a dynamic combination of the temporal attention model and static salient model. In temporal attention model, motion contrast information can be computed from the phase disparity between two consecutive frames. The phase is extracted from quaternionic pyramid. In static salient model, the spatial attention information is computed by an inverse quaternion wavelet transform over the set of scale-weighted center-surround responses. The scale-weighting function has been optimized to better replicate psychophysical data on color appearance. We combine the two kinds of attention information to get the preliminary results and use Grabuct algorithm for the optimization of the result finally. The segmentation and comparison experimental results demonstrate the validity of proposed algorithm. © (2014) Trans Tech Publications, Switzerland.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013614","afid":"60013614","affilname":"Hangzhou Dianzi University","affiliation-city":"Hangzhou","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36185418400","authid":"36185418400","authname":"Hu W.","surname":"Hu","given-name":"Wei Hua","initials":"W.H.","afid": [{"@_fa": "true", "$" :"60013614"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56102455600","authid":"56102455600","authname":"Gu L.","surname":"Gu","given-name":"Liang","initials":"L.","afid": [{"@_fa": "true", "$" :"60013614"}]}],"authkeywords":"Color sensitivity | Dynamic spatiotemporal saliency | Motion salient features | Quaternion wavelet transform | Temporal saliency mapping | Video segmentation","source-id":"4700151914","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84896371432"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84896371432?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84896371432&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84896371432&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84896371432","dc:identifier":"SCOPUS_ID:84896371432","eid":"2-s2.0-84896371432","dc:title":"Double color image encryption using iterative phase retrieval algorithm in quaternion gyrator domain","dc:creator":"Shao Z.","prism:publicationName":"Optics Express","prism:eIssn":"10944087","prism:volume":"22","prism:issueIdentifier":"5","prism:pageRange":"4932-4942","prism:coverDate":"2014-03-10","prism:coverDisplayDate":"10 March 2014","prism:doi":"10.1364/OE.22.004932","dc:description":"This paper describes a novel algorithm to encrypt double color images into a single undistinguishable image in quaternion gyrator domain. By using an iterative phase retrieval algorithm, the phase masks used for encryption are obtained. Subsequently, the encrypted image is generated via cascaded quaternion gyrator transforms with different rotation angles. The parameters in quaternion gyrator transforms and phases serve as encryption keys. By knowing these keys, the original color images can be fully restituted. Numerical simulations have demonstrated the validity of the proposed encryption system as well as its robustness against loss of data and additive Gaussian noise. © 2014 Optical Society of America.","citedby-count":"37","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60110235","afid":"60110235","affilname":"IMT Atlantique","affiliation-city":"Nantes","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105589","afid":"60105589","affilname":"Laboratoire Traitement du Signal et de l'Image","affiliation-city":"Rennes","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005244","afid":"60005244","affilname":"Southeast University","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/105141997","afid":"105141997","affilname":"Centre de Recherche en Information Biomedicale Sino-Francais (LIA CRIBs)","affiliation-city":"Rennes","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55849891700","authid":"55849891700","authname":"Shao Z.","surname":"Shao","given-name":"Zhuhong","initials":"Z.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7203086899","authid":"7203086899","authname":"Shu H.","surname":"Shu","given-name":"Huazhong","initials":"H.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"105141997"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/34874119700","authid":"34874119700","authname":"Wu J.","surname":"Wu","given-name":"Jiasong","initials":"J.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"60105589"},{"@_fa": "true", "$" :"105141997"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/34871839100","authid":"34871839100","authname":"Dong Z.","surname":"Dong","given-name":"Zhifang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/6505931513","authid":"6505931513","authname":"Coatrieux G.","surname":"Coatrieux","given-name":"Gouenou","initials":"G.","afid": [{"@_fa": "true", "$" :"60110235"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/7005301307","authid":"7005301307","authname":"Coatrieux J.","surname":"Coatrieux","given-name":"Jean Louis","initials":"J.L.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"60105589"},{"@_fa": "true", "$" :"60105589"},{"@_fa": "true", "$" :"105141997"}]}],"source-id":"12862","fund-acr":"NSFC","fund-no":"undefined","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84896840838"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84896840838?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84896840838&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84896840838&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84896840838","dc:identifier":"SCOPUS_ID:84896840838","eid":"2-s2.0-84896840838","dc:title":"Fabric image edge detection based on octonion and echo state networks","dc:creator":"Chen J.C.","prism:publicationName":"Applied Mechanics and Materials","prism:issn":"16609336","prism:eIssn":"16627482","prism:isbn": [{"@_fa": "true", "$" :"9783038350194"}],"prism:volume":"519-520","prism:pageRange":"712-716","prism:coverDate":"2014-03-07","prism:coverDisplayDate":"2014","prism:doi":"10.4028/www.scientific.net/AMM.519-520.712","dc:description":"Based on synthesizing octonions and the R, G, B components of color image, a color image edge detection algorithm is proposed,combining octonions with Echo State Networks(ESN).The judged pixel and its eight-neighbourhood mean is used to calculate vector product as the feature vectors of image edge. Then the ESN is trained with training samples and the trained ESN is directly used for edge detection. Experiments show that this method has good effect of fabric edge detection with a stronger ability to keep the details. © (2014) Trans Tech Publications, Switzerland.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60138345","afid":"60138345","affilname":"Zhejiang Industry Polytechnic College","affiliation-city":"Shaoxing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024781","afid":"60024781","affilname":"Shaoxing University","affiliation-city":"Shaoxing","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36599968500","authid":"36599968500","authname":"Chen J.C.","surname":"Chen","given-name":"Jian Cheng","initials":"J.C.","afid": [{"@_fa": "true", "$" :"60138345"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35779248400","authid":"35779248400","authname":"Tu A.Y.","surname":"Tu","given-name":"Ang Yan","initials":"A.Y.","afid": [{"@_fa": "true", "$" :"60024781"}]}],"authkeywords":"Echo State Networks(ESN) | Edge detection | Feature vector | Octonion | Octonion vector product","source-id":"4700151914","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899439497"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84899439497?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84899439497&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84899439497&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84899439497","dc:identifier":"SCOPUS_ID:84899439497","eid":"2-s2.0-84899439497","dc:title":"Convolution products for hypercomplex Fourier transforms","dc:creator":"Bujack R.","prism:publicationName":"Journal of Mathematical Imaging and Vision","prism:issn":"09249907","prism:volume":"48","prism:issueIdentifier":"3","prism:pageRange":"606-624","prism:coverDate":"2014-03-01","prism:coverDisplayDate":"March 2014","prism:doi":"10.1007/s10851-013-0430-y","dc:description":"Hypercomplex Fourier transforms are increasingly used in signal processing for the analysis of higher-dimensional signals such as color images. A main stumbling block for further applications, in particular concerning filter design in the Fourier domain, is the lack of a proper convolution theorem. The present paper develops and studies two conceptually new ways to define convolution products for such transforms. As a by-product, convolution theorems are obtained that will enable the development and fast implementation of new filters for quaternionic signals and systems, as well as for their higher dimensional counterparts. © 2013 Springer Science+Business Media New York.","citedby-count":"20","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60033316","afid":"60033316","affilname":"Universiteit Gent","affiliation-city":"Ghent","affiliation-country":"Belgium"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008042","afid":"60008042","affilname":"Universität Leipzig","affiliation-city":"Leipzig","affiliation-country":"Germany"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55236534500","authid":"55236534500","authname":"Bujack R.","surname":"Bujack","given-name":"Roxana","initials":"R.","afid": [{"@_fa": "true", "$" :"60008042"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/22134443600","authid":"22134443600","authname":"De Bie H.","surname":"De Bie","given-name":"Hendrik","initials":"H.","afid": [{"@_fa": "true", "$" :"60033316"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6602880592","authid":"6602880592","authname":"De Schepper N.","surname":"De Schepper","given-name":"Nele","initials":"N.","afid": [{"@_fa": "true", "$" :"60033316"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/6603909142","authid":"6603909142","authname":"Scheuermann G.","surname":"Scheuermann","given-name":"Gerik","initials":"G.","afid": [{"@_fa": "true", "$" :"60008042"}]}],"authkeywords":"Clifford-Fourier transform | Color image processing | Convolution product | Generalized Fourier transform | Geometric Fourier transform | Hypercomplex analysis | Quaternionic Fourier transform","source-id":"28501","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84894494811"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84894494811?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84894494811&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84894494811&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84894494811","dc:identifier":"SCOPUS_ID:84894494811","eid":"2-s2.0-84894494811","dc:title":"Anisotropy preserving DTI processing","dc:creator":"Collard A.","prism:publicationName":"International Journal of Computer Vision","prism:issn":"09205691","prism:eIssn":"15731405","prism:volume":"107","prism:issueIdentifier":"1","prism:pageRange":"58-74","prism:coverDate":"2014-03-01","prism:coverDisplayDate":"March 2014","prism:doi":"10.1007/s11263-013-0674-4","dc:description":"Statistical analysis of diffusion tensor imaging (DTI) data requires a computational framework that is both numerically tractable (to account for the high dimensional nature of the data) and geometric (to account for the nonlinear nature of diffusion tensors). Building upon earlier studies exploiting a Riemannian framework to address these challenges, the present paper proposes a novel metric and an accompanying computational framework for DTI data processing. The proposed approach grounds the signal processing operations in interpolating curves. Well-chosen interpolating curves are shown to provide a computational framework that is at the same time tractable and information relevant for DTI processing. In addition, and in contrast to earlier methods, it provides an interpolation method which preserves anisotropy, a central information carried by diffusion tensor data. © 2013 Springer Science+Business Media New York.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031101","afid":"60031101","affilname":"University of Cambridge","affiliation-city":"Cambridge","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030506","afid":"60030506","affilname":"Mines Paris - PSL","affiliation-city":"Paris","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000964","afid":"60000964","affilname":"Université de Liège","affiliation-city":"Liege","affiliation-country":"Belgium"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35331631300","authid":"35331631300","authname":"Collard A.","surname":"Collard","given-name":"Anne","initials":"A.","afid": [{"@_fa": "true", "$" :"60000964"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/14622218300","authid":"14622218300","authname":"Bonnabel S.","surname":"Bonnabel","given-name":"Silvère","initials":"S.","afid": [{"@_fa": "true", "$" :"60030506"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7403135552","authid":"7403135552","authname":"Phillips C.","surname":"Phillips","given-name":"Christophe","initials":"C.","afid": [{"@_fa": "true", "$" :"60000964"},{"@_fa": "true", "$" :"60000964"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7004560925","authid":"7004560925","authname":"Sepulchre R.","surname":"Sepulchre","given-name":"Rodolphe","initials":"R.","afid": [{"@_fa": "true", "$" :"60000964"},{"@_fa": "true", "$" :"60031101"}]}],"authkeywords":"Anisotropy | Diffusion tensor MRI | Interpolation | Quaternions | Riemannian manifold | Spectral decomposition","source-id":"72242","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84894207148"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84894207148?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84894207148&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84894207148&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84894207148","dc:identifier":"SCOPUS_ID:84894207148","eid":"2-s2.0-84894207148","dc:title":"Fifth International Conference on Graphic and Image Processing, ICGIP 2013","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781628410013"}],"prism:volume":"9069","prism:pageRange":null,"prism:coverDate":"2014-02-24","prism:coverDisplayDate":"2014","dc:description":"The proceedings contain 75 papers. The topics discussed include: mammographic mass detection based on extended concentric morphology model; realistic facial animation generation based on facial expression mapping; graph-based image completion using patch offsets and structure feature; a geometric distortion correction method for lithographic watermarked authentication images; semi-automatic 2D-to-3D conversion of human-centered videos enhanced by age and gender estimation; anisotropic progressive photon mapping; a survey on the visualization and reconstruction of vasculatures; automated identification of mitochondrial regions in complex intracellular space by texture analysis; H.264/AVC digital fingerprinting based on spatio-temporal just noticeable distortion; pipeline in wall 3D measurement system based on the cross structured light; and hepatic vessel segmentation from computed tomography using three-dimensional hypercomplex edge detection operator.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84894144471"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84894144471?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84894144471&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84894144471&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84894144471","dc:identifier":"SCOPUS_ID:84894144471","eid":"2-s2.0-84894144471","dc:title":"Hepatic vessel segmentation from computed tomography using three-dimensional hyper-complex edge detection operator","dc:creator":"Ma Y.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781628410013"}],"prism:volume":"9069","prism:pageRange":null,"prism:coverDate":"2014-02-24","prism:coverDisplayDate":"2014","prism:doi":"10.1117/12.2050193","dc:description":"This paper proposes a three-dimensional(3D) segmentation algorithm using hyper-complex edge detection operator and applies the new algorithm to three-dimensional hepatic vessel segmentation from computed tomography (CT) volumetric data. A 3D hyper-complex edge detection operator is constructed by combining octonion and gradient operator. We replace every voxel of the volumetric data by one octonion which consist of its gray-level and its 6 neighborhoods' gray-level. Via this the original volumetric data is defined as octonion volumetric data. Similar to the Sobel operator, there are three principal directions (coordinate axes) in 3D hyper-complex edge detection operator, and each element in this operator is a octonion. The operator is circularly convoluted with octonion volumetric data to get the value of matching response. If matched, this voxel is the edge of vessel. Experimental results show that the algorithm can effectively segment small vascular tree branches. © 2014 Copyright SPIE.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005816","afid":"60005816","affilname":"South China Normal University","affiliation-city":"Guangzhou","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56040306700","authid":"56040306700","authname":"Ma Y.","surname":"Ma","given-name":"Yang","initials":"Y.","afid": [{"@_fa": "true", "$" :"60005816"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57192491091","authid":"57192491091","authname":"Li X.","surname":"Li","given-name":"Xingmin","initials":"X.","afid": [{"@_fa": "true", "$" :"60005816"}]}],"authkeywords":"3D segmentation | CT images | edge detection | liver vessel segmentation","article-number":"90690K","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84895062848"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84895062848?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84895062848&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84895062848&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84895062848","dc:identifier":"SCOPUS_ID:84895062848","eid":"2-s2.0-84895062848","dc:title":"Complementary observer for body segments motion capturing by inertial and magnetic sensors","dc:creator":"Fourati H.","prism:publicationName":"IEEE/ASME Transactions on Mechatronics","prism:issn":"10834435","prism:volume":"19","prism:issueIdentifier":"1","prism:pageRange":"149-157","prism:coverDate":"2014-02-01","prism:coverDisplayDate":"February 2014","prism:doi":"10.1109/TMECH.2012.2225151","dc:description":"This paper presents a viable quaternion-based complementary observer (CO) that is designed for rigid body attitude estimation. We claim that this approach is an alternative one to overcome the limitations of the extended Kalman filter. The CO processes data from a small inertial/magnetic sensor module containing triaxial angular rate sensors, accelerometers, and magnetometers, without resorting to GPS data. The proposed algorithm incorporates a motion kinematic model and adopts a two-layer filter architecture. In the latter, the Levenberg Marquardt algorithm preprocesses acceleration and local magnetic field measurements, to produce what will be called the system's output. The system's output together with the angular rate measurements will become measurement signals for the CO. In this way, the overall CO design is greatly simplified. The efficiency of the CO is experimentally investigated through an industrial robot and a commercial IMU during human segment motion exercises. These results are promising for human motion applications, in particular future ambulatory monitoring. © 1996-2012 IEEE.","citedby-count":"118","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60120519","afid":"60120519","affilname":"Centre de Recherche en Science et Technologie de l'Information et de la Communication (CRESTIC)","affiliation-city":"Reims","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104170","afid":"60104170","affilname":"Grenoble Images Parole Signal Automatique","affiliation-city":"Saint Martin d'Heres","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60103368","afid":"60103368","affilname":"Université de Strasbourg","affiliation-city":"Strasbourg","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35589710000","authid":"35589710000","authname":"Fourati H.","surname":"Fourati","given-name":"Hassen","initials":"H.","afid": [{"@_fa": "true", "$" :"60104170"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55902066100","authid":"55902066100","authname":"Manamanni N.","surname":"Manamanni","given-name":"Noureddine","initials":"N.","afid": [{"@_fa": "true", "$" :"60120519"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6507911791","authid":"6507911791","authname":"Afilal L.","surname":"Afilal","given-name":"Lissan","initials":"L.","afid": [{"@_fa": "true", "$" :"60120519"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/6701899485","authid":"6701899485","authname":"Handrich Y.","surname":"Handrich","given-name":"Yves","initials":"Y.","afid": [{"@_fa": "true", "$" :"60103368"}]}],"authkeywords":"Complementary observer (CO) | inertial measurement unit (IMU) | motion capture | quaternion | wearable MEMS sensors","article-number":"6355691","source-id":"19113","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84893367557"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84893367557?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84893367557&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84893367557&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84893367557","dc:identifier":"SCOPUS_ID:84893367557","eid":"2-s2.0-84893367557","dc:title":"About QLMS derivations","dc:creator":"Barthélemy Q.","prism:publicationName":"IEEE Signal Processing Letters","prism:issn":"10709908","prism:volume":"21","prism:issueIdentifier":"2","prism:pageRange":"240-243","prism:coverDate":"2014-02-01","prism:coverDisplayDate":"February 2014","prism:doi":"10.1109/LSP.2014.2299066","dc:description":"In this letter, a review of the quaternionic least mean squares (QLMS) algorithm is proposed. Three versions coming from three derivation ways exist: the original QLMS [1] based on componentwise gradients, HR-QLMS [2] based on a quaternion gradient operator and iQLMS [3] based on an involutions-gradient. Noting and investigating the differences between the three QLMS formulations, we show that the original QLMS suffers from a mistake in the derivation calculus. Thus, we propose to derive rigorously the criterion following the first way, giving the correct version of QLMS. A comparison with the other QLMS versions validates these results on simulated data. © 1994-2012 IEEE.","citedby-count":"19","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104170","afid":"60104170","affilname":"Grenoble Images Parole Signal Automatique","affiliation-city":"Saint Martin d'Heres","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007816","afid":"60007816","affilname":"Commissariat a l'Energie Atomique et aux Energies Alternatives","affiliation-city":"Gif-sur-Yvette","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/50361026200","authid":"50361026200","authname":"Barthélemy Q.","surname":"Barthélemy","given-name":"Quentin","initials":"Q.","afid": [{"@_fa": "true", "$" :"60007816"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/13007441000","authid":"13007441000","authname":"Larue A.","surname":"Larue","given-name":"Anthony","initials":"A.","afid": [{"@_fa": "true", "$" :"60007816"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7004216193","authid":"7004216193","authname":"Mars J.","surname":"Mars","given-name":"Jérôme I.","initials":"J.I.","afid": [{"@_fa": "true", "$" :"60104170"}]}],"authkeywords":"Adaptive filtering | QLMS | quaternionic signal processing","article-number":"6705599","source-id":"17316","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84891508563"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84891508563?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84891508563&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84891508563&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84891508563","dc:identifier":"SCOPUS_ID:84891508563","eid":"2-s2.0-84891508563","dc:title":"A unified methodology for computing accurate quaternion color moments and moment invariants","dc:creator":"Karakasis E.","prism:publicationName":"IEEE Transactions on Image Processing","prism:issn":"10577149","prism:volume":"23","prism:issueIdentifier":"2","prism:pageRange":"596-611","prism:coverDate":"2014-02-01","prism:coverDisplayDate":"February 2014","prism:doi":"10.1109/TIP.2013.2289997","dc:description":"In this paper, a general framework for computing accurate quaternion color moments and their corresponding invariants is proposed. The proposed unified scheme arose by studying the characteristics of different orthogonal polynomials. These polynomials are used as kernels in order to form moments, the invariants of which can easily be derived. The resulted scheme permits the usage of any polynomial-like kernel in a unified and consistent way. The resulted moments and moment invariants demonstrate robustness to noisy conditions and high discriminative power. Additionally, in the case of continuous moments, accurate computations take place to avoid approximation errors. Based on this general methodology, the quaternion Tchebichef, Krawtchouk, Dual Hahn, Legendre, orthogonal Fourier-Mellin, pseudo Zernike and Zernike color moments, and their corresponding invariants are introduced. A selected paradigm presents the reconstruction capability of each moment family, whereas proper classification scenarios evaluate the performance of color moment invariants. © 2013 IEEE.","citedby-count":"57","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104301","afid":"60104301","affilname":"Nazarbayev University","affiliation-city":"Astana","affiliation-country":"Kazakhstan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030988","afid":"60030988","affilname":"Democritus University of Thrace","affiliation-city":"Komotini","affiliation-country":"Greece"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011510","afid":"60011510","affilname":"Eastern Macedonia and Thrace Institute of Technology","affiliation-city":"Kavala","affiliation-country":"Greece"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/23097725600","authid":"23097725600","authname":"Karakasis E.","surname":"Karakasis","given-name":"Evangelos G.","initials":"E.G.","afid": [{"@_fa": "true", "$" :"60030988"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/14060879200","authid":"14060879200","authname":"Papakostas G.","surname":"Papakostas","given-name":"George A.","initials":"G.A.","afid": [{"@_fa": "true", "$" :"60011510"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6603137113","authid":"6603137113","authname":"Koulouriotis D.","surname":"Koulouriotis","given-name":"Dimitrios E.","initials":"D.E.","afid": [{"@_fa": "true", "$" :"60030988"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/6701828439","authid":"6701828439","authname":"Tourassis V.","surname":"Tourassis","given-name":"Vassilios D.","initials":"V.D.","afid": [{"@_fa": "true", "$" :"60104301"}]}],"authkeywords":"accurate computation | color moment invariants | color moments | image reconstruction | Quaternions","article-number":"6657778","source-id":"25534","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84887021550"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84887021550?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84887021550&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84887021550&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0031320313003373"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84887021550","dc:identifier":"SCOPUS_ID:84887021550","eid":"2-s2.0-84887021550","dc:title":"Quaternion Bessel-Fourier moments and their invariant descriptors for object reconstruction and recognition","dc:creator":"Shao Z.","prism:publicationName":"Pattern Recognition","prism:issn":"00313203","prism:volume":"47","prism:issueIdentifier":"2","prism:pageRange":"603-611","prism:coverDate":"2014-02-01","prism:coverDisplayDate":"February 2014","prism:doi":"10.1016/j.patcog.2013.08.016","pii":"S0031320313003373","dc:description":"In this paper, the quaternion Bessel-Fourier moments are introduced. The significance of phase information in quaternion Bessel-Fourier moments is investigated and an accurate estimation method for rotation angle is described. Furthermore, a new set of invariant descriptors based on the magnitude and the phase information of quaternion Bessel-Fourier moments is derived. Experimental results show that quaternion Bessel-Fourier moments lead to better performance for color image reconstruction than the other quaternion orthogonal moments such as quaternion Zernike moments, quaternion pseudo-Zernike moments and quaternion orthogonal Fourier-Mellin moments. In addition, the angles estimated by the proposed moments are more accurate than those obtained by using other quaternion orthogonal moments. The proposed invariant descriptors show also better robustness to geometric and photometric transformations. © 2013 Elsevier Ltd.","citedby-count":"66","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105589","afid":"60105589","affilname":"Laboratoire Traitement du Signal et de l'Image","affiliation-city":"Rennes","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005244","afid":"60005244","affilname":"Southeast University","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113841448","afid":"113841448","affilname":"Centre de Recherche en Information Médicale Sino-français (CRIBs)","affiliation-city":"Rennes","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55849891700","authid":"55849891700","authname":"Shao Z.","surname":"Shao","given-name":"Zhuhong","initials":"Z.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7203086899","authid":"7203086899","authname":"Shu H.","surname":"Shu","given-name":"Huazhong","initials":"H.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"113841448"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/34874119700","authid":"34874119700","authname":"Wu J.","surname":"Wu","given-name":"Jiasong","initials":"J.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"113841448"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/36805188500","authid":"36805188500","authname":"Chen B.","surname":"Chen","given-name":"Beijing","initials":"B.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7005301307","authid":"7005301307","authname":"Coatrieux J.","surname":"Coatrieux","given-name":"Jean Louis","initials":"J.L.","afid": [{"@_fa": "true", "$" :"60105589"},{"@_fa": "true", "$" :"60105589"},{"@_fa": "true", "$" :"113841448"}]}],"authkeywords":"Color image | Invariant descriptor | Phase | Quaternion Bessel-Fourier moment | Recognition","source-id":"24823","fund-acr":"NSFC","fund-no":"61073138","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84983133988"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84983133988?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84983133988&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84983133988&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84983133988","dc:identifier":"SCOPUS_ID:84983133988","eid":"2-s2.0-84983133988","dc:title":"Strategic image denoising using a support vector machine with seam energy and saliency features","dc:creator":"McCrackin L.","prism:publicationName":"2014 IEEE International Conference on Image Processing, ICIP 2014","prism:isbn": [{"@_fa": "true", "$" :"9781479957514"}],"prism:pageRange":"2684-2688","prism:coverDate":"2014-01-28","prism:coverDisplayDate":"28 January 2014","prism:doi":"10.1109/ICIP.2014.7025543","dc:description":"We propose a method of using a support vector machine (SVM) to select between multiple well-performing contemporary denoising algorithms for each pixel of a noisy image. We describe a number of novel and pre-existing features based on seam energy, local colour, and saliency which are used as inputs to the SVM. Our SVM strategic image de-noising (SVMSID) results demonstrate better image quality than either candidate denoising algorithm, as measured using the perceptually-based quaternion structural similarity image metric (QSSIM).","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031828","afid":"60031828","affilname":"McMaster University","affiliation-city":"Hamilton","affiliation-country":"Canada"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190796745","authid":"57190796745","authname":"McCrackin L.","surname":"McCrackin","given-name":"Laura","initials":"L.","afid": [{"@_fa": "true", "$" :"60031828"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7004043661","authid":"7004043661","authname":"Shirani S.","surname":"Shirani","given-name":"Shahram","initials":"S.","afid": [{"@_fa": "true", "$" :"60031828"}]}],"authkeywords":"Image denoising | saliency | seam carving | seam energy | support vector machine","article-number":"7025543","source-id":"21100775289","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84983127776"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84983127776?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84983127776&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84983127776&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84983127776","dc:identifier":"SCOPUS_ID:84983127776","eid":"2-s2.0-84983127776","dc:title":"A correspondence based method for activity recognition in human skeleton motion sequences","dc:creator":"Fotiadou E.","prism:publicationName":"2014 IEEE International Conference on Image Processing, ICIP 2014","prism:isbn": [{"@_fa": "true", "$" :"9781479957514"}],"prism:pageRange":"1500-1504","prism:coverDate":"2014-01-28","prism:coverDisplayDate":"28 January 2014","prism:doi":"10.1109/ICIP.2014.7025300","dc:description":"In this paper we present an algorithm for efficient activity recognition operating upon human skeleton motion sequences, derived through motion capture systems or by analyzing the output of RGB-D sensors. Our approach is driven from the assumption that, if two such sequences describe similar activities, then, consecutive frames (poses) of one sequence are expected to be similar to consecutive frames of the other. The proposed method adopts a quaternion based distance metric to calculate the similarity between poses and an intuitive method for estimating a similarity score between two skeleton motion sequences, based on the structure of a pose correspondence matrix. Our method achieved 99.5% correct activity recognition, when applied on motion capture data, in a classification task consisting of 18 classes of activities.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015331","afid":"60015331","affilname":"Aristotle University of Thessaloniki","affiliation-city":"Thessaloniki","affiliation-country":"Greece"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56285919500","authid":"56285919500","authname":"Fotiadou E.","surname":"Fotiadou","given-name":"Eftychia","initials":"E.","afid": [{"@_fa": "true", "$" :"60015331"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7006823545","authid":"7006823545","authname":"Nikolaidis N.","surname":"Nikolaidis","given-name":"Nikos","initials":"N.","afid": [{"@_fa": "true", "$" :"60015331"}]}],"authkeywords":"activity recognition | classification","article-number":"7025300","source-id":"21100775289","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}