{"search-results":{"opensearch:totalResults":"179","opensearch:startIndex":"100","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "100"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=100&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=75&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=154&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2014&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84940249153"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84940249153?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84940249153&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84940249153&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84940249153","dc:identifier":"SCOPUS_ID:84940249153","eid":"2-s2.0-84940249153","dc:title":"Classification of complete projective special real surfaces","dc:creator":"Cortés V.","prism:publicationName":"Proceedings of the London Mathematical Society","prism:issn":"00246115","prism:eIssn":"1460244X","prism:volume":"109","prism:issueIdentifier":"2","prism:pageRange":"423-445","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"August 2014","prism:doi":"10.1112/plms/pdu013","dc:description":"We determine all complete projective special real surfaces. By the supergravity r-map, they give rise to complete projective special Kähler manifolds of dimension 6, which are distinguished by the image of their scalar curvature function. By the supergravity c-map, the latter manifolds define in turn complete quaternionic Kähler manifolds of dimension 16. © 2014 London Mathematical Society.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028229","afid":"60028229","affilname":"Universität Hamburg","affiliation-city":"Hamburg","affiliation-country":"Germany"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56231949800","authid":"56231949800","authname":"Cortés V.","surname":"Cortés","given-name":"V.","initials":"V.","afid": [{"@_fa": "true", "$" :"60028229"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56575147300","authid":"56575147300","authname":"Dyckmanns M.","surname":"Dyckmanns","given-name":"M.","initials":"M.","afid": [{"@_fa": "true", "$" :"60028229"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56804642700","authid":"56804642700","authname":"Lindemann D.","surname":"Lindemann","given-name":"D.","initials":"D.","afid": [{"@_fa": "true", "$" :"60028229"}]}],"source-id":"24487","fund-acr":"DFG","fund-no":"undefined","fund-sponsor":"Deutsche Forschungsgemeinschaft","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84937951644"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84937951644?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84937951644&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84937951644&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84937951644","dc:identifier":"SCOPUS_ID:84937951644","eid":"2-s2.0-84937951644","dc:title":"Microacceleration research using international space station mission","dc:creator":"Matveeva T.V.","prism:publicationName":"Proceedings of the International Astronautical Congress, IAC","prism:issn":"00741795","prism:isbn": [{"@_fa": "true", "$" :"9781634399869"}],"prism:volume":"2","prism:pageRange":"765-776","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","dc:description":"The paper presents results of microacceleration research performed onboard the Russian Segment of the International Space Station (ISS RS) with the frequencies from 0 to 2 Hz. Micro accelerations measured in different flight modes were studied: in flight without dynamic operations, during operations of docking and undocking, in modes with Service Module thrusters burning. Onboard accelerometer measurements, telemetry information about the station attitude and orbital motion were analyzed in research. Quasi-steady microacceleration component (with frequencies from 0 to 0.01 Hz), which is the most essential for some physical processes investigated on the spacecraft, was of primary interest in research. The quasi-steady microacceleration component was calculated using different techniques to approximate the station attitude motion. Telemetry data of the station angular rate and the quaternion of its attitude with respect to the inertial coordinate system were used for reconstruction of the station attitude motion. The calculations were based on kinematical equations of motion of the station as of an absolutely rigid body. This approach allows to approximate motion of any type and to estimate the quasi-steady microacceleration component at any point of the ISS as a function of time. The results of such calculations were used to verify onboard accelerometers. The method described above was used to recalculate the low frequency micro-accelerations measured by the accelerometers from the point of their location to the required point on the station with the purpose to estimate the level of residual micro-accelerations in that point and to get more realistic initial data for microaccelerations mathematical modeling in some space experiments with liquid motion. In particular, the calculated analogs of the real signals incoming into the DACON convection sensor were generated during the experiments on the ISS. Comparison of calculated input data with real output signals gave good results and proved that sensors of such type can be used to monitor low frequency microaccelerations onboard spacecraft. Analysis of the microaccelerations measurements obtained onboard the ISS also allowed to solve some additional problems of its flight control. Taking into account the results of the ISS RS microaccelerations environment investigation we proposed to perform experiments with the DACON sensor on the Progress transport cargo vehicle upon completion its mandatory functions of the ISS supporting. For that purpose, special methods of the Progress vehicle flight control during microgravity research were developed and series of technical experiments to test the proposed methods were executed with the \"Progress M-20M\" vehicle in 2014.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010862","afid":"60010862","affilname":"Keldysh Institute of Applied Mathematics of Russian Academy of Sciences","affiliation-city":"Moscow","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/115479860","afid":"115479860","affilname":"Korolev Rocket Space Corporation","affiliation-city":null,"affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/109654946","afid":"109654946","affilname":"JSC Russian Space Systems","affiliation-city":"Moscow","affiliation-country":"Russian Federation"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8699991100","authid":"8699991100","authname":"Matveeva T.V.","surname":"Matveeva","given-name":"T. V.","initials":"T.V.","afid": [{"@_fa": "true", "$" :"115479860"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003903533","authid":"7003903533","authname":"Belyaev M.Y.","surname":"Belyaev","given-name":"M. Yu","initials":"M.Y.","afid": [{"@_fa": "true", "$" :"115479860"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6504690227","authid":"6504690227","authname":"Zavalishin D.A.","surname":"Zavalishin","given-name":"D. A.","initials":"D.A.","afid": [{"@_fa": "true", "$" :"109654946"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/35615326500","authid":"35615326500","authname":"Sazonov V.V.","surname":"Sazonov","given-name":"V. V.","initials":"V.V.","afid": [{"@_fa": "true", "$" :"60010862"}]}],"source-id":"21100255701","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84935024811"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84935024811?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84935024811&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84935024811&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84935024811","dc:identifier":"SCOPUS_ID:84935024811","eid":"2-s2.0-84935024811","dc:title":"Discrete Fractional COSHAD Transform and Its Application","dc:creator":"Zhu H.","prism:publicationName":"Mathematical Problems in Engineering","prism:issn":"1024123X","prism:eIssn":"15635147","prism:volume":"2014","prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1155/2014/567414","dc:description":"In recent years, there has been a renewed interest in finding methods to construct orthogonal transforms. This interest is driven by the large number of applications of the orthogonal transforms in image analysis and compression, especially for colour images. Inspired by this motivation, this paper first introduces a new orthogonal transform known as a discrete fractional COSHAD (FrCOSHAD) using the Kronecker product of eigenvectors and the eigenvalues of the COSHAD kernel functions. Next, this study discusses the properties of the FrCOSHAD kernel function, such as angle additivity. Using the algebra of quaternions, the study presents quaternion COSHAD/FrCOSHAD transforms to represent colour images in a holistic manner. This paper also develops an inverse polynomial reconstruction method (IPRM) in the discrete COSHAD/FrCOSHAD domains. This method can effectively recover a piecewise smooth signal from the finite set of its COSHAD/FrCOSHAD coefficients, with high accuracy. The convergence theorem has proved that the partial sum of COSHAD provides a spectrally accurate approximation to the underlying piecewise smooth signal. The experimental results verify the numerical stability and accuracy of the proposed methods.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011069","afid":"60011069","affilname":"East China University of Science and Technology","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001305","afid":"60001305","affilname":"North University of China","affiliation-city":"Taiyuan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8538289200","authid":"8538289200","authname":"Zhu H.","surname":"Zhu","given-name":"Hongqing","initials":"H.","afid": [{"@_fa": "true", "$" :"60011069"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/10340349000","authid":"10340349000","authname":"Gui Z.","surname":"Gui","given-name":"Zhiguo","initials":"Z.","afid": [{"@_fa": "true", "$" :"60001305"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55723822400","authid":"55723822400","authname":"Zhu Y.","surname":"Zhu","given-name":"Yu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60011069"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57193651268","authid":"57193651268","authname":"Chen Z.","surname":"Chen","given-name":"Zhihua","initials":"Z.","afid": [{"@_fa": "true", "$" :"60011069"}]}],"article-number":"567414","source-id":"13082","fund-no":"61271357","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84928503233"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84928503233?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84928503233&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84928503233&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84928503233","dc:identifier":"SCOPUS_ID:84928503233","eid":"2-s2.0-84928503233","dc:title":"A general quaternion-valued gradient operator and its applications to computational fluid dynamics and adaptive beamforming","dc:creator":"Jiang M.","prism:publicationName":"International Conference on Digital Signal Processing, DSP","prism:isbn": [{"@_fa": "true", "$" :"9781479946129"}],"prism:volume":"2014-January","prism:pageRange":"821-826","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/ICDSP.2014.6900781","dc:description":"Quaternion-valued signal processing has received increasing attention recently. One key operation involved in derivation of all kinds of adaptive algorithms is the gradient operator. Although there have been some derivations of this operator in literature with different level of details, it is still not fully clear how this operator can be derived in the most general case and how it can be applied to various signal processing problems. In this work, we will give a general derivation of the quaternion-valued gradient operator and then apply it to two different areas. One is to combine with the classic computational fluid dynamics (CFD) approach in wind profile prediction and the other one is to apply the result to the adaptive beamforming problem for vector sensor arrays.","citedby-count":"19","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001881","afid":"60001881","affilname":"The University of Sheffield","affiliation-city":"Sheffield","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56042877600","authid":"56042877600","authname":"Jiang M.","surname":"Jiang","given-name":"Mengdi","initials":"M.","afid": [{"@_fa": "true", "$" :"60001881"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56645219600","authid":"56645219600","authname":"Liu W.","surname":"Liu","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60001881"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56044382000","authid":"56044382000","authname":"Li Y.","surname":"Li","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60001881"}]}],"article-number":"6900781","source-id":"21100511427","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84926029967"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84926029967?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84926029967&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84926029967&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84926029967","dc:identifier":"SCOPUS_ID:84926029967","eid":"2-s2.0-84926029967","dc:title":"A unified algorithm for analysis and simulation of planar four-bar motions defined with r-and p-joints","dc:creator":"Li X.","prism:publicationName":"Proceedings of the ASME Design Engineering Technical Conference","prism:isbn": [{"@_fa": "true", "$" :"9780791846377"}],"prism:volume":"5B","prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1115/DETC201435203","dc:description":"This paper presents a single, unified and efficient algorithm for animating the motions of the coupler of all four-bar mechanisms formed with revolute (R) and prismatic (P) joints. This is achieved without having to formulate and solve the loop closure equation associated with each type of four-bar linkages separately. In our previous paper on four-bar linkage synthesis, we map the planar displacements from Cartesian to image space using planar quaternion. Given a set of image points that represent planar displacements, the problem of synthesizing a planar fourbar linkage is reduced to finding a pencil of Generalized- or Gmanifolds that best fit the image points in the least squares sense. The three planar dyads associated with Generalized G-manifolds are RR, PR and RP which could construct six types of four-bar mechanisms. In this paper, we show that the same unified formulation for linkage synthesis leads to a unified algorithm for linkage analysis and simulation as well. Both the unified synthesis and analysis algorithms have been implemented on Apple's iOS platform.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60026415","afid":"60026415","affilname":"Stony Brook University","affiliation-city":"Stony Brook","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55364330300","authid":"55364330300","authname":"Li X.","surname":"Li","given-name":"Xiangyun","initials":"X.","afid": [{"@_fa": "true", "$" :"60026415"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56577189600","authid":"56577189600","authname":"Ge X.","surname":"Ge","given-name":"Xin","initials":"X.","afid": [{"@_fa": "true", "$" :"60026415"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/16068884300","authid":"16068884300","authname":"Purwar A.","surname":"Purwar","given-name":"Anurag","initials":"A.","afid": [{"@_fa": "true", "$" :"60026415"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7101922139","authid":"7101922139","authname":"Ge Q.J.","surname":"Ge","given-name":"Q. J.","initials":"Q.J.","afid": [{"@_fa": "true", "$" :"60026415"}]}],"source-id":"91976","fund-acr":"NSF","fund-no":"undefined","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84925372656"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84925372656?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84925372656&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84925372656&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84925372656","dc:identifier":"SCOPUS_ID:84925372656","eid":"2-s2.0-84925372656","dc:title":"Development of sewer pipe inspection vehicle using integrated sensing system","dc:creator":"Ikeda F.","prism:publicationName":"MOVIC 2014 - 12th International Conference on Motion and Vibration Control","prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","dc:description":"The total length of sewer pipelines in Japan is over 440, 000 kilometers. Until now, visual inspection by experienced staff members have been carried out to watch in-pipes animation images which are obtained from an autonomous vehicle equipped with a CCD camera. Quantitative measurement methods for regularly scheduled inspection of those pipelines have been desired instead. In this study, we developed vehicles equipped with an inertial navigation system (INS) consists of a gyro sensor and an accelerometer, so that we can measure unevenness of the sewer pipe accurately and quantitatively. We also aim to achieve a simple measurement scheme at comparatively low cost. To accomplish these missions, two vehicles are designed and manufactured respectively. The first vehicle is designed for the function of driving to drag a second vehicle. The second vehicle has only a function of measurement to be towed and does not move independently. We use the MEMS sensor devices installed on the second vehicle to suit our particular needs which have their low cost and small sizes. However, they are notorious for their accuracy such as drift error in the gyro sensor. We apply the extended Kalman filter (EKF) algorithm to reduce the estimation errors by using the data of gyro sensor and accelerometer. We use Quaternion as state variables of the attitude for its coordinate system. The experimental study shows that the suggested algorithms effectively remove the errors and it can lead to systematic measurement schemes to accurately obtain the unevenness of the sewer pipes.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104706","afid":"60104706","affilname":"National Institute of Technology, Nagaoka College","affiliation-city":"Nagaoka","affiliation-country":"Japan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/115904426","afid":"115904426","affilname":"Kumota Incorporated Company","affiliation-city":"Myoko-shi, Niigata","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/12794150200","authid":"12794150200","authname":"Ikeda F.","surname":"Ikeda","given-name":"Fujio","initials":"F.","afid": [{"@_fa": "true", "$" :"60104706"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24725534500","authid":"24725534500","authname":"Toyama S.","surname":"Toyama","given-name":"Shigehiro","initials":"S.","afid": [{"@_fa": "true", "$" :"60104706"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56566791400","authid":"56566791400","authname":"Kumota T.","surname":"Kumota","given-name":"Toshio","initials":"T.","afid": [{"@_fa": "true", "$" :"115904426"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56566091700","authid":"56566091700","authname":"Yanagisawa T.","surname":"Yanagisawa","given-name":"Takashi","initials":"T.","afid": [{"@_fa": "true", "$" :"115904426"}]}],"authkeywords":"Accelerometer | Extended Kalman filter | Gyro sensor | Measurement vehicle | Quaternion | Sewer pipe","source-id":"21100381222","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84922725707"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84922725707?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84922725707&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84922725707&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84922725707","dc:identifier":"SCOPUS_ID:84922725707","eid":"2-s2.0-84922725707","dc:title":"Learning to predict where human gaze is using quaternion DCT based regional saliency detection","dc:creator":"Li T.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781628412444"}],"prism:volume":"9217","prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1117/12.2063974","dc:description":"Many current visual attention approaches used semantic features to accurately capture human gaze. However, these approaches demand high computational cost and can hardly be applied to daily use. Recently, some quaternion-based saliency detection models, such as PQFT (phase spectrum of Quaternion Fourier Transform), QDCT (Quaternion Discrete Cosine Transform), have been proposed to meet real-time requirement of human gaze tracking tasks. However, current saliency detection methods used global PQFT and QDCT to locate jump edges of the input, which can hardly detect the object boundaries accurately. To address the problem, we improved QDCT-based saliency detection model by introducing superpixel-wised regional saliency detection mechanism. The local smoothness of saliency value distribution is emphasized to distinguish noises of background from salient regions. Our algorithm called saliency confidence can distinguish the patches belonging to the salient object and those of the background. It decides whether the image patches belong to the same region. When an image patch belongs to a region consisting of other salient patches, this patch should be salient as well. Therefore, we use saliency confidence map to get background weight and foreground weight to do the optimization on saliency map obtained by QDCT. The optimization is accomplished by least square method. The optimization approach we proposed unifies local and global saliency by combination of QDCT and measuring the similarity between each image superpixel. We evaluate our model on four commonly-used datasets (Toronto, MIT, OSIE and ASD) using standard precision-recall curves (PR curves), the mean absolute error (MAE) and area under curve (AUC) measures. In comparison with most state-of-art models, our approach can achieve higher consistency with human perception without training. It can get accurate human gaze even in cluttered background. Furthermore, it achieves better compromise between speed and accuracy.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025084","afid":"60025084","affilname":"Shanghai Jiao Tong University","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55567464300","authid":"55567464300","authname":"Li T.","surname":"Li","given-name":"Ting","initials":"T.","afid": [{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55695017800","authid":"55695017800","authname":"Xu Y.","surname":"Xu","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8397907500","authid":"8397907500","authname":"Zhang C.","surname":"Zhang","given-name":"Chongyang","initials":"C.","afid": [{"@_fa": "true", "$" :"60025084"}]}],"authkeywords":"Optimization model | Quaternion transform | Saliency detection | Superpixels","article-number":"92171K","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84920252710"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84920252710?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84920252710&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84920252710&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84920252710","dc:identifier":"SCOPUS_ID:84920252710","eid":"2-s2.0-84920252710","dc:title":"Visual objects tracking and identification based on reduced quaternion wavelet transform","dc:creator":"Gai S.","prism:publicationName":"Signal, Image and Video Processing","prism:issn":"18631703","prism:eIssn":"18631711","prism:volume":"8","prism:issueIdentifier":"1","prism:pageRange":"75-84","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1007/s11760-014-0636-5","dc:description":"In this paper, a new method for tracking moving objects based on reduced quaternion wavelet transform by using color space information is proposed. The reduced quaternion wavelet transform is a new multi-scale analysis tool for geometric image features. Meanwhile, it is a near-shift-invariant tight frame representation whose coefficients can sport local image shift and geometric information. The main objective of visual tracking is to closely follow objects in each frame of video stream. The new proposed method can calculate the mean value and edge energy of visual objects by using the reduced quaternion wavelet coefficients. The experimental results show that the proposed method is effective and efficient.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005244","afid":"60005244","affilname":"Southeast University","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35748407200","authid":"35748407200","authname":"Gai S.","surname":"Gai","given-name":"Shan","initials":"S.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57199078163","authid":"57199078163","authname":"Luo L.","surname":"Luo","given-name":"Limin","initials":"L.","afid": [{"@_fa": "true", "$" :"60005244"}]}],"authkeywords":"Multi-scale geometric analysis | Object identification | Object tracking | Reduced quaternion wavelet transform","source-id":"6200180165","fund-no":"61162002","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84911434041"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84911434041?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84911434041&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84911434041&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84911434041","dc:identifier":"SCOPUS_ID:84911434041","eid":"2-s2.0-84911434041","dc:title":"Bender: An open source software for efficient model posing and morphing","dc:creator":"Finet J.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783319120560"}],"prism:volume":"8789","prism:pageRange":"203-210","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1007/978-3-319-12057-7_23","dc:description":"In this paper, we present Bender, an interactive and freely available software application for changing the pose of anatomical models that are represented as labeled, voxel-based volumes.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60114004","afid":"60114004","affilname":"Kitware, Inc.","affiliation-city":"Clifton Park","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019228","afid":"60019228","affilname":"Air Force Research Laboratory","affiliation-city":"Dayton","affiliation-country":"United States"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/38561197900","authid":"38561197900","authname":"Finet J.","surname":"Finet","given-name":"Julien","initials":"J.","afid": [{"@_fa": "true", "$" :"60114004"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56421498000","authid":"56421498000","authname":"Ortiz R.","surname":"Ortiz","given-name":"Ricardo","initials":"R.","afid": [{"@_fa": "true", "$" :"60114004"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55823575600","authid":"55823575600","authname":"Andruejol J.","surname":"Andruejol","given-name":"Johan","initials":"J.","afid": [{"@_fa": "true", "$" :"60114004"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7801316765","authid":"7801316765","authname":"Enquobahrie A.","surname":"Enquobahrie","given-name":"Andinet","initials":"A.","afid": [{"@_fa": "true", "$" :"60114004"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/6507216580","authid":"6507216580","authname":"Jomier J.","surname":"Jomier","given-name":"Julien","initials":"J.","afid": [{"@_fa": "true", "$" :"60114004"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57196532742","authid":"57196532742","authname":"Payne J.","surname":"Payne","given-name":"Jason","initials":"J.","afid": [{"@_fa": "true", "$" :"60019228"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/7004344836","authid":"7004344836","authname":"Aylward S.","surname":"Aylward","given-name":"Stephen","initials":"S.","afid": [{"@_fa": "true", "$" :"60114004"}]}],"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84911188223"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84911188223?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84911188223&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84911188223&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84911188223","dc:identifier":"SCOPUS_ID:84911188223","eid":"2-s2.0-84911188223","dc:title":"An effective video saliency detection model based on human visual acuity and spatiotemporal cues in cloud systems","dc:creator":"Fang Z.","prism:publicationName":"Journal of Internet Technology","prism:issn":"16079264","prism:eIssn":"20794029","prism:volume":"15","prism:issueIdentifier":"5","prism:pageRange":"835-840","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.6138/JIT.2014.15.5.13","dc:description":"Video services achieved from the cloud computing become a critical concern. In various image processing applications, the organizations are slow in accepting it due to security issues and challenges associated with it. In terms of security, cloud-based video services must be managed and operated at equivalent levels to enterprise systems. For various image processing applications, saliency detection can be used to extract the regions of interest for images. Compared with images, the motion feature has to be considered for video saliency detection. This paper proposes a new video saliency detection model based on human visual acuity and spatiotemporal cues in cloud systems. Firstly, each video frame is divided into small image patches. Four features (including one intensity, one motion and two colour features) are extracted from each image patch. Based on these four features, the Quaternion Fourier Transform is used to obtain the amplitude spectrum for each image patch. The saliency value of each image patch is determined by two factors: the amplitude difference between this image patch and other image patch in the video frame, and the corresponding weighting of visual impact by human visual acuity. Experimental results demonstrate that the performance of the proposed video saliency detection model in cloud systems is better than other existing ones.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032504","afid":"60032504","affilname":"Shanghai University of Engineering Science","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028275","afid":"60028275","affilname":"Jiangxi University of Finance and Economics","affiliation-city":"Nanchang","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023813","afid":"60023813","affilname":"Shanghai University","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/13605852400","authid":"13605852400","authname":"Fang Z.","surname":"Fang","given-name":"Zhijun","initials":"Z.","afid": [{"@_fa": "true", "$" :"60023813"},{"@_fa": "true", "$" :"60028275"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57956213800","authid":"57956213800","authname":"Zhang J.","surname":"Zhang","given-name":"Juan","initials":"J.","afid": [{"@_fa": "true", "$" :"60032504"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7103364775","authid":"7103364775","authname":"Wan W.","surname":"Wan","given-name":"Wanggen","initials":"W.","afid": [{"@_fa": "true", "$" :"60023813"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/8435698900","authid":"8435698900","authname":"Fang Y.","surname":"Fang","given-name":"Yuming","initials":"Y.","afid": [{"@_fa": "true", "$" :"60028275"}]}],"authkeywords":"Cloud systems | Human visual acuity | Video saliency detection | Visual attention","source-id":"17604","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84908218543"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84908218543?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84908218543&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84908218543&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84908218543","dc:identifier":"SCOPUS_ID:84908218543","eid":"2-s2.0-84908218543","dc:title":"Direction finding and positioning algorithm with COLD-ULA based on quaternion theory","dc:creator":"Wang L.","prism:publicationName":"Journal of Communications","prism:issn":"17962021","prism:volume":"9","prism:issueIdentifier":"10","prism:pageRange":"778-784","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"1 October 2014","prism:doi":"10.12720/jcm.9.10.778-784","dc:description":"Electromagnetic vector sensor arrays have been widely applied in the communication, radio, navigation, and so on. The application of electromagnetic vector sensor antenna array will greatly improve the overall performance of the communication system. In this paper, a novel quaternion- ESPRIT (estimation of signal parameters via rotational invariance techniques) algorithm for direction finding and positioning based on COLD (cocentered orthogonal loop and dipole) uniform linear array (COLD-ULA) is proposed. First, quaternion data model of COLD-ULA is deduced and constructed. Second, the array steering vector and the angle of arrival (DOA) are estimated using a quaternion eigenvalue decomposition of the data covariance matrix. Finally, the estimation of polarization parameters are required using the relationships between the dipoles and the loops. The proposed technique not only decouples the DOA estimation information from the polarization estimation information, but also improves the ability of signal detection. Moreover, the proposed technique has the advantage of small amount of calculation and parameter automatic matching. Simulation results show that the performance of quaternion method is obviously better than that of the long-vector method.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025578","afid":"60025578","affilname":"Xidian University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/10042713200","authid":"10042713200","authname":"Wang L.","surname":"Wang","given-name":"Lanmei","initials":"L.","afid": [{"@_fa": "true", "$" :"60025578"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55826253100","authid":"55826253100","authname":"Chen Z.","surname":"Chen","given-name":"Zhihai","initials":"Z.","afid": [{"@_fa": "true", "$" :"60025578"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55827761200","authid":"55827761200","authname":"Wang G.","surname":"Wang","given-name":"Guibao","initials":"G.","afid": [{"@_fa": "true", "$" :"60025578"}]}],"authkeywords":"Antenna array | Array signal processing | Direction of arrival | Polarization | Quaternion-ESPRIT | Subspace","source-id":"21100230800","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84908020906"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84908020906?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84908020906&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84908020906&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84908020906","dc:identifier":"SCOPUS_ID:84908020906","eid":"2-s2.0-84908020906","dc:title":"Human posture recognition based on Kinect depth images","dc:creator":"Zhu Q.","prism:publicationName":"WIT Transactions on Information and Communication Technologies","prism:issn":"17433517","prism:isbn": [{"@_fa": "true", "$" :"9781845649203"}],"prism:volume":"59","prism:pageRange":"239-245","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"1 March 2014","prism:doi":"10.2495/ICACC130331","dc:description":"As the developing of computer application technology, batches of new generation of somatosensory devices emerge. In June 2010 Microsoft release of the kinect motion-sensing camera is one of the most representative somatosensory devices. The kinect camera, compared with the traditional camera, the biggest advantage of is the depth camera. Many professionals were called depth camera kinect as “the third eye”. The depth camera can take not only a traditional 2D image which have xy two axes, but also the depth image data which can be used to describe the z axis. By using the depth image data for image recognition, we can identify a more accurate human behaviour. This paper mainly expounds how to use depth data, combined with quaternion rotation to identify and track a more accurate human behavior.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022281","afid":"60022281","affilname":"Beijing University of Technology","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57189497573","authid":"57189497573","authname":"Zhu Q.","surname":"Zhu","given-name":"Qing","initials":"Q.","afid": [{"@_fa": "true", "$" :"60022281"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56387677300","authid":"56387677300","authname":"Wang Y.","surname":"Wang","given-name":"Yayi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60022281"}]}],"authkeywords":"Human posture identification | Kinect | Skeleton tracking","source-id":"5700191222","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84907560646"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84907560646?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84907560646&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84907560646&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84907560646","dc:identifier":"SCOPUS_ID:84907560646","eid":"2-s2.0-84907560646","dc:title":"Nonlinear diffusion filtering method based on wavelet image","dc:creator":"Zhao X.","prism:publicationName":"International Journal of Multimedia and Ubiquitous Engineering","prism:issn":"19750080","prism:volume":"9","prism:issueIdentifier":"9","prism:pageRange":"29-40","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.14257/ijmue.2014.9.9.04","dc:description":"In this paper, on the basis of the anisotropic diffusion mechanism, analyzes emphatically represented by P - M model of diffusion filter principle of several kinds of nonlinear diffusion model, and their respective characteristics and problems. In-depth analysis of the nonlinear diffusion model, the threshold and termination mechanism of combining image geometric structure feature and visual information (gradient, brightness, contrast, structural information), in view of the existing nonlinear diffusion filtering model, the diffusion coefficient depends on the gradient and the problem that the susceptible to noise interference, presents a fidelity term used in image denoising and restoration contain nonlinear wavelet diffusion model, the theoretical analysis and experimental results show that this method is compared with other diffusion model while denoising can keep image edges and details characteristics, image visual effect is better.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60261038","afid":"60261038","affilname":"Shandong Women’s University","affiliation-city":"Jinan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35099874500","authid":"35099874500","authname":"Zhao X.","surname":"Zhao","given-name":"Xiaofeng","initials":"X.","afid": [{"@_fa": "true", "$" :"60261038"}]}],"authkeywords":"Donoho’s threshold | Image denoising | Quaternion analytic signal | Quaternion wavelettransform (QWT)","source-id":"21100197523","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84907393497"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84907393497?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84907393497&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84907393497&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84907393497","dc:identifier":"SCOPUS_ID:84907393497","eid":"2-s2.0-84907393497","dc:title":"A novel feature extraction technique for human activity recognition","dc:creator":"Elvira V.","prism:publicationName":"IEEE Workshop on Statistical Signal Processing Proceedings","prism:isbn": [{"@_fa": "true", "$" :"9781479949755"}],"prism:pageRange":"177-180","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/SSP.2014.6884604","dc:description":"This work presents a novel feature extraction technique for human activity recognition using inertial and magnetic sensors. The proposed method estimates the orientation of the person with respect to the earth frame by using quaternion representation. This estimation is performed automatically without any extra information about where the sensor is placed on the body of the person. Furthermore, the method is also robust to displacements of the sensor with respect to the body. This novel feature extraction technique is used to feed a classification algorithm showing excellent results that outperform those obtained by an existing state-of-the-art feature extraction technique. © 2014 IEEE.","citedby-count":"10","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001741","afid":"60001741","affilname":"Universidad Carlos III de Madrid","affiliation-city":"Getafe","affiliation-country":"Spain"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56369475400","authid":"56369475400","authname":"Elvira V.","surname":"Elvira","given-name":"Víctor","initials":"V.","afid": [{"@_fa": "true", "$" :"60001741"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56369513900","authid":"56369513900","authname":"Nazábal-Rentería A.","surname":"Nazábal-Rentería","given-name":"Alfredo","initials":"A.","afid": [{"@_fa": "true", "$" :"60001741"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6603954601","authid":"6603954601","authname":"Artés-Rodríguez A.","surname":"Artés-Rodríguez","given-name":"Antonio","initials":"A.","afid": [{"@_fa": "true", "$" :"60001741"}]}],"authkeywords":"Activity Classification | Ambulatory Monitoring | Features Extraction | Inertial Sensors | Magnetic Sensors | Orientation Estimation | Quaternions","article-number":"6884604","source-id":"76112","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84907375319"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84907375319?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84907375319&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84907375319&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84907375319","dc:identifier":"SCOPUS_ID:84907375319","eid":"2-s2.0-84907375319","dc:title":"Bilateral motion spectra: Analysis and representation of human movement","dc:creator":"Schultz A.","prism:publicationName":"PhyCS 2014 - Proceedings of the International Conference on Physiological Computing Systems","prism:isbn": [{"@_fa": "true", "$" :"9789897580062"}],"prism:pageRange":"137-144","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.5220/0004700401370144","dc:description":"The body's bilateral symmetry allows for various kinds of human motion patterns. Our paper presents a method for analyzing and representing motion capture time series that effectively identifies spatial and temporal patterns. We develop a factored representation of joint angle data based on quaternions and a metric pair for comparing different physical states of articulation. This metric pair is used to generate a metric space pair over the set of time series states. The result is represented as a 2-dimensional color image termed a bilateral motion spectrum. Several spectral motifs are presented and characterized. Copyright © 2014 SCITEPRESS - Science and Technology Publications. All rights reserved.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023630","afid":"60023630","affilname":"Sarah Lawrence College","affiliation-city":"Bronxville","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56367626500","authid":"56367626500","authname":"Schultz A.","surname":"Schultz","given-name":"Anthony","initials":"A.","afid": [{"@_fa": "true", "$" :"60023630"}]}],"authkeywords":"Data representation | Human movement | Motion capture analysis | Pattern recognition","source-id":"21100984488","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906853461"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906853461?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84906853461&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84906853461&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84906853461","dc:identifier":"SCOPUS_ID:84906853461","eid":"2-s2.0-84906853461","dc:title":"A basic study on a method of evaluating 3-dimentional foot movements in walking","dc:creator":"Shiotani M.","prism:publicationName":"2014 IEEE-EMBS International Conference on Biomedical and Health Informatics, BHI 2014","prism:isbn": [{"@_fa": "true", "$" :"9781479921317"}],"prism:pageRange":"543-546","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/BHI.2014.6864422","dc:description":"Lower limb motor function is important for activities of daily living. Since gait movements of elderly subjects differ from those of young people, gait measurement is considered to be effective for evaluating lower limb motor function. In this paper, focusing on foot movements during gait, a method of evaluating 3-dimentional movements of the foot during walking was examined. Gait movements were measured with 3 healthy females using the wireless inertial sensor system developed by our research group. Then, foot inclination angle and vector locus of the foot vector were calculated from angular velocity and acceleration signals by using quaternion-based attitude representation. They were projected onto each plane of the global coordinate system. The results showed similar angle waveforms and locus patterns between subjects. These suggested that the angles and the vector loci would be useful in evaluation of lower limb motor function. Developing quantitative evaluation method and making clear meanings of the angles and the vector loci projected to the planes are necessary. © 2014 IEEE.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008435","afid":"60008435","affilname":"Tohoku University","affiliation-city":"Sendai","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56347501200","authid":"56347501200","authname":"Shiotani M.","surname":"Shiotani","given-name":"Maho","initials":"M.","afid": [{"@_fa": "true", "$" :"60008435"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/16183143000","authid":"16183143000","authname":"Watanabe T.","surname":"Watanabe","given-name":"Takashi","initials":"T.","afid": [{"@_fa": "true", "$" :"60008435"}]}],"article-number":"6864422","source-id":"21100332414","fund-acr":"JSPS","fund-no":"26560299","fund-sponsor":"Japan Society for the Promotion of Science","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906573055"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906573055?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84906573055&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84906573055&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84906573055","dc:identifier":"SCOPUS_ID:84906573055","eid":"2-s2.0-84906573055","dc:title":"15th International Conference on Engineering Applications of Neural Networks, EANN 2014","prism:publicationName":"Communications in Computer and Information Science","prism:issn":"18650929","prism:isbn": [{"@_fa": "true", "$" :"9783319110707"}],"prism:volume":"459 CCIS","prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","dc:description":"The proceedings contain 23 papers. The special focus in this conference is on Engineering Applications of Neural Networks. The topic include: Remarks on computational facial expression recognition from HOG features using quaternion multi-layer neural network; classification of database by using parallelization of algorithms third generation in a GPU; an iterative feature filter for sensor timeseries in pervasive computing applications; fuzzy-logic decision fusion for nonintrusive early detection of driver fatigue or drowsiness; neural trade-offs among specialist and generalist neurons in pattern recognition; classification of events in switch machines using bayes, fuzzy logic system and neural network; an accurate flood forecasting model using wireless sensor networks and chaos theory; regenerative braking control strategy for hybrid and electric vehicles using artificial neural networks; automatic screening and classification of diabetic retinopathy fundus images; brain neural data analysis using machine learning feature selection and classification methods; application of neural networks solar radiation prediction for hybrid renewable energy systems; a new user similarity computation method for collaborative filtering using artificial neural network; a new user similarity computation method for collaborative filtering using artificial neural network; detecting port scans against mobile devices with neural networks and decision trees; categorization and construction of rule based systems; tiling of satellite images to capture an island object; learning user models in multi-criteria recommender systems; estimation of the electric field across medium voltage surge arresters using artificial neural networks and decoding hand trajectory from primary motor cortex ECoG using time delay neural network.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"17700155007","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906546767"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906546767?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84906546767&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84906546767&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84906546767","dc:identifier":"SCOPUS_ID:84906546767","eid":"2-s2.0-84906546767","dc:title":"Remarks on Computational Facial Expression Recognition from HOG Features Using Quaternion Multi-layer Neural Network","dc:creator":"Takahashi K.","prism:publicationName":"Communications in Computer and Information Science","prism:issn":"18650929","prism:isbn": [{"@_fa": "true", "$" :"9783319110707"}],"prism:volume":"459 CCIS","prism:pageRange":"15-24","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1007/978-3-319-11071-4_2","dc:description":"Facial expression recognition is an important technology in human-computer interaction. This study investigates a method for facial expression recognition using quaternion neural networks. A multi-layer quaternion neural network that conducts its learning using a quaternion back-propagation algorithm is employed to design the facial expression recognition system. The input feature vector of the recognition system is composed of histograms of oriented gradients calculated from an input facial expression image, and the output vector of the quaternion neural network indicates the class of facial expressions such as happiness, anger, sadness, fear, disgust, surprise and neutral. Computational experimental results show the feasibility of the proposed method for recognising human facial expressions. © Springer International Publishing Switzerland 2014.","citedby-count":"19","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010726","afid":"60010726","affilname":"Doshisha University","affiliation-city":"Kyoto","affiliation-country":"Japan"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7409417392","authid":"7409417392","authname":"Takahashi K.","surname":"Takahashi","given-name":"Kazuhiko","initials":"K.","afid": [{"@_fa": "true", "$" :"60010726"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56337895400","authid":"56337895400","authname":"Takahashi S.","surname":"Takahashi","given-name":"Sae","initials":"S.","afid": [{"@_fa": "true", "$" :"60010726"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55943718900","authid":"55943718900","authname":"Cui Y.","surname":"Cui","given-name":"Yunduan","initials":"Y.","afid": [{"@_fa": "true", "$" :"60010726"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57211218398","authid":"57211218398","authname":"Hashimoto M.","surname":"Hashimoto","given-name":"Masafumi","initials":"M.","afid": [{"@_fa": "true", "$" :"60010726"}]}],"authkeywords":"Facial expression recognition | Histograms of oriented gradients | Image processing | Quaternion neural network","source-id":"17700155007","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906536141"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906536141?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84906536141&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84906536141&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84906536141","dc:identifier":"SCOPUS_ID:84906536141","eid":"2-s2.0-84906536141","dc:title":"Quaternion Phase Congruency model for edge saliency map extraction and image blur measurement","dc:creator":"Feng Z.","prism:publicationName":"IEEE International Symposium on Broadband Multimedia Systems and Broadcasting, BMSB","prism:issn":"21555044","prism:eIssn":"21555052","prism:isbn": [{"@_fa": "true", "$" :"9781479916542"}],"prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/BMSB.2014.6873515","dc:description":"Image edge detection is one of the most important foundations of image analysis and comprehension. Traditional edge detectors are not robust enough to illumination variations. In last decade, detector based on Phase Congruency (PC) model was proposed and invariant to illumination variations. In this paper, we introduce the quaternion Wavelet Transform to PC model and propose a new edge metric of quaternion Phase Congruency (QPC). QPC model overcomes one of the disadvantages of PC model. It is reliable to distinguish the significant skeleton structures from the relatively trivial texture structures. Experimental results show that our new model provides a more consistent edge saliency metric with human perception. © 2014 IEEE.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025084","afid":"60025084","affilname":"Shanghai Jiao Tong University","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56338251100","authid":"56338251100","authname":"Feng Z.","surname":"Feng","given-name":"Zihao","initials":"Z.","afid": [{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55695017800","authid":"55695017800","authname":"Xu Y.","surname":"Xu","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60025084"},{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7406503333","authid":"7406503333","authname":"Yang X.","surname":"Yang","given-name":"Xiaokang","initials":"X.","afid": [{"@_fa": "true", "$" :"60025084"}]}],"authkeywords":"edge saliency map | Phase Congruency | Quaternion Phase Congruency | Quaternion Wavelet Transform","article-number":"6873515","source-id":"21100218013","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906244600"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84906244600?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84906244600&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84906244600&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84906244600","dc:identifier":"SCOPUS_ID:84906244600","eid":"2-s2.0-84906244600","dc:title":"Research of the 3D splicing technology based on the binocular vision","dc:creator":"Xie M.","prism:publicationName":"Key Engineering Materials","prism:issn":"10139826","prism:eIssn":"16629795","prism:isbn": [{"@_fa": "true", "$" :"9783038351863"}],"prism:volume":"621","prism:pageRange":"641-648","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.4028/www.scientific.net/KEM.621.641","dc:description":"In order to achieve three-dimensional automatic splicing from the multi-angle, the paper presents a new splicing method. The method utilizes the invariance of the spatial characteristics of the characteristic landmarks and then marks the characteristic landmarks by introducing the angle collection between the characteristic landmarks, and match in space for the characteristic landmarks within two perspective regional based on this characteristic collection. This method eliminates the tedious encoding process of the landmarks, so improves the spatial matching rate and ensures the matching accuracy. In addition, in the process of striking the three-dimensional coordinates of the landmarks, this paper strikes image coordinate of the characteristic signs circle center by introducing the regional connectivity feature flag. This method eliminates interference from unwanted areas, and distinguish between the various signs round independence and improves the strike rate of the circle center. At the end rotation matrix R and translation vector T of the coordinate system normalization are solved by the quadruple method. Examples show that the algorithm has strong robustness, can realize quickly, automatic stitching for the visual data, and has the very good practical value. © (2014) Trans Tech Publications, Switzerland.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60006106","afid":"60006106","affilname":"Huaqiao University","affiliation-city":"Quanzhou","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56281148200","authid":"56281148200","authname":"Xie M.","surname":"Xie","given-name":"Minghong","initials":"M.","afid": [{"@_fa": "true", "$" :"60006106"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56331087400","authid":"56331087400","authname":"Wang C.","surname":"Wang","given-name":"Changbo","initials":"C.","afid": [{"@_fa": "true", "$" :"60006106"}]}],"authkeywords":"3D splicing | Connected region | Landmark | Quaternion | Space matching","source-id":"12378","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905964053"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905964053?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84905964053&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84905964053&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84905964053","dc:identifier":"SCOPUS_ID:84905964053","eid":"2-s2.0-84905964053","dc:title":"A quaternionic wavelet transform-based approach for object recognition","dc:creator":"Priyadharshini R.A.","prism:publicationName":"Defence Science Journal","prism:issn":"0011748X","prism:eIssn":"0976464X","prism:volume":"64","prism:issueIdentifier":"4","prism:pageRange":"350-357","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"July 2014","prism:doi":"10.14429/dsj.64.4503","dc:description":"Recognizing the objects in complex natural scenes is the challenging task as the object may be occluded, may vary in shape, position and in size. In this paper a method to recognize objects from different categories of images using quaternionic wavelet transform (QWT) is presented. This transform separates the information contained in the image better than a traditional Discrete wavelet transform and provides a multiscale image analysis whose coefficients are 2D analytic, with one near-shift invariant magnitude and three phases. The two phases encode local image shifts and the third one contains texture information. In the domain of object recognition, it is often to classify objects from images that make only limited part of the image. Hence to identify local features and certain region of images, patches are extracted over the interest points detected from the original image using Wavelet based interest point detector. Here QWT magnitude and phase features are computed for every patch. Then these features are trained, tested and classified using SVM classifier in order to have supervised learning model. In order to compare the performance of local feature with global feature, the transform is applied to the entire image and the global features are derived. The performance of QWT is compared with discrete wavelet transform (DWT) and dual tree discrete wavelet transform (DTDWT). Observations revealed that QWT outperforms the DWT and shift invariant DTDWT with lesser equal error rate. The experimental evaluation is done using the complex Graz databases. © 2014, DESIDOC.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60070202","afid":"60070202","affilname":"Mepco Schlenk Engineering College","affiliation-city":"Sivakasi","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57821337700","authid":"57821337700","authname":"Priyadharshini R.A.","surname":"Priyadharshini","given-name":"R. Ahila","initials":"R.A.","afid": [{"@_fa": "true", "$" :"60070202"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8351565000","authid":"8351565000","authname":"Arivazhagan S.","surname":"Arivazhagan","given-name":"S.","initials":"S.","afid": [{"@_fa": "true", "$" :"60070202"}]}],"authkeywords":"Object recognition | Patch | Quaternionic wavelet transform | Salient point detector","source-id":"17294","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905735663"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905735663?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84905735663&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84905735663&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84905735663","dc:identifier":"SCOPUS_ID:84905735663","eid":"2-s2.0-84905735663","dc:title":"Edge detection, color quantization, segmentation, texture removal, and noise reduction of color image using quaternion iterative filtering","dc:creator":"Hsiao Y.","prism:publicationName":"Journal of Electronic Imaging","prism:issn":"10179909","prism:eIssn":"1560229X","prism:volume":"23","prism:issueIdentifier":"4","prism:pageRange":null,"prism:coverDate":"2014-01-01","prism:coverDisplayDate":"July 2014","prism:doi":"10.1117/1.JEI.23.4.043001","dc:description":"Empirical mode decomposition (EMD) is a simple, local, adaptive, and efficient method for nonlinear and nonstationary signal analysis. However, for dealing with multidimensional signals, EMD and its variants such as bidimensional EMD (BEMD) and multidimensional EMD (MEMD) are very slow due to the needs of a large amount of envelope interpolations. Recently, a method called iterative filtering has been proposed. This filteringbased method is not as precise as EMD but its processing speed is very fast and can achieve comparable results as EMD does in many image and signal processing applications. We combine quaternion algebra and iterative filtering to achieve the edge detection, color quantization, segmentation, texture removal, and noise reduction task of color images. We can obtain similar results by using quaternion combined with EMD; however, as mentioned before, EMD is slow and cumbersome. Therefore, we propose to use quaternion iterative filtering as an alternative method for quaternion EMD (QEMD). The edge of color images can be detected by using intrinsic mode functions (IMFs) and the color quantization results can be obtained from residual image. The noise reduction algorithm of our method can be used to deal with Gaussian, salt-and-pepper, speckle noise, etc. The peak signal-to-noise ratio results are satisfactory and the processing speed is also very fast. Since textures in a color image are high-frequency components, we also can use quaternion iterative filtering to decompose a color image into many high- and low-frequency IMFs and remove textures by eliminating high-frequency IMFs. © 2014 SPIE and IS&T.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005429","afid":"60005429","affilname":"National Taiwan University","affiliation-city":"Taipei","affiliation-country":"Taiwan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35191694600","authid":"35191694600","authname":"Hsiao Y.","surname":"Hsiao","given-name":"Yu Zhe","initials":"Y.Z.","afid": [{"@_fa": "true", "$" :"60005429"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7202463605","authid":"7202463605","authname":"Pei S.","surname":"Pei","given-name":"Soo Chang","initials":"S.C.","afid": [{"@_fa": "true", "$" :"60005429"}]}],"authkeywords":"color quantization | edge detection | empirical mode decomposition | image denoising | iterative filtering | texture removal","article-number":"043001","source-id":"25978","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905714878"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905714878?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84905714878&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84905714878&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84905714878","dc:identifier":"SCOPUS_ID:84905714878","eid":"2-s2.0-84905714878","dc:title":"A new approach for solving the Five-Point Relative Pose Problem for vision-based estimation and control","dc:creator":"Fathian K.","prism:publicationName":"Proceedings of the American Control Conference","prism:issn":"07431619","prism:isbn": [{"@_fa": "true", "$" :"9781479932726"}],"prism:pageRange":"103-109","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/ACC.2014.6859364","dc:description":"The problem of finding the relative camera pose between two calibrated camera views given five matched feature points is called the Five Point Relative Pose Problem. There exists a variety of solutions in the literature. However, existing methods rely on solving an optimization problem that is based on the Essential matrix. The Essential matrix has fundamental weaknesses, and introduces these weaknesses into algorithms that employ it. In this paper, we propose a new and practical method eschews the essential matrix by representing the pose estimation problem in the quaternion space. The new method has numerous advantages. Unlike the Essential Matrix, it is not prone to problems when faced with coplanar points or zero translation between two camera views. Rotation, scaled translation, and scaled depth of the points with respect to both camera frames are simultaneously recovered. Furthermore, the algorithm is robust to noise and can be easily extended to more than five points. Investigations using simulated images under noise have validated the new method and verify that the algorithm can be used in practical context such as Position Based Visual Servoing. © 2014 American Automatic Control Council.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009415","afid":"60009415","affilname":"The University of Texas at Dallas","affiliation-city":"Richardson","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/40761168200","authid":"40761168200","authname":"Fathian K.","surname":"Fathian","given-name":"Kaveh","initials":"K.","afid": [{"@_fa": "true", "$" :"60009415"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/15750786600","authid":"15750786600","authname":"Gans N.","surname":"Gans","given-name":"Nicholas R.","initials":"N.R.","afid": [{"@_fa": "true", "$" :"60009415"}]}],"authkeywords":"Optimization algorithms | Vision-based control","article-number":"6859364","source-id":"18692","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905694151"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905694151?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84905694151&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84905694151&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84905694151","dc:identifier":"SCOPUS_ID:84905694151","eid":"2-s2.0-84905694151","dc:title":"Almost global finite-time stable observer for rigid body attitude dynamics","dc:creator":"Bohn J.","prism:publicationName":"Proceedings of the American Control Conference","prism:issn":"07431619","prism:isbn": [{"@_fa": "true", "$" :"9781479932726"}],"prism:pageRange":"4949-4954","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/ACC.2014.6858823","dc:description":"A state observer is proposed for rigid body attitude motion with a given attitude dynamics model. This observer is designed on the state space of rigid body attitude motion, which is the tangent bundle of the Lie group of rigid body rotations in three dimensions, SO(3), and therefore avoids instability due to the unwinding phenomenon seen with unit quaternion-based attitude observers. In the absence of measurement noise and disturbance torques, the observer designed leads to almost global finite-time stable convergence of attitude motion state estimates to the actual states for a rigid body whose inertia is known. Almost global finite-time stability of this observer is shown using a Morse function as part of a Lyapunov analysis; this Morse function has been previously used for almost global asymptotic stabilization of rigid body attitude motion. Numerical simulation results confirm the analytically obtained stability properties of this attitude state observer. Numerical results also show that state estimate errors are bounded in the presence of bounded measurement noise and bounded disturbance torque. © 2014 American Automatic Control Council.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002162","afid":"60002162","affilname":"New Mexico State University","affiliation-city":"Las Cruces","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57193098766","authid":"57193098766","authname":"Bohn J.","surname":"Bohn","given-name":"Jan","initials":"J.","afid": [{"@_fa": "true", "$" :"60002162"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7101788910","authid":"7101788910","authname":"Sanyal A.K.","surname":"Sanyal","given-name":"Amit K.","initials":"A.K.","afid": [{"@_fa": "true", "$" :"60002162"}]}],"authkeywords":"Aerospace | Algebraic/geometric methods | Observers for nonlinear systems","article-number":"6858823","source-id":"18692","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905675273"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84905675273?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84905675273&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84905675273&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84905675273","dc:identifier":"SCOPUS_ID:84905675273","eid":"2-s2.0-84905675273","dc:title":"QWT enhanced SVM for Hyperspectral image classification","dc:creator":"Shen Y.","prism:publicationName":"Conference Record - IEEE Instrumentation and Measurement Technology Conference","prism:issn":"10915281","prism:isbn": [{"@_fa": "true", "$" :"9781467363853"}],"prism:pageRange":"1454-1458","prism:coverDate":"2014-01-01","prism:coverDisplayDate":"2014","prism:doi":"10.1109/I2MTC.2014.6860986","dc:description":"Higher and higher accuracy is demanded in the development of Hyperspectral images classification technology, which faces the challenge of increasing amount of data. This paper proposes to combine the standard support vector machine (SVM) classification technique, utilized for land-cover classification studies, with the quaternion wavelet transform (QWT) to enhance the classification accuracy of SVM. This novel algorithm applies QWT to generate additional features prior to SVM, which is selected for classifying the images. Furthermore, two simulation experiments on AVIRIS hyperspectral image are conducted for comparing the performances achieved by the proposed QWT enhanced SVM classification method and the original one respectively. The results demonstrate that the improved SVM classification process, which is derived after the application of QWT, is superior to the raw one in relation to the issue of accuracy. © 2014 IEEE.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019616","afid":"60019616","affilname":"Harbin Institute of Technology","affiliation-city":"Harbin","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/110035057","afid":"110035057","affilname":"China Astronaut Research and Training Center","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56315530800","authid":"56315530800","authname":"Shen Y.","surname":"Shen","given-name":"Yue","initials":"Y.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55825476400","authid":"55825476400","authname":"Feng H.","surname":"Feng","given-name":"Hongqi","initials":"H.","afid": [{"@_fa": "true", "$" :"110035057"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57199479168","authid":"57199479168","authname":"Wang Q.","surname":"Wang","given-name":"Qiang","initials":"Q.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/47962202000","authid":"47962202000","authname":"Liu Y.","surname":"Liu","given-name":"Yipeng","initials":"Y.","afid": [{"@_fa": "true", "$" :"60019616"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/36604533800","authid":"36604533800","authname":"He Z.","surname":"He","given-name":"Zhi","initials":"Z.","afid": [{"@_fa": "true", "$" :"60019616"}]}],"authkeywords":"classification accuracy | Hyperspectral images | quaternion wavelet transform (QWT) | support vector machine (SVM)","article-number":"6860986","source-id":"15045","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}