{"search-results":{"opensearch:totalResults":"225","opensearch:startIndex":"125","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "125"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2019&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2019&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=100&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2019&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=150&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2019&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=200&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2019&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85063503906"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85063503906?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85063503906&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85063503906&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85063503906","dc:identifier":"SCOPUS_ID:85063503906","eid":"2-s2.0-85063503906","dc:title":"Remarks on Control of Robot Manipulator Using Quaternion Neural Network","dc:creator":"Takahashi K.","prism:publicationName":"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2018 - Proceedings","prism:isbn": [{"@_fa": "true", "$" :"9789881476852"}],"prism:pageRange":"560-565","prism:coverDate":"2019-03-04","prism:coverDisplayDate":"4 March 2019","prism:doi":"10.23919/APSIPA.2018.8659775","dc:description":"High-dimensional neural networks, in which all the network parameters, states, signals and activation functions are expressed using hypercomplex numbers, have received increasing attention as solutions to real-world problems in many fields of science and engineering. Quaternion numbers constitute a class of the hypercomplex number system, and several successful applications based on quaternion neural networks have been demonstrated. In this study, the application of a quaternion neural network to control systems is investigated. An adaptive-type servo controller, in which a quaternion neural network output is used as the control input of a plant to ensure the plant output matches the desired output, is presented. The quaternion neural network has a multi-layer feedforward network topology with a split-type quaternion function as the activation function of neurons, and a tapped-delay-line method is used to compose the network input. To train the network parameters by using the gradient error minimisation, a feedback error learning scheme is introduced into the control system. Computational experiments for controlling a two-link robot manipulator by using the proposed quaternion neural network-based controller are conducted, and the simulation results obtained demonstrate the feasibility of using the proposed controller in practical control applications.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010726","afid":"60010726","affilname":"Doshisha University","affiliation-city":"Kyoto","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7409417392","authid":"7409417392","authname":"Takahashi K.","surname":"Takahashi","given-name":"Kazuhiko","initials":"K.","afid": [{"@_fa": "true", "$" :"60010726"}]}],"article-number":"8659775","source-id":"21100902102","fund-acr":"MEXT","fund-no":"undefined","fund-sponsor":"Ministry of Education, Culture, Sports, Science and Technology","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85074075243"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85074075243?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074075243&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85074075243&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85074075243","dc:identifier":"SCOPUS_ID:85074075243","eid":"2-s2.0-85074075243","dc:title":"Endoscopic image colorization using convolutional neural network","dc:creator":"Jiang H.","prism:publicationName":"Proceedings of 2019 IEEE 7th International Conference on Bioinformatics and Computational Biology, ICBCB 2019","prism:isbn": [{"@_fa": "true", "$" :"9781728106410"}],"prism:pageRange":"162-166","prism:coverDate":"2019-03-01","prism:coverDisplayDate":"March 2019","prism:doi":"10.1109/ICBCB.2019.8854646","dc:description":"Colorization of grayscale images is crucial for clinical image-based diagnosis. However, it is an ill-posed problem that requires a comprehensive understanding of image content. The present study proposes a novel convolutional neural network (CNN) for a fully automatic colorization process by first employing the pre-trained residual network to extract high-level image features and then introducing the CNN to analyze the complex nonlinear relationship between the image features and chrominance values. Luminance and the learned chrominance values are then combined to recover the color of the image, and the proposed color-perceptual loss function is used to calculate the recovered and real color image loss. Based on the experiments conducted, the proposed method was proven to be highly effective and robust in restoring endoscopic images to their true colors. The average values of the feature similarity index incorporating chromatic information (FSIMc) and the quaternion structural similarity (QSSIM) for the experimental endoscopic image datasets reached 0.9961 and 0.9739, respectively.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57211474101","authid":"57211474101","authname":"Jiang H.","surname":"Jiang","given-name":"Huipeng","initials":"H.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/12243879800","authid":"12243879800","authname":"Tang S.","surname":"Tang","given-name":"Songyuan","initials":"S.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57211479424","authid":"57211479424","authname":"Li Y.","surname":"Li","given-name":"Yating","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56173394200","authid":"56173394200","authname":"Ai D.","surname":"Ai","given-name":"Danni","initials":"D.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7404037613","authid":"7404037613","authname":"Song H.","surname":"Song","given-name":"Hong","initials":"H.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57091071100","authid":"57091071100","authname":"Yang J.","surname":"Yang","given-name":"Jian","initials":"J.","afid": [{"@_fa": "true", "$" :"60016835"}]}],"authkeywords":"Deep learning | Image colorization | Medical image processing","article-number":"8854646","source-id":"21100933889","fund-no":"2017YFC0107800","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85066251316"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85066251316?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85066251316&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85066251316&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85066251316","dc:identifier":"SCOPUS_ID:85066251316","eid":"2-s2.0-85066251316","dc:title":"Copy-Move Forgery Detection for Color Images Based on QPCA","dc:creator":"Wang J.","prism:publicationName":"Yingyong Kexue Xuebao/Journal of Applied Sciences","prism:issn":"02558297","prism:volume":"37","prism:issueIdentifier":"2","prism:pageRange":"291-300","prism:coverDate":"2019-03-01","prism:coverDisplayDate":"March 2019","prism:doi":"10.3969/j.issn.0255-8297.2019.02.014","dc:description":"Currently, in order to deal with color images, most forensics methods transform color images into gray images,which results in the color property not being fully used. Aimed at this problem, a copy-move forgery detection scheme based on quaternion principal component analysis (QPCA) is proposed in this paper. The scheme makes full use of the color property and the relationship among all color channels, which improves the accuracy in forged area effectively. The proposed scheme is block-based and firstly it divides images into overlapping blocks and performs QPCA of all the blocks to extract features. Then the features are lexicographical ordered to obtain shift vector and its frequency. Finally we compare the shift vector frequency to the threshold to locate the forged region. Experiments show that the missing-false alarm rate in the proposed method is lower than the existing methods and has a better accuracy.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57192930875","authid":"57192930875","authname":"Wang J.","surname":"Wang","given-name":"Jin Wei","initials":"J.W.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57209010327","authid":"57209010327","authname":"Xu C.","surname":"Xu","given-name":"Chun Hui","initials":"C.H.","afid": [{"@_fa": "true", "$" :"60064143"}]}],"authkeywords":"Block-based | Color image | Copy-move forgery detection | Quaternion principal component analysis (QPCA)","source-id":"19700170833","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85020936929"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85020936929?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85020936929&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85020936929&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S1063520317300507"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85020936929","dc:identifier":"SCOPUS_ID:85020936929","eid":"2-s2.0-85020936929","dc:title":"Time–frequency analysis of bivariate signals","dc:creator":"Flamant J.","prism:publicationName":"Applied and Computational Harmonic Analysis","prism:issn":"10635203","prism:eIssn":"1096603X","prism:volume":"46","prism:issueIdentifier":"2","prism:pageRange":"351-383","prism:coverDate":"2019-03-01","prism:coverDisplayDate":"March 2019","prism:doi":"10.1016/j.acha.2017.05.007","pii":"S1063520317300507","dc:description":"Many phenomena are described by bivariate signals or bidimensional vectors in applications ranging from radar to EEG, optics and oceanography. We show that an adequate quaternion Fourier transform permits to build relevant time–frequency representations of bivariate signals that naturally identify geometrical or polarization properties. First, a bivariate counterpart of the usual analytic signal of real signals is introduced, called the quaternion embedding of bivariate signals. Then two fundamental theorems ensure that a quaternion short term Fourier transform and a quaternion continuous wavelet transform are well defined and obey desirable properties such as conservation laws and reconstruction formulas. The resulting spectrograms and scalograms provide meaningful representations of both the time–frequency and geometrical/polarization content of the signal. Moreover the numerical implementation remains simply based on the use of FFT. A toolbox is available for reproducibility. Synthetic and real-world examples illustrate the relevance and efficiency of the proposed approach.","citedby-count":"16","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104665","afid":"60104665","affilname":"Université de Lille","affiliation-city":"Lille","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104170","afid":"60104170","affilname":"Grenoble Images Parole Signal Automatique","affiliation-city":"Saint Martin d'Heres","affiliation-country":"France"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57189218541","authid":"57189218541","orcid":"0000-0001-9994-173X","authname":"Flamant J.","surname":"Flamant","given-name":"Julien","initials":"J.","afid": [{"@_fa": "true", "$" :"60104665"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6507015909","authid":"6507015909","orcid":"0000-0001-6175-6045","authname":"Le Bihan N.","surname":"Le Bihan","given-name":"Nicolas","initials":"N.","afid": [{"@_fa": "true", "$" :"60104170"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6505961382","authid":"6505961382","authname":"Chainais P.","surname":"Chainais","given-name":"Pierre","initials":"P.","afid": [{"@_fa": "true", "$" :"60104665"}]}],"authkeywords":"Bivariate signal | Polarization properties | Quaternion embedding | Quaternion Fourier Transform | Stokes parameters | Time–frequency analysis","source-id":"25150","fund-acr":"FP7","fund-no":"326176","fund-sponsor":"Seventh Framework Programme","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061193017"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061193017?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061193017&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85061193017&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85061193017","dc:identifier":"SCOPUS_ID:85061193017","eid":"2-s2.0-85061193017","dc:title":"Colour face recognition using fuzzy quaternion-based discriminant analysis","dc:creator":"Bao S.","prism:publicationName":"International Journal of Machine Learning and Cybernetics","prism:issn":"18688071","prism:eIssn":"1868808X","prism:volume":"10","prism:issueIdentifier":"2","prism:pageRange":"385-395","prism:coverDate":"2019-02-04","prism:coverDisplayDate":"4 February 2019","prism:doi":"10.1007/s13042-017-0722-4","dc:description":"Colour information has been shown to be effective in improving object recognition performance. In this paper, we propose a novel quaternion-based colour model with enhanced fuzzy parameterized discriminant analysis to perform face recognition. The proposed method represents and classifies colour images by using an improved fuzzy quaternion-based discriminant (FQD) model, which is effective for colour image feature representation, extraction and classification. More specifically, each pixel in a colour image is first assigned a quaternion number, and a quaternion-based vector is then generated to represent this colour image. Second, an enhanced fuzzy parameterized discriminant analysis is used to transform the original quaternion-based vector into an optimized discriminant quaternion space. Third, colour face recognition is conducted by interpreting the colour feature model as fuzzy weight measurement in a quaternion discriminant analysis. The main contribution of this paper is that it provides a novel fuzzy supervised learning approach to reconstruct the quaternion-based discriminant vector space, thus showing the importance of the FQD characteristic from colour spaces for colour-image-based face recognition. Experimental results on the AR and Georgia Tech colour datasets demonstrate the effectiveness of the proposed method.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60088078","afid":"60088078","affilname":"Minjiang University","affiliation-city":"Fuzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069722","afid":"60069722","affilname":"Dalian Minzu University","affiliation-city":"Dalian","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029322","afid":"60029322","affilname":"Dalian Maritime University","affiliation-city":"Dalian","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021097","afid":"60021097","affilname":"University of Surrey","affiliation-city":"Guildford","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010080","afid":"60010080","affilname":"Nanjing University of Science and Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007029","afid":"60007029","affilname":"Jiangnan University","affiliation-city":"Wuxi","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35209559900","authid":"35209559900","authname":"Bao S.","surname":"Bao","given-name":"Shuzhe","initials":"S.","afid": [{"@_fa": "true", "$" :"60029322"},{"@_fa": "true", "$" :"60069722"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8304894200","authid":"8304894200","authname":"Song X.","surname":"Song","given-name":"Xiaoning","initials":"X.","afid": [{"@_fa": "true", "$" :"60007029"},{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60088078"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55925786500","authid":"55925786500","authname":"Hu G.","surname":"Hu","given-name":"Guosheng","initials":"G.","afid": [{"@_fa": "true", "$" :"60021097"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/23020119200","authid":"23020119200","authname":"Yang X.","surname":"Yang","given-name":"Xibei","initials":"X.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56308871700","authid":"56308871700","authname":"Wang C.","surname":"Wang","given-name":"Chunli","initials":"C.","afid": [{"@_fa": "true", "$" :"60029322"}]}],"authkeywords":"Colour image recognition | Fuzzy parameterized discriminant analysis | Quaternion-based vector","source-id":"19700177336","fund-acr":"MOE","fund-no":"JYB201603","fund-sponsor":"Ministry of Education of the People's Republic of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85067652617"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85067652617?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85067652617&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85067652617&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85067652617","dc:identifier":"SCOPUS_ID:85067652617","eid":"2-s2.0-85067652617","dc:title":"Robust quaternion-valued wideband adaptive beamforming","dc:creator":"Duan X.","prism:publicationName":"Journal of Radars","prism:issn":"2095283X","prism:volume":"8","prism:issueIdentifier":"1","prism:pageRange":"117-124","prism:coverDate":"2019-02-01","prism:coverDisplayDate":"February 2019","prism:doi":"10.12000/JR18083","dc:description":"A robust quaternion-valued wideband adaptive beamformer is proposed, in which a quaternion is utilized to arrange the output of the array element. By exploiting the augmented envelope alignment technique, adopting the three involutions of quaternion, and incorporating the noncircular information of the signal simultaneously, a quaternion-valued wideband augmented signal model is established to achieve the robust adaptive beamforming based on signal subspace projection. Compared with other wideband beamformers, the proposed scheme exhibits a better performance in extracting noncircular signals by array aperture extension, and is insensitive to the pointing error. The simulation results verify the efficiency of the proposed beamformer.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57209415156","authid":"57209415156","authname":"Duan X.","surname":"Duan","given-name":"Xiaofei","initials":"X.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57192586797","authid":"57192586797","authname":"Liu Z.","surname":"Liu","given-name":"Zhiwen","initials":"Z.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/16320275100","authid":"16320275100","authname":"Xu Y.","surname":"Xu","given-name":"Yougen","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"}]}],"authkeywords":"Noncircular signal | Quaternion | Robust adaptive beamforming | Wideband array signal processing","source-id":"21100812209","fund-acr":"NSFC","fund-no":"61331019","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85065655344"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85065655344?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85065655344&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85065655344&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85065655344","dc:identifier":"SCOPUS_ID:85065655344","eid":"2-s2.0-85065655344","dc:title":"Block-Wise Two Dimensional Kernel Quaternion Principal Component Analysis","dc:creator":"Chen B.J.","prism:publicationName":"Beijing Youdian Daxue Xuebao/Journal of Beijing University of Posts and Telecommunications","prism:issn":"10075321","prism:volume":"42","prism:issueIdentifier":"1","prism:pageRange":"53-60","prism:coverDate":"2019-02-01","prism:coverDisplayDate":"1 February 2019","prism:doi":"10.13190/j.jbupt.2018-045","dc:description":"Currently, kernel quaternion principal component analysis (KQPCA) has been proposed and successfully applied to process linear quaternion signals. However, two dimensional version of KQPCA (2DKQPCA) has not been successfully implemented due to the quite time-consuming problem for diagonalizing the high dimensional kernel matrix. So, using the block-based idea and the parallel computing idea, the block-wise 2DKQPCA (B2DKQPCA) is proposed to implement 2DKQPCA really. After the overall consideration of computational complexity, application performance and quaternion Hermitian block, B2DKQPCA mainly processes the blocks of three directions: main-diagonal direction, anti-diagonal direction and side-diagonal direction. Then, B2DKQPCA is applied into RGB-D object recognition by combining B2DKQPCA and quaternion representation of RGB-D images. Experimental results on two publicly available datasets demonstrate that the proposed RGB-D object recognition algorithm based on the column direction B2DKQPCA outperforms some existing algorithms using principal component analysis and some existing algorithms using convolutional neural network.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073726","afid":"60073726","affilname":"Ludong University","affiliation-city":"Yantai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36805188500","authid":"36805188500","authname":"Chen B.J.","surname":"Chen","given-name":"Bei Jing","initials":"B.J.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57195995772","authid":"57195995772","authname":"Yang J.H.","surname":"Yang","given-name":"Jian Hao","initials":"J.H.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/36109921300","authid":"36109921300","authname":"Fan C.N.","surname":"Fan","given-name":"Chun Nian","initials":"C.N.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/26633246300","authid":"26633246300","authname":"Su Q.T.","surname":"Su","given-name":"Qing Tang","initials":"Q.T.","afid": [{"@_fa": "true", "$" :"60073726"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55978231100","authid":"55978231100","authname":"Wang D.C.","surname":"Wang","given-name":"Ding Cheng","initials":"D.C.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]}],"authkeywords":"Color image | Kernel principal component analysis | Quaternion | RGB-D object recognition","source-id":"17751","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061718120"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061718120?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061718120&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85061718120&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85061718120","dc:identifier":"SCOPUS_ID:85061718120","eid":"2-s2.0-85061718120","dc:title":"Color image quality assessment based on quaternion spectral residual","dc:creator":"Jing Y.","prism:publicationName":"Laser and Optoelectronics Progress","prism:issn":"10064125","prism:volume":"56","prism:issueIdentifier":"3","prism:pageRange":null,"prism:coverDate":"2019-02-01","prism:coverDisplayDate":"February 2019","prism:doi":"10.3788/LOP56.031009","dc:description":"The quaternion spectral residual method for detecting the visual saliency regions of two images is proposed, by expressing the reference image and the distorted image as a pure quaternion matrix. Then both the method and the quaternion gradient features are employed to design color image quality evaluation, as well as visual saliency as the weight of the evaluation index. Numerical experiments are conducted on the T1D2013 and CS1Q databases to calculate four kinds of objective evaluation indexes such as the Spearman rank correlation coefficient (SROCC), the Kendall rank correlation coefficient, the Pearson linear correlation coefficient, and the root mean squared error. The results show that the experimental SROCC value on TID2013 reaches 0.8169, which matches the subjective evaluation of humans.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003630","afid":"60003630","affilname":"Ningxia University","affiliation-city":"Yinchuan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57206468390","authid":"57206468390","authname":"Jing Y.","surname":"Jing","given-name":"Yue","initials":"Y.","afid": [{"@_fa": "true", "$" :"60003630"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/12782839700","authid":"12782839700","authname":"Guojun L.","surname":"Guojun","given-name":"Liu","initials":"L.","afid": [{"@_fa": "true", "$" :"60003630"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57206467729","authid":"57206467729","authname":"Hao F.","surname":"Hao","given-name":"Fu","initials":"F.","afid": [{"@_fa": "true", "$" :"60003630"}]}],"authkeywords":"Color image quality assessment | Image processing | Quaternion | Spectral residual | Visual saliency","article-number":"031009","source-id":"21100855971","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85058655750"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85058655750?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85058655750&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85058655750&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0263224118311345"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85058655750","dc:identifier":"SCOPUS_ID:85058655750","eid":"2-s2.0-85058655750","dc:title":"Image hash authentication algorithm for orthogonal moments of fractional order chaotic scrambling coupling hyper-complex number","dc:creator":"Tao F.","prism:publicationName":"Measurement: Journal of the International Measurement Confederation","prism:issn":"02632241","prism:volume":"134","prism:pageRange":"866-873","prism:coverDate":"2019-02-01","prism:coverDisplayDate":"February 2019","prism:doi":"10.1016/j.measurement.2018.11.079","pii":"S0263224118311345","dc:description":"In this paper, the image Hash authentication algorithm for orthogonal moments of fractional order chaotic scrambling coupling hyper-complex number Tchebichef is proposed. The improved PDE function and Ring segmentation mechanism are used to process the initial image and output the secondary image to improve the robustness of Hash's scaling and rotation; and by taking full account into the color information of the image, the image R, G and B position is regarded as its imaginary part. In addition, the invariant moment of the hyper-complex number Tchebichef is desgined, and the robust characteristics of the secondary image is fully extracted to greatly improve its ability to recognize the rotation tampering. At the same time, in order to improve the security of the Hash sequence, the fractional order Logistic mapping and chaotic scrambling technique is constructed to encrypt the eigenvector; and the image information is authenticated by the Hamming distance. Finally, the robustness and tampering recognition accuracy of the proposed Hash algorithm are tested.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018540","afid":"60018540","affilname":"Southwestern University of Finance and Economics","affiliation-city":"Chengdu","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000142","afid":"60000142","affilname":"Konkuk University","affiliation-city":"Seoul","affiliation-country":"South Korea"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205121132","authid":"57205121132","authname":"Tao F.","surname":"Tao","given-name":"Feng","initials":"F.","afid": [{"@_fa": "true", "$" :"60018540"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57205120651","authid":"57205120651","authname":"Qian W.","surname":"Qian","given-name":"Wu","initials":"W.","afid": [{"@_fa": "true", "$" :"60000142"}]}],"authkeywords":"Chaotic scrambling technique | Hyper-complex moment | Image Hash | Ring segmentation | Secondary image","source-id":"15424","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054850595"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054850595?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054850595&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85054850595&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165168418303384"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85054850595","dc:identifier":"SCOPUS_ID:85054850595","eid":"2-s2.0-85054850595","dc:title":"An effective vector filter for impulse noise reduction based on adaptive quaternion color distance mechanism","dc:creator":"Jin L.","prism:publicationName":"Signal Processing","prism:issn":"01651684","prism:volume":"155","prism:pageRange":"334-345","prism:coverDate":"2019-02-01","prism:coverDisplayDate":"February 2019","prism:doi":"10.1016/j.sigpro.2018.10.007","pii":"S0165168418303384","dc:description":"The measure of color distances plays an important role in color image processing. An effective color distance method is based on quaternion representation, which computes a color distance by weighted average of the distances of luminance and quaternion chromaticity. However, the mechanism of assigning fixed weights to luminance and chromaticity distances cannot always effectively measure color distances, since in a color image chromaticity can change significantly. To address this issue, this paper proposes an adaptive weighted quaternion color distance method. Based on the new color distance measure, the robust outlyingness ratio and local reachability density, which are defined in grayscale images, are extended to color images to implement a coarse-to-fine color noise detection operator. In noise filtering, a weighted vector median filter is employed to restore the pixels judged as noisy. Experimental results exhibit the validity of the proposed method by showing better performance in terms of both objective criteria and visual effect, compared to other widely-used color image filtering methods.","citedby-count":"20","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025761","afid":"60025761","affilname":"Huazhong University of Science and Technology","affiliation-city":"Wuhan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/15922652500","authid":"15922652500","authname":"Jin L.","surname":"Jin","given-name":"Lianghai","initials":"L.","afid": [{"@_fa": "true", "$" :"60025761"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57213268188","authid":"57213268188","orcid":"0000-0001-9216-6726","authname":"Zhu Z.","surname":"Zhu","given-name":"Zhiliang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60025761"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/23767272300","authid":"23767272300","orcid":"0000-0003-1434-5758","authname":"Song E.","surname":"Song","given-name":"Enmin","initials":"E.","afid": [{"@_fa": "true", "$" :"60025761"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55706250100","authid":"55706250100","authname":"Xu X.","surname":"Xu","given-name":"Xiangyang","initials":"X.","afid": [{"@_fa": "true", "$" :"60025761"}]}],"authkeywords":"Color image | Impulse noise | Quaternion | Vector filter","source-id":"25548","fund-acr":"NSFC","fund-no":"61370179","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052923117"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052923117?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85052923117&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85052923117&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85052923117","dc:identifier":"SCOPUS_ID:85052923117","eid":"2-s2.0-85052923117","dc:title":"Discrimination of Computer Generated and Photographic Images Based on CQWT Quaternion Markov Features","dc:creator":"Wang J.","prism:publicationName":"International Journal of Pattern Recognition and Artificial Intelligence","prism:issn":"02180014","prism:volume":"33","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2019-02-01","prism:coverDisplayDate":"1 February 2019","prism:doi":"10.1142/S0218001419540077","dc:description":"In this paper, an effective method based on the color quaternion wavelet transform (CQWT) for image forensics is proposed. Compared to discrete wavelet transform (DWT), the CQWT provides more information, such as the quaternion's magnitude and phase measures, to discriminate between computer generated (CG) and photographic (PG) images. Meanwhile, we extend the classic Markov features into the quaternion domain to develop the quaternion Markov statistical features for color images. Experimental results show that the proposed scheme can achieve the classification rate of 92.70%, which is 6.89% higher than the classic Markov features.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60072429","afid":"60072429","affilname":"Asia University","affiliation-city":"Taichung","affiliation-country":"Taiwan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022904","afid":"60022904","affilname":"New Jersey Institute of Technology","affiliation-city":"Newark","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57219116697","authid":"57219116697","authname":"Wang J.","surname":"Wang","given-name":"Jinwei","initials":"J.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57192070035","authid":"57192070035","authname":"Li T.","surname":"Li","given-name":"Ting","initials":"T.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7103035038","authid":"7103035038","authname":"Shih F.Y.","surname":"Shih","given-name":"Frank Y.","initials":"F.Y.","afid": [{"@_fa": "true", "$" :"60022904"},{"@_fa": "true", "$" :"60072429"}]}],"authkeywords":"classification | forensics | Markov | Quaternion | wavelet transform","article-number":"1954007","source-id":"24310","fund-acr":"NSF","fund-no":"undefined","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85040972211"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85040972211?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85040972211&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85040972211&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85040972211","dc:identifier":"SCOPUS_ID:85040972211","eid":"2-s2.0-85040972211","dc:title":"Plancherel theorem and quaternion Fourier transform for square integrable functions","dc:creator":"Cheng D.","prism:publicationName":"Complex Variables and Elliptic Equations","prism:issn":"17476933","prism:eIssn":"17476941","prism:volume":"64","prism:issueIdentifier":"2","prism:pageRange":"223-242","prism:coverDate":"2019-02-01","prism:coverDisplayDate":"1 February 2019","prism:doi":"10.1080/17476933.2018.1427080","dc:description":"The quaternion Fourier transform (QFT), a generalization of the classical 2D Fourier transform, plays an increasingly active role in particular signal and colour image processing. There tends to be an inordinate degree of interest placed on the properties of QFT. The classical convolution theorem and multiplication formula are only suitable for 2D Fourier transform of complex-valued signal, and do not hold for QFT of quaternion-valued signal. The purpose of this paper is to overcome these problems and establish the Plancherel and inversion theorems of QFT in the square integrable signals space L1. First, we investigate the behaviours of QFT in the integrable signals space L1. Next, we deduce the energy preservation property which extends functions from L1 to L2 space. Moreover, some other important properties such as modified multiplication formula are also analyzed for QFT.","citedby-count":"17","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022317","afid":"60022317","affilname":"University of Macau","affiliation-city":"Taipa","affiliation-country":"Macao"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57194324445","authid":"57194324445","authname":"Cheng D.","surname":"Cheng","given-name":"Dong","initials":"D.","afid": [{"@_fa": "true", "$" :"60022317"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003837546","authid":"7003837546","authname":"Kou K.I.","surname":"Kou","given-name":"Kit Ian","initials":"K.I.","afid": [{"@_fa": "true", "$" :"60022317"}]}],"authkeywords":"42A38 | 42B10 | 43A32 | 43A50 | inversion theorem | linear canonical transform | multiplication formula | Plancherel theorem | Quaternion Fourier transforms","source-id":"17900156742","fund-acr":"UM","fund-no":"11401606","fund-sponsor":"Universidade de Macau","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85062537039"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85062537039?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062537039&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85062537039&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85062537039","dc:identifier":"SCOPUS_ID:85062537039","eid":"2-s2.0-85062537039","dc:title":"Spike Quaternion Neural Networks Control for a Hand prosthesis","dc:creator":"Lizrraga-Rodrguez J.","prism:publicationName":"2018 IEEE Latin American Conference on Computational Intelligence, LA-CCI 2018","prism:isbn": [{"@_fa": "true", "$" :"9781538646250"}],"prism:pageRange":null,"prism:coverDate":"2019-01-23","prism:coverDisplayDate":"23 January 2019","prism:doi":"10.1109/LA-CCI.2018.8625239","dc:description":"In this work, a robotic prosthesis controlled by Spike-type neural networks in conjunction with quaternions is developed. Neural networks are implemented from the development of myoelectric signals to the control of the hand prosthesis. Similarly, the development and obtaining of the prosthesis seen from a mechanical part is shown.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018216","afid":"60018216","affilname":"CINVESTAV Unidad Guadalajara","affiliation-city":"Guadalajara","affiliation-country":"Mexico"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57207459490","authid":"57207459490","authname":"Lizrraga-Rodrguez J.","surname":"Lizrraga-Rodrguez","given-name":"Jorge","initials":"J.","afid": [{"@_fa": "true", "$" :"60018216"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57190285638","authid":"57190285638","authname":"Lechuga-Gutierrez L.","surname":"Lechuga-Gutierrez","given-name":"Luis","initials":"L.","afid": [{"@_fa": "true", "$" :"60018216"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55995861000","authid":"55995861000","authname":"Bayro-Corrochano E.","surname":"Bayro-Corrochano","given-name":"Eduardo","initials":"E.","afid": [{"@_fa": "true", "$" :"60018216"}]}],"authkeywords":"Quaternion | Spike Neural Network","article-number":"8625239","source-id":"21100900510","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85080090289"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85080090289?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85080090289&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85080090289&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85080090289","dc:identifier":"SCOPUS_ID:85080090289","eid":"2-s2.0-85080090289","dc:title":"The quaternion-based anisotropic gradient for the color images","dc:creator":"Voronin V.","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:volume":"2019","prism:issueIdentifier":"11","prism:pageRange":null,"prism:coverDate":"2019-01-13","prism:coverDisplayDate":"13 January 2019","prism:doi":"10.2352/ISSN.2470-1173.2019.11.IPAS-277","dc:description":"Image gradient, as a preprocessing step is an essential tool in image processing in many research areas such as edge detection, segmentation, smoothing, inpainting, etc. In the present paper, we develop a new gradient by integrated the quaternion framework with LPA-ICI (local polynomial approximation - the intersection of confidence intervals) based on anisotropic gradient concepts for the color image processing applications. Computer simulations on the Berkeley Segmentation Dataset show that the new quaternion anisotropic gradient exhibits fewer color artifacts compared to state-of-the-art techniques including well-knowledge gradient operators.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018011","afid":"60018011","affilname":"Donskoj Gosudarstvennyj Tehniceskij Universitet","affiliation-city":"Rostov-on-Don","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60014196","afid":"60014196","affilname":"Moscow State Technological University Stankin","affiliation-city":"Moscow","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010187","afid":"60010187","affilname":"College of Staten Island","affiliation-city":"New York","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55802371401","authid":"55802371401","authname":"Voronin V.","surname":"Voronin","given-name":"V.","initials":"V.","afid": [{"@_fa": "true", "$" :"60018011"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57204649388","authid":"57204649388","authname":"Zelensky A.","surname":"Zelensky","given-name":"A.","initials":"A.","afid": [{"@_fa": "true", "$" :"60014196"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35321805400","authid":"35321805400","authname":"Agaian S.","surname":"Agaian","given-name":"S.","initials":"S.","afid": [{"@_fa": "true", "$" :"60010187"}]}],"article-number":"IPAS-277","source-id":"21100846961","fund-acr":"RSF","fund-no":"18-71-00137","fund-sponsor":"Russian Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85062401907"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85062401907?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85062401907&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85062401907&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85062401907","dc:identifier":"SCOPUS_ID:85062401907","eid":"2-s2.0-85062401907","dc:title":"Remarks on a recurrent quaternion neural network with application to servo control systems","dc:creator":"Takahashi K.","prism:publicationName":"ANZCC 2018 - 2018 Australian and New Zealand Control Conference","prism:isbn": [{"@_fa": "true", "$" :"9781538666173"}],"prism:pageRange":"45-50","prism:coverDate":"2019-01-09","prism:coverDisplayDate":"9 January 2019","prism:doi":"10.1109/ANZCC.2018.8606573","dc:description":"This paper investigates the control system application of a fully connected recurrent neural network in which all network parameters and signals are expressed in quaternion numbers, and the training of the network is conducted using a real-time recurrent learning algorithm. The recurrent quaternion neural network (RQNN), which synthesises the control input to track the outputs of the non-linear system to the desired outputs, assumes the role of an adaptive-type servo controller in the control system. A feedback error learning method is used to train the RQNN using an online method in the control system. Numerical simulations for controlling discrete-time non-linear plants are performed to evaluate the characteristics of the RQNN-based adaptive-type controller. The simulation results demonstrate the feasibility and effectiveness of the proposed controller.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010726","afid":"60010726","affilname":"Doshisha University","affiliation-city":"Kyoto","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7409417392","authid":"7409417392","authname":"Takahashi K.","surname":"Takahashi","given-name":"Kazuhiko","initials":"K.","afid": [{"@_fa": "true", "$" :"60010726"}]}],"article-number":"8606573","source-id":"21100900284","fund-acr":"Monbusho","fund-no":"undefined","fund-sponsor":"Ministry of Education, Culture, Sports, Science and Technology","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061822413"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85061822413?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85061822413&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85061822413&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85061822413","dc:identifier":"SCOPUS_ID:85061822413","eid":"2-s2.0-85061822413","dc:title":"Quaternion based representation of Vector Sensor Receiver","dc:creator":"Fauziya F.","prism:publicationName":"OCEANS 2018 MTS/IEEE Charleston, OCEAN 2018","prism:isbn": [{"@_fa": "true", "$" :"9781538648148"}],"prism:pageRange":null,"prism:coverDate":"2019-01-07","prism:coverDisplayDate":"7 January 2019","prism:doi":"10.1109/OCEANS.2018.8604766","dc:description":"The use of vector sensors as receivers for Underwater Acoustic Communications systems is gaining popularity. Traditionally vector sensors have been used for estimating the Direction of Arrival. Of late, vector sensors are finding applications in the area of underwater acoustic communications. The ability of a single vector sensor to provide spatial diversity has resulted in their becoming popular as receivers in underwater acoustic communication systems. An outcome of this trend is that now there is a need to represent the vector sensor signals in a format that is amenable to performing processing and computations. An apt representation for such signals is the quaternion, since we need to represent two complex quantities simultaneously. This representation is motivated from the use of quaternion in vector sensor based RF communications, where diversity is obtained by using different polarization on orthogonal components of the signal. In acoustic communications, diversity is obtained by signal acquisition in orthogonal directions. In this paper we show how to perform manipulations on matrices of quaternions and use those results to obtain a receiver with operations performed entirely in the quaternion domain. This results in a compact representation and saving in computation.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032730","afid":"60032730","affilname":"Indian Institute of Technology Delhi","affiliation-city":"New Delhi","affiliation-country":"India"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57192586727","authid":"57192586727","authname":"Fauziya F.","surname":"Fauziya","given-name":"Farheen","initials":"F.","afid": [{"@_fa": "true", "$" :"60032730"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35854246100","authid":"35854246100","authname":"Agrawal M.","surname":"Agrawal","given-name":"Monika","initials":"M.","afid": [{"@_fa": "true", "$" :"60032730"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7003946630","authid":"7003946630","authname":"Lall B.","surname":"Lall","given-name":"Brejesh","initials":"B.","afid": [{"@_fa": "true", "$" :"60032730"}]}],"article-number":"8604766","source-id":"21100898933","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85117586275"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85117586275?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85117586275&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85117586275&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85117586275","dc:identifier":"SCOPUS_ID:85117586275","eid":"2-s2.0-85117586275","dc:title":"Image Fusion for Apple Quality Detection","dc:creator":"Luo X.","prism:publicationName":"Journal of Food Science and Biotechnology","prism:issn":"16731689","prism:volume":"38","prism:issueIdentifier":"9","prism:pageRange":"33-40","prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","prism:doi":"10.3969/j.issn.1673-1689.2019.09.005","dc:description":"The damage of fruit not only affects the appearance quality, but also causes nutritional loss and bacterial infection. The purpose of this paper is to research an image fusion method for quality detection of fruit and then provide the damage information of fruit to farmers or distributors, which help them take early means to avoid greater economic losses. Firstly, low-frequency and high-frequency subbands are obtained by implementing the quaternion wavelet transform (QWT) on the visible image and the infrared image of apple. Secondly, the low-frequency coefficients are fused using the weighted average fusion rule based on the local average gradient. The high frequency coefficients are integrated by choose-max fusion rule based on guided filter. Finally, the fused image is obtained by using the inverse QWT after the fusion of the low frequency coefficients and high frequency coefficients. The experimental results show that the proposed method can preserve the detail texture of the epidermis in the visible light image and the secondary surface damage information detected in the infrared image. Therefore, the proposed method is helpful for improving the quality detection accuracy of apples.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007029","afid":"60007029","affilname":"Jiangnan University","affiliation-city":"Wuxi","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/23985472800","authid":"23985472800","authname":"Luo X.","surname":"Luo","given-name":"Xiaoqing","initials":"X.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57204416482","authid":"57204416482","authname":"Yuan C.","surname":"Yuan","given-name":"Chenchen","initials":"C.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57195467535","authid":"57195467535","authname":"Chai P.","surname":"Chai","given-name":"Pengfei","initials":"P.","afid": [{"@_fa": "true", "$" :"60007029"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/58551246200","authid":"58551246200","authname":"Li K.","surname":"Li","given-name":"Kai","initials":"K.","afid": [{"@_fa": "true", "$" :"60007029"}]}],"authkeywords":"image fusion | quality detection | quaternion wavelet transform","source-id":"21100846923","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85099315621"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85099315621?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85099315621&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85099315621&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85099315621","dc:identifier":"SCOPUS_ID:85099315621","eid":"2-s2.0-85099315621","dc:title":"First-order ambisonic coding with PCA matrixing and quaternion-based interpolation","dc:creator":"Mahé P.","prism:publicationName":"Proceedings of the International Conference on Digital Audio Effects, DAFx","prism:issn":"24136700","prism:eIssn":"24136689","prism:pageRange":"284-291","prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","dc:description":"We present a spatial audio coding method which can extend existing speech/audio codecs, such as EVS or Opus, to represent first-order ambisonic (FOA) signals at low bit rates. The proposed method is based on principal component analysis (PCA) to decorrelate ambisonic components prior to multi-mono coding. The PCA rotation matrices are quantized in the generalized Euler angle domain; they are interpolated in quaternion domain to avoid discontinuities between successive signal blocks. We also describe an adaptive bit allocation algorithm for an optimized multi-mono coding of principal components. A subjective evaluation using the MUSHRA methodology is presented to compare the performance of the proposed method with naive multi-mono coding using a fixed bit allocation. Results show significant quality improvements at bit rates in the range of 52.8 kbit/s (4 × 13.2) to 97.6 kbit/s (4 × 24.4) using the EVS codec.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60122452","afid":"60122452","affilname":"Laboratoire Informatique, Image et Interaction (L3i)","affiliation-city":"La Rochelle","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104081","afid":"60104081","affilname":"Orange Labs","affiliation-city":"Issy-les-Moulineaux","affiliation-country":"France"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57221497969","authid":"57221497969","authname":"Mahé P.","surname":"Mahé","given-name":"Pierre","initials":"P.","afid": [{"@_fa": "true", "$" :"60104081"},{"@_fa": "true", "$" :"60122452"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/18042416800","authid":"18042416800","authname":"Ragot S.","surname":"Ragot","given-name":"Stéphane","initials":"S.","afid": [{"@_fa": "true", "$" :"60104081"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7004320655","authid":"7004320655","authname":"Marchand S.","surname":"Marchand","given-name":"Sylvain","initials":"S.","afid": [{"@_fa": "true", "$" :"60122452"}]}],"source-id":"21101106370","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85090974991"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85090974991?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85090974991&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85090974991&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85090974991","dc:identifier":"SCOPUS_ID:85090974991","eid":"2-s2.0-85090974991","dc:title":"Applications of autonomous navigation in next-generation mars rovers","dc:creator":"Dlouhy S.","prism:publicationName":"Proceedings of the International Telemetering Conference","prism:issn":"08845123","prism:isbn": [{"@_fa": "true", "$" :"9781713801887"}],"prism:volume":"55","prism:pageRange":"631-638","prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","dc:description":"This paper describes a module used to provide autonomous navigation and obstacle avoidance to a teleoperated prototype Mars rover designed to compete in the 2019 University Rover Challenge. For the competition's Autonomous Traversal task, the rover must be capable of traversing difficult desert terrain in search of visual waypoints. Our design uses a custom Navigation Board (NavBoard), a mobile robotics computer, and a sensor capable of producing a dense point cloud. NavBoard provides quaternion-based orientation data, distance measurements from a 1D LiDAR system, and GPS data over ethernet to a mobile robotics computer. This computer derives a 3D point cloud from a three-headed collinear stereoscopic camera then processes that data along with the data from NavBoard to determine the correct action to navigate through sparsely mapped terrain.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024728","afid":"60024728","affilname":"Missouri University of Science and Technology","affiliation-city":"Rolla","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57219003052","authid":"57219003052","authname":"Dlouhy S.","surname":"Dlouhy","given-name":"Sarah","initials":"S.","afid": [{"@_fa": "true", "$" :"60024728"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57218994576","authid":"57218994576","authname":"Arneson E.","surname":"Arneson","given-name":"Ethan","initials":"E.","afid": [{"@_fa": "true", "$" :"60024728"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6603109025","authid":"6603109025","authname":"Kosbar K.","surname":"Kosbar","given-name":"Kurt","initials":"K.","afid": [{"@_fa": "true", "$" :"60024728"}]}],"source-id":"69495","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85088228714"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85088228714?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85088228714&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85088228714&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85088228714","dc:identifier":"SCOPUS_ID:85088228714","eid":"2-s2.0-85088228714","dc:title":"A novel contribution to an hybrid INS/GPS system using a fuzzy approach","dc:creator":"Wassim K.","prism:publicationName":"CEUR Workshop Proceedings","prism:issn":"16130073","prism:volume":"2622","prism:pageRange":"89-94","prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","dc:description":"—In this paper, we present a technique based on fuzzy logic to improve the performance of an integrated inertial navigation system with GPS. The fuzzy technique proposed is mainly used to predict position and velocity measurements during the absence of GPS signals. As long as GPS measurements are available, the Q-SUKF [1] filter for INS / GPS integration works efficiently and provides an accurate estimate of the states of navigation. Nevertheless, during the disturbance of GPS signals, the fuzzy technique will be used with the Q-SUKF filter to correct the performance degradation of the algorithm. Finally, an experimental part on the use of the fuzzy technique proposed with the Q-SUKF has been validated. The aftereffects of our experiment have demonstrated the adequacy and the critical effect of the fuzzy method used. It decreases the error’s estimation of the position and velocity during GPS blackout periods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60068774","afid":"60068774","affilname":"Université Libanaise","affiliation-city":"Beirut","affiliation-country":"Lebanon"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57218196160","authid":"57218196160","authname":"Wassim K.","surname":"Wassim","given-name":"Khoder","initials":"K.","afid": [{"@_fa": "true", "$" :"60068774"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57218196159","authid":"57218196159","authname":"Monzer A.","surname":"Monzer","given-name":"Alwan","initials":"A.","afid": [{"@_fa": "true", "$" :"60068774"}]}],"authkeywords":"Fuzzy C-Means | Global Positioning System | Inertial Navigation System | Quaternion Scaled Unscented Kalman Filter | Takagi-Sugeno Fuzzy Model","source-id":"21100218356","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083950517"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85083950517?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083950517&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85083950517&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85083950517","dc:identifier":"SCOPUS_ID:85083950517","eid":"2-s2.0-85083950517","dc:title":"Quaternion recurrent neural networks","dc:creator":"Parcollet T.","prism:publicationName":"7th International Conference on Learning Representations, ICLR 2019","prism:pageRange":null,"prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","dc:description":"Recurrent neural networks (RNNs) are powerful architectures to model sequential data, due to their capability to learn short and long-term dependencies between the basic elements of a sequence. Nonetheless, popular tasks such as speech or images recognition, involve multi-dimensional input features that are characterized by strong internal dependencies between the dimensions of the input vector. We propose a novel quaternion recurrent neural network (QRNN), alongside with a quaternion long-short term memory neural network (QLSTM), that take into account both the external relations and these internal structural dependencies with the quaternion algebra. Similarly to capsules, quaternions allow the QRNN to code internal dependencies by composing and processing multidimensional features as single entities, while the recurrent operation reveals correlations between the elements composing the sequence. We show that both QRNN and QLSTM achieve better performances than RNN and LSTM in a realistic application of automatic speech recognition. Finally, we show that QRNN and QLSTM reduce by a maximum factor of 3.3x the number of free parameters needed, compared to real-valued RNNs and LSTMs to reach better results, leading to a more compact representation of the relevant information.","citedby-count":"37","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60176018","afid":"60176018","affilname":"Element AI Inc.","affiliation-city":"Montreal","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031214","afid":"60031214","affilname":"Université d'Avignon et des Pays du Vaucluse","affiliation-city":"Avignon","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009507","afid":"60009507","affilname":"University of Montreal","affiliation-city":"Montreal","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002494","afid":"60002494","affilname":"Université McGill","affiliation-city":"Montreal","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/115923149","afid":"115923149","affilname":"Orkis","affiliation-city":"Aix-en-Provence","affiliation-country":"France"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57193704479","authid":"57193704479","authname":"Parcollet T.","surname":"Parcollet","given-name":"Titouan","initials":"T.","afid": [{"@_fa": "true", "$" :"60031214"},{"@_fa": "true", "$" :"115923149"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24722956800","authid":"24722956800","authname":"Ravanelli M.","surname":"Ravanelli","given-name":"Mirco","initials":"M.","afid": [{"@_fa": "true", "$" :"60009507"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55697911300","authid":"55697911300","authname":"Morchid M.","surname":"Morchid","given-name":"Mohamed","initials":"M.","afid": [{"@_fa": "true", "$" :"60031214"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/6603063660","authid":"6603063660","authname":"Linarès G.","surname":"Linarès","given-name":"Georges","initials":"G.","afid": [{"@_fa": "true", "$" :"60031214"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57202470277","authid":"57202470277","authname":"Trabelsi C.","surname":"Trabelsi","given-name":"Chiheb","initials":"C.","afid": [{"@_fa": "true", "$" :"60009507"},{"@_fa": "true", "$" :"60176018"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/35547954100","authid":"35547954100","authname":"De Mori R.","surname":"De Mori","given-name":"Renato","initials":"R.","afid": [{"@_fa": "true", "$" :"60031214"},{"@_fa": "true", "$" :"60002494"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/7003958245","authid":"7003958245","authname":"Bengio Y.","surname":"Bengio","given-name":"Yoshua","initials":"Y.","afid": [{"@_fa": "true", "$" :"60009507"}]}],"source-id":"21100925600","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081631410"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85081631410?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85081631410&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85081631410&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S2405896319325662"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85081631410","dc:identifier":"SCOPUS_ID:85081631410","eid":"2-s2.0-85081631410","dc:title":"Comparison of Neural Network-Based Adaptive Controllers Using Hypercomplex Numbers for Controlling Robot Manipulator","dc:creator":"Takahashi K.","prism:publicationName":"IFAC-PapersOnLine","prism:eIssn":"24058963","prism:volume":"52","prism:issueIdentifier":"29","prism:pageRange":"67-72","prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","prism:doi":"10.1016/j.ifacol.2019.12.623","pii":"S2405896319325662","dc:description":"This study investigates an adaptive controller by applying a neural network, in which all the network parameters, states, signals and functions are expressed using hypercomplex numbers and algebras; its application to dynamics control of a robot manipulator. To design hypercomplex-valued neural networks where each neural network is a multilayer feedforward network with a split-type activation function of neurons using a tapped-delay-line input, we consider the following four types of hypercomplex numbers: complex, hyperbolic, bicomplex and quaternion numbers. In the control system, we utilise a feedback error-learning scheme to conduct the training of the network through a back-propagation algorithm. In the computational experiments, we explore a hypercomplex-valued neural network-based controller as a trajectory control problem of a three-link robot manipulator, in which the position of the end-effector follows to the desired trajectory in a 3-dimensional space. The simulation results validate the feasibility and effectiveness of the quaternion neural network-based controller for this task.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010726","afid":"60010726","affilname":"Doshisha University","affiliation-city":"Kyoto","affiliation-country":"Japan"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7409417392","authid":"7409417392","authname":"Takahashi K.","surname":"Takahashi","given-name":"Kazuhiko","initials":"K.","afid": [{"@_fa": "true", "$" :"60010726"}]}],"authkeywords":"Control | Hypercomplex number | Neural network | Robot manipulator","source-id":"21100456158","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079169634"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85079169634?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85079169634&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85079169634&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85079169634","dc:identifier":"SCOPUS_ID:85079169634","eid":"2-s2.0-85079169634","dc:title":"Dual quaternion based autonomous rendezvous and docking via model predictive control","dc:creator":"Iskender O.B.","prism:publicationName":"Proceedings of the International Astronautical Congress, IAC","prism:issn":"00741795","prism:volume":"2019-October","prism:pageRange":null,"prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","dc:description":"This paper presents a Guidance and Control (G&C) strategy to address 6-Degrees-Of-Freedom (6-DOF) spacecraft attitude and position control for future Rendezvous and Docking (RVD) missions. Future RVD missions, specifically when the target is uncooperative, are challenging as geometric constraints and parameter uncertainties are both present. In addition, due to close proximity and potential angular motion of the target satellite, the point mass approach is no longer sufficient to represent the relative motion dynamics. Hence, throughout this paper, the coupling between translational and rotational motion of spacecraft relative motion is addressed via Dual Quaternions and Piece-wise Model Predictive Control (MPC) framework. The algorithm is developed such that the relative position of interest is no longer Centre-Of-Mass (COM) position of the target satellite but can be the docking port or a predefined grasping feature. In addition, physical constraints are explicitly formulated and respected by formulating a constrained optimization problem. The proposed framework is real-time implementable because the control problem is formulated as a convex optimization problem. This is demonstrated by Hardware-In-The-Loop experiments to control a 5-DOF motion of spacecraft. The spacecraft simulator has 16 thrusters; therefore, convex optimization based allocation strategy to map the force and torque control signals to the 16 thrusters is also proposed.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031101","afid":"60031101","affilname":"University of Cambridge","affiliation-city":"Cambridge","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019894","afid":"60019894","affilname":"Thales Alenia Space","affiliation-city":"Toulouse","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007798","afid":"60007798","affilname":"Deutsches Zentrum für Luft- und Raumfahrt (DLR)","affiliation-city":"Koln","affiliation-country":"Germany"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005510","afid":"60005510","affilname":"Nanyang Technological University","affiliation-city":"Singapore City","affiliation-country":"Singapore"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205375711","authid":"57205375711","authname":"Iskender O.B.","surname":"Iskender","given-name":"Omer Burak","initials":"O.B.","afid": [{"@_fa": "true", "$" :"60005510"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7102762975","authid":"7102762975","authname":"Ling K.V.","surname":"Ling","given-name":"Keck Voon","initials":"K.V.","afid": [{"@_fa": "true", "$" :"60005510"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35782519700","authid":"35782519700","authname":"Simonini L.","surname":"Simonini","given-name":"Luca","initials":"L.","afid": [{"@_fa": "true", "$" :"60019894"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/16647199500","authid":"16647199500","authname":"Schlotterer M.","surname":"Schlotterer","given-name":"Markus","initials":"M.","afid": [{"@_fa": "true", "$" :"60007798"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57208624371","authid":"57208624371","authname":"Seelbinder D.","surname":"Seelbinder","given-name":"David","initials":"D.","afid": [{"@_fa": "true", "$" :"60007798"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/6604025103","authid":"6604025103","authname":"Theil S.","surname":"Theil","given-name":"Stephan","initials":"S.","afid": [{"@_fa": "true", "$" :"60007798"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/7005735237","authid":"7005735237","authname":"Maciejowski J.M.","surname":"Maciejowski","given-name":"Jan Marian","initials":"J.M.","afid": [{"@_fa": "true", "$" :"60031101"}]}],"authkeywords":"Docking | Embedded Optimization | Real-time Implementation | Rendezvous | Space Servicing | Spacecraft","article-number":"IAC-19_C1_8_4_x49460","source-id":"21100255701","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85078792484"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85078792484?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078792484&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85078792484&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85078792484","dc:identifier":"SCOPUS_ID:85078792484","eid":"2-s2.0-85078792484","dc:title":"Monocular visual inertial odometry (VIO) dataset collection with a self-calibrating platform for inertial measurement unit (IMU)","dc:creator":"Tian Y.","prism:publicationName":"ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)","prism:isbn": [{"@_fa": "true", "$" :"9780791883518"}],"prism:volume":"14","prism:pageRange":null,"prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","prism:doi":"10.1115/IMECE2019-10595","dc:description":"In this study, we built a monocular visual inertial odometry (VIO) dataset with a proposed self-calibrating platform for an inertial measurement unit (IMU). For a learning-based method, lack of database is the biggest limitation. One goal of this study is to generate a high-quality VIO database. Meanwhile, a properly calibrated inertial measurement unit (IMU) is critical for improving VIO system accuracy and precision. However, a professional IMU calibration tool is usually expensive and large. The proposed self-calibrating platform shows its benefits in eliminating the manual work in calibration and reducing the cost of the expensive platform, which brings more opportunities to students and researchers. This self-calibrating system was useful for collecting monocular visual inertial odometry datasets while driving. . The calibrated IMU generates 14 numbers at 100Hz: time, 3-axis accelerometer measurements, 3-axis gyroscope measurements, 3 Euler angles, and 4 quaternions. This VIO system is composed of a monocular camera, GoPro Hero 3, an IMU, BNO055, and a GPS, ANT-555. The sensors are mounted on a John Deere Gator™ Full-Size Crossover Utility Vehicle and are operated on an Intel NUC, a mini-size computer. The final dataset contains monocular images, IMU measurements, and GPS outputs.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028872","afid":"60028872","affilname":"Embry-Riddle Aeronautical University","affiliation-city":"Daytona Beach","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57198239537","authid":"57198239537","authname":"Tian Y.","surname":"Tian","given-name":"Yuan","initials":"Y.","afid": [{"@_fa": "true", "$" :"60028872"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/16446185200","authid":"16446185200","authname":"Compere M.","surname":"Compere","given-name":"Marc","initials":"M.","afid": [{"@_fa": "true", "$" :"60028872"}]}],"authkeywords":"IMU | Self-calibration | VIO dataset","source-id":"21100821109","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85078571154"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85078571154?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078571154&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85078571154&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85078571154","dc:identifier":"SCOPUS_ID:85078571154","eid":"2-s2.0-85078571154","dc:title":"Multi-view DDoS network flow feature extraction method via convolutional neural network","dc:creator":"Liu Y.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030373511"}],"prism:volume":"11983 LNCS","prism:pageRange":"30-41","prism:coverDate":"2019-01-01","prism:coverDisplayDate":"2019","prism:doi":"10.1007/978-3-030-37352-8_3","dc:description":"Distributed Denial of Service (DDoS) has caused tremendous damage to the network in large data environment. The features extracted by existing feature methods can not accurately represent the characteristics of network flow, and have the characteristics of high false alarm rate and high false alarm rate. This paper presents a multi-view distributed denial of service attack network flow feature extraction method based on convolutional neural network. According to the different characteristics of attack flow and normal flow in TCP/IP protocol, the related attributes of network flow are transformed into binary matrix, and the IP address and port number are reorganized into dual-channel matrix. Then, the multi-view perspective is composed of IP dual-channel matrix, port number dual-channel matrix, packet size grayscale matrix and TCP flag grayscale matrix. According to the characteristics of each attribute, different convolutional neural network models are used to extract the local features of each view, and the extracted local features are fused to form quaternion features to describe the characteristics of network flow. We use MVNFF to train the model, a distributed denial of service (DDoS) classifier based on multiple views is constructed. Experiments show that the features extracted by this method can more accurately represent the characteristics of network traffic and it can improve the robustness of the classifier and reduce the false alarm rate and false alarm rate.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017716","afid":"60017716","affilname":"Hainan University","affiliation-city":"Haikou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/118727280","afid":"118727280","affilname":"State Key Laboratory of Marine Resource Utilization in South China Sea","affiliation-city":"Haikou","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205023607","authid":"57205023607","authname":"Liu Y.","surname":"Liu","given-name":"Yifu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/34871417700","authid":"34871417700","authname":"Cheng J.","surname":"Cheng","given-name":"Jieren","initials":"J.","afid": [{"@_fa": "true", "$" :"60017716"},{"@_fa": "true", "$" :"118727280"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56327220600","authid":"56327220600","authname":"Tang X.","surname":"Tang","given-name":"Xiangyan","initials":"X.","afid": [{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57161259800","authid":"57161259800","authname":"Li M.","surname":"Li","given-name":"Mengyang","initials":"M.","afid": [{"@_fa": "true", "$" :"60017716"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57214268796","authid":"57214268796","authname":"Xie L.","surname":"Xie","given-name":"Luyi","initials":"L.","afid": [{"@_fa": "true", "$" :"60017716"}]}],"authkeywords":"Convolutional neural network | DDoS attack | Feature extraction | Multi view","source-id":"25674","fund-acr":"NSFC","fund-no":"61702539","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false}]}}