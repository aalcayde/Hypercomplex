{"search-results":{"opensearch:totalResults":"235","opensearch:startIndex":"150","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "150"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=150&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=175&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=210&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2020&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85094885377"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85094885377?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85094885377&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85094885377&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85094885377","dc:identifier":"SCOPUS_ID:85094885377","eid":"2-s2.0-85094885377","dc:title":"An active contour model for medical image segmentation using a quaternion framework","dc:creator":"Voronin V.","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:volume":"2020","prism:issueIdentifier":"10","prism:pageRange":null,"prism:coverDate":"2020-01-26","prism:coverDisplayDate":"26 January 2020","prism:doi":"10.2352/ISSN.2470-1173.2020.10.IPAS-062","dc:description":"This paper presents a new method for segmenting medical images is based on Hamiltonian quaternions and the associative algebra, method of the active contour model and LPA-ICI (local polynomial approximation - the intersection of confidence intervals) anisotropic gradient. Since for segmentation tasks, the image is usually converted to grayscale, this leads to the loss of important information about color, saturation, and other important information associated color. To solve this problem, we use the quaternion framework to represent a color image to consider all three channels simultaneously when segmenting the RGB image. As a method of noise reduction, adaptive filtering based on local polynomial estimates using the ICI rule is used. The presented new approach allows obtaining clearer and more detailed boundaries of objects of interest. The experiments performed on real medical images (Z-line detection) show that our segmentation method of more efficient compared with the current state-of-art methods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018011","afid":"60018011","affilname":"Donskoj Gosudarstvennyj Tehniceskij Universitet","affiliation-city":"Rostov-on-Don","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60014196","afid":"60014196","affilname":"Moscow State Technological University Stankin","affiliation-city":"Moscow","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010187","afid":"60010187","affilname":"College of Staten Island","affiliation-city":"New York","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55802371401","authid":"55802371401","authname":"Voronin V.","surname":"Voronin","given-name":"V.","initials":"V.","afid": [{"@_fa": "true", "$" :"60014196"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57219971735","authid":"57219971735","authname":"Zhdanova M.","surname":"Zhdanova","given-name":"M.","initials":"M.","afid": [{"@_fa": "true", "$" :"60014196"},{"@_fa": "true", "$" :"60018011"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56572834900","authid":"56572834900","authname":"Semenishchev E.","surname":"Semenishchev","given-name":"E.","initials":"E.","afid": [{"@_fa": "true", "$" :"60014196"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57204649388","authid":"57204649388","authname":"Zelensky A.","surname":"Zelensky","given-name":"A.","initials":"A.","afid": [{"@_fa": "true", "$" :"60014196"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/35321805400","authid":"35321805400","authname":"Agaian S.","surname":"Agaian","given-name":"S.","initials":"S.","afid": [{"@_fa": "true", "$" :"60010187"}]}],"source-id":"21100846961","fund-acr":"Minobrnauka","fund-no":"218","fund-sponsor":"Ministry of Education and Science of the Russian Federation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082554305"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85082554305?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082554305&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85082554305&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85082554305","dc:identifier":"SCOPUS_ID:85082554305","eid":"2-s2.0-85082554305","dc:title":"Visual Based Robotic Hoisting Motion Following Control","dc:creator":"Xu C.","prism:publicationName":"Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery","prism:issn":"10001298","prism:volume":"51","prism:issueIdentifier":"1","prism:pageRange":"417-426","prism:coverDate":"2020-01-25","prism:coverDisplayDate":"25 January 2020","prism:doi":"10.6041/j.issn.1000-1298.2020.01.046","dc:description":"The marine economy plays a very important and positive role in the national economy and social development. Because the ocean surges have a great impact on the safety and efficiency of marine logistics hoisting machine. At present, the wave motion compensation is mostly based on ship-specific sensors such as IMU or MRU, and the cost is high. A combination of logos was used, and a vision-based robotic hoisting motion following control method was proposed. Firstly, the kinematics analysis and hand-eye calibration of the manipulator were carried out. By using visual marker, the target objects in complex environments can be detected and identified. The man direction and direct linear transfer algorithm was used to calculate the orientation and position of the marker. A combination marker resisting image noise and occlusion issues with pose confusion scheme was designed. A quaternion based Kalman filter was used for pose estimation of combined marker. Then by establishing the hoist system model, the pseudo-differential feedback compound control algorithm was used on the speed loop. Trajectory tracking performance was improved. Based on the double S-shaped curve motion planning algorithm, the target motion tracking and path re-planning were performed, and the acceleration/deceleration method was used to generate motion trajectory. Based on the comprehensive experimental platform of marine automatic and intelligent lifting equipment which can simulate the offshore working environment, the visual-based hoisting robot arm winch lifting and following control method was studied. And static targets and dynamic target following experiments were performed, the feasibility of the hoisting lift control and the effectiveness of the follow-up control strategy were verified.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018465","afid":"60018465","affilname":"Yanshan University","affiliation-city":"Qinhuangdao","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007711","afid":"60007711","affilname":"Jilin University","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57198225364","authid":"57198225364","authname":"Xu C.","surname":"Xu","given-name":"Chunbo","initials":"C.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8324390600","authid":"8324390600","authname":"Zhao D.","surname":"Zhao","given-name":"Dingxuan","initials":"D.","afid": [{"@_fa": "true", "$" :"60007711"},{"@_fa": "true", "$" :"60018465"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57215502630","authid":"57215502630","authname":"Kong W.","surname":"Kong","given-name":"Weitian","initials":"W.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57211058948","authid":"57211058948","authname":"Zou S.","surname":"Zou","given-name":"Shaoyuan","initials":"S.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/8721421100","authid":"8721421100","authname":"Ni T.","surname":"Ni","given-name":"Tao","initials":"T.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57215505812","authid":"57215505812","authname":"Shu L.","surname":"Shu","given-name":"Lizhi","initials":"L.","afid": [{"@_fa": "true", "$" :"60007711"}]}],"authkeywords":"Hand-eye calibration | Hoisting robot | Kinematics analysis | Motion planning | Visual marker based localization","source-id":"59863","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85077974500"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85077974500?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85077974500&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85077974500&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85077974500","dc:identifier":"SCOPUS_ID:85077974500","eid":"2-s2.0-85077974500","dc:title":"Research on an infrared multi-target saliency detection algorithm under sky background conditions","dc:creator":"Dai S.","prism:publicationName":"Sensors (Switzerland)","prism:issn":"14248220","prism:volume":"20","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2020-01-02","prism:coverDisplayDate":"2 January 2020","prism:doi":"10.3390/s20020459","dc:description":"Aiming at solving the problem of incomplete saliency detection and unclear boundaries in infrared multi-target images with different target sizes and low signal-to-noise ratio under sky background conditions, this paper proposes a saliency detection method for multiple targets based on multi-saliency detection. The multiple target areas of the infrared image are mainly bright and the background areas are dark. Combining with the multi-scale top hat (Top-hat) transformation, the image is firstly corroded and expanded to extract the subtraction of light and shade parts and reconstruct the image to reduce the interference of sky blurred background noise. Then the image obtained by a multi-scale Top-hat transformation is transformed from the time domain to the frequency domain, and the spectral residuals and phase spectrum are extracted directly to obtain two kinds of image saliency maps by multi-scale Gauss filtering reconstruction, respectively. On the other hand, the quaternion features are extracted directly to transform the phase spectrum, and then the phase spectrum is reconstructed to obtain one kind of image saliency map by the Gauss filtering. Finally, the above three saliency maps are fused to complete the saliency detection of infrared images. The test results show that after the experimental analysis of infrared video photographs and the comparative analysis of Receiver Operating Characteristic (ROC) curve and Area Under the Curve (AUC) index, the infrared image saliency map generated by this method has clear target details and good background suppression effect, and the AUC index performance is good, reaching over 99%. It effectively improves the multi-target saliency detection effect of the infrared image under the sky background and is beneficial to subsequent detection and tracking of image targets.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60020620","afid":"60020620","affilname":"Chongqing University of Posts and Telecommunications","affiliation-city":"Chongqing","affiliation-country":"China"}],"pubmed-id":"31947536","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8321581900","authid":"8321581900","authname":"Dai S.","surname":"Dai","given-name":"Shaosheng","initials":"S.","afid": [{"@_fa": "true", "$" :"60020620"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57211523595","authid":"57211523595","authname":"Li D.","surname":"Li","given-name":"Dongyang","initials":"D.","afid": [{"@_fa": "true", "$" :"60020620"}]}],"authkeywords":"Infrared multi-target | Multi-scale saliency fusion | Multi-scale top-hat | Sky background","article-number":"459","source-id":"130124","fund-acr":"NSFC","fund-no":"CSTC2015JCYJA40032","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85077895477"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85077895477?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85077895477&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85077895477&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85077895477","dc:identifier":"SCOPUS_ID:85077895477","eid":"2-s2.0-85077895477","dc:title":"Cost-effective wearable indoor localization and motion analysis via the integration of UWB and IMU","dc:creator":"Zhang H.","prism:publicationName":"Sensors (Switzerland)","prism:issn":"14248220","prism:volume":"20","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2020-01-02","prism:coverDisplayDate":"2 January 2020","prism:doi":"10.3390/s20020344","dc:description":"Wearable indoor localization can now find applications in a wide spectrum of fields, including the care of children and the elderly, sports motion analysis, rehabilitation medicine, robotics navigation, etc. Conventional inertial measurement unit (IMU)-based position estimation and radio signal indoor localization methods based on WiFi, Bluetooth, ultra-wide band (UWB), and radio frequency identification (RFID) all have their limitations regarding cost, accuracy, or usability, and a combination of the techniques has been considered a promising way to improve the accuracy. This investigation aims to provide a cost-effective wearable sensing solution with data fusion algorithms for indoor localization and real-time motion analysis. The main contributions of this investigation are: (1) the design of a wireless, battery-powered, and light-weight wearable sensing device integrating a low-cost UWB module-DWM1000 and micro-electromechanical system (MEMS) IMU-MPU9250 for synchronized measurement; (2) the implementation of a Mahony complementary filter for noise cancellation and attitude calculation, and quaternions for frame rotation to obtain the continuous attitude for displacement estimation; (3) the development of a data fusion model integrating the IMU and UWB data to enhance the measurement accuracy using Kalman-filter-based time-domain iterative compensations; and (4) evaluation of the developed sensor module by comparing it with UWB-and IMU-only solutions. The test results demonstrate that the average error of the integrated module reached 7.58 cm for an arbitrary walking path, which outperformed the IMU-and UWB-only localization solutions. The module could recognize lateral roll rotations during normal walking, which could be potentially used for abnormal gait recognition.","citedby-count":"36","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032389","afid":"60032389","affilname":"Hebei University of Technology","affiliation-city":"Tianjin","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/118424988","afid":"118424988","affilname":"Ministry of Industry and Information Technology","affiliation-city":"Nanjing","affiliation-country":"China"}],"pubmed-id":"31936175","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55685618000","authid":"55685618000","authname":"Zhang H.","surname":"Zhang","given-name":"Hui","initials":"H.","afid": [{"@_fa": "true", "$" :"60032389"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56068551900","authid":"56068551900","authname":"Zhang Z.","surname":"Zhang","given-name":"Zonghua","initials":"Z.","afid": [{"@_fa": "true", "$" :"60032389"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35195704600","authid":"35195704600","authname":"Gao N.","surname":"Gao","given-name":"Nan","initials":"N.","afid": [{"@_fa": "true", "$" :"60032389"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/35174052700","authid":"35174052700","authname":"Xiao Y.","surname":"Xiao","given-name":"Yanjun","initials":"Y.","afid": [{"@_fa": "true", "$" :"60032389"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57189347882","authid":"57189347882","authname":"Meng Z.","surname":"Meng","given-name":"Zhaozong","initials":"Z.","afid": [{"@_fa": "true", "$" :"60032389"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57191446985","authid":"57191446985","authname":"Li Z.","surname":"Li","given-name":"Zhen","initials":"Z.","afid": [{"@_fa": "true", "$" :"60021666"},{"@_fa": "true", "$" :"118424988"}]}],"authkeywords":"Indoor localization | Inertial measurement unit (IMU) | Motion analysis | Ultra-wide band (UWB) | Wearable sensing devices","article-number":"344","source-id":"130124","fund-acr":"NSFC","fund-no":"C20190324","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85127963904"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85127963904?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85127963904&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85127963904&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85127963904","dc:identifier":"SCOPUS_ID:85127963904","eid":"2-s2.0-85127963904","dc:title":"A Smooth Representation of Belief over SO(3) for Deep Rotation Learning with Uncertainty","dc:creator":"Peretroukhin V.","prism:publicationName":"Robotics: Science and Systems","prism:eIssn":"2330765X","prism:isbn": [{"@_fa": "true", "$" :"9780992374761"}],"prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.15607/RSS.2020.XVI.007","dc:description":"Accurate rotation estimation is at the heart of robot perception tasks such as visual odometry and object pose estimation. Deep neural networks have provided a new way to perform these tasks, and the choice of rotation representation is an important part of network design. In this work, we present a novel symmetric matrix representation of the 3D rotation group, SO(3), with two important properties that make it particularly suitable for learned models: (1) it satisfies a smoothness property that improves convergence and generalization when regressing large rotation targets, and (2) it encodes a symmetric Bingham belief over the space of unit quaternions, permitting the training of uncertainty-aware models. We empirically validate the benefits of our formulation by training deep neural rotation regressors on two data modalities. First, we use synthetic point-cloud data to show that our representation leads to superior predictive accuracy over existing representations for arbitrary rotation targets. Second, we use image data collected onboard ground and aerial vehicles to demonstrate that our representation is amenable to an effective out-of-distribution (OOD) rejection technique that significantly improves the robustness of rotation estimates to unseen environmental effects and corrupted input images, without requiring the use of an explicit likelihood loss, stochastic sampling, or an auxiliary classifier. This capability is key for safety-critical applications where detecting novel inputs can prevent catastrophic failure of learned models.","citedby-count":"19","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60071030","afid":"60071030","affilname":"University of Toronto Institute for Aerospace Studies","affiliation-city":"Toronto","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022195","afid":"60022195","affilname":"Massachusetts Institute of Technology","affiliation-city":"Cambridge","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60006320","afid":"60006320","affilname":"MIT Computer Science &amp; Artificial Intelligence Laboratory","affiliation-city":"Cambridge","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56202208000","authid":"56202208000","authname":"Peretroukhin V.","surname":"Peretroukhin","given-name":"Valentin","initials":"V.","afid": [{"@_fa": "true", "$" :"60071030"},{"@_fa": "true", "$" :"60006320"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55372205200","authid":"55372205200","authname":"Giamou M.","surname":"Giamou","given-name":"Matthew","initials":"M.","afid": [{"@_fa": "true", "$" :"60071030"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55325613100","authid":"55325613100","authname":"Rosen D.M.","surname":"Rosen","given-name":"David M.","initials":"D.M.","afid": [{"@_fa": "true", "$" :"60022195"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57190127747","authid":"57190127747","authname":"Greene W.N.","surname":"Greene","given-name":"W. Nicholas","initials":"W.N.","afid": [{"@_fa": "true", "$" :"60006320"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7101831781","authid":"7101831781","authname":"Roy N.","surname":"Roy","given-name":"Nicholas","initials":"N.","afid": [{"@_fa": "true", "$" :"60006320"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57210998988","authid":"57210998988","authname":"Kelly J.","surname":"Kelly","given-name":"Jonathan","initials":"J.","afid": [{"@_fa": "true", "$" :"60071030"}]}],"source-id":"21100448299","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85110454728"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85110454728?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85110454728&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85110454728&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85110454728","dc:identifier":"SCOPUS_ID:85110454728","eid":"2-s2.0-85110454728","dc:title":"Local binary quaternion rotation pattern for colour texture retrieval","dc:creator":"Jebali H.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:issn":"10514651","prism:isbn": [{"@_fa": "true", "$" :"9781728188089"}],"prism:pageRange":"3698-3705","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ICPR48806.2021.9413192","dc:description":"Color is very important feature for image representation, it assumes very essential in the human visual recognition process. Although, several color extension of Local Binary Pattern processes the color texture from the three color channels separately (Marginal way). Aware of the high interaction that exists between different channels in the color image, this work introduces a new vector process to define a local descriptor for color images named Local Binary Quaternion Rotation Pattern (LBQRP). In this LBQRP purpose, the quaternion representation is used to represent color texture. The distance between two color can be expressed as the angle of rotation between two unit quaternions using the geodesic distance. After a LBQRP coding, local histograms are extracted and used as features. Experiments on three challenging color datasets: Vistex, Outex-TC13 and USPtex are carried out to evaluate the LBQRP performance in texture classification. Results show the high efficiency of the proposed approach facing to several stat-of-art methods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60091645","afid":"60091645","affilname":"Université de Tunis El Manar, Faculté des Sciences de Tunis","affiliation-city":"Tunis","affiliation-country":"Tunisia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032653","afid":"60032653","affilname":"Universite de Poitiers","affiliation-city":"Poitiers","affiliation-country":"France"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57204186075","authid":"57204186075","authname":"Jebali H.","surname":"Jebali","given-name":"Hela","initials":"H.","afid": [{"@_fa": "true", "$" :"60091645"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56211892500","authid":"56211892500","authname":"Richard N.","surname":"Richard","given-name":"Noël","initials":"N.","afid": [{"@_fa": "true", "$" :"60032653"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/36242201000","authid":"36242201000","authname":"Naouai M.","surname":"Naouai","given-name":"Mohamed","initials":"M.","afid": [{"@_fa": "true", "$" :"60091645"}]}],"article-number":"9413192","source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85109458833"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85109458833?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85109458833&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85109458833&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85109458833","dc:identifier":"SCOPUS_ID:85109458833","eid":"2-s2.0-85109458833","dc:title":"A Two-Stage Quaternion Vector Median Filter for Removing Impulse Noise in Color Images","dc:creator":"Roji Chanu P.","prism:publicationName":"ARPN Journal of Engineering and Applied Sciences","prism:eIssn":"18196608","prism:volume":"15","prism:issueIdentifier":"2","prism:pageRange":"350-364","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.36478/JEASCI.2020.350.364","dc:description":"This study presents a novel two-stage filtering algorithm for removing impulse noise in color images. Quaternion theory is used to represent the intensity and chromaticity differences of two color pixels. Use of quaternion treats color pixels as vectors and processes color images as single unit rather than as separated color components. This preserves the existing correlation and three dimensional vector natures of the color channels. In the first stage of noise detection, the color pixels are sorted and assigned a rank based on the aggregated sum of color pixel differences with other pixels inside the filtering window. The central pixel is considered as probably corrupted by an impulse if its rank is bigger than a predefined rank. In the second stage, the probably corrupted candidate is again checked for an edge or an impulse by using four Laplacian convolution kernels. If the minimum difference of these four convolution is larger than a predefined threshold, then the central pixel is regarded as an impulse. The noisy pixel is replaced by output of weighted vector median filter implemented using the quaternion distance. More weight is assigned to those pixels belonging to the direction of minimum difference. Experimental results indicate the improved performance of the proposed filter in suppressing the impulse noise while retaining the original image details comparing against other well-known filters.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60107385","afid":"60107385","affilname":"National Institute of Technology Nagaland","affiliation-city":"Dimapur","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60107383","afid":"60107383","affilname":"National Institute of Technology Manipur","affiliation-city":"Imphal","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57225190194","authid":"57225190194","authname":"Roji Chanu P.","surname":"Roji Chanu","given-name":"P.","initials":"P.","afid": [{"@_fa": "true", "$" :"60107385"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55665304800","authid":"55665304800","authname":"Singh K.M.","surname":"Singh","given-name":"Kh Manglem","initials":"K.M.","afid": [{"@_fa": "true", "$" :"60107383"}]}],"authkeywords":"chromaticity | convolution | impulse | laplacian | Quaternion | vector median","source-id":"21100200825","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108577100"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108577100?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108577100&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85108577100&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85108577100","dc:identifier":"SCOPUS_ID:85108577100","eid":"2-s2.0-85108577100","dc:title":"16th International Forum on Digital Media Communication, IFTC 2019","prism:publicationName":"Communications in Computer and Information Science","prism:issn":"18650929","prism:eIssn":"18650937","prism:isbn": [{"@_fa": "true", "$" :"9789811533402"}],"prism:volume":"1181","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","dc:description":"The proceedings contain 34 papers. The special focus in this conference is on Digital Media Communication. The topics include: Interactive Face Liveness Detection Based on OpenVINO and Near Infrared Camera; multi-scale Generative Adversarial Learning for Facial Attribute Transfer; convolutional-Block-Attention Dual Path Networks for Slide Transition Detection in Lecture Videos; preface; fast Traffic Sign Detection Using Color-Specific Quaternion Gabor Filters; attention-Based Top-Down Single-Task Action Recognition in Still Images; adaptive Person-Specific Appearance-Based Gaze Estimation; preliminary Study on Visual Attention Maps of Experts and Nonexperts When Examining Pathological Microscopic Images; few-Shot Learning for Crossing-Sentence Relation Classification; image Classification of Submarine Volcanic Smog Map Based on Convolution Neural Network; multi-Scale Depthwise Separable Convolutional Neural Network for Hyperspectral Image Classification; Joint SPSL and CCWR for Chinese Short Text Entity Recognition and Linking; a Reading Assistant System for Blind People Based on Hand Gesture Recognition; intrusion Detection Based on Fusing Deep Neural Networks and Transfer Learning; the Competition of Garbage Classification Visual Recognition; smoke Detection Based on Image Analysis Technology; an Academic Achievement Prediction Model Enhanced by Stacking Network; blind Panoramic Image Quality Assessment Based on Project-Weighted Local Binary Pattern; blind 3D Image Quality Assessment Based on Multi-scale Feature Learning; research on Influence of Content Diversity on Full-Reference Image Quality Assessment; screen Content Picture Quality Evaluation by Colorful Sparse Reference Information; PMIQD 2019: A Pathological Microscopic Image Quality Database with Nonexpert and Expert Scores; a Generalized Cellular Automata Approach to Modelling Contagion and Monitoring for Emergent Events in Sensor Networks.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"17700155007","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108459715"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85108459715?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108459715&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85108459715&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85108459715","dc:identifier":"SCOPUS_ID:85108459715","eid":"2-s2.0-85108459715","dc:title":"Fast Traffic Sign Detection Using Color-Specific Quaternion Gabor Filters","dc:creator":"Yin S.","prism:publicationName":"Communications in Computer and Information Science","prism:issn":"18650929","prism:eIssn":"18650937","prism:isbn": [{"@_fa": "true", "$" :"9789811533402"}],"prism:volume":"1181","prism:pageRange":"3-12","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-981-15-3341-9_1","dc:description":"A novel and fast traffic sign detection method is proposed based on color-specific quaternion Gabor filtering (CS-QGF). The proposed method is based on the fact that traffic signs are usually specialized in color and shape. Accordingly, we apply a quaternion Gabor transformation to extract the color and shape features of traffic signs simultaneously. Statistical color distribution of traffic sign is analyzed to optimize the construction of quaternion Gabor filters. The feature extracted via CS-QGF is robust to the distortion of color, the change of image resolution, and the change of lighting and shading conditions, which helps the following traffic sign detector reduce the search range of proposal regions. Experiments on GTSDB and TT100K datasets demonstrate that the proposed method helps to localize traffic signs in images with high efficiency, which outperforms state-of-the-art methods on both detection speed and final recognition accuracy.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025084","afid":"60025084","affilname":"Shanghai Jiao Tong University","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57224881999","authid":"57224881999","orcid":"0000-0002-4550-4371","authname":"Yin S.","surname":"Yin","given-name":"Shiqi","initials":"S.","afid": [{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55695017800","authid":"55695017800","authname":"Xu Y.","surname":"Xu","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60025084"}]}],"authkeywords":"Color-specific quaternion Gabor filtering | Traffic sign detection | Traffic sign recognition","source-id":"17700155007","fund-acr":"NSFC","fund-no":"61671298","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85107714530"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85107714530?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85107714530&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85107714530&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85107714530","dc:identifier":"SCOPUS_ID:85107714530","eid":"2-s2.0-85107714530","dc:title":"Clifford Geometric Algebra-Based Approach for 3D Modeling of Agricultural Images Acquired by UAVs","dc:creator":"Khan P.W.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"226297-226308","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.3045443","dc:description":"Three-dimensional image modeling is essential in many scientific disciplines, including computer vision and precision agriculture. So far, various methods of creating three-dimensional (3D) models have been considered. However, the processing of transformation matrices of each input image data is not controlled. Site-specific crop mapping is essential because it helps farmers determine yield, biodiversity, energy, crop coverage, etc. Clifford Geometric Algebraic understanding of signaling and image processing has become increasingly important in recent years. Geometric Algebraic treats multi-dimensional signals in a holistic way to maintain relationship between side sizes and prevent loss of information. This article has used agricultural images acquired by unmanned aerial vehicles (UAVs) to construct three-dimensional models using Clifford geometric algebra. The qualitative and quantitative performance evaluation results show that Clifford geometric algebra can generate a three-dimensional geometric statistical model directly from drones' RGB images. Through peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and visual comparison, the proposed algorithm's performance is compared with latest algorithms. Experimental results show that proposed algorithm is better than other leading 3D modeling algorithms.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60117634","afid":"60117634","affilname":"Jeju National University","affiliation-city":"Jeju","affiliation-country":"South Korea"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60078212","afid":"60078212","affilname":"University of Agriculture, Faisalabad","affiliation-city":"Faisalabad","affiliation-country":"Pakistan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57202838110","authid":"57202838110","orcid":"0000-0002-2561-4389","authname":"Khan P.W.","surname":"Khan","given-name":"Prince Waqas","initials":"P.W.","afid": [{"@_fa": "true", "$" :"60117634"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8897891700","authid":"8897891700","orcid":"0000-0003-1107-9941","authname":"Byun Y.C.","surname":"Byun","given-name":"Yung Cheol","initials":"Y.C.","afid": [{"@_fa": "true", "$" :"60117634"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57205010858","authid":"57205010858","orcid":"0000-0003-4812-1680","authname":"Latif M.A.","surname":"Latif","given-name":"Muhammad Ahsan","initials":"M.A.","afid": [{"@_fa": "true", "$" :"60078212"}]}],"authkeywords":"3D images | Clifford algebra | computer vision | geometric algebra | image processing | precision agriculture | quaternions | remote sensing | unmanned aerial vehicles","article-number":"9296775","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85107182906"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85107182906?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85107182906&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85107182906&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85107182906","dc:identifier":"SCOPUS_ID:85107182906","eid":"2-s2.0-85107182906","dc:title":"Video source identification algorithm based on 3D geometric transformation","dc:creator":"Li J.","prism:publicationName":"Computer Systems Science and Engineering","prism:issn":"02676192","prism:volume":"35","prism:issueIdentifier":"6","prism:pageRange":"513-521","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.32604/CSSE.2020.35.513","dc:description":"Digital video has become one of the most preferred ways for people to share information. Considering people tend to release illegal information in anonymous way, the problem of video source identification attracts more and more attention as an important part of multimedia forensics. The Photo-Response Non-Uniformity (PRNU) based algorithm shows to be a promising solution for the problem of video source identification. However, it is necessary to make a geometric transformation for testing PRNU noise to align it with the reference noise, due to the effect of video stabilization. This paper analyzes the three-dimensional (3D) characteristics of camera jitters and studies how to estimate the parameters of 3D geometric transformation when aligning PRNU noises between reference and test. In the algorithm design, quaternion is used to transform PRNU noise image in 3D space, and 15 rotation axes of 3D space are estimated for experiments. 162 videos of 9 smart phones were tested. Most of the videos got a higher peak to correlation energy (PCE) value by using this algorithm, and showed better results when applied to videos with complex texture. The experiment part also records the geometric transformation parameters of the PRNU noise which need to map from image domain to video domain.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022659","afid":"60022659","affilname":"University of Connecticut","affiliation-city":"Storrs","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011592","afid":"60011592","affilname":"Qilu University of Technology","affiliation-city":"Jinan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56290438800","authid":"56290438800","authname":"Li J.","surname":"Li","given-name":"Jian","initials":"J.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57224197599","authid":"57224197599","authname":"Lv Y.","surname":"Lv","given-name":"Yang","initials":"Y.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57204589541","authid":"57204589541","authname":"Ma B.","surname":"Ma","given-name":"Bin","initials":"B.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/35932591300","authid":"35932591300","authname":"Yang M.","surname":"Yang","given-name":"Meihong","initials":"M.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55318994100","authid":"55318994100","authname":"Wang C.","surname":"Wang","given-name":"Chunpeng","initials":"C.","afid": [{"@_fa": "true", "$" :"60011592"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57224187035","authid":"57224187035","authname":"Zheng Y.","surname":"Zheng","given-name":"Yang","initials":"Y.","afid": [{"@_fa": "true", "$" :"60022659"}]}],"authkeywords":"Photo-Response Non-Uniformity (PRNU) noise | Video forensics | video source identification | video stabilization","source-id":"12324","fund-acr":"NSFC","fund-no":"2019GXRC031","fund-sponsor":"Department of Science and Technology of Shandong Province","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherhybridgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Hybrid Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85106451225"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85106451225?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85106451225&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85106451225&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85106451225","dc:identifier":"SCOPUS_ID:85106451225","eid":"2-s2.0-85106451225","dc:title":"Ground roll attenuation through quaternionic inversion with sparsity constraints","dc:creator":"Bahia B.","prism:publicationName":"SEG Technical Program Expanded Abstracts","prism:issn":"10523812","prism:eIssn":"19494645","prism:volume":"2020-October","prism:pageRange":"3254-3258","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1190/segam2020-3405908.1","dc:description":"Surface waves, such as ground roll, are a major source of coherent noise in land seismic data, and its attenuation is still a challenge during processing. Even with the most simplifying assumption of a homogenous half-space, one can show that ground roll displacements in x and z components of a vectorvalued dataset are related. This paper discusses how these displacements can be integrated into a quaternion array in the frequency-space domain and aim at exploiting the mutual information between these signals. One can use the quaternion array to model surface waves using a least-squares inversion methodology with sparsity constraints and then follow with a subtraction strategy to attenuate the surface waves from the multicomponent data. The quaternionic approach, when contrasted with its scalar/componentwise counterpart, could provide better ground roll attenuation as presented with a test using a 2C-2D field data from Alberta, Canada.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030835","afid":"60030835","affilname":"University of Alberta","affiliation-city":"Edmonton","affiliation-country":"Canada"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205750370","authid":"57205750370","authname":"Bahia B.","surname":"Bahia","given-name":"Breno","initials":"B.","afid": [{"@_fa": "true", "$" :"60030835"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57337586200","authid":"57337586200","authname":"Papathanasaki I.","surname":"Papathanasaki","given-name":"Illiana","initials":"I.","afid": [{"@_fa": "true", "$" :"60030835"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57203080832","authid":"57203080832","authname":"Sacchi M.D.","surname":"Sacchi","given-name":"Mauricio D.","initials":"M.D.","afid": [{"@_fa": "true", "$" :"60030835"}]}],"authkeywords":"Noise | Sparse | Surface wave","article-number":"2851","source-id":"5100152902","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105868095"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105868095?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105868095&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105868095&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85105868095","dc:identifier":"SCOPUS_ID:85105868095","eid":"2-s2.0-85105868095","dc:title":"Widely linear quaternion-valued least-mean kurtosis algorithm","dc:creator":"Mengüç E.C.","prism:publicationName":"IEEE Transactions on Signal Processing","prism:issn":"1053587X","prism:eIssn":"19410476","prism:volume":"68","prism:pageRange":"5914-5922","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/TSP.2020.3029959","dc:description":"A widely linear quaternion-valued least-mean kurtosis (WL-QLMK) algorithm is introduced for adaptive filtering of quaternion-valued circular and noncircular signals. In the design, kurtosis-based cost function is first defined in the quaternion domain by integrating the widely linearmodel, and augmented statistics, and then minimized using the recently developed generalized Hamilton-real (GHR) calculus. In this way, the novel WL-QLMK algorithm is obtained for training quaternion-valued adaptive filter structures. Furthermore, its steady-state performance is theoretically analyzed to determine the bounds of the step size, which provides a theoretical justification for simulations. The simulation results over both benchmark system identification scenarios, and one-step-ahead predictions of real-world 4D pathological resting tremors show that the proposed WL-QLMK algorithm, by virtue of its newly defined cost function, significantly enhances the performance compared to the recently developed quaternion-valued algorithms, especially for noncircular signals.","citedby-count":"13","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60204070","afid":"60204070","affilname":"Milli Savunma Üniversitesi","affiliation-city":"Istanbul","affiliation-country":"Turkey"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015150","afid":"60015150","affilname":"Imperial College London","affiliation-city":"London","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004366","afid":"60004366","affilname":"Nigde Omer Halisdemir University","affiliation-city":"Niğde","affiliation-country":"Turkey"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/43261698200","authid":"43261698200","authname":"Mengüç E.C.","surname":"Mengüç","given-name":"Engin Cemal","initials":"E.C.","afid": [{"@_fa": "true", "$" :"60004366"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/9638783300","authid":"9638783300","authname":"Acir N.","surname":"Acir","given-name":"Nurettin","initials":"N.","afid": [{"@_fa": "true", "$" :"60204070"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7006513328","authid":"7006513328","authname":"Mandic D.P.","surname":"Mandic","given-name":"Danilo P.","initials":"D.P.","afid": [{"@_fa": "true", "$" :"60015150"}]}],"authkeywords":"Adaptive filters | Circular and noncircular quaternion signals | Least mean kurtosis | Strictly linear | Widely linear","article-number":"9220824","source-id":"17391","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105831988"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105831988?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105831988&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105831988&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85105831988","dc:identifier":"SCOPUS_ID:85105831988","eid":"2-s2.0-85105831988","dc:title":"Doppler frequency performance of KOMPSat-5 measured from worldwide uniform backscattering coefficient area","dc:creator":"Jeong H.R.","prism:publicationName":"40th Asian Conference on Remote Sensing, ACRS 2019: Progress of Remote Sensing Technology for Smart Future","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","dc:description":"The estimation accuracy of Doppler centroid frequency is important to process azimuth focusing and to provide well-focused SAR images. Basically Doppler frequency can be evaluated from roll/yaw/pitch or quaternion measured from attitude sensor, but additional Doppler shift due to mechanical mismatch between payload and bus and electrical mispointing from synthetic error of phased array antenna. Therefore, it is important to check estimation accuracy of Doppler centroid frequency by measuring it from uniform backscattering coefficient area. In the paper, the estimation accuracy of KOMPSAT-5 Doppler centroid frequency will be presented. To show it, image data acquired from three uniform area and one corner reflector was used. Finally, it will be presented that KOMPSAT-5 payload and bus attitude pointing is very good by exhibiting difference between two Doppler frequency measured from uniform area image and evaluated from attitude data was small.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60068719","afid":"60068719","affilname":"Korea Aerospace Research Institute","affiliation-city":"Daejeon","affiliation-country":"South Korea"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/9741936800","authid":"9741936800","authname":"Jeong H.R.","surname":"Jeong","given-name":"Ho Ryung","initials":"H.R.","afid": [{"@_fa": "true", "$" :"60068719"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57198637189","authid":"57198637189","authname":"Kim D.H.","surname":"Kim","given-name":"Dong Hyun","initials":"D.H.","afid": [{"@_fa": "true", "$" :"60068719"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56732166400","authid":"56732166400","authname":"Yang D.C.","surname":"Yang","given-name":"Do Chul","initials":"D.C.","afid": [{"@_fa": "true", "$" :"60068719"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57207418668","authid":"57207418668","authname":"Lee D.H.","surname":"Lee","given-name":"Dong Han","initials":"D.H.","afid": [{"@_fa": "true", "$" :"60068719"}]}],"authkeywords":"Antenna | Calibration | Doppler | Frequency | SAR","source-id":"21101045287","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104093992"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104093992?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85104093992&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85104093992&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85104093992","dc:identifier":"SCOPUS_ID:85104093992","eid":"2-s2.0-85104093992","dc:title":"The two-sided gabor quaternionic fourier transform and uncertainty principles","dc:creator":"El Kassimi M.","prism:publicationName":"Applied and Numerical Harmonic Analysis","prism:issn":"22965009","prism:eIssn":"22965017","prism:pageRange":"3-19","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1007/978-3-030-35202-8_1","dc:description":"In this paper, we define a new transform called the Gabor quaternionic Fourier transform (GQFT), which generalizes the classical windowed Fourier transform to quaternion-valued signals, and we give several important properties such as the Plancherel formula and inversion formula. Finally, we establish the Heisenberg uncertainty principles for the GQFT.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019715","afid":"60019715","affilname":"Faculté des Sciences de Meknès","affiliation-city":"Meknes","affiliation-country":"Morocco"}],"prism:aggregationType":"Book Series","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57189763208","authid":"57189763208","authname":"El Kassimi M.","surname":"El Kassimi","given-name":"Mohammed","initials":"M.","afid": [{"@_fa": "true", "$" :"60019715"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/26635064100","authid":"26635064100","authname":"Fahlaoui S.","surname":"Fahlaoui","given-name":"Saïd","initials":"S.","afid": [{"@_fa": "true", "$" :"60019715"}]}],"authkeywords":"Gabor transform | Heisenberg uncertainty | Logarithmic uncertainty | Quaternion algebra | Quaternionic transform","source-id":"21100860901","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102783288"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102783288?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85102783288&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85102783288&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85102783288","dc:identifier":"SCOPUS_ID:85102783288","eid":"2-s2.0-85102783288","dc:title":"Construction of signal sets from quotient rings of the quaternion orders associated with arithmetic fuchsian groups","dc:creator":"De Oliveira Quilles Queiroz C.R.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"8","prism:pageRange":"196050-196061","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.3034455","dc:description":"This paper aims to construct signal sets from quotient rings of the quaternion over a real number field associated with the arithmetic Fuchsian group 04g, where g is the genus of the associated surface. These Fuchsian groups consist of the edge-pairing isometries of the regular hyperbolic polygons (fundamental region) P4g, which tessellate the hyperbolic plane D2. The corresponding tessellations are the self-dual tessellations f4g; 4gg. Knowing the generators of the quaternion orders which realize the edge-pairings of the polygons, the signal points of the signal sets derived from the quotient rings of the quaternion orders are determined. It is shown by examples the relevance of adequately selecting the ideal in the maximal order to construct the signal sets satisfying the property of geometrical uniformity. The labeling of such signals is realized by using the mapping by set partitioning concept to solve the corresponding Diophantine equations (extreme quadratic forms). Trellis coded modulation and multilevel codes whose signal sets are derived from quotient rings of quaternion orders are considered possible applications.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029570","afid":"60029570","affilname":"Universidade Estadual de Campinas","affiliation-city":"Campinas","affiliation-country":"Brazil"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002101","afid":"60002101","affilname":"Universidade Federal de Alfenas","affiliation-city":"Alfenas","affiliation-country":"Brazil"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57222481646","authid":"57222481646","authname":"De Oliveira Quilles Queiroz C.R.","surname":"De Oliveira Quilles Queiroz","given-name":"Cátia Regina","initials":"C.R.","afid": [{"@_fa": "true", "$" :"60002101"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7007159678","authid":"7007159678","authname":"Palazzo R.","surname":"Palazzo","given-name":"Reginaldo","initials":"R.","afid": [{"@_fa": "true", "$" :"60029570"}]}],"authkeywords":"Arithmetic Fuchsian group | Diophantine equation | Hyperbolic tessellations | Quaternion orders | Signal sets | Signal space codes","source-id":"21100374601","fund-acr":"FAPESP","fund-no":"23087.016009/2020-87","fund-sponsor":"Fundação de Amparo à Pesquisa do Estado de São Paulo","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102486343"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102486343?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85102486343&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85102486343&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85102486343","dc:identifier":"SCOPUS_ID:85102486343","eid":"2-s2.0-85102486343","dc:title":"Image colour edge detection using hypercomplex convolution","dc:creator":"Zaghloul R.I.","prism:publicationName":"International Journal of Signal and Imaging Systems Engineering","prism:issn":"17480698","prism:eIssn":"17480701","prism:volume":"12","prism:issueIdentifier":"1-2","prism:pageRange":"54-61","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1504/IJSISE.2020.113569","dc:description":"Quaternions are considered for colour image edge detection. Most work on quaternions is based on a linear quaternion system (LQS) which applies multi-directional kernels (horizontal, vertical, and diagonal) using hypercomplex convolution, each kernel producing an edge map for a specific direction, and the final result is a combination of these maps. This paper introduces a new colour image edge detection filter based on LQS convolution. The process starts by applying quaternion convolution with the proposed filter, and then generating the final edge map by computing the magnitude of the result. The proposed filter is able to highlight both colour and greyscale edges in multiple directions using a single LQS convolution pass. The validity of the proposed filter is demonstrated, and its performance is supported experimentally through a set of comparisons with state-of-the-art methods.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064180","afid":"60064180","affilname":"The University of Jordan","affiliation-city":"Amman","affiliation-country":"Jordan"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60062395","afid":"60062395","affilname":"Al-Balqa Applied University","affiliation-city":"Al Salt","affiliation-country":"Jordan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/50662440600","authid":"50662440600","authname":"Zaghloul R.I.","surname":"Zaghloul","given-name":"Rawan I.","initials":"R.I.","afid": [{"@_fa": "true", "$" :"60062395"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/15848528400","authid":"15848528400","authname":"Hiary H.","surname":"Hiary","given-name":"Hazem","initials":"H.","afid": [{"@_fa": "true", "$" :"60064180"}]}],"authkeywords":"Colour image | Edge detection | Hypercomplex convolution | Linear quaternion system | LQS | Multi-directional kernels | Quaternions","source-id":"19500157222","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100924259"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100924259?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85100924259&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85100924259&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85100924259","dc:identifier":"SCOPUS_ID:85100924259","eid":"2-s2.0-85100924259","dc:title":"Cooperative localization of vehicles in three-dimensional space","dc:creator":"Oliveros J.C.","prism:publicationName":"ASME 2020 Dynamic Systems and Control Conference, DSCC 2020","prism:isbn": [{"@_fa": "true", "$" :"9780791884287"}],"prism:volume":"2","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1115/DSCC2020-3206","dc:description":"Effective trajectory planning and cooperative control of multi-agent systems require accurate localization of the agents to perform collaborative missions. Accurate localization may be achieved by Global Positioning System (GPS) and simultaneous localization and mapping. However, GPS signals and fixed features may not be readily available, particularly in remote and unstructured environments. Under these circumstances, Cooperative Localization (CL) has been proposed as a short-term solution that can significantly improve vehicle pose estimation. CL algorithms have been developed and tested mainly on mobile robots and planar vehicles due to complexities of three-dimensional (3D) motion. In this paper, we present a CL algorithm for multi-agent systems comprised of 3D vehicles. Each vehicle’s pose is represented by three position and three orientation variables. Quaternions are employed to represent orientation and avoid singularities associated with Euler angle. Vehicle kinematic velocity relations are used to model vehicle dynamics with respect to a fixed reference frame. It is assumed a vehicle can take relative pose measurements of other neighboring vehicles within an ad hoc network of agents. We then designate the observed as target vehicles and the observers as base vehicles and determine the linearized output matrix of the relative measurements for Extended Kalman Filter (EKF) application. Simulations are presented to discuss the advantages and shortcomings of the algorithm.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000009","afid":"60000009","affilname":"Villanova University","affiliation-city":"Villanova","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57222010122","authid":"57222010122","authname":"Oliveros J.C.","surname":"Oliveros","given-name":"Juan Carlos","initials":"J.C.","afid": [{"@_fa": "true", "$" :"60000009"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7004089764","authid":"7004089764","authname":"Ashrafiuon H.","surname":"Ashrafiuon","given-name":"Hashem","initials":"H.","afid": [{"@_fa": "true", "$" :"60000009"}]}],"source-id":"21101038549","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85098122685"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85098122685?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85098122685&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85098122685&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85098122685","dc:identifier":"SCOPUS_ID:85098122685","eid":"2-s2.0-85098122685","dc:title":"Quaternion Neural Networks for Multi-channel Distant Speech Recognition","dc:creator":"Qiu X.","prism:publicationName":"Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","prism:issn":"2308457X","prism:eIssn":"19909772","prism:volume":"2020-October","prism:pageRange":"329-333","prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.21437/Interspeech.2020-1682","dc:description":"Despite the significant progress in automatic speech recognition (ASR), distant ASR remains challenging due to noise and reverberation. A common approach to mitigate this issue consists of equipping the recording devices with multiple microphones that capture the acoustic scene from different perspectives. These multi-channel audio recordings contain specific internal relations between each signal. In this paper, we propose to capture these inter- and intra- structural dependencies with quaternion neural networks, which can jointly process multiple signals as whole quaternion entities. The quaternion algebra replaces the standard dot product with the Hamilton one, thus offering a simple and elegant way to model dependencies between elements. The quaternion layers are then coupled with a recurrent neural network, which can learn long-term dependencies in the time domain. We show that a quaternion long-short term memory neural network (QLSTM), trained on the concatenated multi-channel speech signals, outperforms equivalent real-valued LSTM on two different tasks of multi-channel distant speech recognition.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60113142","afid":"60113142","affilname":"Montreal Institute for Learning Algorithms","affiliation-city":"Montreal","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031214","afid":"60031214","affilname":"Université d'Avignon et des Pays du Vaucluse","affiliation-city":"Avignon","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60026851","afid":"60026851","affilname":"University of Oxford","affiliation-city":"Oxford","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/124434384","afid":"124434384","affilname":"Samsung AI Center","affiliation-city":"Cambridge","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57219740531","authid":"57219740531","authname":"Qiu X.","surname":"Qiu","given-name":"Xinchi","initials":"X.","afid": [{"@_fa": "true", "$" :"60026851"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57193704479","authid":"57193704479","authname":"Parcollet T.","surname":"Parcollet","given-name":"Titouan","initials":"T.","afid": [{"@_fa": "true", "$" :"60026851"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/24722956800","authid":"24722956800","authname":"Ravanelli M.","surname":"Ravanelli","given-name":"Mirco","initials":"M.","afid": [{"@_fa": "true", "$" :"60113142"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/23135333200","authid":"23135333200","authname":"Lane N.","surname":"Lane","given-name":"Nicholas","initials":"N.","afid": [{"@_fa": "true", "$" :"60026851"},{"@_fa": "true", "$" :"124434384"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55697911300","authid":"55697911300","authname":"Morchid M.","surname":"Morchid","given-name":"Mohamed","initials":"M.","afid": [{"@_fa": "true", "$" :"60031214"}]}],"authkeywords":"Distant speech recognition | Multi-microphone speech recognition | Quaternion neural networks","source-id":"21100212301","fund-acr":"ANR","fund-no":"EP/S001530/","fund-sponsor":"Agence Nationale de la Recherche","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097932099"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097932099?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097932099&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097932099&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097932099","dc:identifier":"SCOPUS_ID:85097932099","eid":"2-s2.0-85097932099","dc:title":"Robust Hashing Based on Quaternion Gyrator Transform for Image Authentication","dc:creator":"Ouyang J.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1109/ACCESS.2020.3043111","dc:description":"Image hashing is one of the most effective methods in many image processing applications including image recognition or authentication, tampering detection, image retrieval, etc. In this paper, we propose a novel image hash method based on quaternion gyrator transform, which is more secure and compact in addition to its robustness and discriminative properties. In this proposed method, the quaternion gyrator transform (QGT), like the traditional quaternion Fourier transform which is a linear regular integral ratio transform is applied to effectively extract image features. Firstly, our hash function needs to scale all pictures to a fixed size. And the quaternion gyrator transform is used to transform each non-overlapping block in the original image for extracting the feature map of the source image. For each block, the inner product of the feature and a random weight is used to be one bit of the final image hash. Experiments with different image databases are conducted to test and verify the efficiency of our method. The result has proved that our method of constructing hash is robust to most of the content-preserving operations with a good distinction. Compared with some state-of-the-art hash algorithms, our algorithm is more excellent and has better performance in robustness and distinguishability.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024617","afid":"60024617","affilname":"Hunan University of Science and Technology","affiliation-city":"Xiangtan","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55446539500","authid":"55446539500","authname":"Ouyang J.","surname":"Ouyang","given-name":"Junlin","initials":"J.","afid": [{"@_fa": "true", "$" :"60024617"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57220962797","authid":"57220962797","authname":"Zhang X.","surname":"Zhang","given-name":"Xiao","initials":"X.","afid": [{"@_fa": "true", "$" :"60024617"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55445953300","authid":"55445953300","authname":"Wen X.","surname":"Wen","given-name":"Xingzi","initials":"X.","afid": [{"@_fa": "true", "$" :"60024617"}]}],"authkeywords":"Image Authentication | Image Feature | Quaternion Gyrator Transform | Robust Hashing","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097392118"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097392118?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097392118&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097392118&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097392118","dc:identifier":"SCOPUS_ID:85097392118","eid":"2-s2.0-85097392118","dc:title":"21th International Conference on Intelligent Data Engineering and Automated Learning, IDEAL 2020","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030623616"}],"prism:volume":"12489 LNCS","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","dc:description":"The proceedings contain 34 papers. The special focus in this conference is on Intelligent Data Engineering and Automated Learning. The topics include: Network Analysis for Fraud Detection in Portuguese Public Procurement; biased Language Detection in Court Decisions; a One-by-One Method for Community Detection in Attributed Networks; data Pre-processing and Data Generation in the Student Flow Case Study; a Hybrid Approach to the Analysis of a Collection of Research Papers; Sequential Self-tuning Clustering for Automatic Delimitation of Coastal Upwelling on SST Images; time Series Clustering for Knowledge Discovery on Metal Additive Manufacturing; quaternion Neural Networks: State-of-the-Art and Research Challenges; a Solar Thermal System Temperature Prediction of a Smart Building for Data Recovery and Security Purposes; a Fault Detection System for Power Cells During Capacity Confirmation Test Through a Global One-Class Classifier; a Deep Metric Neural Network with Disentangled Representation for Detecting Smartphone Glass Defects; improving Performance of Recommendation System Architecture; automated Learning of In-vehicle Noise Representation with Triplet-Loss Embedded Convolutional Beamforming Network; Sequence Mining for Automatic Generation of Software Tests from GUI Event Traces; enhanced Credit Prediction Using Artificial Data; deep Learning Based Algorithms for Welding Edge Points Detection; detecting Performance Anomalies in the Multi-component Software a Collaborative Robot; prediction of Small-Wind Turbine Performance from Time Series Modelling Using Intelligent Techniques; review of Trends in Automatic Human Activity Recognition Using Synthetic Audio-Visual Data; atmospheric Tomography Using Convolutional Neural Networks; workshop on Machine Learning in Smart Mobility; Driver Monitoring System Based on CNN Models: An Approach for Attention Level Detection; preface.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097304262"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097304262?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097304262&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097304262&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097304262","dc:identifier":"SCOPUS_ID:85097304262","eid":"2-s2.0-85097304262","dc:title":"Research on polarized light detection of oil spill based on quaternion","dc:creator":"Li D.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510639553"}],"prism:volume":"11567","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1117/12.2575806","dc:description":"In order to better characterize the polarization characteristics of reflected light in oil spill monitoring by remote sensing on the sea surface and improve the accuracy of oil spill detection, the quaternion method is introduced into the oil spill detection system, and a kind of oil spill monitoring technology based on quaternion is proposed in this paper. Firstly, the quaternion matrix method for calculating the sea surface reflection polarization information is proposed, and the relationship between the characteristic parameters of quaternion and the refractive index of oil film is discussed. Then four kinds of oils crude oil, soybean oil, lubricating oil and diesel oil are used as the experimental samples for oily pollution on water surface, and the characteristic quaternion parameters, s and p components of different samples are obtained through the reflection images at different polarization directions, so the identification of different oil products is realized. The experimental results show that the quaternion polarization characteristics can be used as an important parameter for oil identification.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105111","afid":"60105111","affilname":"China University of Petroleum (East China)","affiliation-city":"Qingdao","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7405326329","authid":"7405326329","authname":"Li D.","surname":"Li","given-name":"Dailin","initials":"D.","afid": [{"@_fa": "true", "$" :"60105111"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57220203225","authid":"57220203225","authname":"Yu X.","surname":"Yu","given-name":"Xinfeng","initials":"X.","afid": [{"@_fa": "true", "$" :"60105111"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57203129125","authid":"57203129125","authname":"Li G.","surname":"Li","given-name":"Guilei","initials":"G.","afid": [{"@_fa": "true", "$" :"60105111"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57220209202","authid":"57220209202","authname":"Xu Y.","surname":"Xu","given-name":"Yanjun","initials":"Y.","afid": [{"@_fa": "true", "$" :"60105111"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55888324500","authid":"55888324500","authname":"Wang N.","surname":"Wang","given-name":"Ning","initials":"N.","afid": [{"@_fa": "true", "$" :"60105111"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/36457635400","authid":"36457635400","authname":"Ni H.","surname":"Ni","given-name":"Hao","initials":"H.","afid": [{"@_fa": "true", "$" :"60105111"}]}],"authkeywords":"Fresnel formula | Oil spill | Polarized light detection | Quaternion","article-number":"115670T","source-id":"40067","fund-acr":"NSFC","fund-no":"GG201809250065","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097293733"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097293733?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097293733&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097293733&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097293733","dc:identifier":"SCOPUS_ID:85097293733","eid":"2-s2.0-85097293733","dc:title":"Research on Ambiguity Resolution Algorithm by Quaternion Based on Acoustic Vector Sensor","dc:creator":"Wang G.","prism:publicationName":"Journal of Sensors","prism:issn":"1687725X","prism:eIssn":"16877268","prism:volume":"2020","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1155/2020/2402489","dc:description":"The increase in element spacing can increase the aperture of the array and improve its resolution performance. However, phase ambiguity will occur when the array element interval is larger than the minimum half wavelength of the incident signal. The three acoustic velocity components of the acoustic vector are ingeniously constructed into a new kind of quaternions because of the special structure of the acoustic vector sensor array, and the rough estimation of the direction of arrival (DOA) is obtained using the rotation relationship between the subarray steering vectors corresponding to quaternion data. The rough estimate is used to resolve the phase ambiguity of the spatial phase difference between the array elements, and the high-precision DOA estimation of the signal can be obtained. Simulation results show that the method is effective.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60089942","afid":"60089942","affilname":"Shaanxi University of Technology","affiliation-city":"Hanzhong","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025578","afid":"60025578","affilname":"Xidian University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55827761200","authid":"55827761200","orcid":"0000-0002-6860-4594","authname":"Wang G.","surname":"Wang","given-name":"Guibao","initials":"G.","afid": [{"@_fa": "true", "$" :"60089942"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57221484281","authid":"57221484281","orcid":"0000-0003-2680-0279","authname":"Wang X.","surname":"Wang","given-name":"Xinkuan","initials":"X.","afid": [{"@_fa": "true", "$" :"60089942"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/10042713200","authid":"10042713200","orcid":"0000-0003-3095-6655","authname":"Wang L.","surname":"Wang","given-name":"Lanmei","initials":"L.","afid": [{"@_fa": "true", "$" :"60025578"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57828984300","authid":"57828984300","orcid":"0000-0002-4966-7733","authname":"Wang X.","surname":"Wang","given-name":"Xiangyu","initials":"X.","afid": [{"@_fa": "true", "$" :"60089942"}]}],"article-number":"2402489","source-id":"17700156304","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097260348"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097260348?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097260348&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097260348&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097260348","dc:identifier":"SCOPUS_ID:85097260348","eid":"2-s2.0-85097260348","dc:title":"UAV target saliency detection based on frequency domain transform","dc:creator":"Wang X.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510639553"}],"prism:volume":"11567","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","prism:doi":"10.1117/12.2576594","dc:description":"In order to solve the difficult problem of unmanned air vehicle(UAV) target detection in visible light images under complex sky background, this paper proposes a UAV target detection method based on frequency domain transform. First, the B-channel in the image LAB space is used to extract the sky and cloud boundary images, and then the image feature channel is used to construct a quaternion function. Secondly, Fourier transform is performed on the quaternion function to extract the amplitude spectrum and phase spectrum, then the amplitude spectrum image is subjected to multi-scale decomposition using wavelet transform in the frequency domain, the amplitude spectrum image of each scale and the phase spectrum image are combined by inverse Fourier transform, and the evaluation function is used to obtain the best scale image. Finally, the best-scale image and the boundary image are normalized to make a difference to obtain the final detection result. Experimental results show that the algorithm can effectively detect UAV targets under complex cloud background.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023277","afid":"60023277","affilname":"Xi'an Institute of Optics and Precision Mechanics Chinese Academy of Sciences","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57220207005","authid":"57220207005","authname":"Wang X.","surname":"Wang","given-name":"Xin","initials":"X.","afid": [{"@_fa": "true", "$" :"60023277"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57191700134","authid":"57191700134","authname":"Li Z.","surname":"Li","given-name":"Zhe","initials":"Z.","afid": [{"@_fa": "true", "$" :"60023277"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57198238976","authid":"57198238976","authname":"Tian Y.","surname":"Tian","given-name":"Yan","initials":"Y.","afid": [{"@_fa": "true", "$" :"60023277"}]}],"authkeywords":"frequency domain | saliency detection | UAV | wavelet transform","article-number":"1156718","source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097179626"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097179626?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097179626&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097179626&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097179626","dc:identifier":"SCOPUS_ID:85097179626","eid":"2-s2.0-85097179626","dc:title":"21th International Conference on Intelligent Data Engineering and Automated Learning, IDEAL 2020","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030623647"}],"prism:volume":"12490 LNCS","prism:pageRange":null,"prism:coverDate":"2020-01-01","prism:coverDisplayDate":"2020","dc:description":"The proceedings contain 34 papers. The special focus in this conference is on Intelligent Data Engineering and Automated Learning. The topics include: Network Analysis for Fraud Detection in Portuguese Public Procurement; biased Language Detection in Court Decisions; a One-by-One Method for Community Detection in Attributed Networks; data Pre-processing and Data Generation in the Student Flow Case Study; a Hybrid Approach to the Analysis of a Collection of Research Papers; Sequential Self-tuning Clustering for Automatic Delimitation of Coastal Upwelling on SST Images; time Series Clustering for Knowledge Discovery on Metal Additive Manufacturing; quaternion Neural Networks: State-of-the-Art and Research Challenges; a Solar Thermal System Temperature Prediction of a Smart Building for Data Recovery and Security Purposes; a Fault Detection System for Power Cells During Capacity Confirmation Test Through a Global One-Class Classifier; a Deep Metric Neural Network with Disentangled Representation for Detecting Smartphone Glass Defects; improving Performance of Recommendation System Architecture; automated Learning of In-vehicle Noise Representation with Triplet-Loss Embedded Convolutional Beamforming Network; Sequence Mining for Automatic Generation of Software Tests from GUI Event Traces; enhanced Credit Prediction Using Artificial Data; deep Learning Based Algorithms for Welding Edge Points Detection; detecting Performance Anomalies in the Multi-component Software a Collaborative Robot; prediction of Small-Wind Turbine Performance from Time Series Modelling Using Intelligent Techniques; review of Trends in Automatic Human Activity Recognition Using Synthetic Audio-Visual Data; atmospheric Tomography Using Convolutional Neural Networks; workshop on Machine Learning in Smart Mobility; Driver Monitoring System Based on CNN Models: An Approach for Attention Level Detection; preface.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}