{"search-results":{"opensearch:totalResults":"212","opensearch:startIndex":"175","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "175"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=175&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2018&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2018&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=150&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2018&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=200&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2018&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=187&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2018&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85055586427"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85055586427?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85055586427&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85055586427&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85055586427","dc:identifier":"SCOPUS_ID:85055586427","eid":"2-s2.0-85055586427","dc:title":"Suppression of impulse noise in colour images using quaternion transformation and vector median filtering","dc:creator":"Aminu R.","prism:publicationName":"International Journal of Engineering Research and Technology","prism:issn":"09743154","prism:volume":"11","prism:issueIdentifier":"7","prism:pageRange":"1085-1107","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"Images are often corrupted by impulse noise due to electronic interference, switching effects, faulty charge-coupled devices, poor acquisition or recording and channel environmental degradation. This leads to the discolouration of some pixels in the image and has an adverse effect on the performance of many image application systems. In this paper, a new switching method based on the effective Quaternion transformation of colour images and vector median filtering is proposed and employed in the suppression of impulse noise. The proposed switching method comprises of two stages; impulse noise detection and image restoration. In the first stage, a Quaternion unit transform is used in detecting the corrupted pixels. In the second stage, the corrupted pixels are restored using a vector median filtering process while the noise-free ones are kept unaffected. The simulation results demonstrate that the proposed method based on the Quaternion transform achieves an acceptable balance between the details preservation and noise suppression than the classical switching filtering methods.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60277821","afid":"60277821","affilname":"The Pan African University Institute for Basic Sciences, technology and Innovation (PAUSTI)","affiliation-city":"Nairobi","affiliation-country":"Kenya"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60052242","afid":"60052242","affilname":"Jomo Kenyatta University of Agriculture and Technology","affiliation-city":"Nairobi","affiliation-country":"Kenya"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60048717","afid":"60048717","affilname":"University of Nairobi","affiliation-city":"Nairobi","affiliation-country":"Kenya"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57204425648","authid":"57204425648","authname":"Aminu R.","surname":"Aminu","given-name":"Rabiu","initials":"R.","afid": [{"@_fa": "true", "$" :"60277821"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6701891993","authid":"6701891993","authname":"Mwangi E.","surname":"Mwangi","given-name":"Elijah","initials":"E.","afid": [{"@_fa": "true", "$" :"60048717"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57204434964","authid":"57204434964","authname":"Ndungu E.","surname":"Ndungu","given-name":"Edward","initials":"E.","afid": [{"@_fa": "true", "$" :"60052242"}]}],"authkeywords":"Colour pixel difference | Image restoration | Impulse noise | Noise detection | Quaternion transform","source-id":"21100828027","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85055416446"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85055416446?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85055416446&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85055416446&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85055416446","dc:identifier":"SCOPUS_ID:85055416446","eid":"2-s2.0-85055416446","dc:title":"Quaternion convolutional neural networks","dc:creator":"Zhu X.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030012366"}],"prism:volume":"11212 LNCS","prism:pageRange":"645-661","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1007/978-3-030-01237-3_39","dc:description":"Neural networks in the real domain have been studied for a long time and achieved promising results in many vision tasks for recent years. However, the extensions of the neural network models in other number fields and their potential applications are not fully-investigated yet. Focusing on color images, which can be naturally represented as quaternion matrices, we propose a quaternion convolutional neural network (QCNN) model to obtain more representative features. In particular, we re-design the basic modules like convolution layer and fully-connected layer in the quaternion domain, which can be used to establish fully-quaternion convolutional neural networks. Moreover, these modules are compatible with almost all deep learning techniques and can be plugged into traditional CNNs easily. We test our QCNN models in both color image classification and denoising tasks. Experimental results show that they outperform the real-valued CNNs with same structures.","citedby-count":"28","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025084","afid":"60025084","affilname":"Shanghai Jiao Tong University","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008724","afid":"60008724","affilname":"Duke University","affiliation-city":"Durham","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/121413887","afid":"121413887","affilname":"Infinia ML","affiliation-city":"Durham","affiliation-country":"United States"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57204390155","authid":"57204390155","authname":"Zhu X.","surname":"Zhu","given-name":"Xuanyu","initials":"X.","afid": [{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55695017800","authid":"55695017800","authname":"Xu Y.","surname":"Xu","given-name":"Yi","initials":"Y.","afid": [{"@_fa": "true", "$" :"60025084"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/54788433800","authid":"54788433800","authname":"Xu H.","surname":"Xu","given-name":"Hongteng","initials":"H.","afid": [{"@_fa": "true", "$" :"121413887"},{"@_fa": "true", "$" :"60008724"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55754097300","authid":"55754097300","authname":"Chen C.","surname":"Chen","given-name":"Changjian","initials":"C.","afid": [{"@_fa": "true", "$" :"60025084"}]}],"authkeywords":"Color image classification | Color image denoising | Quaternion convolutional neural network | Quaternion-based layers","source-id":"25674","fund-acr":"NSFC","fund-no":"61502301","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054618249"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054618249?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054618249&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85054618249&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85054618249","dc:identifier":"SCOPUS_ID:85054618249","eid":"2-s2.0-85054618249","dc:title":"Relative State and Inertia Estimation of Unknown Tumbling Spacecraft by Stereo Vision","dc:creator":"Feng Q.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"6","prism:pageRange":"54126-54138","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1109/ACCESS.2018.2872039","dc:description":"A novel algorithm is proposed to estimate the relative state, including position, attitude, linear velocity, angular velocity, and inertia parameters of an unknown tumbling spacecraft, by stereo vision. Feature points of the target are selected in situ, and their positions and velocities are estimated by the measurements of perspective projection and optical flow. Then, the relative attitude and angular velocity of the spacecraft are estimated by a unit quaternion method and least square method, respectively. After that, the relative position and translational velocity of the spacecraft, together with the relative positions of the detected feature points, are estimated simultaneously based on the relative translational motion model of the target by successive images. Finally, inertia parameters of the spacecraft are estimated by a quadratic optimization method based on angular momentum conservation subject to physical constraints. The performance of the newly proposed algorithm is verified by comparing with an existing case in the literature. Moreover, the performance is validated by Monte-Carlo simulations in different cases.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60033420","afid":"60033420","affilname":"York University","affiliation-city":"Toronto","affiliation-country":"Canada"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003977","afid":"60003977","affilname":"Northwestern Polytechnical University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56949725500","authid":"56949725500","authname":"Feng Q.","surname":"Feng","given-name":"Qian","initials":"Q.","afid": [{"@_fa": "true", "$" :"60003977"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/34871188900","authid":"34871188900","orcid":"0000-0002-0149-0473","authname":"Zhu Z.H.","surname":"Zhu","given-name":"Zheng H.","initials":"Z.H.","afid": [{"@_fa": "true", "$" :"60033420"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7202997700","authid":"7202997700","authname":"Pan Q.","surname":"Pan","given-name":"Quan","initials":"Q.","afid": [{"@_fa": "true", "$" :"60003977"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/35146170600","authid":"35146170600","authname":"Hou X.","surname":"Hou","given-name":"Xiaolei","initials":"X.","afid": [{"@_fa": "true", "$" :"60003977"}]}],"authkeywords":"inertia parameters | relative state estimation | stereo vision | Unknown tumbling spacecraft","article-number":"8471167","source-id":"21100374601","fund-acr":"NSERC","fund-no":"61503304","fund-sponsor":"Natural Sciences and Engineering Research Council of Canada","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054617765"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054617765?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054617765&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85054617765&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85054617765","dc:identifier":"SCOPUS_ID:85054617765","eid":"2-s2.0-85054617765","dc:title":"Fractional quaternion zernike moments for robust color image copy-move forgery detection","dc:creator":"Chen B.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"6","prism:pageRange":"56637-56646","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1109/ACCESS.2018.2871952","dc:description":"In this paper, fractional Zernike moments (FrZMs) for complex signals are generalized to fractional quaternion Zernike moments (FrQZMs) for quaternion signal processing in a holistic manner by the quaternion algebra. We first present the definition of FrQZMs and an efficient implementation algorithm for speeding up the computation of FrQZMs through FrZMs of each component of the quaternion signal. The performance of the proposed FrQZMs is evaluated by considering robust color image copy-move forgery detection. The proposed robust copy-move forgery-detection algorithm considers the FrQZMs as a feature and a modified PatchMatch algorithm as a feature matching algorithm. Experimental results on two publicly available data sets (FAU and GRIP data set) have demonstrated that the proposed FrQZM-based algorithm can achieve an overall better performance than the state-of-the-art algorithms, especially in some additional operation cases.","citedby-count":"79","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073726","afid":"60073726","affilname":"Ludong University","affiliation-city":"Yantai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022904","afid":"60022904","affilname":"New Jersey Institute of Technology","affiliation-city":"Newark","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36805188500","authid":"36805188500","orcid":"0000-0002-2506-0427","authname":"Chen B.","surname":"Chen","given-name":"Beijing","initials":"B.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55286480600","authid":"55286480600","authname":"Yu M.","surname":"Yu","given-name":"Ming","initials":"M.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/26633246300","authid":"26633246300","authname":"Su Q.","surname":"Su","given-name":"Qingtang","initials":"Q.","afid": [{"@_fa": "true", "$" :"60073726"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/8560446300","authid":"8560446300","authname":"Shim H.J.","surname":"Shim","given-name":"Hiuk Jae","initials":"H.J.","afid": [{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7404964736","authid":"7404964736","authname":"Shi Y.Q.","surname":"Shi","given-name":"Yun Qing","initials":"Y.Q.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60022904"}]}],"authkeywords":"color image | fractional Zernike moments | image forgery detection | Quaternion","article-number":"8471093","source-id":"21100374601","fund-acr":"NSFC","fund-no":"61572258","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054051368"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85054051368?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85054051368&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85054051368&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85054051368","dc:identifier":"SCOPUS_ID:85054051368","eid":"2-s2.0-85054051368","dc:title":"International Conference on Computer Vision and Graphics, ICCVG 2018","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030006914"}],"prism:volume":"11114 LNCS","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"The proceedings contain 45 papers. The special focus in this conference is on Computer Vision and Graphics. The topics include: A System for Automatic Town Sign Recognition for Driver Assistance Systems; selective and Simple Graph Structures for Better Description of Local Point-Based Image Features; Scene Recognition for Indoor Localization of Mobile Robots Using Deep CNN; character Recognition Based on Skeleton Analysis; weather Characterization from Outdoor Scene Images; clustering Quality Measures for Point Cloud Segmentation Tasks; multi-camera Photometric Simulation for Creation of 3D Object Reconstruction System; Quality Evaluation of 3D Printed Surfaces Based on HOG Features; convolutional Neural Network-Based Action Recognition on Depth Maps; gaze-Dependent Screen Space Ambient Occlusion; an Integrated Procedure for Calibrating and Distortion Correction of the Structure Sensor and Stereo-Vision Depth Sensors; second-Order Algebraic Surfaces and Two Image Photometric Stereo; Improving RGB Descriptors Using Depth Cues; embedding Spatial Context into Spectral Angle Based Nonlinear Mapping for Hyperspectral Image Analysis; color Object Retrieval Using Local Features Based on Opponent-Process Theory; extracting Textual Overlays from Social Media Videos Using Neural Networks; Choosing an Optimal Bracketing Sequence for HDR Imaging; detection of Pollen Grains in Digital Microscopy Images by Means of Modified Histogram Thresholding; U-CatcHCC: An Accurate HCC Detector in Hepatic DCE-MRI Sequences Based on an U-Net Framework; unsupervised Caries Detection in Non-standardized Periapical Dental X-Rays; a Fast Algorithm for Quaternion-Based 4D Rotation; localizing Characteristic Points on a Vertebra Contour by Using Shape Language; lytic Region Recognition in Hip Radiograms by Means of Statistical Dominance Transform; ulam Spiral and Prime-Rich Polynomials.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052900904"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052900904?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85052900904&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85052900904&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85052900904","dc:identifier":"SCOPUS_ID:85052900904","eid":"2-s2.0-85052900904","dc:title":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:volume":"Part F138652","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"The proceedings contain 29 papers. The topics discussed include: color visibility images and measures of image enhancement; an estimation method of human impression factors for objects from their 3D shapes using a deep neural network; sharpening image details using local phase congruency analysis; automatic banknote stain detection; robust linearized combined metrics of image visual quality; blind image watermarking in wavelet-domain robust to printing and smart-phone acquisition; 1-bit tensor completion; learning adaptive parameter tuning for image processing; methods and tools for denoising of complex-valued images based on block-matching and high order singular value decomposition; deep P-Fibonacci scattering networks; separation of scanned media using a strip based methodology; blind estimation of white Gaussian noise variance in highly textured images; disparity estimation using fast motion-search algorithm and local image characteristics; combined local and global image enhancement algorithm; a similarity measurement method for diffuse lung disease CT slice image retrieval; compression of signs of DCT coefficients for additional lossless compression of JPEG images; rule-based optical character recognition for serial number on Renminbi banknote; color facial image representation with new quaternion gradients; and real-time 3DRS motion estimation for frame-rate conversion.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"21100846961","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052643190"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052643190?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85052643190&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85052643190&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85052643190","dc:identifier":"SCOPUS_ID:85052643190","eid":"2-s2.0-85052643190","dc:title":"Multispectral salient object detection based on frequency domain","dc:creator":"Jiani G.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:eIssn":"1996756X","prism:isbn": [{"@_fa": "true", "$" :"9781510621992"}],"prism:volume":"10806","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1117/12.2503218","dc:description":"In this paper, a multispectral salient object detection algorithm based on frequency domain is proposed, which has the advantages of high efficiency and simplicity. In this paper, the principle of the saliency detection in frequency domain is first studied, and the advantages of it in the detection of abnormal target are demonstrated. Then, using quaternion transform to extract spectral features in two spectral intervals. We extract salient information in frequency domain by quaternion fourier transform, the saliency map of two spectral interval method using PCA fusion. The adaptive threshold is used to segment image for highlighting salient objects. Finally, we collect multispectral images from the spectral system built by AOTF and near-infrared camera, and test the original and noisy images. The results show that the algorithm is efficient and robust.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010080","afid":"60010080","affilname":"Nanjing University of Science and Technology","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57203686908","authid":"57203686908","authname":"Jiani G.","surname":"Jiani","given-name":"Gao","initials":"G.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57203679388","authid":"57203679388","authname":"Jing H.","surname":"Jing","given-name":"Han","initials":"H.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7201957199","authid":"7201957199","authname":"Lianfa B.","surname":"Lianfa","given-name":"Bai","initials":"B.","afid": [{"@_fa": "true", "$" :"60010080"}]}],"authkeywords":"Saliency detection，quaternion，frequency domain，PCA fusion","article-number":"108061G","source-id":"40067","fund-acr":"NSFC","fund-no":"61501235","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052538636"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052538636?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85052538636&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85052538636&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85052538636","dc:identifier":"SCOPUS_ID:85052538636","eid":"2-s2.0-85052538636","dc:title":"COMPLEXIS 2018 - Proceedings of the 3rd International Conference on Complexity, Future Information Systems and Risk","prism:publicationName":"COMPLEXIS 2018 - Proceedings of the 3rd International Conference on Complexity, Future Information Systems and Risk","prism:isbn": [{"@_fa": "true", "$" :"9789897582974"}],"prism:volume":"2018-March","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"The proceedings contain 19 papers. The topics discussed include: communicability in networked systems - implications for stability, spatial efficiency and dynamical process; why so emotional? an analysis of emotional Bot-generated Content on Twitter; PaaS-BDP a multi-cloud architectural pattern for big data processing on a platform-as-a-service model; a new pricing model for freelancing platforms based on financial and social capital; on code-prompting auto-catalytic sets and the origins of coded life; using tag based semantic annotation to empower client and REST service interaction; a novel algorithm for bi-level image coding and lossless compression based on virtual ant colonies; proposing a holistic framework for the assessment and management of manufacturing complexity through data-centric and human-centric approaches; CBR-mining approach to improve learning system engineering in a collaborative e-learning platform; a new pricing model for freelancing platforms based on financial and social capital; on the public perception of police forces in riot events - the role of emotions in three major social networks during the 2017 G20 riots; complexity evaluation with business process modeling and simulation; modeling and implementation of a Ludic application using simple reactive agents - hydrological impact of high Andean ecosystems; bio-backfill: a scheduling policy enhancing the performance of bioinformatics workflows in shared clusters; and the fuzzy mortality model based on quaternion theory.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"21100875567","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052013860"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85052013860?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85052013860&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85052013860&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85052013860","dc:identifier":"SCOPUS_ID:85052013860","eid":"2-s2.0-85052013860","dc:title":"3D orientation estimation of industrial parts from 2D images using neural networks","dc:creator":"Langlois J.","prism:publicationName":"ICPRAM 2018 - Proceedings of the 7th International Conference on Pattern Recognition Applications and Methods","prism:isbn": [{"@_fa": "true", "$" :"9789897582769"}],"prism:volume":"2018-January","prism:pageRange":"409-416","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.5220/0006597604090416","dc:description":"In this paper we propose a pose regression method employing a convolutional neural network (CNN) fed with single 2D images to estimate the 3D orientation of a specific industrial part. The network training dataset is generated by rendering pose-views from a textured CAD model to compensate for the lack of real images and their associated position label. Using several lighting conditions and material reflectances increases the robustness of the prediction and allows to anticipate challenging industrial situations. We show that using a geodesic loss function, the network is able to estimate a rendered view pose with a 5◦ accuracy while inferring from real images gives visually convincing results suitable for any pose refinement processes.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032006","afid":"60032006","affilname":"Nantes Université","affiliation-city":"Nantes","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/121215812","afid":"121215812","affilname":"Multitude-Technologies a company of Wedo","affiliation-city":null,"affiliation-country":"France"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57203514321","authid":"57203514321","authname":"Langlois J.","surname":"Langlois","given-name":"Julien","initials":"J.","afid": [{"@_fa": "true", "$" :"60032006"},{"@_fa": "true", "$" :"121215812"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/16024847700","authid":"16024847700","authname":"Mouchère H.","surname":"Mouchère","given-name":"Harold","initials":"H.","afid": [{"@_fa": "true", "$" :"60032006"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6603951502","authid":"6603951502","authname":"Normand N.","surname":"Normand","given-name":"Nicolas","initials":"N.","afid": [{"@_fa": "true", "$" :"60032006"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/9133978000","authid":"9133978000","authname":"Viard-Gaudin C.","surname":"Viard-Gaudin","given-name":"Christian","initials":"C.","afid": [{"@_fa": "true", "$" :"60032006"}]}],"authkeywords":"2D Images | 3D Pose Estimation | Data Augmentation | Deep Learning | Geodesic Loss | Neural Networks | Quaternions | Rendered Data","source-id":"21100991569","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherhybridgold"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Hybrid Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051841620"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051841620?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85051841620&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85051841620&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85051841620","dc:identifier":"SCOPUS_ID:85051841620","eid":"2-s2.0-85051841620","dc:title":"Color facial image representation with new quaternion gradients","dc:creator":"Grigoryan A.","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.2352/ISSN.2470-1173.2018.13.IPAS-383","dc:description":"This paper proposes a new color image representation and multiple feature fusion based method for improving color face recognition performance under different lighting conditions. First, a new image color image representation has been derived. Second, a quaternion gradient has been given to enhance and extract the faces/object's edges, contours, and texture. Also, we propose a novel feature representation based on Quaternion Gradient-based LBP tool for color face recognition. Finally, we present a concept of combining the color facial recognition system, which is based on the local quaternion gradients based binary patterns LBP Image Representation, and a new color-to-gray new mapping. The presented concept can be used for surveillance, security systems, computer animation, face tagging, human- computer interface, biometric identification, behavioral analysis, content-based image and video indexing applications.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010187","afid":"60010187","affilname":"College of Staten Island","affiliation-city":"New York","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003212","afid":"60003212","affilname":"The University of Texas at San Antonio","affiliation-city":"San Antonio","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006123399","authid":"7006123399","authname":"Grigoryan A.","surname":"Grigoryan","given-name":"Artyom","initials":"A.","afid": [{"@_fa": "true", "$" :"60003212"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003395533","authid":"7003395533","authname":"Agaian S.","surname":"Agaian","given-name":"Sos","initials":"S.","afid": [{"@_fa": "true", "$" :"60010187"}]}],"article-number":"383","source-id":"21100846961","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051840695"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051840695?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85051840695&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85051840695&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85051840695","dc:identifier":"SCOPUS_ID:85051840695","eid":"2-s2.0-85051840695","dc:title":"Enhancement of underwater color images by two-side 2-D quaternion discrete Fourier transform","dc:creator":"Grigoryan A.M.","prism:publicationName":"IS and T International Symposium on Electronic Imaging Science and Technology","prism:eIssn":"24701173","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.2352/ISSN.2470-1173.2018.13.IPAS-441","dc:description":"The research problem is to find an effective enhancement method for enhancing raw underwater color images. In underwater, as depth increases the high wavelength regions of the light spectrum are absorbed by the water and the light spectrum consists only of low wavelength regions such as green and blue and therefore, the image captured underwater looks green or greenish blue. This paper proposes an enhancement algorithm for improving the quality of raw underwater images by the method of alpha-rooting by two-side 2-D quaternion discrete Fourier transform (QDFT) with color correction done by multiscale retinex (MSR). The results of proposed enhancement are compared with the alpha-rooting method, by transforming color images to 2-D grayscale images. The enhancement are measured with reference to the metric color enhancement measure estimation.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010187","afid":"60010187","affilname":"College of Staten Island","affiliation-city":"New York","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003212","afid":"60003212","affilname":"The University of Texas at San Antonio","affiliation-city":"San Antonio","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006123399","authid":"7006123399","authname":"Grigoryan A.M.","surname":"Grigoryan","given-name":"Artyom M.","initials":"A.M.","afid": [{"@_fa": "true", "$" :"60003212"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57194467413","authid":"57194467413","authname":"John A.","surname":"John","given-name":"Aparna","initials":"A.","afid": [{"@_fa": "true", "$" :"60003212"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7003395533","authid":"7003395533","authname":"Agaian S.S.","surname":"Agaian","given-name":"Sos S.","initials":"S.S.","afid": [{"@_fa": "true", "$" :"60010187"}]}],"article-number":"441","source-id":"21100846961","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051800961"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85051800961?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85051800961&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85051800961&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85051800961","dc:identifier":"SCOPUS_ID:85051800961","eid":"2-s2.0-85051800961","dc:title":"Using quaternion fourier transform in steganography systems","dc:creator":"Khalil M.I.","prism:publicationName":"International Journal of Communication Networks and Information Security","prism:issn":"20760930","prism:eIssn":"2073607X","prism:volume":"10","prism:issueIdentifier":"2","prism:pageRange":"425-431","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"Steganography is the discipline of exchanging information messages in such way that no one, other than the intended recipient, suspects the existence of the message. The transmitted message can be in textual or multimedia form (audio, image or video) and can be hidden within cover media. Moreover, the hidden message can be in either plain or cipher form. In steganography, the majority of hiding techniques are implemented either in spatial domain or in frequency domain of the cover media. The current contribution introduces a new a steganography technique for hiding a textual message within a cover image. Both the message and the cover image is converted to quaternion form and then only the quaternion message is converted to the frequency domain using Quaternion Fast Fourier Discrete Transform (QFFDT) technique. Simple quaternion mathematics are used to combine the message (in quaternion frequency domain) within the cover image (in quaternion form). Conversely, the hidden message can be revealed at the receiver using simple quaternion mathematics in presence of the original cover image. The proposed method allows hiding a huge amount of data and it is much complicated against steganalysis compared to the traditional methods. The method is assessed using the known performance metrics and the obtained results show that it is robust and more secure against steganalysis attacks without affecting the consumed bandwidth of the communication channel.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105146","afid":"60105146","affilname":"Princess Nourah Bint Abdulrahman University","affiliation-city":"Riyadh","affiliation-country":"Saudi Arabia"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57195264555","authid":"57195264555","authname":"Khalil M.I.","surname":"Khalil","given-name":"M. I.","initials":"M.I.","afid": [{"@_fa": "true", "$" :"60105146"}]}],"authkeywords":"Cryptography | Fourier Transform | Quaternions | Steganography","source-id":"19900195075","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85050731269"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85050731269?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85050731269&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85050731269&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85050731269","dc:identifier":"SCOPUS_ID:85050731269","eid":"2-s2.0-85050731269","dc:title":"Application of modified ellipsoidal filter in integrated strapdown inertial navigation system","dc:creator":"Salnikov N.","prism:publicationName":"Journal of Automation and Information Sciences","prism:issn":"10642315","prism:volume":"50","prism:issueIdentifier":"4","prism:pageRange":"35-53","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1615/JAutomatInfScien.v50.i4.40","dc:description":"Consideration is given to solving the correction problems of slowly varying shifts of microelectronic mechanical system of gyroscopes readings using object position measurements via global navigation satellite system. For measurement noises only their maximum values are known, the presence of stochastic properties is not assumed. The moving object attitude is described by quaternions. The task of strapdown inertial navigation systems readings correction is considered in a simplified formulation, an inertial coordinate system is used, the Coriolis force and inhomogeneity of the Earth gravitational field are not taken into account. The application of the proposed approach is demonstrated on the test example.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011313","afid":"60011313","affilname":"National Academy of Sciences in Ukraine","affiliation-city":"Kyiv","affiliation-country":"Ukraine"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6505955589","authid":"6505955589","authname":"Salnikov N.","surname":"Salnikov","given-name":"N. N.","initials":"N.N.","afid": [{"@_fa": "true", "$" :"60011313"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7004361810","authid":"7004361810","authname":"Gubarev V.","surname":"Gubarev","given-name":"V. F.","initials":"V.F.","afid": [{"@_fa": "true", "$" :"60011313"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57191882734","authid":"57191882734","authname":"Melnichuk S.","surname":"Melnichuk","given-name":"S. V.","initials":"S.V.","afid": [{"@_fa": "true", "$" :"60011313"}]}],"authkeywords":"Gravitational field | Measurement noise | Modified ellipsoidal filter | Moving object attitude | Strapdown inertial navigation system","source-id":"25497","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049958506"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049958506?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85049958506&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85049958506&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85049958506","dc:identifier":"SCOPUS_ID:85049958506","eid":"2-s2.0-85049958506","dc:title":"Spatial Registration of a Cranio-maxillofacial Surgery Robot and Its Experiments","dc:creator":"Duan X.","prism:publicationName":"Jiqiren/Robot","prism:issn":"10020446","prism:volume":"40","prism:issueIdentifier":"1","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"1 January 2018","prism:doi":"10.13973/j.cnki.robot.170221","dc:description":"Cranio-maxillofacial region is of a complex structure, its surgery is of high-risk, and therefore it demands a high accuracy. For this reason, a set of cranio-maxillofacial surgery robot system is developed. Firstly, a spatial registration method of the cranio-maxillofacial surgery robot based on optical localization is proposed and established, to complete the spatial registration of the robot system efficiently and accurately. And the coordinate system transformation between different subsystems of the robot is realized by the spatial registration method. Then, the matrix conversion between point sets is realized by the quaternion based iterative closest points registration algorithm. The verification experiments of registration accuracy and positioning accuracy are carried out respectively, as well as the model and cadaver puncture positioning experiments of trigeminal radiofrequency thermocoagulation, based on the spatial registration of the medical image, the robot and its each subsystem. The average registration errors of registration accuracy verification experiment are less than 0.75 mm. The average error of the positioning accuracy verification experiment is 0.56 mm. The successful rate of puncture is 100% in model experiments, and it is 95% in cadaver experiments. The comprehensive experimental results show that the spatial registration method is of a high registration accuracy and a certain feasibility, which meets the needs of the cranio-maxillofacial surgery robot system.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/116582561","afid":"116582561","affilname":"Beijing Advanced Innovation Center for Intelligent Robots and Systems","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55646016600","authid":"55646016600","authname":"Duan X.","surname":"Duan","given-name":"Xingguang","initials":"X.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56406758500","authid":"56406758500","authname":"Gao L.","surname":"Gao","given-name":"Liang","initials":"L.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35766515500","authid":"35766515500","authname":"Li J.","surname":"Li","given-name":"Jianxi","initials":"J.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55414766600","authid":"55414766600","authname":"Wang Y.","surname":"Wang","given-name":"Yonggui","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57190127713","authid":"57190127713","authname":"Li H.","surname":"Li","given-name":"Haoyuan","initials":"H.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57113825600","authid":"57113825600","authname":"Guo Y.","surname":"Guo","given-name":"Yanjun","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]}],"authkeywords":"Cranio-maxillofacial surgery | Optical localization | Spatial registration | Surgery robot","source-id":"18056","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049460373"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049460373?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85049460373&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85049460373&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85049460373","dc:identifier":"SCOPUS_ID:85049460373","eid":"2-s2.0-85049460373","dc:title":"DTI Segmentation Using Anisotropy Preserving Quaternion Based Distance Measure","dc:creator":"Kaushik S.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783319929996"}],"prism:volume":"10882 LNCS","prism:pageRange":"81-89","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1007/978-3-319-93000-8_10","dc:description":"In brain research, the second order tensor model of the diffusion tensor imaging (DTI) encodes diffusion of water molecules in micro-structures of tissues. These tensors are real matrices lying in a non-linear space enjoying the Riemannian symmetric space structure. Thus, there are natural intrinsic metrics there, together with their extrinsic approximations. The effective implementations are based on the extrinsic ones employing their vector space structure. In processing DTI, the Log-Euclidean (LogE) metric is most popular, though very far from optimal. The spectral decomposition approach yields the distance measures which respect the anisotropy much better. In the present work, we propose to use the spherical linear interpolation (slerp-SQ) which performs much better than the LogE one and provides better interpolation of geodesics than the spectral-quaternion one. We have implemented the localized active contour segmentation method for these metrics, providing much better handling of the inhomogeneity of the data than global counterpart.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029543","afid":"60029543","affilname":"Masaryk University","affiliation-city":"Brno","affiliation-country":"Czech Republic"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57203077389","authid":"57203077389","authname":"Kaushik S.","surname":"Kaushik","given-name":"Sumit","initials":"S.","afid": [{"@_fa": "true", "$" :"60029543"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7004033982","authid":"7004033982","authname":"Slovak J.","surname":"Slovak","given-name":"Jan","initials":"J.","afid": [{"@_fa": "true", "$" :"60029543"}]}],"authkeywords":"Anisotropy | Diffusion tensor imaging | Riemannian symmetric spaces","source-id":"25674","fund-acr":"GA ČR","fund-no":"GA17-01171S","fund-sponsor":"Grantová Agentura České Republiky","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049381376"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049381376?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85049381376&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85049381376&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85049381376","dc:identifier":"SCOPUS_ID:85049381376","eid":"2-s2.0-85049381376","dc:title":"Spacecraft attitude estimation using unscented kalman filters, regularized particle filter and extended H filter","dc:creator":"Silva W.R.","prism:publicationName":"Advances in the Astronautical Sciences","prism:issn":"00653438","prism:isbn": [{"@_fa": "true", "$" :"9780877036456"}],"prism:volume":"162","prism:pageRange":"1195-1214","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"In this work, the attitude determination and the gyros drift estimation will be described for nonlinear systems using the Extended Kalman Filter (EKF), Extended H Filter (EHF), Second-Order Extended H Filter (SOEHF), Unscented Kalman Filter (UKF) and Regularized Particle Filter (RPF). An analysis of these estimation methods will be done, verifying which of them present better precision in such study. The attitude model is described by quaternions and the attitude sensors available are two DSS (Digital Sun Sensors), two IRES (Infrared Earth Sensor), and one triad of mechanical gyros. The application uses the simulated measurement data for orbit and attitude of the CBERS-2 (China Brazil Earth Resources Satellite) which has polar sun-synchronous orbit with an altitude of 778km, making about 14 revolutions per day. In this orbit, the satellite crosses the equator line always at the same local time, around 10:30 am. This dynamics allows the same conditions of solar illumination to be obtained during the acquisition of images. The simulated measurements of the CBERS-2 were provided by the inhouse package PROPAT, a Satellite Attitude and Orbit Toolbox for Matlab. The results in this work show that one can reach accuracies in attitude determination within the prescribed requirements, besides providing estimates of the gyro drifts which can be further used to enhance the gyro error model.","citedby-count":"5","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021657","afid":"60021657","affilname":"Instituto Tecnologico de Aeronautica","affiliation-city":"Sao Jose dos Campos","affiliation-country":"Brazil"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60012729","afid":"60012729","affilname":"Instituto Nacional de Pesquisas Espaciais","affiliation-city":"Sao Jose dos Campos","affiliation-country":"Brazil"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008088","afid":"60008088","affilname":"Universidade de São Paulo","affiliation-city":"Sao Paulo","affiliation-country":"Brazil"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60001430","afid":"60001430","affilname":"Universidade Federal do ABC","affiliation-city":"Santo Andre","affiliation-country":"Brazil"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55969647200","authid":"55969647200","authname":"Silva W.R.","surname":"Silva","given-name":"William R.","initials":"W.R.","afid": [{"@_fa": "true", "$" :"60021657"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35723676800","authid":"35723676800","authname":"Garcia R.V.","surname":"Garcia","given-name":"Roberta V.","initials":"R.V.","afid": [{"@_fa": "true", "$" :"60008088"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7004718441","authid":"7004718441","authname":"Kuga H.K.","surname":"Kuga","given-name":"Hélio K.","initials":"H.K.","afid": [{"@_fa": "true", "$" :"60012729"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7003345621","authid":"7003345621","authname":"Zanardi M.C.","surname":"Zanardi","given-name":"Maria C.","initials":"M.C.","afid": [{"@_fa": "true", "$" :"60001430"}]}],"source-id":"12376","fund-acr":"CNPq","fund-no":"2038/2014","fund-sponsor":"Conselho Nacional de Desenvolvimento Científico e Tecnológico","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049067792"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85049067792?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85049067792&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85049067792&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S187705091830838X"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85049067792","dc:identifier":"SCOPUS_ID:85049067792","eid":"2-s2.0-85049067792","dc:title":"On Detectors and Descriptors based Techniques for Face Recognition","dc:creator":"Vinay A.","prism:publicationName":"Procedia Computer Science","prism:eIssn":"18770509","prism:volume":"132","prism:pageRange":"908-917","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1016/j.procs.2018.05.106","pii":"S187705091830838X","dc:description":"Out of all forms of biometrics, Face Recognition (FR) emerges as the most incredible one. Apart from offering revolutionary applications for business and law-enforcement purposes, it has also opened numerous research avenues in various domains like security, surveillance and social network. One of the many factors critical to having an efficient face recognition system is having at hand, a suitable combination of feature descriptor and feature detector. A feature detector makes use of methods that make local decisions regarding the presence/absence of image features of a given type. A feature descriptor, on the other hand, simplifies the image by extracting useful information and disposing irrelevant information. Our research discusses the goodness of various feature descriptor-detector combination. We do this by simply carrying out the process of feature matching using various combinations of detectors and descriptors. This experiment includes incorporation of dimensionality reduction on the images using Hypercomplex Fourier Transform (HFT) and RANSAC for noise reduction. Out of the diverse options available, we chose to test LGHD, PCEHD and EHD for feature descriptors; for feature detectors, we chose the ones that make use of popular algorithms like Harris-Stephen Algorithm, Minimum Eigen Value and SURF. A series of strict and thorough experiments on popularly available datasets - Faces94 and Grimace led us to an astonishing observation - an accuracy of 90.67% for the former and 71.3% for the latter for Minimum Eigen Value paired with LGHD! This in comparison to those for all other combinations is a lot superior. We thereby conclusively state that feature detector using Minimum Eigen Value algorithm paired with feature descriptor - LGHD outplays other combinations making this combination the best choice for Face Recognition.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60097260","afid":"60097260","affilname":"PES University","affiliation-city":"Bengaluru","affiliation-country":"India"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36810902100","authid":"36810902100","authname":"Vinay A.","surname":"Vinay","given-name":"A.","initials":"A.","afid": [{"@_fa": "true", "$" :"60097260"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57202719181","authid":"57202719181","authname":"Aklecha N.","surname":"Aklecha","given-name":"Nishant","initials":"N.","afid": [{"@_fa": "true", "$" :"60097260"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57202712577","authid":"57202712577","authname":"Meghana ","surname":"Meghana","given-name":null,"initials":null,"afid": [{"@_fa": "true", "$" :"60097260"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7201420738","authid":"7201420738","authname":"Murthy K.N.B.","surname":"Murthy","given-name":"K. N.Balasubramanya","initials":"K.N.B.","afid": [{"@_fa": "true", "$" :"60097260"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57219252936","authid":"57219252936","authname":"Natarajan S.","surname":"Natarajan","given-name":"S.","initials":"S.","afid": [{"@_fa": "true", "$" :"60097260"}]}],"authkeywords":"descriptors | detectors | EHD | Face Recognision | feature extraction | features | Harris-Stephen | HFT | LGHD | Minimum Eigen | PCEHD | RANSAC | SURF","source-id":"19700182801","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85048601829"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85048601829?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85048601829&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85048601829&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85048601829","dc:identifier":"SCOPUS_ID:85048601829","eid":"2-s2.0-85048601829","dc:title":"Ensemble swarm intelligent based vote classification (ESIVC) for snore sounds detection","dc:creator":"Jeslin Renjith E.","prism:publicationName":"Journal of Advanced Research in Dynamical and Control Systems","prism:eIssn":"1943023X","prism:volume":"10","prism:issueIdentifier":"4","prism:pageRange":"152-165","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","dc:description":"Obstructive Sleep Apnea (OSA) is a dangerous constant disease and a risk cause for cardiovascular diseases. Snoring is a typical symptom of OSA patients. The major objective of this paper is to introduce and experiment an Ensemble Swarm Intelligent based VOTE Classification (ESIVC) approach with high efficiency, and perceptive whole-night snore sound detector based on non-contact knowledge. At initially the collected audio signals recorded using Drug-Induced Sleep Endoscopy, for easy purpose these audio signals in the sleep lab were digitized by the frequency rate of 44.1 kHz, Pulse Code Modulation (PCM), and down-sampled to 16 kHz per each sample, which is the lowest sampling rate of the audio recorder. Then the noises presented in the audio signals were removed by Wiener-Filter (WF) algorithm. Some of the features such as Crest Factor, original Frequency, Spectral Frequency Features, Subband Energy Ratio, Mel-Scale Frequency Cepstral Coefficients(MFCC), Empirical Mode Decomposition (EMD) Features, and Wavelet Energy Features have been extracted from the noise suppressed audio signals and input into ESIVC approach. Before that important feature has been ranked and selected using ReliefF based multi-feature selection algorithm. The design of ESIVC approach is to create a new classification approach by combining multiple classifiers such as Particle Swarm Optimization (PSO) and Quaternions Firefly Algorithm (QFA). Consecutively increase the accuracy of the optimization based classifiers. The proposed ESIC approach is distinguished with the purpose of single classifiers and has been used for increasing the snore detection prediction performance.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013041","afid":"60013041","affilname":"Bharathiar University","affiliation-city":"Coimbatore","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57202514409","authid":"57202514409","authname":"Jeslin Renjith E.","surname":"Jeslin Renjith","given-name":"E.","initials":"E.","afid": [{"@_fa": "true", "$" :"60013041"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57211298298","authid":"57211298298","authname":"Christy A.","surname":"Christy","given-name":"A.","initials":"A.","afid": [{"@_fa": "true", "$" :"60013041"}]}],"authkeywords":"Ensemble swarm intelligent based VOTE classification (ESIC) | Multi-feature selection algorithm | Obstructive sleep apnea (OSA) | Particle swarm optimization (PSO) | Quaternions firefly algorithm (QFA) | Velum oropharyngeal tongue epiglottis (VOTE)","source-id":"20500195215","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85047935250"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85047935250?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85047935250&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85047935250&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85047935250","dc:identifier":"SCOPUS_ID:85047935250","eid":"2-s2.0-85047935250","dc:title":"A Color Image Watermarking Approach Based on Synchronization Correction","dc:creator":"Wang X.","prism:publicationName":"Fundamenta Informaticae","prism:issn":"01692968","prism:volume":"158","prism:issueIdentifier":"4","prism:pageRange":"385-407","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.3233/FI-2018-1654","dc:description":"Digital watermarking has been proposed as an effective technology of copyright protection and content authentication, yet up to now, research on the robust watermarking against geometric attacks is still a challenging task. This paper presents a novel robust watermarking algorithm in nonsubsampled shearlet transform (NSST) domain using quaternion polar harmonic transform (PHT) and least squares support vector regression (LS-SVR), which is a recently developed geometric correction algorithm for digital color image. The major innovative works of the proposed approach lie in that (1) the NSST is applied to embed the watermark, which can provide the image function with nearly optimal approximation and employ fully the properties of human visual system (HVS), (2) the robust 2D transform, namely quaternion PHT is introduced to represent the characteristics of color image, and (3) the novel synchronous correction method is proposed using the excellent LS-SVR and quaternion PHTs, which can accurately estimate the geometric distortions parameters. In our experiments, we applied the proposed method to the standard color image test dataset, and the experimental results demonstrate that the proposed algorithm is not only invisible, but also robustness against common signal processing operations and geometric attacks.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017010","afid":"60017010","affilname":"Liaoning Normal University","affiliation-city":"Dalian","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/34972239800","authid":"34972239800","authname":"Wang X.","surname":"Wang","given-name":"Xiang Yang","initials":"X.Y.","afid": [{"@_fa": "true", "$" :"60017010"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57190879168","authid":"57190879168","authname":"Xu H.","surname":"Xu","given-name":"Huan","initials":"H.","afid": [{"@_fa": "true", "$" :"60017010"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57202335087","authid":"57202335087","authname":"Zhang S.","surname":"Zhang","given-name":"Si Yu","initials":"S.Y.","afid": [{"@_fa": "true", "$" :"60017010"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57161849900","authid":"57161849900","authname":"Liang L.","surname":"Liang","given-name":"Lin Lin","initials":"L.L.","afid": [{"@_fa": "true", "$" :"60017010"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/16205443400","authid":"16205443400","authname":"Niu P.","surname":"Niu","given-name":"Pan Pan","initials":"P.P.","afid": [{"@_fa": "true", "$" :"60017010"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/34972350300","authid":"34972350300","authname":"Yang H.","surname":"Yang","given-name":"Hong Ying","initials":"H.Y.","afid": [{"@_fa": "true", "$" :"60017010"}]}],"authkeywords":"Color image watermarking | geometric distortions | least squares support vector regression | nonsubsampled shearlet transform | quaternion polar harmonic transform","source-id":"28474","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85047919294"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85047919294?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85047919294&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85047919294&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85047919294","dc:identifier":"SCOPUS_ID:85047919294","eid":"2-s2.0-85047919294","dc:title":"Image denoising using fractional quaternion wavelet transform","dc:creator":"Nandal S.","prism:publicationName":"Advances in Intelligent Systems and Computing","prism:issn":"21945357","prism:isbn": [{"@_fa": "true", "$" :"9789811078972"}],"prism:volume":"704","prism:pageRange":"301-313","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1007/978-981-10-7898-9_25","dc:description":"This paper presents an image denoising algorithm using fractional quaternion wavelet transform (FrQWT). In particular, images corrupted with additive Gaussian noise are considered and FrQWT is performed via hard and semi-soft thresholds. The thresholding on the wavelet coefficients reveals the capabilities of wavelet transform in the restoration of an image degraded by noise. FrQWT is simple and adaptive since the estimation of threshold parameters depends on the data of wavelet coefficients. The fractional order captures the texture details of an image in more adaptive way. Experimental results exploit the better performance compared to the various techniques such as denoising in discrete wavelets, complex wavelet and quaternion wavelet transform domains in terms of high peak signal-to-noise ratio (PSNR).","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031818","afid":"60031818","affilname":"Indian Institute of Technology Roorkee","affiliation-city":"Roorkee","affiliation-country":"India"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57212228564","authid":"57212228564","authname":"Nandal S.","surname":"Nandal","given-name":"Savita","initials":"S.","afid": [{"@_fa": "true", "$" :"60031818"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57220591978","authid":"57220591978","authname":"Kumar S.","surname":"Kumar","given-name":"Sanjeev","initials":"S.","afid": [{"@_fa": "true", "$" :"60031818"}]}],"authkeywords":"Fractional quaternion wavelet transform | Image denoising | Magnitude thresholding | Peak signal-to-noise ratio (PSNR) | Phase regularization","source-id":"5100152904","fund-acr":"MOEHRD","fund-no":"undefined","fund-sponsor":"Ministry of Education and Human Resources Development","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046862117"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046862117?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046862117&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85046862117&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85046862117","dc:identifier":"SCOPUS_ID:85046862117","eid":"2-s2.0-85046862117","dc:title":"Ship Detection on Sea Surface Based on Visual Saliency","dc:creator":"Ding P.","prism:publicationName":"Tien Tzu Hsueh Pao/Acta Electronica Sinica","prism:issn":"03722112","prism:volume":"46","prism:issueIdentifier":"1","prism:pageRange":"127-134","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"1 January 2018","prism:doi":"10.3969/j.issn.0372-2112.2018.01.018","dc:description":"The ship detection technology is of special significance in both military and civilian level. In order to detect ship targets quickly, efficiently and accurately in a wide and complex sea surface environment, a new method for ship detection based on multi-features and multi-scale visual saliency is proposed. This method makes full use of features of the hyper-complex images which can be operated simultaneously in a number of channels, save operation time, and guarantee the characteristics of different scale characteristics. First, the method uses top-hat algorithm for image preprocessing of the original image to suppress the interference of clouds and oil. Secondly, a variety of features are extracted to form hyper-complex images to detect the significance of ship targets. When we get the last saliency map, we segment ships to ensure the target location by using the OTSU algorithm, and then we mark the ship target in the original image. We make the experimental analysis in several sea conditions, and experimental results show that the algorithm can eliminate fog, cloud and grease interfering with accurate detection of ship targets. In this algorithm, true rate meets 96.52% and the false alarm rate is as low as 2.11%. Compared to other saliency detection algorithm in ship detection, this algorithm has obvious advantages.","citedby-count":"15","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190837671","authid":"57190837671","authname":"Ding P.","surname":"Ding","given-name":"Peng","initials":"P.","afid": [{"@_fa": "true", "$" :"60004828"},{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57214252416","authid":"57214252416","authname":"Zhang Y.","surname":"Zhang","given-name":"Ye","initials":"Y.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/22953433000","authid":"22953433000","authname":"Jia P.","surname":"Jia","given-name":"Ping","initials":"P.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57196419611","authid":"57196419611","authname":"Chang X.L.","surname":"Chang","given-name":"Xu Ling","initials":"X.L.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57190844479","authid":"57190844479","authname":"Liu R.","surname":"Liu","given-name":"Rang","initials":"R.","afid": [{"@_fa": "true", "$" :"60004828"},{"@_fa": "true", "$" :"60027363"}]}],"authkeywords":"PQFT algorithm | Ship detection | Visual saliency","source-id":"24288","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046721511"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046721511?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046721511&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85046721511&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85046721511","dc:identifier":"SCOPUS_ID:85046721511","eid":"2-s2.0-85046721511","dc:title":"Sensor synchronization for android phone tightly-coupled visual-inertial SLAM","dc:creator":"Feng Z.","prism:publicationName":"Lecture Notes in Electrical Engineering","prism:issn":"18761100","prism:eIssn":"18761119","prism:isbn": [{"@_fa": "true", "$" :"9789811300288"}],"prism:volume":"499","prism:pageRange":"601-612","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1007/978-981-13-0029-5_52","dc:description":"At present, the majority of Android phones only support satellite positioning and cellular localization. Both of them are of poor indoor performance, which limits the development of the relevant indoor location based services. In this paper, we attempt to achieve positioning with raw image and Inertial Measurement Unit (IMU) data from Android phone. We first introduce a state-of-the-art framework for tightly-coupled monocular visual-inertial Simultaneous Localization and Mapping (SLAM) using image and IMU data. Then we focus on the unsynchronization problem between camera and IMU of Android phone, and propose a grid search algorithm based on spherical quaternion interpolation for delay estimation. The results of indoor and outdoor experiments show that the algorithm can estimate the delay of image timestamp effectively, and the percentage of positioning plane error is 0.79% indoors and 8.09% outdoors respectively.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069731","afid":"60069731","affilname":"Information Engineering University China","affiliation-city":"Zhengzhou","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57206248495","authid":"57206248495","authname":"Feng Z.","surname":"Feng","given-name":"Zheyu","initials":"Z.","afid": [{"@_fa": "true", "$" :"60069731"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/20433817200","authid":"20433817200","authname":"Li J.","surname":"Li","given-name":"Jianwen","initials":"J.","afid": [{"@_fa": "true", "$" :"60069731"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57189233784","authid":"57189233784","authname":"Dai T.","surname":"Dai","given-name":"Taogao","initials":"T."}],"authkeywords":"Android phone | SLAM | Synchronization | Tightly-coupled | VINS","source-id":"19700186822","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046156894"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85046156894?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85046156894&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85046156894&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85046156894","dc:identifier":"SCOPUS_ID:85046156894","eid":"2-s2.0-85046156894","dc:title":"Algebraic models and methods of computer image processing. Part 1. Multiplet models of multichannel images","dc:creator":"Labunets V.G.","prism:publicationName":"Computer Optics","prism:issn":"01342452","prism:eIssn":"24126179","prism:volume":"42","prism:issueIdentifier":"1","prism:pageRange":"84-95","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"January-February 2018","prism:doi":"10.18287/2412-6179-2018-42-1-84-95","dc:description":"We present a new theoretical framework for multichannel image processing using commutative hypercomplex algebras. Hypercomplex algebras generalize the algebras of complex numbers. The main goal of the work is to show that hypercomplex algebras can be used to solve problems of multichannel (color, multicolor, and hyperspectral) image processing in a natural and effective manner. In this work, we suppose that the animal brain operates with hypercomplex numbers when processing multichannel retinal images. In our approach, each multichannel pixel is considered not as an K-D vector, but as an K-D hypercomplex number, where K is the number of different optical channels. The aim of this part is to present algebraic models of subjective perceptual color, multicolor and multichannel spaces.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60108900","afid":"60108900","affilname":"Ural State Forest Engineering University","affiliation-city":"Yekaterinburg","affiliation-country":"Russian Federation"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/114798627","afid":"114798627","affilname":"Capricat LLC","affiliation-city":"Pompano Beach","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6701610877","authid":"6701610877","authname":"Labunets V.G.","surname":"Labunets","given-name":"Valeri Grigorievich","initials":"V.G.","afid": [{"@_fa": "true", "$" :"60108900"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57201799174","authid":"57201799174","authname":"Kokh E.V.","surname":"Kokh","given-name":"Elena Viktorovna","initials":"E.V.","afid": [{"@_fa": "true", "$" :"60108900"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56440079800","authid":"56440079800","authname":"Ostheimer Rundblad E.","surname":"Ostheimer Rundblad","given-name":"Ekaterina","initials":"E.","afid": [{"@_fa": "true", "$" :"114798627"}]}],"authkeywords":"Hypercomplex algebra | Image processing | Multichannel images","source-id":"21100203110","fund-acr":"РФФИ","fund-no":"# 17-07-00886","fund-sponsor":"Russian Foundation for Basic Research","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85042594351"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85042594351?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85042594351&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85042594351&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85042594351","dc:identifier":"SCOPUS_ID:85042594351","eid":"2-s2.0-85042594351","dc:title":"Modelling and Experiment Based on a Navigation System for a Cranio-Maxillofacial Surgical Robot","dc:creator":"Duan X.","prism:publicationName":"Journal of Healthcare Engineering","prism:issn":"20402295","prism:eIssn":"20402309","prism:volume":"2018","prism:pageRange":null,"prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1155/2018/4670852","dc:description":"In view of the characteristics of high risk and high accuracy in cranio-maxillofacial surgery, we present a novel surgical robot system that can be used in a variety of surgeries. The surgical robot system can assist surgeons in completing biopsy of skull base lesions, radiofrequency thermocoagulation of the trigeminal ganglion, and radioactive particle implantation of skull base malignant tumors. This paper focuses on modelling and experimental analyses of the robot system based on navigation technology. Firstly, the transformation relationship between the subsystems is realized based on the quaternion and the iterative closest point registration algorithm. The hand-eye coordination model based on optical navigation is established to control the end effector of the robot moving to the target position along the planning path. The closed-loop control method, \"kinematics + optics\" hybrid motion control method, is presented to improve the positioning accuracy of the system. Secondly, the accuracy of the system model was tested by model experiments. And the feasibility of the closed-loop control method was verified by comparing the positioning accuracy before and after the application of the method. Finally, the skull model experiments were performed to evaluate the function of the surgical robot system. The results validate its feasibility and are consistent with the preoperative surgical planning.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/116582561","afid":"116582561","affilname":"Beijing Advanced Innovation Center for Intelligent Robots and Systems","affiliation-city":"Beijing","affiliation-country":"China"}],"pubmed-id":"29599948","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55646016600","authid":"55646016600","authname":"Duan X.","surname":"Duan","given-name":"Xingguang","initials":"X.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56406758500","authid":"56406758500","authname":"Gao L.","surname":"Gao","given-name":"Liang","initials":"L.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55414766600","authid":"55414766600","orcid":"0000-0003-2734-0147","authname":"Wang Y.","surname":"Wang","given-name":"Yonggui","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/35766515500","authid":"35766515500","authname":"Li J.","surname":"Li","given-name":"Jianxi","initials":"J.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57190127713","authid":"57190127713","authname":"Li H.","surname":"Li","given-name":"Haoyuan","initials":"H.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57113825600","authid":"57113825600","authname":"Guo Y.","surname":"Guo","given-name":"Yanjun","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"},{"@_fa": "true", "$" :"116582561"}]}],"article-number":"4670852","source-id":"21100205972","fund-acr":"NSFC","fund-no":"61673064","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85042228299"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85042228299?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85042228299&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85042228299&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85042228299","dc:identifier":"SCOPUS_ID:85042228299","eid":"2-s2.0-85042228299","dc:title":"Full-quaternion color correction in images for person re-identification","dc:creator":"Guerra R.L.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783319751924"}],"prism:volume":"10657 LNCS","prism:pageRange":"339-346","prism:coverDate":"2018-01-01","prism:coverDisplayDate":"2018","prism:doi":"10.1007/978-3-319-75193-1_41","dc:description":"Nowadays, video surveillance systems are very used to safeguard airport areas, train stations, public places, among others. Using these systems, the person re-identification is an automated task. However, there are many problems that affect the good performance of person re-identification algorithms. For example, illumination changes in the scenes is one of the essential problems. It increases the false colors on the person appearance. Moreover, in the extraction of low level features (color) there is a need to obtain reliable colors of the image or person appearance. To this end, we propose a new algorithm using full-quaternions for color image representation. The quaternionic trigonometry and the Quaternion Fast Fourier Transform are used to improve person image in the frequency domain. Finally, to see the transformed image, an adaptive gamma function is developed. Experiment results on two datasets (VIPeR and GRID) show consistent improvements over the state-of-the-art approaches.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60086400","afid":"60086400","affilname":"Centro de Aplicaciones de Tecnologías de Avanzada, Cuba","affiliation-city":"Havana","affiliation-country":"Cuba"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57200694499","authid":"57200694499","authname":"Guerra R.L.","surname":"Guerra","given-name":"Reynolds León","initials":"R.L.","afid": [{"@_fa": "true", "$" :"60086400"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/23472512800","authid":"23472512800","authname":"García Reyes E.B.","surname":"García Reyes","given-name":"Edel B.","initials":"E.B.","afid": [{"@_fa": "true", "$" :"60086400"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55387742500","authid":"55387742500","authname":"Mata F.J.S.","surname":"Mata","given-name":"Francisco J.Silva","initials":"F.J.S.","afid": [{"@_fa": "true", "$" :"60086400"}]}],"authkeywords":"Color | Fourier transforms | Full-quaternion | Person image","source-id":"25674","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}