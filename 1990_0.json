{"search-results":{"opensearch:totalResults":"16","opensearch:startIndex":"0","opensearch:itemsPerPage":"16","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "0"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=1990&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=1990&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025657228"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025657228?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025657228&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025657228&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025657228","dc:identifier":"SCOPUS_ID:0025657228","eid":"2-s2.0-0025657228","dc:title":"Image surface predicates and the neural encoding of two-dimensional signal variations","dc:creator":"Zetzsche C.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:isbn": [{"@_fa": "true", "$" :"0819402966"}],"prism:volume":"1249","prism:pageRange":"160-177","prism:coverDate":"1990-12-01","prism:coverDisplayDate":"1990","dc:description":"Empirical evidence from both psychology and physiology stresses the importance of inherently two-dimensional signals and corresponding operations in vision. Examples of this are the existence of 'bug-detectors', hypercomplex and dot-responsive cells, the occurence of contour illusions, and interactions of patterns with clearly separated orientations. These phenomena can not be described, and have been largely ignored, by common theories of size and orientation selective channels. The reason for this is shown to be located at the heart of the theory of linear systems: their one-dimensional eigenfunctions and the 'or'-like character of the superposition principle. Consequently, a nonlinear theory is needed. We present a first approach towards a general framework for the description of 2D-signals and 2D-cells in biological vision.","citedby-count":"26","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019722","afid":"60019722","affilname":"Technische Universität München","affiliation-city":"Munich","affiliation-country":"Germany"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56021568900","authid":"56021568900","authname":"Zetzsche C.","surname":"Zetzsche","given-name":"C.","initials":"C.","afid": [{"@_fa": "true", "$" :"60019722"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35616238000","authid":"35616238000","authname":"Barth E.","surname":"Barth","given-name":"E.","initials":"E.","afid": [{"@_fa": "true", "$" :"60019722"}]}],"source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025592601"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025592601?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025592601&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025592601&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025592601","dc:identifier":"SCOPUS_ID:0025592601","eid":"2-s2.0-0025592601","dc:title":"Hypercomplex numbers in digital signal processing","dc:creator":"Schutte H.","prism:publicationName":"Proceedings - IEEE International Symposium on Circuits and Systems","prism:issn":"02714310","prism:volume":"2","prism:pageRange":"1557-1560","prism:coverDate":"1990-12-01","prism:coverDisplayDate":"1990","dc:description":"A new number system, reduced biquaternions (RBs), is introduced. They are related to the quaternions and biquaternions proposed by W. R. Hamilton (1969). It is shown that a further reduction of a systems degree will occur if RBs are used. An example shows the realization of a fourth-order real filter by means of a first-order RB filter. With the introduction of the RBs a new method is obtained for the design of wave digital Hilbert transformers.","citedby-count":"59","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60020238","afid":"60020238","affilname":"Universität Paderborn","affiliation-city":"Paderborn","affiliation-country":"Germany"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7102094114","authid":"7102094114","authname":"Schutte H.","surname":"Schutte","given-name":"Hans Dieter","initials":"H.D.","afid": [{"@_fa": "true", "$" :"60020238"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7103178967","authid":"7103178967","authname":"Wenzel J.","surname":"Wenzel","given-name":"Jorg","initials":"J.","afid": [{"@_fa": "true", "$" :"60020238"}]}],"source-id":"56190","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025566442"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025566442?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025566442&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025566442&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025566442","dc:identifier":"SCOPUS_ID:0025566442","eid":"2-s2.0-0025566442","dc:title":"A Kalman filter approach for accurate 3-D motion estimation from a sequence of stereo images","dc:creator":"Lee S.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:isbn": [{"@_fa": "true", "$" :"0818620625"}],"prism:volume":"1","prism:pageRange":"104-108","prism:coverDate":"1990-12-01","prism:coverDisplayDate":"1990","dc:description":"The authors present a Kalman filter approach for accurately estimating the 3-D position and orientation of a moving object from a sequence of stereo images. One of the drawbacks of using a long sequence of images is that the noisy images taken from a longer distance result in larger errors in 3-D reconstruction and, consequently, lead to a serious degradation in motion estimation. To overcome this drawback, the authors have derived a new set of Kalman filter equations for motion estimation in the quaternion representation. The measurement equation is obtained by analyzing the effect of white Gaussian noise in 2-D images on 3-D positional errors, instead of directly assigning Gaussian noise to 3-D feature points, and incorporating the optimal 3-D reconstruction under the consistency constraint. The state propagation equation is formulated by specifying the error between the true rotation and the nominal rotation in terms of the measurement noise in 2-D images. Actual rotation parameters have been computed from the estimated quaternions by the iterated least-squares method. Simulation results indicate that the Kalman filter equations derived are an accurate model for 3-D motion estimation, thus providing significant error reduction in the presence of large measurement noise in a long sequence of images, as well as allowing a shorter transition period for convergence to the true values.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009037","afid":"60009037","affilname":"Jet Propulsion Laboratory","affiliation-city":"Pasadena","affiliation-country":"United States"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7601402085","authid":"7601402085","authname":"Lee S.","surname":"Lee","given-name":"Sukhan","initials":"S.","afid": [{"@_fa": "true", "$" :"60009037"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6603659226","authid":"6603659226","authname":"Kay Y.","surname":"Kay","given-name":"Youngchul","initials":"Y.","afid": [{"@_fa": "true", "$" :"60009037"}]}],"source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025550361"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025550361?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025550361&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025550361&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025550361","dc:identifier":"SCOPUS_ID:0025550361","eid":"2-s2.0-0025550361","dc:title":"Harmonic analysis for the affine group of visual motion","dc:creator":"Eagleson R.","prism:isbn": [{"@_fa": "true", "$" :"0818621087"}],"prism:pageRange":"176-181","prism:coverDate":"1990-12-01","prism:coverDisplayDate":"1990","dc:description":"For the task of 3-D visuomotor tracking, local image-based transformations of moving object surfaces can be modeled by a six-parameter affine group on the 2-D intensity function. The six degrees of freedom of the Euclidean rigid-body motion group project perspectively to a unique six-dimensional vector field group. This allows convolution kernels to be specified by the invariants of the subgroups of 2-D visual motion in terms of conjugate harmonic functions, providing infinitesimal measures of the one-parameter groups comprising the local affine transformations in the moving scenes. The subgroups form a canonical basis for estimating 3-D relative motion and surface orientation, as specified by the state of a quarternion. Using these convolution kernels as measures of the rigid-motion tangent space, it is posssible to integrate the global trajectory on a 6-D manifold by means of a standard recursive estimator, e.g., a Kalman filter.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010884","afid":"60010884","affilname":"Western University","affiliation-city":"London","affiliation-country":"Canada"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6603343533","authid":"6603343533","authname":"Eagleson R.","surname":"Eagleson","given-name":"Roy","initials":"R.","afid": [{"@_fa": "true", "$" :"60010884"}]}],"source-id":"137311","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025543859"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025543859?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025543859&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025543859&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025543859","dc:identifier":"SCOPUS_ID:0025543859","eid":"2-s2.0-0025543859","dc:title":"Fuzzy quaternion approach to object recognition incorporating Zernike moment invariants","dc:creator":"Ngan K.","prism:publicationName":"Proceedings - International Conference on Pattern Recognition","prism:isbn": [{"@_fa": "true", "$" :"0818620625"}],"prism:volume":"1","prism:pageRange":"288-290","prism:coverDate":"1990-12-01","prism:coverDisplayDate":"1990","dc:description":"A novel approach to 3-D object recognition based on fuzzy subset theory is described. This method uses Zernike moment invariants of the silhouette of the unknown object to form a set of fuzzy-weighted quantities called fuzzy quaternions. These are matched against those of known objects at predetermined viewpoints. The determination of the Zernike moment invariants can be faster if the equivalent contour integrals are calculated instead. By employing a novel ρ-correction scheme, errors due to the digitization are reduced. To speed up the recognition process, a modified Nelder-Mead simplex method is used. Preliminary results demonstrate the potential of the fuzzy quaternion as a viable basis for discrimination. It is concluded that the primary merits of this approach are the ease of model formation, the simplicity of the recognition scheme, and the speed of object recognition. Its disadvantages include the inability to recognize occluded objects and a poor object recognition rate for high perspective distortion of objects.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017161","afid":"60017161","affilname":"National University of Singapore","affiliation-city":"Singapore City","affiliation-country":"Singapore"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7005884930","authid":"7005884930","authname":"Ngan K.","surname":"Ngan","given-name":"King Ngi","initials":"K.N.","afid": [{"@_fa": "true", "$" :"60017161"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57198580819","authid":"57198580819","authname":"Kang S.","surname":"Kang","given-name":"Sing Bing","initials":"S.B.","afid": [{"@_fa": "true", "$" :"60017161"}]}],"source-id":"24282","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025543449"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025543449?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025543449&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025543449&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025543449","dc:identifier":"SCOPUS_ID:0025543449","eid":"2-s2.0-0025543449","dc:title":"Scanning laser ophthalmoscopy (SLO) - a new tool in vision and oculomotor research","dc:creator":"Ott D.","prism:publicationName":"Proceedings of SPIE - The International Society for Optical Engineering","prism:issn":"0277786X","prism:volume":"1357","prism:pageRange":"218-227","prism:coverDate":"1990-12-01","prism:coverDisplayDate":"1990","dc:description":"A new optical method for measuring eye movements in three dimensions is presented. It is based on imaging the ocular fundus with a scanning laser ophthalmoscope (SLO) and determining the rotational state of the eye from the positions of retinal features in subsequent images. The hardware required for image acquisition as well as algorithms for image correction, fundus tracking, and 3-D data processing are described. The method operates linearly within ±15 deg about the primary eye position with an angular resolution of 0.1 deg and a sampling rate of 50 Hz. The kinematic parameters of an eye rotation are expressed as (1) rotation vector, (2) Euler angles, and (3) quaternions. Additionally, the SLO allows precise retinotopic visual stimulation (via modulating the laser intensity), thereby rendering the evaluation of the correlation between stimulus movements and eye movements feasible. Examples of eye movement recordings are presented.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025310","afid":"60025310","affilname":"Heinrich-Heine-Universität Düsseldorf","affiliation-city":"Dusseldorf","affiliation-country":"Germany"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7202475771","authid":"7202475771","authname":"Ott D.","surname":"Ott","given-name":"Dietmar","initials":"D.","afid": [{"@_fa": "true", "$" :"60025310"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55937006700","authid":"55937006700","authname":"Holthoff K.","surname":"Holthoff","given-name":"Knut","initials":"K.","afid": [{"@_fa": "true", "$" :"60025310"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/17835048800","authid":"17835048800","authname":"Lades M.","surname":"Lades","given-name":"Martin","initials":"M.","afid": [{"@_fa": "true", "$" :"60025310"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7005782820","authid":"7005782820","authname":"Eckmiller R.","surname":"Eckmiller","given-name":"Rolf","initials":"R.","afid": [{"@_fa": "true", "$" :"60025310"}]}],"source-id":"40067","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025585043"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025585043?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025585043&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025585043&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-003132039090107V"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025585043","dc:identifier":"SCOPUS_ID:0025585043","eid":"2-s2.0-0025585043","dc:title":"Model-based recognition and positioning of polyhedra using intensity-guided range sensing and interpretation in 3-D space","dc:creator":"Lie W.","prism:publicationName":"Pattern Recognition","prism:issn":"00313203","prism:volume":"23","prism:issueIdentifier":"9","prism:pageRange":"983-997","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"1990","prism:doi":"10.1016/0031-3203(90)90107-V","pii":"0031-3203(90)90107-V","dc:description":"This paper presents a design of 3-D multi-sensory (visual and ranging) system capable of identifying and locating polyhedral objects in six degrees of spatial freedom. Due to differences in sensor characteristics, e.g. the fast data acquisition in intensity domain and the abundance of information inherent in range domain, sensors should operate in a cooperative manner to increase system efficiency and to yield information otherwise unavailable, or hard to obtain, from any single sensor. The adopted strategy of intensity-guided range sensing firstly extracts features (e.g. the line drawing and the \"control points\") from intensity images and then uses them as a guide to selectively sense ranges. Through the interfusion of both types of information, 3-D object description in terms of a relational graph structure is thus constructed for recognition and positioning purposes. To identify the object, interpretation tree search in 3-D space is applied to the matching between the constructed relational graph and those stored in database. Since high level primitives (such as faces) derived from intensity and range informations are utilized for interpretation (or, matching), the search space can be significantly reduced. Finally, a non-iterative method based on the quaternion technique is adopted to solve the transformation between sensor and model coordinates for further robotic applications. © 1990.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018029","afid":"60018029","affilname":"National Tsing Hua University","affiliation-city":"Hsinchu","affiliation-country":"Taiwan"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7005752227","authid":"7005752227","authname":"Lie W.","surname":"Lie","given-name":"Wen Nung","initials":"W.N.","afid": [{"@_fa": "true", "$" :"60018029"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/37065599800","authid":"37065599800","authname":"Yu C.","surname":"Yu","given-name":"Ching Wen","initials":"C.W.","afid": [{"@_fa": "true", "$" :"60018029"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7601424197","authid":"7601424197","authname":"Chen Y.","surname":"Chen","given-name":"Yung Chang","initials":"Y.C.","afid": [{"@_fa": "true", "$" :"60018029"}]}],"authkeywords":"Attributed relational graph | Geometrical transformation | Interpretation tree | Object recognition | Positioning | Quaternion | Sensor integration","source-id":"24823","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025541013"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025541013?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025541013&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025541013&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025541013","dc:identifier":"SCOPUS_ID:0025541013","eid":"2-s2.0-0025541013","dc:title":"Polynomial Methods for Structure from Motion","dc:creator":"Jerian C.","prism:publicationName":"IEEE Transactions on Pattern Analysis and Machine Intelligence","prism:issn":"01628828","prism:volume":"12","prism:issueIdentifier":"12","prism:pageRange":"1150-1166","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"December 1990","prism:doi":"10.1109/34.62604","dc:description":"Most structure from motion (SFM) methods presented in the literature have the following demonstrated problems. First, the nonlinear least-squares methods are crucially dependent on a good starting point. Second, the linear methods depend on the distribution of errors, since they omit certain necessary constraints. They only work well for larger numbers of data points where such errors tend to cancel. Third, they generally ignore the multiple solutions of a set of nonlinear equations, and use the nonlinear least-squares method to find zeros; the nonlinear least squares often converges to a local minimum and not to zero. We propose the use of a polynomial system of equations, with the unit quaternions representing rotation, to recover SFM under perspective projection. We combine the equations by the method of resultants with the MAXIMA symbolic algebra system, reducing the system to a single polynomial. Then, we find its real roots with Sturm sequences. Since this system has multiple solutions, we use a hypothesize and verify scheme to eliminate the incorrect ones. Hypothesize and verify diminishes the sensitivity of using polynomial equations. We examine the effect of different rotation axes and angles on SFM accuracy and compare the performance of our algorithm to a few earlier approaches. Generally we found that large rotation angles are more important than multiple frames for structure recovery. Our results show that a large amount of motion is the most important factor in getting good SFM accuracy. © 1990 IEEE","citedby-count":"20","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025778","afid":"60025778","affilname":"University of Michigan, Ann Arbor","affiliation-city":"Ann Arbor","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6602803640","authid":"6602803640","authname":"Jerian C.","surname":"Jerian","given-name":"Charles","initials":"C.","afid": [{"@_fa": "true", "$" :"60025778"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7403423939","authid":"7403423939","authname":"Jain R.","surname":"Jain","given-name":"Ramesh","initials":"R.","afid": [{"@_fa": "true", "$" :"60025778"}]}],"authkeywords":"Perspective projection | quaternions | structure from motion | Sturm sequences | symbolic algebra","source-id":"24254","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025503608"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025503608?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025503608&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025503608&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025503608","dc:identifier":"SCOPUS_ID:0025503608","eid":"2-s2.0-0025503608","dc:title":"Tesseral quaternions for the octtree","dc:creator":"Bell S.","prism:publicationName":"Computer Journal","prism:issn":"00104620","prism:volume":"33","prism:issueIdentifier":"5","prism:pageRange":"386-397","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"Oct","prism:doi":"10.1093/comjnl/33.5.386","dc:description":"The linear octtree of Gargantini is discussed. Its addressing is extended to the whole of 3-dimensional Euclidean space. A place-system Tesseral arithmetic operating directly on the octtree addresses is described. It is based on the quaternions. They provide the geometrical operations of vector addition and subtraction, and rotate and scale.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60012197","afid":"60012197","affilname":"University of Reading","affiliation-city":"Reading","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7401587937","authid":"7401587937","authname":"Bell S.","surname":"Bell","given-name":"S. B.M.","initials":"S.B.M.","afid": [{"@_fa": "true", "$" :"60012197"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7401469110","authid":"7401469110","authname":"Mason D.","surname":"Mason","given-name":"D. C.","initials":"D.C.","afid": [{"@_fa": "true", "$" :"60012197"}]}],"source-id":"23792","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025483856"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025483856?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025483856&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025483856&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-030439919090113Z"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025483856","dc:identifier":"SCOPUS_ID:0025483856","eid":"2-s2.0-0025483856","dc:title":"Representation of rotations by unit quaternions","dc:creator":"Harauz G.","prism:publicationName":"Ultramicroscopy","prism:issn":"03043991","prism:volume":"33","prism:issueIdentifier":"3","prism:pageRange":"209-213","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"September 1990","prism:doi":"10.1016/0304-3991(90)90113-Z","pii":"030439919090113Z","dc:description":"A closed form solution by Horn of an absolute orientation problem in photogrammetry and robotics entails the equivalent expression of rotation matrices by unit quaternions [B.K.P. Horn, J. Opt. Soc. Am. 4 (1987) 629]. Such representation by quaternions offers practical advantages in electron microscopy of macromolecular structures, where rotation angles must also be determined by optimisation techniques. © 1990.","citedby-count":"16","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015881","afid":"60015881","affilname":"University of Guelph","affiliation-city":"Guelph","affiliation-country":"Canada"}],"prism:aggregationType":"Journal","subtype":"le","subtypeDescription":"Letter","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7004328741","authid":"7004328741","authname":"Harauz G.","surname":"Harauz","given-name":"George","initials":"G.","afid": [{"@_fa": "true", "$" :"60015881"}]}],"source-id":"20941","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025468434"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025468434?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025468434&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025468434&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025468434","dc:identifier":"SCOPUS_ID:0025468434","eid":"2-s2.0-0025468434","dc:title":"3-D Motion Estimation Using a Sequence of Noisy Stereo Images: Models, Estimation, and Uniqueness Results","dc:creator":"Young G.S.J.","prism:publicationName":"IEEE Transactions on Pattern Analysis and Machine Intelligence","prism:issn":"01628828","prism:volume":"12","prism:issueIdentifier":"8","prism:pageRange":"735-759","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"August 1990","prism:doi":"10.1109/34.57666","dc:description":"We discuss a kinematic model-based approach for the estimation of 3-D motion parameters from a sequence of noisy stereo images. The approach is based on representing the constant acceleration translational motion and constant precession rotational motion in the form of a bilinear state-space model using standard rectilinear states for translation and quaternions for rotation. Closed-form solutions of the state transition equations are obtained to propagate the quaternions. The measurements are noisy perturbations of 3-D feature points represented in an inertial coordinate system. It is assumed that the 3-D feature points are extracted from the stereo images and matched over the frames. Owing to the nonlinearity in the state model, nonlinear filters are designed for the estimation of motion parameters. Simulation results are included. The Cramér-Rao performance bounds for motion parameter estimates are computed. A constructive proof for the uniqueness of motion parameters is given. We show that with uniform sampling in time, three noncollinear feature points in five consecutive binocular image pairs contain all the spatial and temporal information. Both nondegenerate and degenerate motions are analyzed. A deterministic algorithm to recover motion parameters from a stereo image sequence is summarized from the constructive proof. © 1990 IEEE","citedby-count":"110","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029311","afid":"60029311","affilname":"University of Southern California","affiliation-city":"Los Angeles","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7402900380","authid":"7402900380","authname":"Young G.S.J.","surname":"Young","given-name":"Gem Sun J.","initials":"G.S.J.","afid": [{"@_fa": "true", "$" :"60029311"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57203078416","authid":"57203078416","authname":"Chellappa R.","surname":"Chellappa","given-name":"Rama","initials":"R.","afid": [{"@_fa": "true", "$" :"60029311"}]}],"authkeywords":"3-D motion estimation | Motion analysis | motion from stereo images | recursive motion estimation | uniqueness","source-id":"24254","fund-acr":"NSF","fund-no":"IRI-87-13585","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025457309"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025457309?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025457309&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025457309&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025457309","dc:identifier":"SCOPUS_ID:0025457309","eid":"2-s2.0-0025457309","dc:title":"Recursive 3-D Motion Estimation From A Monocular Image Sequence","dc:creator":"Broida T.J.","prism:publicationName":"IEEE Transactions on Aerospace and Electronic Systems","prism:issn":"00189251","prism:volume":"26","prism:issueIdentifier":"4","prism:pageRange":"639-656","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"July 1990","prism:doi":"10.1109/7.55557","dc:description":"The problem considered here involves the design and application of a recursive algorithm to a sequence or images of a moving object to estimate both its structure and kinematics. The object is assumed to be rigid, and its motion is assumed to be “smooth” in the sense that it can be modeled by retaining an arbitrary number of terms in the appropriate Taylor series expansions. Translational motion involves a standard rectilinear model, while rotational motion is described with quaternions. Neglected terms of the Taylor series are modeled as process noise. A state-space model is constructed, incorporating both kinematic and structural states, and recursive techniques are used to estimate the state vector as a function of time. A set of object match points is assumed to be available, consisting of fixed features on the object, the image plane coordinates of which have been extracted from successive images in the sequence. The measured data are the noisy image plane coordinates of this set (or of a subset of this set) of object match points, taken from each image in the sequence. High image plane noise levels (up to ~ 10 percent of the object image size) are allowed. The problem is formulated as a parameter estimation and tracking problem, which can use an arbitrarily large number of images in a sequence. The recursive estimation is done using an iterated extended Kalman filter (IEKF), initialized with the output of a batch algorithm run on the first few frames. Approximate Cramér-Rao lower bounds on the error covariance of the batch estimate are used as the initial state estimate error covariance of the IEKF. The performance of the recursive estimator is illustrated using both real and synthetic image sequences. © 1990 IEEE","citedby-count":"239","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60029311","afid":"60029311","affilname":"University of Southern California","affiliation-city":"Los Angeles","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005304","afid":"60005304","affilname":"Raytheon","affiliation-city":"Waltham","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/6602885676","authid":"6602885676","authname":"Broida T.J.","surname":"Broida","given-name":"T. J.","initials":"T.J.","afid": [{"@_fa": "true", "$" :"60005304"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6701615713","authid":"6701615713","authname":"Chandrashekhar S.","surname":"Chandrashekhar","given-name":"S.","initials":"S.","afid": [{"@_fa": "true", "$" :"60029311"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57203078416","authid":"57203078416","authname":"Chellappa R.","surname":"Chellappa","given-name":"R.","initials":"R.","afid": [{"@_fa": "true", "$" :"60029311"}]}],"source-id":"17336","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025211470"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025211470?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025211470&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025211470&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-089360809090046N"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025211470","dc:identifier":"SCOPUS_ID:0025211470","eid":"2-s2.0-0025211470","dc:title":"The superior colliculus and spatiotemporal translation in the saccadic system","dc:creator":"Tweed D.","prism:publicationName":"Neural Networks","prism:issn":"08936080","prism:volume":"3","prism:issueIdentifier":"1","prism:pageRange":"75-86","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"1990","prism:doi":"10.1016/0893-6080(90)90046-N","pii":"0893-6080(90)90046-N","dc:description":"The superior colliculus (SC) plays an important part in generating saccadic eye movements, sending signals coding desired eye rotation to the brainstem. These signals must be translated from the topographic (spatial) representation used in the SC to the firing frequency (temporal) code used downstream. We show that a model of the saccadic system using the quaternion representation of eye rotations yields a spatiotemporal translation with all the experimentally observed properties: activation of a particular site in the SC generates a saccade of a particular amplitude and direction; activation of multiple sites evokes a vector average (weighted by activity levels) of the saccades coded by the individual sites; the intensity and temporal profile of activation determine saccade speed but not metrics. The feature of the model that is essential to these results is a particular sort of redundancy in the quaternion representation, coupled with multiplicative downstream handling of SC outputs. © 1990.","citedby-count":"48","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010884","afid":"60010884","affilname":"Western University","affiliation-city":"London","affiliation-country":"Canada"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006141887","authid":"7006141887","authname":"Tweed D.","surname":"Tweed","given-name":"Douglas B.","initials":"D.B.","afid": [{"@_fa": "true", "$" :"60010884"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7006778421","authid":"7006778421","authname":"Vilis T.","surname":"Vilis","given-name":"Tutis","initials":"T.","afid": [{"@_fa": "true", "$" :"60010884"}]}],"authkeywords":"Eye movements | Listing's law | Quaternions | Saccades | Spatiotemporal translation | Superior colliculus | Temporal coding | Topographic coding","source-id":"24804","fund-acr":"MRC","fund-no":"MT9335","fund-sponsor":"Medical Research Council Canada","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025207424"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025207424?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025207424&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025207424&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-089360809090045M"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025207424","dc:identifier":"SCOPUS_ID:0025207424","eid":"2-s2.0-0025207424","dc:title":"Self-organizing neural networks for perception of visual motion","dc:creator":"Marshall J.A.","prism:publicationName":"Neural Networks","prism:issn":"08936080","prism:volume":"3","prism:issueIdentifier":"1","prism:pageRange":"45-74","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"1990","prism:doi":"10.1016/0893-6080(90)90045-M","pii":"0893-6080(90)90045-M","dc:description":"The human visual system overcomes ambiguities, collectively known as the aperture problem, in its local measurements of the direction in which visual objects are moving, producing unambiguous percepts of motion. A new approach to the aperture problem is presented, using an adaptive neural network model. The neural network is exposed to moving images during a developmental period and develops its own structure by adapting to statistical characteristics of its visual input history. Competitive learning rules ensure that only connection \"chains\" between cells of similar direction and velocity sensitivity along successive spatial positions survive. The resultant self-organized configuration implements the type of disambiguation necessary for solving the aperture problem and operates in accord with direction judgments of human experimental subjects. The system not only accommodates its structure to long-term statistics of visual motion, but also simultaneously uses its acquired structure to assimilate, disambiguate, and represent visual motion events in real-time. © 1990.","citedby-count":"47","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60019674","afid":"60019674","affilname":"Boston University","affiliation-city":"Boston","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35502315700","authid":"35502315700","authname":"Marshall J.A.","surname":"Marshall","given-name":"Jonathan A.","initials":"J.A.","afid": [{"@_fa": "true", "$" :"60019674"}]}],"authkeywords":"Aperture problem | Cooperative-competitive learning | Hypercomplex cells | Intrinsic connections | Motion perception | Neural networks | Self-organization | Visual tracking","source-id":"24804","fund-acr":"NSF","fund-no":"IRI-84-17756","fund-sponsor":"National Science Foundation","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025060338"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025060338?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025060338&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025060338&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-0042698990901314"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025060338","dc:identifier":"SCOPUS_ID:0025060338","eid":"2-s2.0-0025060338","dc:title":"Geometric relations of eye position and velocity vectors during saccades","dc:creator":"Tweed D.","prism:publicationName":"Vision Research","prism:issn":"00426989","prism:volume":"30","prism:issueIdentifier":"1","prism:pageRange":"111-127","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"1990","prism:doi":"10.1016/0042-6989(90)90131-4","pii":"0042698990901314","dc:description":"Measurements of angular position and velocity vectors of the eye in three human and three monkey subjects showed that: (1) position vectors lie roughly in a single plane, in accordance with Listing's law, between and during saccades; (2) primary position of the eye is often far from the centre of the oculomotor range. (3) saccades have nearly-fixed rotation axes, which tilt out of Listing's plane in a systematic way depending on current eye position. Findings 1 and 3 show that saccadic control signals accurately reflect the properties of three-dimensional rotations, as predicted by a new quaternion model of the saccadic system; models that approximate rotational kinematics using vectorial addition and integration do not predict these findings. © 1990.","citedby-count":"288","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010884","afid":"60010884","affilname":"Western University","affiliation-city":"London","affiliation-country":"Canada"}],"pubmed-id":"2321357","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006141887","authid":"7006141887","authname":"Tweed D.","surname":"Tweed","given-name":"Douglas","initials":"D.","afid": [{"@_fa": "true", "$" :"60010884"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7006778421","authid":"7006778421","authname":"Vilis T.","surname":"Vilis","given-name":"Tutis","initials":"T.","afid": [{"@_fa": "true", "$" :"60010884"}]}],"authkeywords":"Eye movements | Eye torsion | Integration | Listing's law | Motor error | Quaternions | Saccades","source-id":"15165","fund-no":"MT9335","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025013006"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/0025013006?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=0025013006&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=0025013006&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-004269899090130D"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/0025013006","dc:identifier":"SCOPUS_ID:0025013006","eid":"2-s2.0-0025013006","dc:title":"Computing three-dimensional eye position quaternions and eye velocity from search coil signals","dc:creator":"Tweed D.","prism:publicationName":"Vision Research","prism:issn":"00426989","prism:volume":"30","prism:issueIdentifier":"1","prism:pageRange":"97-110","prism:coverDate":"1990-01-01","prism:coverDisplayDate":"1990","prism:doi":"10.1016/0042-6989(90)90130-D","pii":"004269899090130D","dc:description":"The four-component rotational operators called quaternions, which represent eye rotations in terms of their axes and angles, have several advantages over other representations of eye position (such as Fick coordinates): they provide easy computations, symmetry, a simple form for Listing's law, and useful three-dimensional plots of eye movements. In this paper we present algorithms for computing eye position quaternions and eye angular velocity (not the derivative of position in three dimensions) from two search coils (not necessarily orthogonal) on one eye in two or three magnetic fields, and for locating primary position using quaternions. We show how differentiation of eye position signals yields poor estimates of all three components of eye velocity. © 1990.","citedby-count":"235","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010884","afid":"60010884","affilname":"Western University","affiliation-city":"London","affiliation-country":"Canada"}],"pubmed-id":"2321369","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7006141887","authid":"7006141887","authname":"Tweed D.","surname":"Tweed","given-name":"Douglas","initials":"D.","afid": [{"@_fa": "true", "$" :"60010884"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/6701711878","authid":"6701711878","authname":"Cadera W.","surname":"Cadera","given-name":"Werner","initials":"W.","afid": [{"@_fa": "true", "$" :"60010884"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7006778421","authid":"7006778421","authname":"Vilis T.","surname":"Vilis","given-name":"Tutis","initials":"T.","afid": [{"@_fa": "true", "$" :"60010884"}]}],"authkeywords":"Eye movements | Eye torsion | Listing's law | Quaternions | Search coils","source-id":"15165","fund-no":"MT9335","openaccess":"0","openaccessFlag":false}]}}