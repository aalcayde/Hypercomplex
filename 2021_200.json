{"search-results":{"opensearch:totalResults":"230","opensearch:startIndex":"200","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "200"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=200&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2021&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2021&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=175&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2021&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=225&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2021&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=205&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2021&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85106272389"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85106272389?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85106272389&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85106272389&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85106272389","dc:identifier":"SCOPUS_ID:85106272389","eid":"2-s2.0-85106272389","dc:title":"Ship target detection in optical remote sensing images based on spatial and frequency features","prism:publicationName":"Laser and Optoelectronics Progress","prism:issn":"10064125","prism:volume":"58","prism:issueIdentifier":"4","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.3788/LOP202158.0415005","dc:description":"To address the problem of ship target detection in optical remote sensing images under complex sea surface landform and cloud background conditions, an unsupervised ship target detection algorithm that combines the visual salient features of spatial and frequency domains is proposed. First, based on the RGB color space and the ITTI model of the images, image features are constructed using a combination of image brightness feature map, color feature map, and one-step brightness feature. Moreover, the regional difference in the image is calculated using the covariance matrix of the image region and the entire image. Further, the spatial-domain salient feature map is constructed using the generalized eigenvalue of the covariance matrix, and the frequency-domain salient feature map of the phase spectrum of quaternion Fourier transform (PQFT) model is added. Finally, the spatial- and frequency-domain salient features are combined using cellular automata. The experimental results show that the proposed algorithm is superior to other visual salient algorithms commonly used for ship target detection.","citedby-count":"3","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "0"},"article-number":"0415005","source-id":"21100855971","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85106110193"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85106110193?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85106110193&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85106110193&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85106110193","dc:identifier":"SCOPUS_ID:85106110193","eid":"2-s2.0-85106110193","dc:title":"A Quaternion-Valued Variational Autoencoder","dc:creator":"Grassucci E.","prism:publicationName":"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","prism:issn":"15206149","prism:volume":"2021-June","prism:pageRange":"3310-3314","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1109/ICASSP39728.2021.9413859","dc:description":"Deep probabilistic generative models have achieved incredible success in many fields of application. Among such models, variational autoencoders (VAEs) have proved their ability in modeling a generative process by learning a latent representation of the input. In this paper, we propose a novel VAE defined in the quaternion domain, which exploits the properties of quaternion algebra to improve performance while significantly reducing the number of parameters required by the network. The success of the proposed quaternion VAE with respect to traditional VAEs relies on the ability to leverage the internal relations between quaternion-valued input features and on the properties of second-order statistics which allow to define the latent variables in the augmented quaternion domain. In order to show the advantages due to such properties, we define a plain convolutionalVAE in the quaternion domain and we evaluate its performance with respect to its real-valued counterpart on the CelebA face dataset.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032350","afid":"60032350","affilname":"Sapienza Università di Roma","affiliation-city":"Rome","affiliation-country":"Italy"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57218250258","authid":"57218250258","authname":"Grassucci E.","surname":"Grassucci","given-name":"Eleonora","initials":"E.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/36444807900","authid":"36444807900","authname":"Comminiello D.","surname":"Comminiello","given-name":"Danilo","initials":"D.","afid": [{"@_fa": "true", "$" :"60032350"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7005621339","authid":"7005621339","authname":"Uncini A.","surname":"Uncini","given-name":"Aurelio","initials":"A.","afid": [{"@_fa": "true", "$" :"60032350"}]}],"authkeywords":"Generative models | Quaternion neural networks | Quaternion properness | Quaternion random vectors | Variational autoencoder","source-id":"110544","fund-no":"RG11916B88E1942F","fund-sponsor":"Sapienza Università di Roma","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105953419"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105953419?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105953419&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105953419&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85105953419","dc:identifier":"SCOPUS_ID:85105953419","eid":"2-s2.0-85105953419","dc:title":"6th International Conference on Recent Trends in Computing, ICRTC 2020","prism:publicationName":"Lecture Notes in Networks and Systems","prism:issn":"23673370","prism:eIssn":"23673389","prism:isbn": [{"@_fa": "true", "$" :"9789813345003"}],"prism:volume":"177 LNNS","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","dc:description":"The proceedings contain 77 papers. The special focus in this conference is on Recent Trends in Computing. The topics include: Age-Invariant Facial Expression Classification Method Using Deep Learning; crop Recommendation System Using K-Nearest Neighbors Algorithm; enhancing Spectrum Utilization in 2G to 5G Cognitive Radio Networks; color Face Recognition Based on Quaternion Moment Vectors Using Polynomial Kernel Extreme Learning Machine; human Activity Recognition Using Long Short-Term Memory; an Extended Oddball Technique to Detect Anomaly in Static Attributed Graphs; Secure Routing-Based AODV to Prevent Network from Black Hole Attack in MANET; metamaterial-Loaded Circularly Polarized Patch Antenna Array for C Band Applications; stability Analysis of Fractional-Order Plant with Delay; cluster-Based Approaches for Energy Efficiency in Wireless Sensor Network; Optimal Tuned Linear Active Disturbance Rejection Control Applied to a 2-DOF Robotic Arm Manipulator; reproducible Analysis and Intelligent Scientific Criteria in Engineering Papers Classification Using Data Science; effect of Beta-Frequency Binaural Beats on Cognitive Control in Healthy Adults; enterprise IoT Core Platform; optimization of Web Applications Using Eager Loading; identifying Criminal Suspects by Human Gestures Using Deep Learning; batch Signature-Based Verification of Data Computation in Cloud Applications; a Cellular Automata-Based Bilateral Filter for De-speckling in Ultrasound Imaging; vote Projection Model Based on Past Election Results; national Time Synchronization Augmenting Cybersecurity; an Approach to Detect Alopecia Areata Hair Disease Using Deep Learning; heart Anomaly Detection by Analyzing Heartbeat Sounds Using Deep Learning; improved ResNet-Based Image Classification Technique for Malaria Detection; automated Water Flow Control System in Overhead Tanks Using Internet of Things and Mobile Application; preface.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"21100901469","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105947252"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105947252?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105947252&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105947252&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85105947252","dc:identifier":"SCOPUS_ID:85105947252","eid":"2-s2.0-85105947252","dc:title":"Color Face Recognition Based on Quaternion Moment Vectors Using Polynomial Kernel Extreme Learning Machine","dc:creator":"Anand S.","prism:publicationName":"Lecture Notes in Networks and Systems","prism:issn":"23673370","prism:eIssn":"23673389","prism:isbn": [{"@_fa": "true", "$" :"9789813345003"}],"prism:volume":"177 LNNS","prism:pageRange":"601-611","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1007/978-981-33-4501-0_56","dc:description":"The quaternion moments (QMs) have been successfully utilized for numerous image processing and pattern recognition applications due to their ability to capture and represent the color information holistically. In this paper, we propose a method based on the robust quaternion pseudo-Zernike moments (QPZMs) and polynomial kernel extreme learning machine (P-KELM) for color face recognition. A new hybrid color space-XnSCr is presented that outperforms the accuracies achieved in commonly used color spaces. The comparative performance analysis of the variants of extreme learning machine (ELM) is performed and the experiments exhibit that the proposed method achieves higher recognition accuracies with minimal training time on the benchmark datasets: Faces95 and Georgia Tech.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60000690","afid":"60000690","affilname":"Punjabi University","affiliation-city":"Patiala","affiliation-country":"India"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57221263089","authid":"57221263089","authname":"Anand S.","surname":"Anand","given-name":"Supriya","initials":"S.","afid": [{"@_fa": "true", "$" :"60000690"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55736694900","authid":"55736694900","authname":"Ranade S.K.","surname":"Ranade","given-name":"Sukhjeet K.","initials":"S.K.","afid": [{"@_fa": "true", "$" :"60000690"}]}],"authkeywords":"Color space | Face recognition | Kernel extreme learning machine | Quaternion extreme learning machine | Quaternion moments","source-id":"21100901469","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105786803"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105786803?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105786803&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105786803&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85105786803","dc:identifier":"SCOPUS_ID:85105786803","eid":"2-s2.0-85105786803","dc:title":"Point-cloud splicing algorithm for collaborative matching of two-dimensional cross feature points","dc:creator":"Yi C.","prism:publicationName":"Laser and Optoelectronics Progress","prism:issn":"10064125","prism:volume":"58","prism:issueIdentifier":"2","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.3788/LOP202158.0210003","dc:description":"In order to improve the speed and accuracy of point cloud matching in the structured light threedimensional reconstruction system, a collaborative matching method of two-dimensional view and three-dimensional point cloud across feature points is proposed in this work. First, the normalization of the projected images to be spliced is realized through projection transformation and dimension mapping. After preprocessing, the endpoints and bifurcation points are extracted as key points, and the similar points are triangulated and similarly matched to obtain the initial point set. The initial point set is mapped to three-dimensional space. Second, kd-tree search is used to obtain the centroid of the double neighborhood, and the point set is further screened according to the triangle similarity relationship formed by the three points. Finally, the quaternion method is used to complete the rough splicing, and then an improved iterative closest point (ICP) algorithm is used to complete the fine splicing. Experimental results show that the matching accuracy of the proposed algorithm is 98.16%, the matching time is 3 s, and the center of gravity distance error of the coarse splicing overlap area is 0.018mm. The proposed algorithm has high robustness for two-dimensional image perspective transformation, smooth texture, and uneven light.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60069758","afid":"60069758","affilname":"Changhai Hospital","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032504","afid":"60032504","affilname":"Shanghai University of Engineering Science","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60008691","afid":"60008691","affilname":"University of Shanghai for Science and Technology","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57220117672","authid":"57220117672","authname":"Yi C.","surname":"Yi","given-name":"Chen","initials":"C.","afid": [{"@_fa": "true", "$" :"60008691"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57195228628","authid":"57195228628","authname":"Haima Y.","surname":"Haima","given-name":"Yang","initials":"Y.","afid": [{"@_fa": "true", "$" :"60008691"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/26652771400","authid":"26652771400","authname":"Jin L.","surname":"Jin","given-name":"Liu","initials":"L.","afid": [{"@_fa": "true", "$" :"60032504"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57223403196","authid":"57223403196","authname":"Jun L.","surname":"Jun","given-name":"Li","initials":"L.","afid": [{"@_fa": "true", "$" :"60008691"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57217684332","authid":"57217684332","authname":"Zihao Y.","surname":"Zihao","given-name":"Yu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60032504"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57223401313","authid":"57223401313","authname":"Jun P.","surname":"Jun","given-name":"Pan","initials":"P.","afid": [{"@_fa": "true", "$" :"60069758"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/57223401617","authid":"57223401617","authname":"Ji X.","surname":"Ji","given-name":"Xia","initials":"X.","afid": [{"@_fa": "true", "$" :"60069758"}]}],"authkeywords":"Collaborative matching | Image processing | Iterative closest point algorithm | Perspective transformation | Point cloud splicing | Two dimensions","article-number":"0210003","source-id":"21100855971","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105657764"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85105657764?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85105657764&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85105657764&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85105657764","dc:identifier":"SCOPUS_ID:85105657764","eid":"2-s2.0-85105657764","dc:title":"Structure preserving quaternion generalized minimal residual method","dc:creator":"Jia Z.","prism:publicationName":"SIAM Journal on Matrix Analysis and Applications","prism:issn":"08954798","prism:eIssn":"10957162","prism:volume":"42","prism:issueIdentifier":"4","prism:pageRange":"616-634","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1137/20M133751X","dc:description":"The main aim of this paper is to develop the quaternion generalized minimal residual method (QGMRES) for solving quaternion linear systems. Quaternion linear systems arise from three-dimensional or color imaging filtering problems. The proposed quaternion Arnoldi procedure can preserve quaternion Hessenberg form during the iterations. The main advantage is that the storage of the proposed iterative method can be reduced by comparing with the Hessenberg form constructed by the classical GMRES iterations for the real representation of quaternion linear systems. The convergence of the proposed QGMRES is also established. Numerical examples are presented to demonstrate the effectiveness of the proposed QGMRES compared with the traditional GMRES in terms of storage and computing time.","citedby-count":"20","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60006541","afid":"60006541","affilname":"The University of Hong Kong","affiliation-city":"Hong Kong","affiliation-country":"Hong Kong"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004691","afid":"60004691","affilname":"Jiangsu Normal University","affiliation-city":"Xuzhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8264355300","authid":"8264355300","authname":"Jia Z.","surname":"Jia","given-name":"Zhigang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60004691"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/34571761900","authid":"34571761900","authname":"Ng M.K.","surname":"Ng","given-name":"Michael K.","initials":"M.K.","afid": [{"@_fa": "true", "$" :"60006541"}]}],"authkeywords":"General quaternion linear systems | Quaternion Arnoldi method | Quaternion generalized minimal residual method | Quaternion Krylov subspace | Three-dimensional signal filtering","source-id":"26419","fund-acr":"NSFC","fund-no":"12300218","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104738228"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104738228?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85104738228&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85104738228&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85104738228","dc:identifier":"SCOPUS_ID:85104738228","eid":"2-s2.0-85104738228","dc:title":"1st International Conference on Security and Privacy, ICSP 2020","prism:publicationName":"Lecture Notes in Electrical Engineering","prism:issn":"18761100","prism:eIssn":"18761119","prism:isbn": [{"@_fa": "true", "$" :"9789813367807"}],"prism:volume":"744 LNEE","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","dc:description":"The proceedings contain 14 papers. The special focus in this conference is on Security and Privacy. The topics include: Further Results on Bent–Negabent Boolean Functions; generalization of Lattice-Based Cryptography on Hypercomplex Algebras; health Monitoring of Hydraulic System Using Feature-based Multivariate Time-series Classification Model; image Security Using Hyperchaos and Multidimensional Playfair Cipher; iris Recognition Using Improved Xor-Sum Code; preface; a Score-Level Fusion Method for Protecting Fingerprint and Palmprint Templates; linear Complementary Dual Codes Over Z2Z4 ; low c-Differential Uniformity for the Gold Function Modified on a Subfield; post-Quantum Secure Identity-Based Encryption from Multivariate Public Key Cryptography; provably Insecure Group Authentication: Not All Security Proofs are What they Claim to Be; terahertz Communication: Merits, Demerits, and Future Challenges Regarding 6G Wireless Networks.","citedby-count":"0","prism:aggregationType":"Book Series","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"19700186822","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104462577"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104462577?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85104462577&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85104462577&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85104462577","dc:identifier":"SCOPUS_ID:85104462577","eid":"2-s2.0-85104462577","dc:title":"Quaternion Generative Adversarial Networks for Inscription Detection in Byzantine Monuments","dc:creator":"Sfikas G.","prism:publicationName":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","prism:issn":"03029743","prism:eIssn":"16113349","prism:isbn": [{"@_fa": "true", "$" :"9783030687861"}],"prism:volume":"12667 LNCS","prism:pageRange":"171-184","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1007/978-3-030-68787-8_12","dc:description":"In this work, we introduce and discuss Quaternion Generative Adversarial Networks, a variant of generative adversarial networks that uses quaternion-valued inputs, weights and intermediate network representations. Quaternionic representation has the advantage of treating cross-channel information carried by multichannel signals (e.g. color images) holistically, while quaternionic convolution has been shown to be less resource-demanding. Standard convolutional and deconvolutional layers are replaced by their quaternionic variants, in both generator and discriminator nets, while activations and loss functions are adapted accordingly. We have succesfully tested the model on the task of detecting byzantine inscriptions in the wild, where the proposed model is on par with a vanilla conditional generative adversarial network, but is significantly less expensive in terms of model size (requires 4 × less parameters). Code is available at https://github.com/sfikas/quaternion-gan.","citedby-count":"6","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004716","afid":"60004716","affilname":"University of Ioannina","affiliation-city":"Ioannina","affiliation-country":"Greece"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002947","afid":"60002947","affilname":"National Technical University of Athens","affiliation-city":"Athens","affiliation-country":"Greece"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36893579300","authid":"36893579300","authname":"Sfikas G.","surname":"Sfikas","given-name":"Giorgos","initials":"G.","afid": [{"@_fa": "true", "$" :"60004716"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56868518600","authid":"56868518600","authname":"Giotis A.P.","surname":"Giotis","given-name":"Angelos P.","initials":"A.P.","afid": [{"@_fa": "true", "$" :"60004716"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57188727925","authid":"57188727925","authname":"Retsinas G.","surname":"Retsinas","given-name":"George","initials":"G.","afid": [{"@_fa": "true", "$" :"60002947"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7004062610","authid":"7004062610","authname":"Nikou C.","surname":"Nikou","given-name":"Christophoros","initials":"C.","afid": [{"@_fa": "true", "$" :"60004716"}]}],"authkeywords":"Byzantine inscriptions | Generative Adversarial Networks | Quaternions | Text detection","source-id":"25674","fund-acr":"EC","fund-no":"T6YBΠ-00214","fund-sponsor":"Nvidia","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104367980"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85104367980?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85104367980&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85104367980&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85104367980","dc:identifier":"SCOPUS_ID:85104367980","eid":"2-s2.0-85104367980","dc:title":"Image modal analysis in art design and image recognition using AI techniques","dc:creator":"Zhou Y.","prism:publicationName":"Journal of Intelligent and Fuzzy Systems","prism:issn":"10641246","prism:eIssn":"18758967","prism:volume":"40","prism:issueIdentifier":"4","prism:pageRange":"6961-6971","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.3233/JIFS-189526","dc:description":"Traditional art design models are inefficient and difficult to control the modal characteristics of images. Based on the actual needs of artistic design, this paper builds an intelligent model of artistic design image modal analysis based on machine learning technology and image recognition technology, and proposes a feature extraction method based on wavelet transform and fuzzy logic and an art image classification method based on rotating quaternion wavelet transform. Moreover, this paper calculates the activation intensity value corresponding to each fuzzy area in the fuzzy feature space and normalizes these activation intensity values to form the artistic image feature vector. In addition, this paper uses rotating quaternary wavelet transform to decompose the art image, and then calculate the energy and standard deviation of each decomposed sub-band coefficient. Finally, this paper uses support vector machines to recognize artistic images. The experimental research shows that the model constructed in this paper has certain effects.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104173","afid":"60104173","affilname":"Chongqing University of Science and Technology","affiliation-city":"Chongqing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57222992715","authid":"57222992715","authname":"Zhou Y.","surname":"Zhou","given-name":"Yangxiaoxiao","initials":"Y.","afid": [{"@_fa": "true", "$" :"60104173"}]}],"authkeywords":"Art design | artificial intelligence | image modality | image recognition","source-id":"23917","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103782575"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103782575?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85103782575&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85103782575&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85103782575","dc:identifier":"SCOPUS_ID:85103782575","eid":"2-s2.0-85103782575","dc:title":"Pedestrian Detection Using Quaternion Gradient Based Weber Local Descriptor","dc:creator":"Lian G.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"9","prism:pageRange":"43675-43683","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1109/ACCESS.2021.3063294","dc:description":"In the past decades, pedestrian detection has attracted more attention in many practical applications. In this paper, a novel pedestrian detection method using Quaternion Gradient based Weber Local Descriptor (QGWLD) is proposed. Unlike many other local pedestrian detectors that only extracted features from the gray-scale image, which ignored the color information, a new powerful and robust local pedestrian detector is developed, which integrates the advantages of both the color and texture information and can be used to address the pedestrian detection problem well. As we know, the quaternion can entirely characterize a color object well and the WLD feature consisting of the gradient orientation and differential excitation has acquired a good performance for pedestrian detection. Therefore, combining the WLD feature with the quaternion representation, the QGWLD pedestrian detector is presented. Firstly, the quaternion gradient representation is performed on the color image in the sliding window, and then the Weber Local Descriptor (WLD) is extracted over the quaternion gradient feature map. After that, the QGWLD histogram is constructed to characterize the sliding window. Experimental results on INRIA and PennFudanPed pedestrian databases validate the effectiveness of the proposed QGWLD pedestrian detector. Comparing with the similar pedestrian detectors, the proposed QGWLD pedestrian detector performs better.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007807","afid":"60007807","affilname":"Shenzhen Polytechnic","affiliation-city":"Shenzhen","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "1", "$" :"1"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36659420300","authid":"36659420300","orcid":"0000-0003-4845-6632","authname":"Lian G.","surname":"Lian","given-name":"Guoyun","initials":"G.","afid": [{"@_fa": "true", "$" :"60007807"}]}],"authkeywords":"Pedestrian detection | quaternion gradient | video surveillance | Weber local descriptor","article-number":"9366761","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103652810"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103652810?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85103652810&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85103652810&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85103652810","dc:identifier":"SCOPUS_ID:85103652810","eid":"2-s2.0-85103652810","dc:title":"RFID aided SINS integrated navigation system for lane applications","dc:creator":"Wang Q.","prism:publicationName":"International Journal of Embedded Systems","prism:issn":"17411068","prism:eIssn":"17411076","prism:volume":"14","prism:issueIdentifier":"2","prism:pageRange":"185-193","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1504/IJES.2021.113814","dc:description":"To improve the lane vehicle position accuracy, RFID technology is applied to correct the position of the SINS irregularly with label positioning. The acceleration data of the vehicle in three directions is measured by the accelerometers of the inertial measurement unit, the attitude matrix is updated in real time using the angular velocity of the gyroscope output space, the acceleration component is transformed into the geographic coordinate system, and the acceleration of the inertial measurement unit. The data is subjected to an integral operation process to obtain a spatial displacement value of the vehicle. The real-time updating algorithm of the attitude matrix and the processing of the inertial measurement unit signal are presented. The quaternion-based algorithm is used to solve the attitude matrix as well as updating the coordinate system of the inertial navigation attitude matrix in real time. The Hilbert-Huang transform is used to filter the acceleration signal to solve the integrator saturation problem caused by the low-frequency component of the acceleration signal. The EMD algorithm based on the continuous root mean square error is applied in rejecting the low-frequency components in the signal. The simulation experiments show that the system can be reliable and high precision.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60064143","afid":"60064143","affilname":"Nanjing University of Information Science &amp; Technology","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60028244","afid":"60028244","affilname":"Ball State University","affiliation-city":"Muncie","affiliation-country":"United States"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57199479176","authid":"57199479176","authname":"Wang Q.","surname":"Wang","given-name":"Qi","initials":"Q.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55604360000","authid":"55604360000","authname":"Yang C.S.","surname":"Yang","given-name":"Chang Song","initials":"C.S.","afid": [{"@_fa": "true", "$" :"60064143"},{"@_fa": "true", "$" :"60064143"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/13613225900","authid":"13613225900","authname":"Wu S.","surname":"Wu","given-name":"Shaoen","initials":"S.","afid": [{"@_fa": "true", "$" :"60028244"}]}],"authkeywords":"Attitude matrix | Radio frequency identification | RFID | Simulation experiments | SINS","source-id":"12100157172","fund-no":"KHYS1405","fund-sponsor":"Natural Science Foundation of Jiangsu Province","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103303720"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103303720?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85103303720&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85103303720&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85103303720","dc:identifier":"SCOPUS_ID:85103303720","eid":"2-s2.0-85103303720","dc:title":"RFID Dynamic Performance Measurement System Embedded in Multiscale Deep Learning","dc:creator":"Li L.","prism:publicationName":"IEEE Transactions on Instrumentation and Measurement","prism:issn":"00189456","prism:eIssn":"15579662","prism:volume":"70","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1109/TIM.2021.3068433","dc:description":"Multitag sensitivity would be affected by electromagnetic coupling during simultaneous reading. The reading distance of multitag depends on the least sensitivity and operating power of all tags, which is an indicator of reading performance. The main purpose of this article is to optimize the reading performance of multitag by embedding deep learning, while the reading distance of multitag changes with the 3-D geometric structure. Dynamic multitag image deblurring based on multiscale convolutional neural network (MCNN) improves image restoration ability and clarity. Also, tag detection from the estimated image via YOLOv3 improved by feature enhancement (YOLOv3_f) can improve the detection ability of small size targets, and mean average precision (mAP) is increased by 16.4%. Finally, the 3-D coordinates of tags in pixel space are converted into 3-D coordinates of world space by a quaternion. Comparing our system with the positioning method without deblurring, the 3-D coordinate structures are tested in the dynamic measurement system. The experimental results show that the reading performance of the designed RFID system has been greatly improved as the number of tags increases. Our scheme can improve the reading distance of multitag from the physical structure and the anticollision ability of the RFID system.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/100720424","afid":"100720424","affilname":"National Quality Supervision and Testing Center for RFID Product (Jiangsu)","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57205208799","authid":"57205208799","orcid":"0000-0002-4364-301X","authname":"Li L.","surname":"Li","given-name":"Lin","initials":"L.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/34877962900","authid":"34877962900","orcid":"0000-0003-4859-6352","authname":"Yu X.","surname":"Yu","given-name":"Xiaolei","initials":"X.","afid": [{"@_fa": "true", "$" :"100720424"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57202690835","authid":"57202690835","orcid":"0000-0003-4012-385X","authname":"Liu Z.","surname":"Liu","given-name":"Zhenlu","initials":"Z.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/12791004000","authid":"12791004000","orcid":"0000-0001-6148-1168","authname":"Zhao Z.","surname":"Zhao","given-name":"Zhimin","initials":"Z.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57222069700","authid":"57222069700","orcid":"0000-0002-9289-4122","authname":"Zhang K.","surname":"Zhang","given-name":"Ke","initials":"K.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57222065564","authid":"57222065564","orcid":"0000-0002-3066-0646","authname":"Zhou S.","surname":"Zhou","given-name":"Shanhao","initials":"S.","afid": [{"@_fa": "true", "$" :"60021666"}]}],"authkeywords":"Anticollision | computer vision | convolutional neural network | deep learning | dynamic measurement | reading performance | RFID system | YOLOv3","article-number":"9385117","source-id":"15361","fund-acr":"NSFC","fund-no":"61771240","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103002218"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85103002218?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85103002218&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85103002218&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85103002218","dc:identifier":"SCOPUS_ID:85103002218","eid":"2-s2.0-85103002218","dc:title":"Proceedings - 2021 IEEE International Conference on Big Data and Smart Computing, BigComp 2021","prism:publicationName":"Proceedings - 2021 IEEE International Conference on Big Data and Smart Computing, BigComp 2021","prism:isbn": [{"@_fa": "true", "$" :"9781728189246"}],"prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","dc:description":"The proceedings contain 75 papers. The topics discussed include: STFNet: image classification model based on balanced texture and shape features; multiple 3D LiDARs extrinsic parameter estimation method using plane features; a crowd-enabled task execution approach in UAV networks towards fog computing; discovering business problems using problem hypotheses: a goal-oriented and machine learning-based approach; digital healthcare industry and technology trends; preventing enclave malware with intermediate enclaves on semi-honest cloud platforms; pattern-wise embedding system for scalable time-series database; comparison and analysis of embedding methods for patent documents; QUARC: quaternion multi-modal fusion architecture for hate speech classification; and CHNE: context-aware heterogeneous network embedding.","citedby-count":"0","prism:aggregationType":"Conference Proceeding","subtype":"cr","subtypeDescription":"Conference Review","author-count":{"@limit": "100", "@total": "0"},"source-id":"21101041420","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102973894"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102973894?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85102973894&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85102973894&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85102973894","dc:identifier":"SCOPUS_ID:85102973894","eid":"2-s2.0-85102973894","dc:title":"QUARC: Quaternion multi-modal fusion architecture for hate speech classification","dc:creator":"Kumar D.","prism:publicationName":"Proceedings - 2021 IEEE International Conference on Big Data and Smart Computing, BigComp 2021","prism:isbn": [{"@_fa": "true", "$" :"9781728189246"}],"prism:pageRange":"346-349","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","prism:doi":"10.1109/BigComp51126.2021.00075","dc:description":"Hate speech, quite common in the age of social media, at times harmless but can also cause mental trauma to someone or even riots in communities. Image of a religious symbol with derogatory comment or video of a man abusing a particular community, all become hate speech with its every modality (such as text, image, and audio) contributing towards it. Models based on a particular modality of hate speech post on social media are not useful, rather, we need models like multimodal fusion models that consider both image and text while classifying hate speech. Text-image fusion models are heavily parameterized, hence we propose a quaternion neural network-based model having additional fusion components for each pair of modalities. The Model is tested on the MMHS150K twitter dataset for hate speech classification. The model shows an almost 75% reduction in parameters and also benefits us in terms of storage space and training time while being at par in terms of performance as compared to its real counterpart.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60079949","afid":"60079949","affilname":"Homi Bhabha National Institute","affiliation-city":"Mumbai","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/120471161","afid":"120471161","affilname":"NISER","affiliation-city":"Bhubaneswar","affiliation-country":"India"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57224687060","authid":"57224687060","authname":"Kumar D.","surname":"Kumar","given-name":"Deepak","initials":"D.","afid": [{"@_fa": "true", "$" :"120471161"},{"@_fa": "true", "$" :"60079949"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/58274360900","authid":"58274360900","authname":"Kumar N.","surname":"Kumar","given-name":"Nalin","initials":"N.","afid": [{"@_fa": "true", "$" :"120471161"},{"@_fa": "true", "$" :"60079949"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56289643200","authid":"56289643200","authname":"Mishra S.","surname":"Mishra","given-name":"Subhankar","initials":"S.","afid": [{"@_fa": "true", "$" :"120471161"},{"@_fa": "true", "$" :"60079949"}]}],"authkeywords":"Hate speech | MMHS150K | Octonion | Quaterion algebra | Text-image fusion","article-number":"9373102","source-id":"21101041105","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102695052"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102695052?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85102695052&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85102695052&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85102695052","dc:identifier":"SCOPUS_ID:85102695052","eid":"2-s2.0-85102695052","dc:title":"Robust Sparse Representation in Quaternion Space","dc:creator":"Wang Y.","prism:publicationName":"IEEE Transactions on Image Processing","prism:issn":"10577149","prism:eIssn":"19410042","prism:volume":"30","prism:pageRange":"3637-3649","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1109/TIP.2021.3064193","dc:description":"Sparse representation has achieved great success across various fields including signal processing, machine learning and computer vision. However, most existing sparse representation methods are confined to the real valued data. This largely limit their applicability to the quaternion valued data, which has been widely used in numerous applications such as color image processing. Another critical issue is that their performance may be severely hampered due to the data noise or outliers in practice. To tackle the problems above, in this work we propose a robust quaternion valued sparse representation (RQVSR) method in a fully quaternion valued setting. To handle the quaternion noises, we first define a new robust estimator referred as quaternion Welsch estimator to measure the quaternion residual error. Compared to the conventional quaternion mean square error, it can largely suppress the impact of large data corruption and outliers. To implement RQVSR, we have overcome the difficulties raised by the noncommutativity of quaternion multiplication and developed an effective algorithm by leveraging the half-quadratic theory and the alternating direction method of multipliers framework. The experimental results show the effectiveness and robustness of the proposed method for quaternion sparse signal recovery and color image reconstruction.","citedby-count":"14","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032955","afid":"60032955","affilname":"Huazhong Agricultural University","affiliation-city":"Wuhan","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60022317","afid":"60022317","affilname":"University of Macau","affiliation-city":"Taipa","affiliation-country":"Macao"}],"pubmed-id":"33705312","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55568493500","authid":"55568493500","orcid":"0000-0002-1033-9281","authname":"Wang Y.","surname":"Wang","given-name":"Yulong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60032955"},{"@_fa": "true", "$" :"60022317"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7003837546","authid":"7003837546","orcid":"0000-0003-1924-9087","authname":"Kou K.I.","surname":"Kou","given-name":"Kit Ian","initials":"K.I.","afid": [{"@_fa": "true", "$" :"60022317"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57188872929","authid":"57188872929","orcid":"0000-0002-2283-9048","authname":"Zou C.","surname":"Zou","given-name":"Cuiming","initials":"C.","afid": [{"@_fa": "true", "$" :"60032955"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7404591899","authid":"7404591899","authname":"Tang Y.Y.","surname":"Tang","given-name":"Yuan Yan","initials":"Y.Y.","afid": [{"@_fa": "true", "$" :"60022317"}]}],"authkeywords":"color image processing | Quaternion | quaternion Welsch estimator | signal recovery","article-number":"9376669","source-id":"25534","fund-acr":"NSFC","fund-no":"FDCT/085/2018/A2","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102563510"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85102563510?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85102563510&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85102563510&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85102563510","dc:identifier":"SCOPUS_ID:85102563510","eid":"2-s2.0-85102563510","dc:title":"Motor function assessment of upper limb in stroke patients","dc:creator":"Pan B.","prism:publicationName":"Journal of Healthcare Engineering","prism:issn":"20402295","prism:eIssn":"20402309","prism:volume":"2021","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1155/2021/6621950","dc:description":"Background. Quantitative assessment of motor function is extremely important for poststroke patients as it can be used to develop personalized treatment strategies. is study aimed to propose an evaluation method for upper limb motor function in stroke patients. Methods. irty-four stroke survivors and twenty-five age-matched healthy volunteers as the control group were recruited for this study. Inertial sensor data and surface electromyography (sEMG) signals were collected from the upper limb during voluntary upward reaching. Five features included max shoulder joint angle, peak and average speeds, torso balance calculated from inertial sensor data, and muscle synergy similarity extracted from sEMG data by the nonnegative matrix factorization algorithm. Meanwhile, the Fugl-Meyer score of each patient was graded by professional rehabilitation therapist. Results. Statistically significant differences were observed among severe, mild-To-moderate, and control group of five features (p ≤ 0.001). e features varied as the level of upper limb motor function changes since these features significantly correlated with the Fugl-Meyer assessment scale (p ≤ 0.001). Moreover, the Bland-Altman method was conducted and showed high consistency between the evaluation method of five features and Fugl-Meyer scale. erefore, the five features proposed in this paper can quantitatively evaluate the motor function of stroke patients which is very useful in the rehabilitation process.","citedby-count":"15","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60121971","afid":"60121971","affilname":"Peking University First Hospital","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60027363","afid":"60027363","affilname":"University of Chinese Academy of Sciences","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60012785","afid":"60012785","affilname":"Beijing Sport University","affiliation-city":"Beijing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60012070","afid":"60012070","affilname":"University of Leeds","affiliation-city":"Leeds","affiliation-country":"United Kingdom"}],"pubmed-id":"33708365","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57190228356","authid":"57190228356","authname":"Pan B.","surname":"Pan","given-name":"Bingyu","initials":"B.","afid": [{"@_fa": "true", "$" :"60012785"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/44161117400","authid":"44161117400","authname":"Huang Z.","surname":"Huang","given-name":"Zhen","initials":"Z.","afid": [{"@_fa": "true", "$" :"60121971"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57190229921","authid":"57190229921","authname":"Jin T.","surname":"Jin","given-name":"Tingting","initials":"T.","afid": [{"@_fa": "true", "$" :"60121971"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/56153307600","authid":"56153307600","authname":"Wu J.","surname":"Wu","given-name":"Jiankang","initials":"J.","afid": [{"@_fa": "true", "$" :"60027363"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56879548200","authid":"56879548200","authname":"Zhang Z.","surname":"Zhang","given-name":"Zhiqiang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60012070"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57219224314","authid":"57219224314","authname":"Shen Y.","surname":"Shen","given-name":"Yanfei","initials":"Y.","afid": [{"@_fa": "true", "$" :"60012785"}]}],"article-number":"6621950","source-id":"21100205972","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85101804134"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85101804134?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85101804134&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85101804134&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85101804134","dc:identifier":"SCOPUS_ID:85101804134","eid":"2-s2.0-85101804134","dc:title":"Biologically-Inspired Legged Robot Locomotion Controlled with a BCI by Means of Cognitive Monitoring","dc:creator":"Batres-Mendoza P.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"9","prism:pageRange":"35766-35777","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1109/ACCESS.2021.3062329","dc:description":"Brain-computer interfaces (BCI) are a mechanism to record the electrical signals of the brain and translate them into commands to operate an output device like a robotic system. This article presents the development of a real-time locomotion system of a hexapod robot with bio-inspired movement dynamics inspired in the stick insect and tele-operated by cognitive activities of motor imagination. Brain signals are acquired using only four electrodes from a BCI device and sent to computer equipment for processing and classification by the iQSA method based on quaternion algebra. A structure consisting of three main stages are proposed: (1) signal acquisition, (2) data analysis and processing by the iQSA method, and (3) bio-inspired locomotion system using a Spiking Neural Network (SNN) with twelve neurons. An off-line training stage was carried out with data from 120 users to create the necessary decision rules for the iQSA method, obtaining an average performance of 97.72%. Finally, the experiment was implemented in real-time to evaluate the performance of the entire system. The recognition rate to achieve the corresponding gait pattern is greater than 90% for BCI, and the time delay is approximately from 1 to 1.5 seconds. The results show that all the subjects could generate their desired mental activities, and the robotic system could replicate the gait pattern in line with a slight delay.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60033291","afid":"60033291","affilname":"Universidad de Guanajuato","affiliation-city":"Guanajuato","affiliation-country":"Mexico"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018506","afid":"60018506","affilname":"Universidad Autónoma Benito Juárez de Oaxaca","affiliation-city":"Oaxaca de Juarez","affiliation-country":"Mexico"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57160241800","authid":"57160241800","orcid":"0000-0003-3245-2821","authname":"Batres-Mendoza P.","surname":"Batres-Mendoza","given-name":"Patricia","initials":"P.","afid": [{"@_fa": "true", "$" :"60018506"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57159580000","authid":"57159580000","orcid":"0000-0003-1554-0002","authname":"Guerra-Hernandez E.I.","surname":"Guerra-Hernandez","given-name":"Erick Israel","initials":"E.I.","afid": [{"@_fa": "true", "$" :"60018506"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/54913400900","authid":"54913400900","orcid":"0000-0003-1552-3210","authname":"Espinal A.","surname":"Espinal","given-name":"Andres","initials":"A.","afid": [{"@_fa": "true", "$" :"60033291"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/24825025400","authid":"24825025400","authname":"Perez-Careta E.","surname":"Perez-Careta","given-name":"Eduardo","initials":"E.","afid": [{"@_fa": "true", "$" :"60033291"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56013673200","authid":"56013673200","orcid":"0000-0001-7530-9027","authname":"Rostro-Gonzalez H.","surname":"Rostro-Gonzalez","given-name":"Horacio","initials":"H.","afid": [{"@_fa": "true", "$" :"60033291"}]}],"authkeywords":"Bio-inspired robot | brain-computer interface (BCI) | central pattern generator | electroencephalography | hexapod robot | iQSA method | motor imagery | spiking neural network","article-number":"9363897","source-id":"21100374601","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100169522"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85100169522?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85100169522&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85100169522&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85100169522","dc:identifier":"SCOPUS_ID:85100169522","eid":"2-s2.0-85100169522","dc:title":"Hyperspectral image enhancement by two dimensional quaternion valued singular spectrum analysis for object recognition","dc:creator":"Lin Y.","prism:publicationName":"Remote Sensing","prism:eIssn":"20724292","prism:volume":"13","prism:issueIdentifier":"3","prism:pageRange":"1-22","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","prism:doi":"10.3390/rs13030405","dc:description":"This paper proposes a two dimensional quaternion valued singular spectrum analysis based method for enhancing the hyperspectral image. Here, the enhancement is for performing the object recognition, but neither for improving the visual quality nor suppressing the artifacts. In particular, the two dimensional quaternion valued singular spectrum analysis components are selected in such a way that the ratio of the interclass separation to the intraclass separation of the pixel vectors is maximized. Next, the support vector machine is employed for performing the object recognition. Compared to the conventional two dimensional real valued singular spectrum analysis based method where only the pixels in a color plane is exploited, the two dimensional quaternion valued singular spectrum analysis based method fuses four color planes together for performing the enhancement. Hence, both the spatial information among the pixels in the same color plane and the spectral information among various color planes are exploited. The computer numerical simulation results show that the overall classification accuracy based on our proposed method is higher than the two dimensional real valued singular spectrum analysis based method, the three dimensional singular spectrum analysis based method, the multivariate two dimensional singular spectrum analysis based method, the median filtering based method, the principal component analysis based method, the Tucker decomposition based method and the hybrid spectral convolutional neural network (hybrid SN) based method.","citedby-count":"10","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023998","afid":"60023998","affilname":"Cardiff University","affiliation-city":"Cardiff","affiliation-country":"United Kingdom"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007155","afid":"60007155","affilname":"Guangdong University of Technology","affiliation-city":"Guangzhou","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "7", "$" :"7"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57218477837","authid":"57218477837","authname":"Lin Y.","surname":"Lin","given-name":"Yuxin","initials":"Y.","afid": [{"@_fa": "true", "$" :"60007155"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57210406493","authid":"57210406493","authname":"Ling B.W.K.","surname":"Ling","given-name":"Bingo Wing Kuen","initials":"B.W.K.","afid": [{"@_fa": "true", "$" :"60007155"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57219595106","authid":"57219595106","authname":"Hu L.","surname":"Hu","given-name":"Lingyue","initials":"L.","afid": [{"@_fa": "true", "$" :"60007155"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57221776297","authid":"57221776297","authname":"Zheng Y.","surname":"Zheng","given-name":"Yiting","initials":"Y.","afid": [{"@_fa": "true", "$" :"60023998"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57218475888","authid":"57218475888","authname":"Xu N.","surname":"Xu","given-name":"Nuo","initials":"N.","afid": [{"@_fa": "true", "$" :"60007155"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/57207735250","authid":"57207735250","authname":"Zhou X.","surname":"Zhou","given-name":"Xueling","initials":"X.","afid": [{"@_fa": "true", "$" :"60007155"}]},{"@_fa": "true", "@seq": "7", "author-url":"https://api.elsevier.com/content/author/author_id/57218553995","authid":"57218553995","authname":"Wang X.","surname":"Wang","given-name":"Xinpeng","initials":"X.","afid": [{"@_fa": "true", "$" :"60007155"}]}],"authkeywords":"Component selection | Hyperspectral image | Multichannel two dimensional signals | Object recognition | Two dimensional quaternion valued singular spectrum analysis","article-number":"405","source-id":"86430","fund-acr":"NSFC","fund-no":"2017KCXTD011","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85099167500"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85099167500?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85099167500&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85099167500&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85099167500","dc:identifier":"SCOPUS_ID:85099167500","eid":"2-s2.0-85099167500","dc:title":"Fast Algorithms for Quaternion-Valued Convolutional Neural Networks","dc:creator":"Cariow A.","prism:publicationName":"IEEE Transactions on Neural Networks and Learning Systems","prism:issn":"2162237X","prism:eIssn":"21622388","prism:volume":"32","prism:issueIdentifier":"1","prism:pageRange":"457-462","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","prism:doi":"10.1109/TNNLS.2020.2979682","dc:description":"In this article, we analyze algorithmic ways to reduce the arithmetic complexity of calculating quaternion-valued linear convolution and also synthesize a new algorithm for calculating this convolution. During the synthesis of the discussed algorithm, we use the fact that quaternion multiplication may be represented as a matrix-vector product. The matrix participating in the product has unique structural properties that allow performing its advantageous decomposition. Namely, this decomposition leads to reducing the multiplicative complexity of computations. In addition, we used the fact that when calculating the elements of the quaternion-valued convolution, the part of the calculations of all matrix-vector products is common. It gives an additional reduction in the number of additions of real numbers and, consequently, a decrease in the additive complexity of calculations. Thus, the use of the proposed algorithm will contribute to the acceleration of calculations in quaternion-valued convolution neural networks.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60104305","afid":"60104305","affilname":"West Pomeranian University of Technology, Szczecin","affiliation-city":"Szczecin","affiliation-country":"Poland"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60071839","afid":"60071839","affilname":"Technical University of Moldova","affiliation-city":"Chisinau","affiliation-country":"Moldova"}],"pubmed-id":"32275620","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55448045700","authid":"55448045700","orcid":"0000-0002-4513-4593","authname":"Cariow A.","surname":"Cariow","given-name":"Aleksandr","initials":"A.","afid": [{"@_fa": "true", "$" :"60071839"},{"@_fa": "true", "$" :"60104305"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55485269300","authid":"55485269300","orcid":"0000-0002-3859-484X","authname":"Cariowa G.","surname":"Cariowa","given-name":"Galina","initials":"G.","afid": [{"@_fa": "true", "$" :"60104305"}]}],"authkeywords":"Neural networks | quaternions | signal processing algorithms","article-number":"9058993","source-id":"21100235616","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85098961584"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85098961584?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85098961584&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85098961584&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85098961584","dc:identifier":"SCOPUS_ID:85098961584","eid":"2-s2.0-85098961584","dc:title":"Forward and inverse dynamics of a six-axis accelerometer based on a parallel mechanism","dc:creator":"Wang L.","prism:publicationName":"Sensors (Switzerland)","prism:issn":"14248220","prism:volume":"21","prism:issueIdentifier":"1","prism:pageRange":"1-22","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"1 January 2021","prism:doi":"10.3390/s21010233","dc:description":"The solution of the dynamic equations of the six-axis accelerometer is a prerequisite for sensor calibration, structural optimization, and practical application. However, the forward dynamic equations (FDEs) and inverse dynamic equations (IDEs) of this type of system have not been completely solved due to the strongly nonlinear coupling relationship between the inputs and outputs. This article presents a comprehensive study of the FDEs and IDEs of the six-axis accelerometer based on a parallel mechanism. Firstly, two sets of dynamic equations of the sensor are constructed based on the Newton-Euler method in the configuration space. Secondly, based on the analytical solution of the sensor branch chain length, the coordination equation between the output signals of the branch chain is constructed. The FDEs of the sensor are established by combining the coordination equations and two sets of dynamic equations. Furthermore, by introducing generalized momentum and Hamiltonian function and using Legendre transformation, the vibration differential equations (VDEs) of the sensor are derived. The VDEs and Newton-Euler equations constitute the IDEs of the system. Finally, the explicit recursive algorithm for solving the quaternion in the equation is given in the phase space. Then the IDEs are solved by substituting the quaternion into the dynamic equations in the configuration space. The predicted numerical results of the established FDEs and IDEs are verified by comparing with virtual and actual experimental data. The actual experiment shows that the relative errors of the FDEs and the IDEs constructed in this article are 2.21% and 7.65%, respectively. This research provides a new strategy for further improving the practicability of the six-axis accelerometer.","citedby-count":"8","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60025665","afid":"60025665","affilname":"Nanjing Forestry University","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60010080","afid":"60010080","affilname":"Nanjing University of Science and Technology","affiliation-city":"Nanjing","affiliation-country":"China"}],"pubmed-id":"33401430","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57217228375","authid":"57217228375","authname":"Wang L.","surname":"Wang","given-name":"Linkang","initials":"L.","afid": [{"@_fa": "true", "$" :"60025665"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/36706818800","authid":"36706818800","authname":"You J.","surname":"You","given-name":"Jingjing","initials":"J.","afid": [{"@_fa": "true", "$" :"60025665"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56359230900","authid":"56359230900","authname":"Yang X.","surname":"Yang","given-name":"Xiaolong","initials":"X.","afid": [{"@_fa": "true", "$" :"60010080"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57221384159","authid":"57221384159","authname":"Chen H.","surname":"Chen","given-name":"Huaxin","initials":"H.","afid": [{"@_fa": "true", "$" :"60025665"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/56106032400","authid":"56106032400","authname":"Li C.","surname":"Li","given-name":"Chenggang","initials":"C.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/9636573600","authid":"9636573600","authname":"Wu H.","surname":"Wu","given-name":"Hongtao","initials":"H.","afid": [{"@_fa": "true", "$" :"60021666"}]}],"authkeywords":"Decoupling | Forward dynamics | Inverse dynamics | Parallel mechanism | Six-axis accelerometer","article-number":"233","source-id":"130124","fund-acr":"NSFC","fund-no":"51405237","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85098254036"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85098254036?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85098254036&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85098254036&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85098254036","dc:identifier":"SCOPUS_ID:85098254036","eid":"2-s2.0-85098254036","dc:title":"Design of Line-of-Sight Guidance Law and a Constrained Optimal Controller for an Autonomous Underwater Vehicle","dc:creator":"Rout R.","prism:publicationName":"IEEE Transactions on Circuits and Systems II: Express Briefs","prism:issn":"15497747","prism:eIssn":"15583791","prism:volume":"68","prism:issueIdentifier":"1","prism:pageRange":"416-420","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","prism:doi":"10.1109/TCSII.2020.3000597","dc:description":"A line-of-sight (LOS) guidance law with an explicit model predictive control (MPC) is proposed for an underactuated autonomous underwater vehicle (AUV). The derived LOS law is based on quaternion angles thus avoids the problem of singularity inherited in Euler angles. The proposed guidance and control scheme is computationally inexpensive and generates a robust optimal control signal for AUV dynamics. In view of the practical implementation, the constraints on control planes and parametric uncertainties are taken into consideration while designing the proposed control law. The effectiveness of the proposed controller is verified by both simulation and experimentation using a prototype AUV developed in the laboratory. Subsequently, multiple experiments were conducted to ascertain the applicability of the proposed algorithm in a practical scenario.","citedby-count":"18","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60114558","afid":"60114558","affilname":"Indian Institute of Technology Goa","affiliation-city":"Ponda","affiliation-country":"India"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60108737","afid":"60108737","affilname":"Manipal University Jaipur","affiliation-city":"Jaipur","affiliation-country":"India"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57189368307","authid":"57189368307","orcid":"0000-0001-7468-3017","authname":"Rout R.","surname":"Rout","given-name":"Raja","initials":"R.","afid": [{"@_fa": "true", "$" :"60108737"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/24167438300","authid":"24167438300","orcid":"0000-0003-4383-6783","authname":"Subudhi B.","surname":"Subudhi","given-name":"Bidyadhar","initials":"B.","afid": [{"@_fa": "true", "$" :"60114558"}]}],"authkeywords":"actuator constraints | Autonomous underwater vehicle | model predictive controller | multi-parametric quadratic programming","article-number":"9110550","source-id":"9500153930","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097564282"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097564282?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097564282&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097564282&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097564282","dc:identifier":"SCOPUS_ID:85097564282","eid":"2-s2.0-85097564282","dc:title":"Augmented quaternion music method for a uniform/sparse cold array","dc:creator":"Jiang Z.","prism:publicationName":"Progress in Electromagnetics Research Letters","prism:issn":"19376480","prism:volume":"95","prism:pageRange":"25-32","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.2528/PIERL20102303","dc:description":"—The quaternion multiple signal classification (Q-MUSIC) algorithm reduces the dimension of covariance matrix, which would result in performance degrading of DOA estimation. An augmented quaternion MUSIC algorithm (AQ-MUSIC) based on concentered orthogonal loop and dipole (COLD) array is presented in this paper. The proposed algorithm uses an augmented quaternion formalism to model the completely polarized signals, which allows a concise and novel way to an augmented covariance matrix. The fact reveals that more accurate DOA parameters could be extracted from an augmented covariance matrix. Even compared with the long vector MUSIC (LV-MUSIC) algorithm whose dimension of covariance matrix is the same as AQ-MUSIC, the accuracy of DOA parameter estimation is also improved. Simulation results verify the performance promotion of the proposed approach.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60088063","afid":"60088063","affilname":"China Electronic Technology Group Corporation","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60031419","afid":"60031419","affilname":"Ningbo University","affiliation-city":"Ningbo","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/120817950","afid":"120817950","affilname":"Key Laboratory of Intelligent Perception and Advanced Control of State Ethnic Affairs Commission","affiliation-city":"Dalian","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57220744624","authid":"57220744624","authname":"Jiang Z.","surname":"Jiang","given-name":"Zhiwei","initials":"Z.","afid": [{"@_fa": "true", "$" :"60031419"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57216398555","authid":"57216398555","authname":"Zhang Z.","surname":"Zhang","given-name":"Zehao","initials":"Z.","afid": [{"@_fa": "true", "$" :"60031419"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57219005346","authid":"57219005346","authname":"Zhao T.","surname":"Zhao","given-name":"Tianyi","initials":"T.","afid": [{"@_fa": "true", "$" :"60031419"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57141118300","authid":"57141118300","authname":"Chen H.","surname":"Chen","given-name":"Hua","initials":"H.","afid": [{"@_fa": "true", "$" :"60031419"},{"@_fa": "true", "$" :"120817950"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/57209501205","authid":"57209501205","authname":"Wang W.","surname":"Wang","given-name":"Weifeng","initials":"W.","afid": [{"@_fa": "true", "$" :"60088063"}]}],"source-id":"19700186896","fund-acr":"NSFC","fund-no":"IF2020112","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfree2read"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Bronze"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097171972"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85097171972?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85097171972&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85097171972&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85097171972","dc:identifier":"SCOPUS_ID:85097171972","eid":"2-s2.0-85097171972","dc:title":"A novel chaotic block image encryption algorithm based on deep convolutional generative adversarial networks","dc:creator":"Fang P.","prism:publicationName":"IEEE Access","prism:eIssn":"21693536","prism:volume":"9","prism:pageRange":"18497-18517","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"2021","prism:doi":"10.1109/ACCESS.2020.3040573","dc:description":"This paper proposes a novel chaotic block image encryption algorithm based on deep convolutional generative adversarial networks (DCGANs), quaternions, an improved Feistel network, and an overall scrambling and diffusion mechanism. First, a new hyperchaotic system is introduced and combined with DCGANs to generate a random sequence with better randomness and complexity as a key stream. This sequence is then combined with a quaternion and an improved Feistel network encryption of a colour plaintext image by utilizing the key block matrix to ultimately achieve overall scrambling and diffusion of the cipher image. Finally, the security of this algorithm is quantitatively and qualitatively analysed. The simulation results show that the proposed hyperchaotic system has a large key space and good random characteristics and that the new algorithm yields adequate security and can resist brute-force attacks and chosen-plaintext attacks. Therefore, this approach provides a new way to achieve secure transmission and protection of image information.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073708","afid":"60073708","affilname":"Xi'an Institute of Posts and Telecommunications","affiliation-city":"Xi'an","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60026981","afid":"60026981","affilname":"Xi'an University of Technology","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55487486900","authid":"55487486900","orcid":"0000-0003-2739-0996","authname":"Fang P.","surname":"Fang","given-name":"Pengfei","initials":"P.","afid": [{"@_fa": "true", "$" :"60026981"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56177336900","authid":"56177336900","orcid":"0000-0002-6618-1380","authname":"Liu H.","surname":"Liu","given-name":"Han","initials":"H.","afid": [{"@_fa": "true", "$" :"60026981"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/23007220300","authid":"23007220300","orcid":"0000-0002-5881-4723","authname":"Wu C.","surname":"Wu","given-name":"Chengmao","initials":"C.","afid": [{"@_fa": "true", "$" :"60073708"}]}],"authkeywords":"Chaotic system | Deep convolutional generative adversarial networks | Image encryption","article-number":"9269969","source-id":"21100374601","fund-acr":"NSFC","fund-no":"2018ZDXM-GY-089","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85095970675"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85095970675?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85095970675&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85095970675&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S1051200420302232"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85095970675","dc:identifier":"SCOPUS_ID:85095970675","eid":"2-s2.0-85095970675","dc:title":"Novel Octonion Moments for color stereo image analysis","dc:creator":"Yamni M.","prism:publicationName":"Digital Signal Processing: A Review Journal","prism:issn":"10512004","prism:volume":"108","prism:pageRange":null,"prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","prism:doi":"10.1016/j.dsp.2020.102878","pii":"S1051200420302232","dc:description":"This paper proposes a new category of moments for color stereo image description, called Octonion Moments (OMs). These new descriptors are based on the octonion theory and the moment theory, they generalize the classical and quaternion moments. The octonion moments can be used for any six-layer image stack, allowing us to use them to characterize color stereo images in an efficient, compact and holistic way in both intra- and inter-channel color directions. As a result, redundancies between the six channels of a stereo color image can be well exploited. Tchebichef polynomials are used in this paper to construct the corresponding octonion moments called Octonion Radial Tchebichef Moments (ORTMs). Two applications, image reconstruction and image watermarking, are studied to validate the effectiveness of the proposed ORTMs. In the context of image watermarking, we propose a new zero-watermarking algorithm for copyright protection of color stereo images. The image watermarking requirements, namely imperceptibility, robustness, and security are ensured by the proposed algorithm. This algorithm uses the proposed ORTMs to build descriptors that are stable and robust against image processing attacks and invariant to geometric transformations. The experimental results demonstrate the effectiveness of the proposed ORTMs for reconstruction and image watermarking in a comparison to concurrent recent methods based on other types of moments.","citedby-count":"27","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60063843","afid":"60063843","affilname":"Institute of Information Theory and Automation of the Academy of Sciences of the Czech Republic","affiliation-city":"Prague","affiliation-country":"Czech Republic"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024326","afid":"60024326","affilname":"Laboratoire d'Electronique, Signaux, Systèmes et d'Informatique, Université Sidi Mohamed Ben Abdellah","affiliation-city":"Fez","affiliation-country":"Morocco"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017021","afid":"60017021","affilname":"Université Sidi Mohamed Ben Abdellah","affiliation-city":"Fez","affiliation-country":"Morocco"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57207620865","authid":"57207620865","authname":"Yamni M.","surname":"Yamni","given-name":"M.","initials":"M.","afid": [{"@_fa": "true", "$" :"60024326"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57190495161","authid":"57190495161","authname":"Karmouni H.","surname":"Karmouni","given-name":"H.","initials":"H.","afid": [{"@_fa": "true", "$" :"60024326"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55561914300","authid":"55561914300","authname":"Sayyouri M.","surname":"Sayyouri","given-name":"M.","initials":"M.","afid": [{"@_fa": "true", "$" :"60017021"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/12144280900","authid":"12144280900","authname":"Qjidaa H.","surname":"Qjidaa","given-name":"H.","initials":"H.","afid": [{"@_fa": "true", "$" :"60024326"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7004642542","authid":"7004642542","orcid":"0000-0003-3747-9214","authname":"Flusser J.","surname":"Flusser","given-name":"J.","initials":"J.","afid": [{"@_fa": "true", "$" :"60063843"}]}],"authkeywords":"Color stereo image | Image reconstruction | Octonion | Octonion Moments | Radial Tchebichef Moments | Zero-watermarking","article-number":"102878","source-id":"24306","fund-acr":"GA ČR","fund-no":"GA18-07247S","fund-sponsor":"Grantová Agentura České Republiky","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85091727059"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/85091727059?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85091727059&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85091727059&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/85091727059","dc:identifier":"SCOPUS_ID:85091727059","eid":"2-s2.0-85091727059","dc:title":"Efficient HEVC steganography approach based on audio compression and encryption in QFFT domain for secure multimedia communication","dc:creator":"Soliman N.F.","prism:publicationName":"Multimedia Tools and Applications","prism:issn":"13807501","prism:eIssn":"15737721","prism:volume":"80","prism:issueIdentifier":"3","prism:pageRange":"4789-4823","prism:coverDate":"2021-01-01","prism:coverDisplayDate":"January 2021","prism:doi":"10.1007/s11042-020-09881-8","dc:description":"High-Efficiency Video Coding (HEVC) is the most recent video codec standard. It is substantial to analyze the HEVC steganography process due to its practical and academic significance. Thus, a secure HEVC steganography approach is introduced in this paper to study the possibility of hiding an encrypted secret audio message within a cover compressed video frame in a secure and complicated manner. In the preliminary stage, the secret audio message is compressed utilizing the Discrete Cosine Transform (DCT) to achieve a high capacity performance for the HEVC steganography process. After that, the suggested approach implies two-cascaded encryption layers to encrypt the compressed secret message before embedding it within a cover HEVC frame. In the first encryption layer, a novel encryption technique based on random projection and Legendre sequence in the Discrete Wavelet Transform (DWT) domain is introduced to cipher the compressed secret audio message. In the second encryption layer, the yielded encrypted audio message is represented in a form of quaternion numbers using the Quaternion Fast Fourier Transform (QFFT) technique. Each cover HEVC frame is also represented in a quaternion form. In the suggested approach, some straightforward quaternion mathematical operations are employed on the encrypted secret message and the cover HEVC frames to represent them in a quaternion form in the frequency domain, then the encrypted secret audio message is hidden within the cover HEVC frame. At the receiver, the secret message can be retrieved and extracted from the cover HEVC frame utilizing the same methodology of the employed quaternion mathematical operations. The major contributions of the suggested HEVC steganography scheme are: (1) it allows hiding of massive amount of secret information within cover video frames, and (2) it has higher robustness against multimedia attacks and steganalysis contrasted to the conventional and literature schemes. Furthermore, the proposed approach is evaluated utilizing different assessment metrics like Feature Similarity Index Measure (FSIM), Peak Signal-to-Noise Ratio (PSNR), correlation coefficient, and Structural Similarity Index Measure (SSIM) to evaluate the efficiency of the stego HEVC frames compared to the original ones. The achieved outcomes demonstrate that the suggested steganography scheme is straightforward to implement, more secure, and robust in the presence of steganalysis multimedia attacks compared to the literature approaches.","citedby-count":"28","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60274154","afid":"60274154","affilname":"Faculty of Engineering","affiliation-city":"Zagazig","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60250886","afid":"60250886","affilname":"Faculty of Engineering in Shubra","affiliation-city":"Cairo","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105146","afid":"60105146","affilname":"Princess Nourah Bint Abdulrahman University","affiliation-city":"Riyadh","affiliation-country":"Saudi Arabia"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60026365","afid":"60026365","affilname":"Faculty of Science","affiliation-city":"Giza","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023589","afid":"60023589","affilname":"Nuclear Research Center","affiliation-city":"Cairo","affiliation-country":"Egypt"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003419","afid":"60003419","affilname":"Faculty of Electronic Engineering","affiliation-city":"Shibin El Kom","affiliation-country":"Egypt"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "6", "$" :"6"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7003625335","authid":"7003625335","authname":"Soliman N.F.","surname":"Soliman","given-name":"Naglaa F.","initials":"N.F.","afid": [{"@_fa": "true", "$" :"60105146"},{"@_fa": "true", "$" :"60274154"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57195264555","authid":"57195264555","authname":"Khalil M.I.","surname":"Khalil","given-name":"M. I.","initials":"M.I.","afid": [{"@_fa": "true", "$" :"60023589"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57204971671","authid":"57204971671","authname":"Algarni A.D.","surname":"Algarni","given-name":"Abeer D.","initials":"A.D.","afid": [{"@_fa": "true", "$" :"60105146"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57219218104","authid":"57219218104","authname":"Ismail S.","surname":"Ismail","given-name":"Sahar","initials":"S.","afid": [{"@_fa": "true", "$" :"60105146"},{"@_fa": "true", "$" :"60250886"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/35749022100","authid":"35749022100","authname":"Marzouk R.","surname":"Marzouk","given-name":"Radwa","initials":"R.","afid": [{"@_fa": "true", "$" :"60105146"},{"@_fa": "true", "$" :"60026365"}]},{"@_fa": "true", "@seq": "6", "author-url":"https://api.elsevier.com/content/author/author_id/55819860600","authid":"55819860600","authname":"El-Shafai W.","surname":"El-Shafai","given-name":"Walid","initials":"W.","afid": [{"@_fa": "true", "$" :"60003419"}]}],"authkeywords":"DCT | DWT | HEVC steganography | Legendre sequence | QFFT | Quaternion mathematics | Random projection","source-id":"25627","fund-no":"39/S/250","openaccess":"0","openaccessFlag":false}]}}