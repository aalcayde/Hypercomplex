{"search-results":{"opensearch:totalResults":"166","opensearch:startIndex":"100","opensearch:itemsPerPage":"25","opensearch:Query":{"@role": "request", "@searchTerms": "TITLE-ABS-KEY ( hypercomplex OR hyper-complex OR hipercomplex OR quaternions OR octonions OR quaternionic ) AND TITLE-ABS-KEY ( signal OR image )", "@startPage": "100"},"link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/search/scopus?start=100&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "first", "@href": "https://api.elsevier.com/content/search/scopus?start=0&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "prev", "@href": "https://api.elsevier.com/content/search/scopus?start=75&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "next", "@href": "https://api.elsevier.com/content/search/scopus?start=125&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"},{"@_fa": "true", "@ref": "last", "@href": "https://api.elsevier.com/content/search/scopus?start=141&count=25&query=TITLE-ABS-KEY+%28+hypercomplex+OR+hyper-complex+OR+hipercomplex+OR+quaternions+OR+octonions+OR+quaternionic+%29+AND+TITLE-ABS-KEY+%28+signal+OR+image+%29&date=2013&sort=+pubyear&view=complete", "@type": "application/json"}],"entry": [{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875707526"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875707526?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84875707526&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84875707526&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84875707526","dc:identifier":"SCOPUS_ID:84875707526","eid":"2-s2.0-84875707526","dc:title":"User-parameter-free robust adaptive beamforming algorithm for vector-sensor arrays within the hypercomplex framework","dc:creator":"Gou X.","prism:publicationName":"Journal of Electrical Engineering","prism:issn":"13353632","prism:volume":"64","prism:issueIdentifier":"2","prism:pageRange":"100-105","prism:coverDate":"2013-04-08","prism:coverDisplayDate":"2013","prism:doi":"10.2478/jee-2013-0014","dc:description":"The major flaw of the conventional diagonal loading (DL) method is that it is unclear to choose appropriate DL levels or user-parameters (UPs), though several remarkable contributions have been made to regularize model errors without UPs. An UP-free algorithm for two-component vector-sensor arrays, which is robust to steering vector errors, is considered. The algorithm is within the hypercomplex framework using quaternions, and the optimal solution is found at the maximal correlation between the quaternionic and complex outputs. The performance of the proposed beamformer is illustrated via numerical simulations and is compared with several other UP-free adaptive beamformers.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55286422100","authid":"55286422100","authname":"Gou X.","surname":"Gou","given-name":"Xiaoming","initials":"X.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57192586797","authid":"57192586797","authname":"Liu Z.","surname":"Liu","given-name":"Zhiwen","initials":"Z.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55639112100","authid":"55639112100","authname":"Ma J.","surname":"Ma","given-name":"Jingyan","initials":"J.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/16320275100","authid":"16320275100","authname":"Xu Y.","surname":"Xu","given-name":"Yougen","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"}]}],"authkeywords":"Array signal processing | Quaternion | Robust adaptive beamforming | User-parameter-free | Vector-sensor","source-id":"4000151606","fund-acr":"NSFC","fund-no":"61072098","fund-sponsor":"National Natural Science Foundation of China","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875603944"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875603944?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84875603944&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84875603944&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84875603944","dc:identifier":"SCOPUS_ID:84875603944","eid":"2-s2.0-84875603944","dc:title":"Automatic region-of-interest detection and prioritisation for visually optimised coding of low bit rate videos","dc:creator":"Himawan I.","prism:publicationName":"Proceedings of IEEE Workshop on Applications of Computer Vision","prism:issn":"21583978","prism:eIssn":"21583986","prism:isbn": [{"@_fa": "true", "$" :"9781467350532"}],"prism:pageRange":"76-82","prism:coverDate":"2013-04-04","prism:coverDisplayDate":"2013","prism:doi":"10.1109/WACV.2013.6475002","dc:description":"The increasing popularity of video consumption from mobile devices requires an effective video coding strategy. To overcome diverse communication networks, video services often need to maintain sustainable quality when the available bandwidth is limited. One of the strategy for a visually-optimised video adaptation is by implementing a region-of-interest (ROI) based scalability, whereby important regions can be encoded at a higher quality while maintaining sufficient quality for the rest of the frame. The result is an improved perceived quality at the same bit rate as normal encoding, which is particularly obvious at the range of lower bit rate. However, because of the difficulties of predicting region-of-interest (ROI) accurately, there is a limited research and development of ROI-based video coding for general videos. In this paper, the phase spectrum quaternion of Fourier Transform (PQFT) method is adopted to determine the ROI. To improve the results of ROI detection, the saliency map from the PQFT is augmented with maps created from high level knowledge of factors that are known to attract human attention. Hence, maps that locate faces and emphasise the centre of the screen are used in combination with the saliency map to determine the ROI. The contribution of this paper lies on the automatic ROI detection technique for coding a low bit rate videos which include the ROI prioritisation technique to give different level of encoding qualities for multiple ROIs, and the evaluation of the proposed automatic ROI detection that is shown to have a close performance to human ROI, based on the eye fixation data. Â© 2013 IEEE.","citedby-count":"7","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011019","afid":"60011019","affilname":"Queensland University of Technology","affiliation-city":"Brisbane","affiliation-country":"Australia"}],"prism:aggregationType":"Conference Proceeding","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/23967723700","authid":"23967723700","authname":"Himawan I.","surname":"Himawan","given-name":"Ivan","initials":"I.","afid": [{"@_fa": "true", "$" :"60011019"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57191748664","authid":"57191748664","authname":"Song W.","surname":"Song","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60011019"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6507586021","authid":"6507586021","authname":"Tjondronegoro D.","surname":"Tjondronegoro","given-name":"Dian","initials":"D.","afid": [{"@_fa": "true", "$" :"60011019"}]}],"article-number":"6475002","source-id":"21100201913","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84893399419"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84893399419?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84893399419&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84893399419&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84893399419","dc:identifier":"SCOPUS_ID:84893399419","eid":"2-s2.0-84893399419","dc:title":"The collineations which act as addition and multiplication on points in a certain class of projective Klingenberg planes","dc:creator":"Celik B.","prism:publicationName":"Journal of Inequalities and Applications","prism:issn":"10255834","prism:eIssn":"1029242X","prism:volume":"2013","prism:pageRange":null,"prism:coverDate":"2013-04-01","prism:coverDisplayDate":"April 2013","prism:doi":"10.1186/1029-242X-2013-193","dc:description":"Let PK2 (Q(Îµ)) be the projective Klingenberg plane coordinated by the dual quaternion ring Q (Îµ) = Q + QÎµ = {x + yÎµ | x , y â Q} where Q is any quaternion ring. In this paper, we determine the addition and multiplication of the points on the line [0, 1, 0] of PK 2 (Q(Îµ)) as the image of some collineations of the plane PK 2 (Q(Îµ)). To do this, we give the collineations Sa and La. Later we show that the addition and multiplication of the nonneighbor points on the line [0, 1, 0] can be obtained as the images under that Sa and La. Â© 2013 Celik and Dayioglu; licensee Springer.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009425","afid":"60009425","affilname":"Bursa UludaÄ Ãniversitesi","affiliation-city":"Bursa","affiliation-country":"Turkey"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/23026643900","authid":"23026643900","authname":"Celik B.","surname":"Celik","given-name":"Basri","initials":"B.","afid": [{"@_fa": "true", "$" :"60009425"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/54402697300","authid":"54402697300","authname":"Dayioglu A.","surname":"Dayioglu","given-name":"Abdurrahman","initials":"A.","afid": [{"@_fa": "true", "$" :"60009425"}]}],"authkeywords":"Collineations | Division ring | Local ring | Projective Klingenberg planes","article-number":"193","source-id":"61774","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879765297"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879765297?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84879765297&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84879765297&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84879765297","dc:identifier":"SCOPUS_ID:84879765297","eid":"2-s2.0-84879765297","dc:title":"Generalized fractional differentiation and its applications","dc:creator":"Gao C.","prism:publicationName":"Journal of Computational and Theoretical Nanoscience","prism:issn":"15461955","prism:eIssn":"15461963","prism:volume":"10","prism:issueIdentifier":"4","prism:pageRange":"867-883","prism:coverDate":"2013-04-01","prism:coverDisplayDate":"April 2013","prism:doi":"10.1166/jctn.2013.2783","dc:description":"According to the development of the real fractional differentiation and its applications in the modern signal processing, we extend it to quaternion field and put forward a new concept, quaternion fractional directional differentiation, QFDD for short, and corresponding theories. To achieve the numerical calculation, we deduce two algorithms, QFDD1 algorithm and QFDD2 algorithm, and discuss their numerical computation rules for a digital image. Finally, we apply this new theory to enhance images and transform color images into gray-scale images. Experiments show that, for texture-rich digital images, the capability of nonlinearly enhancing image by QFDD algorithms is very obvious. For quantity analysis, we particularly take the five classical parameters from gray level cooccurrence matrix, which are angle matrix, contrast, correlation, energy and homogeneity, calculate information entropy and average gradient, draw the graphics of power spectrum and take also the vertical projection of gray-level. By these evaluating indicators, the effect of image enhancement by QFDD algorithms is evident. In addition, we give a new method of color to gray, QFDD algorithms. Compared with photoshop, the gray image obtained by QFDD algorithms is clearer. Copyright Â© 2013 American Scientific Publishers All rights reserved.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60102085","afid":"60102085","affilname":"Chengdu University","affiliation-city":"Chengdu","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016521","afid":"60016521","affilname":"Sichuan University","affiliation-city":"Chengdu","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/109996460","afid":"109996460","affilname":"Key Laboratory of Pattern Recognition and Intelligent Information Processing","affiliation-city":"Chengdu","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/24400876000","authid":"24400876000","authname":"Gao C.","surname":"Gao","given-name":"Chaobang","initials":"C.","afid": [{"@_fa": "true", "$" :"60102085"},{"@_fa": "true", "$" :"109996460"},{"@_fa": "true", "$" :"60016521"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/21234416400","authid":"21234416400","authname":"Zhou J.","surname":"Zhou","given-name":"Jiliu","initials":"J.","afid": [{"@_fa": "true", "$" :"109996460"},{"@_fa": "true", "$" :"60016521"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56151308100","authid":"56151308100","authname":"Zhang W.","surname":"Zhang","given-name":"Weihua","initials":"W.","afid": [{"@_fa": "true", "$" :"60016521"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/23097746600","authid":"23097746600","authname":"Gong M.","surname":"Gong","given-name":"Mei","initials":"M.","afid": [{"@_fa": "true", "$" :"60016521"}]}],"authkeywords":"Average gradient | Gray level co-occurrence matrix | Information entropy | Power spectrum | QFDD algorithms","source-id":"28136","fund-acr":"NSFC","fund-no":"60773168","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877042362"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877042362?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84877042362&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84877042362&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84877042362","dc:identifier":"SCOPUS_ID:84877042362","eid":"2-s2.0-84877042362","dc:title":"A multi-scale threshold local binary pattern in quaternion wavelet transform domain for face recognition","dc:creator":"Xu Y.","prism:publicationName":"Journal of Computational Information Systems","prism:issn":"15539105","prism:volume":"9","prism:issueIdentifier":"7","prism:pageRange":"2881-2888","prism:coverDate":"2013-04-01","prism:coverDisplayDate":"1 April 2013","dc:description":"In this paper, a novel face recognition method based on a multi-scale threshold local binary pattern in quaternion wavelet transform domain is proposed. The QWT is a new multi-scale analysis tool for geometric image features. The LBP operator is one of the best performing texture descriptors. However, the principal information, such as the shape and position of eyes, nose, mouth and son on, and non-principal information coming form the skin line, noise, facial expression and A/D transformation error usually, are treated equally. In this paper, The Threshold LBP is proposed, which get principal information and ignore non-principal information. These quaternion magnitude and phases are combined, and then multi-scale Threshold LBP features are extracted. We transform distance of a magnitude and three phases to a order of magnitude and chi-square distance is for classify. Experiment results on several databases confirm the effectiveness of this method. Copyright Â© 2013 Binary Information Press.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021182","afid":"60021182","affilname":"Sun Yat-Sen University","affiliation-city":"Guangzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018465","afid":"60018465","affilname":"Yanshan University","affiliation-city":"Qinhuangdao","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/23062484300","authid":"23062484300","authname":"Xu Y.","surname":"Xu","given-name":"Yonghong","initials":"Y.","afid": [{"@_fa": "true", "$" :"60018465"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55673193900","authid":"55673193900","authname":"Liu B.","surname":"Liu","given-name":"Bosheng","initials":"B.","afid": [{"@_fa": "true", "$" :"60018465"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/54585241400","authid":"54585241400","authname":"Hou J.","surname":"Hou","given-name":"Jing","initials":"J.","afid": [{"@_fa": "true", "$" :"60021182"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7401528170","authid":"7401528170","authname":"Hong W.","surname":"Hong","given-name":"Wenxue","initials":"W.","afid": [{"@_fa": "true", "$" :"60018465"}]}],"authkeywords":"Face recognition | Magnitude/phase features | Multi-scale LBP | Quaternion wavelet transform | Threshold LBP","source-id":"145341","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84871385881"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84871385881?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84871385881&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84871385881&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165168412003726"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84871385881","dc:identifier":"SCOPUS_ID:84871385881","eid":"2-s2.0-84871385881","dc:title":"Biquaternion cumulant-MUSIC for DOA estimation of noncircular signals","dc:creator":"Gou X.","prism:publicationName":"Signal Processing","prism:issn":"01651684","prism:volume":"93","prism:issueIdentifier":"4","prism:pageRange":"874-881","prism:coverDate":"2013-04-01","prism:coverDisplayDate":"April 2013","prism:doi":"10.1016/j.sigpro.2012.10.010","pii":"S0165168412003726","dc:description":"Direction-of-arrival (DOA) estimation for noncircular sources is addressed within the hypercomplex framework utilizing fourth-order (FO) cumulants and a MUSIC-like estimator is proposed. Simulation results show the better performance of the proposed method compared to its complex counterpart in terms of both accuracy and robustness to model errors due to the stronger orthogonality in the biquaternion domain. Â© 2012 Elsevier B.V. All rights reserved.","citedby-count":"21","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016835","afid":"60016835","affilname":"Beijing Institute of Technology","affiliation-city":"Beijing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55286422100","authid":"55286422100","authname":"Gou X.","surname":"Gou","given-name":"Xiaoming","initials":"X.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57192586797","authid":"57192586797","authname":"Liu Z.","surname":"Liu","given-name":"Zhiwen","initials":"Z.","afid": [{"@_fa": "true", "$" :"60016835"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/16320275100","authid":"16320275100","authname":"Xu Y.","surname":"Xu","given-name":"Yougen","initials":"Y.","afid": [{"@_fa": "true", "$" :"60016835"}]}],"authkeywords":"Adaptive array | Array signal processing | Direction-of-arrival estimation","source-id":"25548","fund-acr":"NSFC","fund-no":"61072098","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879045792"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879045792?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84879045792&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84879045792&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84879045792","dc:identifier":"SCOPUS_ID:84879045792","eid":"2-s2.0-84879045792","dc:title":"Unscented Kalman filter based sensor fusion for robust optical and electromagnetic tracking in surgical navigation","dc:creator":"Vaccarella A.","prism:publicationName":"IEEE Transactions on Instrumentation and Measurement","prism:issn":"00189456","prism:volume":"62","prism:issueIdentifier":"7","prism:pageRange":"2067-2081","prism:coverDate":"2013-03-26","prism:coverDisplayDate":"2013","prism:doi":"10.1109/TIM.2013.2248304","dc:description":"Computer-aided surgery systems provide visual guidance to surgeons by showing the real-time pose of surgical instruments overlaid on preoperative medical images of the patient. Surgical instrument poses are localized in space using mainly optical tracking systems (OTS) and electromagnetic tracking systems (EMTS). OTS systems require clear line-of-sight, which is difficult to ensure in current overcrowded operating rooms. On the other hand, EMTSs provide less accuracy and suffer from magnetic field distortion in the presence of metal objects. In this paper, we propose a sensor fusion algorithm to compensate for the drawbacks of OTS and EMTS, and achieve robust tracking of surgical instruments. Spatial alignment of OTS and EMTS data will be achieved through a calibration procedure. The proposed sensor fusion algorithm uses an unscented Kalman filter (UKF), an extension of the standard Kalman filter based on a deterministic sampling of nonlinear functions. Quaternion representation for rotations is used to avoid singularities of other parameterizations (e.g., Euler angles). In cases of optical marker occlusion, our algorithm will take advantage of the EMTS to estimate the position of the hidden marker(s) and feed it in the UKF. The fusion algorithm will also keep track of an error matrix between OTS and EMTS measured poses, providing an up-to-date estimate of the electromagnetic distortion. This will be used to correct EMTS measurement before using it to compensate for possible optical line-of-sight occlusions. The proposed sensor fusion (SF) method is compared to a predictive UKF based on optical data (NSF). Our results show that the SF effectively compensates for short marker occlusion (nine samples) providing a continuous estimate of the instrument pose with an error significantly lower than the NSF method, and reaching a clinically acceptable accuracy. Furthermore, the proposed algorithm increases the accuracy of EMTS in the presence of magnetic field distortion. Â© 1963-2012 IEEE.","citedby-count":"63","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60114004","afid":"60114004","affilname":"Kitware, Inc.","affiliation-city":"Clifton Park","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60023256","afid":"60023256","affilname":"Politecnico di Milano","affiliation-city":"Milan","affiliation-country":"Italy"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021199","afid":"60021199","affilname":"Consiglio Nazionale delle Ricerche","affiliation-city":"Rome","affiliation-country":"Italy"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "4", "$" :"4"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/54418169900","authid":"54418169900","authname":"Vaccarella A.","surname":"Vaccarella","given-name":"Alberto","initials":"A.","afid": [{"@_fa": "true", "$" :"60023256"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/57203951877","authid":"57203951877","authname":"De Momi E.","surname":"De Momi","given-name":"Elena","initials":"E.","afid": [{"@_fa": "true", "$" :"60023256"},{"@_fa": "true", "$" :"60021199"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7801316765","authid":"7801316765","authname":"Enquobahrie A.","surname":"Enquobahrie","given-name":"Andinet","initials":"A.","afid": [{"@_fa": "true", "$" :"60114004"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7005615860","authid":"7005615860","authname":"Ferrigno G.","surname":"Ferrigno","given-name":"Giancarlo","initials":"G.","afid": [{"@_fa": "true", "$" :"60023256"}]}],"authkeywords":"K/Kalman filtering | N/Navigation | O/Optical tracking | S/Surgery | T/Tracking filters","article-number":"6481446","source-id":"15361","fund-acr":"FP7","fund-no":"270460","fund-sponsor":"Seventh Framework Programme","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874981312"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874981312?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84874981312&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84874981312&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84874981312","dc:identifier":"SCOPUS_ID:84874981312","eid":"2-s2.0-84874981312","dc:title":"An adaptive-gain complementary filter for real-time human motion tracking with MARG sensors in free-living environments","dc:creator":"Tian Y.","prism:publicationName":"IEEE Transactions on Neural Systems and Rehabilitation Engineering","prism:issn":"15344320","prism:volume":"21","prism:issueIdentifier":"2","prism:pageRange":"254-264","prism:coverDate":"2013-03-19","prism:coverDisplayDate":"2013","prism:doi":"10.1109/TNSRE.2012.2205706","dc:description":"High-resolution, real-time data obtained by human motion tracking systems can be used for gait analysis, which helps better understanding the cause of many diseases for more effective treatments, such as rehabilitation for outpatients or recovery from lost motor functions after a stroke. In order to achieve real-time ambulatory human motion tracking with low-cost MARG (magnetic, angular rate, and gravity) sensors, a computationally efficient and robust algorithm for orientation estimation is critical. This paper presents an analytically derived method for an adaptive-gain complementary filter based on the convergence rate from the Gauss-Newton optimization algorithm (GNA) and the divergence rate from the gyroscope, which is referred as adaptive-gain orientation filter (AGOF) in this paper. The AGOF has the advantages of one iteration calculation to reduce the computing load and accurate estimation of gyroscope measurement error. Moreover, for handling magnetic distortions especially in indoor environments and movements with excessive acceleration, adaptive measurement vectors and a reference vector for earth's magnetic field selection schemes are introduced to help the GNA find more accurate direction of gyroscope error. The features of this approach include the accurate estimation of the gyroscope bias to correct the instantaneous gyroscope measurements and robust estimation in conditions of fast motions and magnetic distortions. Experimental results are presented to verify the performance of the proposed method, which shows better accuracy of orientation estimation than several well-known methods. Â© 2001-2011 IEEE.","citedby-count":"100","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60083498","afid":"60083498","affilname":"Shandong Jianzhu University","affiliation-city":"Jinan","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016536","afid":"60016536","affilname":"Michigan Technological University","affiliation-city":"Houghton","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015574","afid":"60015574","affilname":"The University of Tennessee, Knoxville","affiliation-city":"Knoxville","affiliation-country":"United States"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013789","afid":"60013789","affilname":"Beihang University","affiliation-city":"Beijing","affiliation-country":"China"}],"pubmed-id":"22801527","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55517043100","authid":"55517043100","authname":"Tian Y.","surname":"Tian","given-name":"Ya","initials":"Y.","afid": [{"@_fa": "true", "$" :"60083498"},{"@_fa": "true", "$" :"60016536"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8202764500","authid":"8202764500","authname":"Wei H.","surname":"Wei","given-name":"Hongxing","initials":"H.","afid": [{"@_fa": "true", "$" :"60013789"},{"@_fa": "true", "$" :"60016536"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7402302766","authid":"7402302766","authname":"Tan J.","surname":"Tan","given-name":"Jindong","initials":"J.","afid": [{"@_fa": "true", "$" :"60015574"}]}],"authkeywords":"Adaptive-gain complementary filter | Gauss-Newton optimization algorithm (GNA) | human motion capture (MoCap) | magnetic, angular rate and gravity (MARG) sensors | quaternion-based orientation","article-number":"6237648","source-id":"16321","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874711384"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874711384?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84874711384&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84874711384&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84874711384","dc:identifier":"SCOPUS_ID:84874711384","eid":"2-s2.0-84874711384","dc:title":"Perspective projection based on quaternion interpolation","dc:creator":"Xing Y.","prism:publicationName":"Applied Mechanics and Materials","prism:issn":"16609336","prism:eIssn":"16627482","prism:isbn": [{"@_fa": "true", "$" :"9783037856529"}],"prism:volume":"303-306","prism:pageRange":"2130-2133","prism:coverDate":"2013-03-12","prism:coverDisplayDate":"2013","prism:doi":"10.4028/www.scientific.net/AMM.303-306.2130","dc:description":"Quaternion sandwiching formula to compute perspective projections has been given by Ron Goldman in an article titled \"Understanding quaternions\". In this paper, we applied this method to obtain perspective images of 3D objects, and proposed a modified method to interpolate two projection planes with different directions and distances from eye point to acquire an intermediate viewing plane. Experimental results show that our interpolation method improves the disadvantage of uneven movement speed when quaternion SLERP method is directly adopted. Â© (2013) Trans Tech Publications, Switzerland.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021070","afid":"60021070","affilname":"Anhui University of Chinese Medicine","affiliation-city":"Hefei","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002836","afid":"60002836","affilname":"Hefei University of Technology","affiliation-city":"Hefei","affiliation-country":"China"}],"prism:aggregationType":"Book Series","subtype":"cp","subtypeDescription":"Conference Paper","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55168153000","authid":"55168153000","authname":"Xing Y.","surname":"Xing","given-name":"Yan","initials":"Y.","afid": [{"@_fa": "true", "$" :"60002836"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55863909600","authid":"55863909600","authname":"Tan J.","surname":"Tan","given-name":"Jieqing","initials":"J.","afid": [{"@_fa": "true", "$" :"60002836"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7102301623","authid":"7102301623","authname":"Hong P.","surname":"Hong","given-name":"Peilin","initials":"P.","afid": [{"@_fa": "true", "$" :"60021070"}]}],"authkeywords":"Perspective projection | Quaternion | Slerp","source-id":"4700151914","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874583935"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874583935?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84874583935&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84874583935&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84874583935","dc:identifier":"SCOPUS_ID:84874583935","eid":"2-s2.0-84874583935","dc:title":"Matrix-valued and quaternion wavelets","dc:creator":"Ginzberg P.","prism:publicationName":"IEEE Transactions on Signal Processing","prism:issn":"1053587X","prism:volume":"61","prism:issueIdentifier":"6","prism:pageRange":"1357-1367","prism:coverDate":"2013-03-11","prism:coverDisplayDate":"2013","prism:doi":"10.1109/TSP.2012.2235434","dc:description":"Wavelet transforms using matrix-valued wavelets (MVWs) can process the components of vector-valued signals jointly. We construct some novel families of non-trivial orthogonal n Ã n MVWs for n=2 and 4 having several vanishing moments. Some useful uniqueness and non-existence results for filters with certain lengths and numbers of vanishing moments are proved. The matrix-based method for n=4 is used for the construction of a non-trivial symmetric quaternion wavelet with compact support. This is an important addition to the literature where existing quaternion wavelet designs suffer from some critical problems. Â© 2012 IEEE.","citedby-count":"19","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60015150","afid":"60015150","affilname":"Imperial College London","affiliation-city":"London","affiliation-country":"United Kingdom"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/40461292500","authid":"40461292500","authname":"Ginzberg P.","surname":"Ginzberg","given-name":"P.","initials":"P.","afid": [{"@_fa": "true", "$" :"60015150"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7006445598","authid":"7006445598","authname":"Walden A.","surname":"Walden","given-name":"A. T.","initials":"A.T.","afid": [{"@_fa": "true", "$" :"60015150"}]}],"authkeywords":"Matrix-valued wavelet | multichannel wavelet | multiwavelet | quaternion wavelet | vector-valued wavelet","article-number":"6387623","source-id":"17391","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874537215"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874537215?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84874537215&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84874537215&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84874537215","dc:identifier":"SCOPUS_ID:84874537215","eid":"2-s2.0-84874537215","dc:title":"Visual saliency based on scale-space analysis in the frequency domain","dc:creator":"Li J.","prism:publicationName":"IEEE Transactions on Pattern Analysis and Machine Intelligence","prism:issn":"01628828","prism:volume":"35","prism:issueIdentifier":"4","prism:pageRange":"996-1010","prism:coverDate":"2013-03-07","prism:coverDisplayDate":"2013","prism:doi":"10.1109/TPAMI.2012.147","dc:description":"We address the issue of visual saliency from three perspectives. First, we consider saliency detection as a frequency domain analysis problem. Second, we achieve this by employing the concept of nonsaliency. Third, we simultaneously consider the detection of salient regions of different size. The paper proposes a new bottom-up paradigm for detecting visual saliency, characterized by a scale-space analysis of the amplitude spectrum of natural images. We show that the convolution of the image amplitude spectrum with a low-pass Gaussian kernel of an appropriate scale is equivalent to an image saliency detector. The saliency map is obtained by reconstructing the 2D signal using the original phase and the amplitude spectrum, filtered at a scale selected by minimizing saliency map entropy. A Hypercomplex Fourier Transform performs the analysis in the frequency domain. Using available databases, we demonstrate experimentally that the proposed model can predict human fixation data. We also introduce a new image database and use it to show that the saliency detector can highlight both small and large salient regions, as well as inhibit repeated distractors in cluttered images. In addition, we show that it is able to predict salient regions on which people focus their attention. Â© 1979-2012 IEEE.","citedby-count":"503","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60024350","afid":"60024350","affilname":"National University of Defense Technology China","affiliation-city":"Changsha","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60002494","afid":"60002494","affilname":"UniversitÃ© McGill","affiliation-city":"Montreal","affiliation-country":"Canada"}],"pubmed-id":"22802112","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55910561300","authid":"55910561300","authname":"Li J.","surname":"Li","given-name":"Jian","initials":"J.","afid": [{"@_fa": "true", "$" :"60024350"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7404035243","authid":"7404035243","authname":"Levine M.D.","surname":"Levine","given-name":"Martin D.","initials":"M.D.","afid": [{"@_fa": "true", "$" :"60002494"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/15623271900","authid":"15623271900","authname":"An X.","surname":"An","given-name":"Xiangjing","initials":"X.","afid": [{"@_fa": "true", "$" :"60024350"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57071888700","authid":"57071888700","authname":"Xu X.","surname":"Xu","given-name":"Xin","initials":"X.","afid": [{"@_fa": "true", "$" :"60024350"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/34769709600","authid":"34769709600","authname":"He H.","surname":"He","given-name":"Hangen","initials":"H.","afid": [{"@_fa": "true", "$" :"60024350"}]}],"authkeywords":"eye tracking | hypercomplex Fourier transform | saliency | scale space analysis | Visual attention","article-number":"6243147","source-id":"24254","fund-no":"undefined","openaccess":"0","openaccessFlag":false,"freetoread":{"value": [{"$" :"all"},{"$" :"repository"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84873865004"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84873865004?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84873865004&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84873865004&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0165027012004840"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84873865004","dc:identifier":"SCOPUS_ID:84873865004","eid":"2-s2.0-84873865004","dc:title":"Multistage histopathological image segmentation of Iba1-stained murine microglias in a focal ischemia model: Methodological workflow and expert validation","dc:creator":"Valous N.A.","prism:publicationName":"Journal of Neuroscience Methods","prism:issn":"01650270","prism:eIssn":"1872678X","prism:volume":"213","prism:issueIdentifier":"2","prism:pageRange":"250-262","prism:coverDate":"2013-03-05","prism:coverDisplayDate":"5 March 2013","prism:doi":"10.1016/j.jneumeth.2012.12.017","pii":"S0165027012004840","dc:description":"A multistage workflow was developed for segmenting and counting murine microglias from histopathological brightfield images, in a permanent focal cerebral ischemia model. Automated counts are useful, since for the assessment of inflammatory mechanisms in ischemic stroke there is a need to quantify the brain's responses to post-ischemia, which primarily is the rapid activation of microglial cells. Permanent middle cerebral artery occlusion was induced in murine brain tissue samples. Positive cells were quantified by immunohistochemistry for the ionized calcium-binding adaptor molecule-1 (Iba1) as the microglia marker. Microglia cells were segmented in seven sequential steps: (i) contrast boosting using quaternion operations, (ii) intensity outlier normalization, (iii) nonlocal total variation denoising, (iv) histogram specification and contrast stretching, (v) homomorphic filtering, (vi) global thresholding, and (vii) morphological filtering. Workflow counts were validated on an image subset, with ground-truth data acquired from manual counts conducted by a neuropathologist. Automated workflow matched ground-truth counts pretty well; 80-90% accuracy was achieved, as regards to time after pMCAO and correspondence to ischemic/non-ischemic tissue. Â© 2013 Elsevier B.V.","citedby-count":"17","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60016908","afid":"60016908","affilname":"UniversitÃ¤t Heidelberg","affiliation-city":"Heidelberg","affiliation-country":"Germany"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60003280","afid":"60003280","affilname":"UniversitÃ¤tsklinikum Heidelberg","affiliation-city":"Heidelberg","affiliation-country":"Germany"}],"pubmed-id":"23274945","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/24605434500","authid":"24605434500","authname":"Valous N.A.","surname":"Valous","given-name":"Nektarios A.","initials":"N.A.","afid": [{"@_fa": "true", "$" :"60016908"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35731632600","authid":"35731632600","authname":"Lahrmann B.","surname":"Lahrmann","given-name":"Bernd","initials":"B.","afid": [{"@_fa": "true", "$" :"60016908"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/56441885800","authid":"56441885800","authname":"Zhou W.","surname":"Zhou","given-name":"Wei","initials":"W.","afid": [{"@_fa": "true", "$" :"60003280"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7003421643","authid":"7003421643","authname":"Veltkamp R.","surname":"Veltkamp","given-name":"Roland","initials":"R.","afid": [{"@_fa": "true", "$" :"60003280"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/23018837200","authid":"23018837200","authname":"Grabe N.","surname":"Grabe","given-name":"Niels","initials":"N.","afid": [{"@_fa": "true", "$" :"60016908"}]}],"authkeywords":"Brightfield microscopy | Cerebral ischemia | Digital neuropathology | Image segmentation | Microglia","source-id":"16765","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84892026972"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84892026972?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84892026972&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84892026972&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84892026972","dc:identifier":"SCOPUS_ID:84892026972","eid":"2-s2.0-84892026972","dc:title":"Pattern recognition using quaternion color moments","dc:creator":"Karakasis E.G.","prism:publicationName":"Pattern Recognition: Practices, Perspectives and Challenges","prism:isbn": [{"@_fa": "true", "$" :"9781626181960"}],"prism:pageRange":"153-176","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","dc:description":"Image moments have been established in the area of pattern recognition and classification, since they can represent image content very effectively. One of the first moment family, and probably one of the most used, is the geometric one. However, a large variety of moments have been introduced so far. Orthogonal continuous moments like Zernike, Fourier-Mellin and pseudo Zernike or orthogonal discrete moments like Tchebichef, Krawtchouk and dual Hahn are only some of the most widespread families. Despite this variety in moment families, their vast majority has been applied in pattern recognition or classification problems where only gray images are considered. Only lately scientists try to address the issue of calculating moments for color images. The traditional way to apply moments to such images is either to use a color reduction method, with the known consequences of losing information, or to convert the color model from RGB to HSV in order to use only the H channel. Another perspective is to represent each color pixel as a 3-element vector. The resulted image can be used in order to compute color moments. This method results in to calculate 3-element vectorized moments, where each element is in relation with the corresponding channel but not with the other elements. Quaternion moments, which have been lately attracting the interest of scientific community, address this problem elegantly. By representing each color pixel as a quaternion and using simple quaternion algebra, the resulted quaternion moments are directly connected to the image color space. In this chapter the basic theory as well as a comparison of the aforementioned two types of color moments is presented. The experimental analysis includes, except of image reconstruction and computation time cases, indicative classification examples in noise free and noisy conditions. Â© 2013 Nova Science Publishers, Inc.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60030988","afid":"60030988","affilname":"Democritus University of Thrace","affiliation-city":"Komotini","affiliation-country":"Greece"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60011510","afid":"60011510","affilname":"Eastern Macedonia and Thrace Institute of Technology","affiliation-city":"Kavala","affiliation-country":"Greece"}],"prism:aggregationType":"Book","subtype":"ch","subtypeDescription":"Book Chapter","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/23097725600","authid":"23097725600","authname":"Karakasis E.G.","surname":"Karakasis","given-name":"E. G.","initials":"E.G.","afid": [{"@_fa": "true", "$" :"60030988"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/14060879200","authid":"14060879200","authname":"Papakostas G.A.","surname":"Papakostas","given-name":"G. A.","initials":"G.A.","afid": [{"@_fa": "true", "$" :"60011510"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/6603137113","authid":"6603137113","authname":"Koulouriotis D.E.","surname":"Koulouriotis","given-name":"D. E.","initials":"D.E.","afid": [{"@_fa": "true", "$" :"60030988"}]}],"authkeywords":"Image moments | Image reconstruction | Moment invariants | Quaternion color moments","source-id":"21100279462","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879690215"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879690215?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84879690215&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84879690215&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84879690215","dc:identifier":"SCOPUS_ID:84879690215","eid":"2-s2.0-84879690215","dc:title":"Angle estimation using quaternion-ESPRIT in bistatic MIMO-radar","dc:creator":"Zhang X.","prism:publicationName":"Wireless Personal Communications","prism:issn":"09296212","prism:volume":"69","prism:issueIdentifier":"2","prism:pageRange":"551-560","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.1007/s11277-012-0589-3","dc:description":"In this letter; we present a novel two-dimensional angle estimation for bistatic multiple-input multiple-output (MIMO) radar. We reconstruct the received signal of MIMO radar to model with quaternion theory, and then angle estimate using quaternion estimation of signal parameters via rotational invariance technique for MIMO radar is proposed. The proposed algorithm can obtain automatically paired two-dimensional angle estimation in MIMO-radar. The proposed algorithm has much better angle estimation performance than the Wang's quaternion algorithm, which has a much heavier computational load than the proposed algorithm. Simulation results verify the usefulness of our algorithm. Â© 2012 Springer Science+Business Media, LLC.","citedby-count":"9","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/8247132000","authid":"8247132000","authname":"Zhang X.","surname":"Zhang","given-name":"Xiaofei","initials":"X.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/56166947700","authid":"56166947700","authname":"Chen C.","surname":"Chen","given-name":"Chen","initials":"C.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/54395647600","authid":"54395647600","authname":"Li J.","surname":"Li","given-name":"Jianfeng","initials":"J.","afid": [{"@_fa": "true", "$" :"60021666"}]}],"authkeywords":"Angle estimation | MIMO radar | Quaternion","source-id":"20725","fund-acr":"NSFC","fund-no":"kfjj20110131","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879157819"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84879157819?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84879157819&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84879157819&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84879157819","dc:identifier":"SCOPUS_ID:84879157819","eid":"2-s2.0-84879157819","dc:title":"Quaternion application in parameters estimation of uniform circular vector-sensor array signal","dc:creator":"Kang X.T.","prism:publicationName":"Jilin Daxue Xuebao (Gongxueban)/Journal of Jilin University (Engineering and Technology Edition)","prism:issn":"16715497","prism:volume":"43","prism:issueIdentifier":"SUPPL.1","prism:pageRange":"154-159","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","dc:description":"Four dimensional super plural structure of a quaternion is an orthogonal structure, which can keep the inherent orthogonality of each vector sensor component, and improve anti-interference ability and discrimination of the vector sensor array. Quaternion theory was applied into parameter estimation of uniform circular vector of array signals, the electromagnetic vector sensor array receiving signal model was established based on quaternion, and joint estimation of the electromagnetic vector sensor array signal's DOA and polarization information using quaternion's multidimensional orthogonal properties and the matrix theory combining with existing algorithm were realized. Simulation results show the effectiveness of the method. Compared with V-MUSIC, the quaternion model can obviously increase the signal parameter precision.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60032504","afid":"60032504","affilname":"Shanghai University of Engineering Science","affiliation-city":"Shanghai","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60007711","afid":"60007711","affilname":"Jilin University","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/7102354352","authid":"7102354352","authname":"Kang X.T.","surname":"Kang","given-name":"Xiao Tao","initials":"X.T.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/55768363200","authid":"55768363200","authname":"Wang Z.Y.","surname":"Wang","given-name":"Zhi Yang","initials":"Z.Y.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55768335100","authid":"55768335100","authname":"Kang B.Y.","surname":"Kang","given-name":"Bo Yu","initials":"B.Y.","afid": [{"@_fa": "true", "$" :"60032504"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/57196161777","authid":"57196161777","authname":"Li J.J.","surname":"Li","given-name":"Jing Jing","initials":"J.J.","afid": [{"@_fa": "true", "$" :"60007711"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7404964763","authid":"7404964763","authname":"Shi Y.W.","surname":"Shi","given-name":"Yao Wu","initials":"Y.W.","afid": [{"@_fa": "true", "$" :"60007711"}]}],"authkeywords":"DOA | Electromagnetic vector sensor | Polarization information | Quaternion | Vector-sensor array","source-id":"145365","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877667735"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84877667735?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84877667735&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84877667735&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84877667735","dc:identifier":"SCOPUS_ID:84877667735","eid":"2-s2.0-84877667735","dc:title":"L<inf>1</inf>-norm minimization for quaternion signals","dc:creator":"Zhang X.","prism:publicationName":"Journal of Southeast University (English Edition)","prism:issn":"10037985","prism:volume":"29","prism:issueIdentifier":"1","prism:pageRange":"33-37","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.3969/j.issn.1003-7985.2013.01.007","dc:description":"An algorithm for recovering the quaternion signals in both noiseless and noise contaminated scenarios by solving an L1-norm minimization problem is presented. The L1-norm minimization problem over the quaternion number field is solved by converting it to an equivalent second-order cone programming problem over the real number field, which can be readily solved by convex optimization solvers like SeDuMi. Numerical experiments are provided to illustrate the effectiveness of the proposed algorithm. In a noiseless scenario, the experimental results show that under some practically acceptable conditions, exact signal recovery can be achieved. With additive noise contamination in measurements, the experimental results show that the proposed algorithm is robust to noise. The proposed algorithm can be applied in compressed-sensing-based signal recovery in the quaternion domain. Â© right.","citedby-count":"3","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60105589","afid":"60105589","affilname":"Laboratoire Traitement du Signal et de l'Image","affiliation-city":"Rennes","affiliation-country":"France"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60005244","afid":"60005244","affilname":"Southeast University","affiliation-city":"Nanjing","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/112808456","afid":"112808456","affilname":"Centre de Recherche en Information BiomÃ©dicale Sino-franÃ§ais","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/56313969000","authid":"56313969000","authname":"Zhang X.","surname":"Zhang","given-name":"Xu","initials":"X.","afid": [{"@_fa": "true", "$" :"60005244"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/34874119700","authid":"34874119700","authname":"Wu J.","surname":"Wu","given-name":"Jiasong","initials":"J.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"112808456"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/16176923900","authid":"16176923900","authname":"Yang G.","surname":"Yang","given-name":"Guanyu","initials":"G.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"112808456"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/55695878200","authid":"55695878200","authname":"Senahdji L.","surname":"Senahdji","given-name":"Lotfi","initials":"L.","afid": [{"@_fa": "true", "$" :"60105589"},{"@_fa": "true", "$" :"112808456"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/7203086899","authid":"7203086899","authname":"Shu H.","surname":"Shu","given-name":"Huazhong","initials":"H.","afid": [{"@_fa": "true", "$" :"60005244"},{"@_fa": "true", "$" :"112808456"}]}],"authkeywords":"Compressed sensing | Quaternion | Signal recovery","source-id":"24883","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84876802968"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84876802968?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84876802968&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84876802968&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84876802968","dc:identifier":"SCOPUS_ID:84876802968","eid":"2-s2.0-84876802968","dc:title":"DOA tracking algorithm based on quaternion data projection method","dc:creator":"Tao J.","prism:publicationName":"Shuju Caiji Yu Chuli/Journal of Data Acquisition and Processing","prism:issn":"10049037","prism:volume":"28","prism:issueIdentifier":"2","prism:pageRange":"244-249","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","dc:description":"The problem of direction-of-arrival (DOA) tracking for multi-signals is researched based on simplified polarization vector-sensor array, and a novel quaternion data projection method (QDPM) is proposed. The proposed algorithm has high robustness to the undulate phenomenon arisen from the initialization, and converges faster than the conventional data projection method (DPM), especially when the DOA changs drastically. Moreover, the QDPM algorithm shows a higher tracking precision than DPM algorithm at low signal-to-noise ratio (SNR). Finally, simulation results verify the effectiveness of the proposed algorithm.","citedby-count":"1","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60073486","afid":"60073486","affilname":"Aviation University of Air Force","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36180346800","authid":"36180346800","authname":"Tao J.","surname":"Tao","given-name":"Jun","initials":"J.","afid": [{"@_fa": "true", "$" :"60073486"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/54929198600","authid":"54929198600","authname":"Yu F.","surname":"Yu","given-name":"Fei","initials":"F.","afid": [{"@_fa": "true", "$" :"60073486"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/55612791900","authid":"55612791900","authname":"Lin Z.","surname":"Lin","given-name":"Zhiyong","initials":"Z.","afid": [{"@_fa": "true", "$" :"60073486"}]}],"authkeywords":"Direction-of-arrival (DOA) | Electromagnetic vector-sensor array | Quaternion | Signal processing | Subspace tracking","source-id":"20765","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84876338713"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84876338713?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84876338713&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84876338713&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84876338713","dc:identifier":"SCOPUS_ID:84876338713","eid":"2-s2.0-84876338713","dc:title":"Color medical image registration based on quaternion moment theory","dc:creator":"Huang Y.","prism:publicationName":"Guangdian Gongcheng/Opto-Electronic Engineering","prism:issn":"1003501X","prism:volume":"40","prism:issueIdentifier":"3","prism:pageRange":"102-107","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.3969/j.issn.1003-501X.2013.03.016","dc:description":"The current method of SPECT/CT color medical image registration uses the location marker in vitro generally, such as SPECT/CT color medical image, but using the external-marker stent fixation with patient for examination is complicated relatively. A method of calculating registration parameters such as rotation angle and translation amount is proposed based on Quaternion color model. Firstly, the color medical image is represented as Quaternion vector matrix form. On the basis of this, a calculation method of Quaternion geometric moment is put forward about SPECT/CT color medical image. According to the distribution of Quaternion image quality, the relative rotation angle of two-mode image is obtained by using rotational inertia properties of Quaternion image. Then, the translation amount between two images is determined to realize registration by using Euclidean distance measure of mass center. The SPECT/CT color medical images are used in registration experiment. Good registration results are obtained, and this method is proved to be of effectiveness and feasibility.","citedby-count":"2","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60026282","afid":"60026282","affilname":"Zhejiang University of Technology","affiliation-city":"Hangzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013614","afid":"60013614","affilname":"Hangzhou Dianzi University","affiliation-city":"Hangzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113536354","afid":"113536354","affilname":"Ningbo Municipal Committee Party School","affiliation-city":"Ningbo","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57196142394","authid":"57196142394","authname":"Huang Y.","surname":"Huang","given-name":"Yu","initials":"Y.","afid": [{"@_fa": "true", "$" :"60026282"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/35195975900","authid":"35195975900","authname":"Hua L.","surname":"Hua","given-name":"Liang","initials":"L.","afid": [{"@_fa": "true", "$" :"60026282"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/35302377700","authid":"35302377700","authname":"Feng H.","surname":"Feng","given-name":"Hao","initials":"H.","afid": [{"@_fa": "true", "$" :"60013614"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7403132986","authid":"7403132986","authname":"Ding L.","surname":"Ding","given-name":"Lijun","initials":"L.","afid": [{"@_fa": "true", "$" :"60026282"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/55654251500","authid":"55654251500","authname":"Chen Y.","surname":"Chen","given-name":"Yong","initials":"Y.","afid": [{"@_fa": "true", "$" :"113536354"}]}],"authkeywords":"Medical image registration | Principal axis direction | Quaternion geometric moment | SPECT/CT","source-id":"16754","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84876329167"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84876329167?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84876329167&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84876329167&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84876329167","dc:identifier":"SCOPUS_ID:84876329167","eid":"2-s2.0-84876329167","dc:title":"Soccer detection in images based on quaternion and pulse coupled neural network","dc:creator":"Zheng T.","prism:publicationName":"Yingyong Kexue Xuebao/Journal of Applied Sciences","prism:issn":"02558297","prism:volume":"31","prism:issueIdentifier":"2","prism:pageRange":"183-189","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.3969/j.issn.0255-8297.2013.02.013","dc:description":"This paper proposes a soccer detection method that combines the attention selection model of phase spectrum of quaternion Fourier transform (PQFT) and pulse coupled neural network (PCNN). In the preprocessing, the region outside the field is removed, and the region of interest extracted using PQFT. The target is detected according to the physical characteristics such as color, shape and size. If no candidate or more than one are detected, a Kalman filter is used to make prediction. Simulation shows that the identification rate is improved by 9.6% and 14.9% respectively as compared to the dynamic Kalman filtering with velocity control and the real time ball detection framework introduced in the literature.","citedby-count":"0","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60009860","afid":"60009860","affilname":"Fudan University","affiliation-city":"Shanghai","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/55653951200","authid":"55653951200","authname":"Zheng T.","surname":"Zheng","given-name":"Tian Yu","initials":"T.Y.","afid": [{"@_fa": "true", "$" :"60009860"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7403204205","authid":"7403204205","authname":"Gu X.","surname":"Gu","given-name":"Xiao Dong","initials":"X.D.","afid": [{"@_fa": "true", "$" :"60009860"}]}],"authkeywords":"Attention selection | Kalman filter | Pulse coupled neural network | Quaternion Fourier transform | Soccer detection","source-id":"19700170833","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875129116"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875129116?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84875129116&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84875129116&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84875129116","dc:identifier":"SCOPUS_ID:84875129116","eid":"2-s2.0-84875129116","dc:title":"Spatio-temporal saliency perception via hypercomplex frequency spectral contrast","dc:creator":"Li C.","prism:publicationName":"Sensors (Switzerland)","prism:issn":"14248220","prism:volume":"13","prism:issueIdentifier":"3","prism:pageRange":"3409-3431","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.3390/s130303409","dc:description":"Salient object perception is the process of sensing the salient information from the spatio-temporal visual scenes, which is a rapid pre-attention mechanism for the target location in a visual smart sensor. In recent decades, many successful models of visual saliency perception have been proposed to simulate the pre-attention behavior. Since most of the methods usually need some ad hoc parameters or high-cost preprocessing, they are difficult to rapidly detect salient object or be implemented by computing parallelism in a smart sensor. In this paper, we propose a novel spatio-temporal saliency perception method based on spatio-temporal hypercomplex spectral contrast (HSC). Firstly, the proposed HSC algorithm represent the features in the HSV (hue, saturation and value) color space and features of motion by a hypercomplex number. Secondly, the spatio-temporal salient objects are efficiently detected by hypercomplex Fourier spectral contrast in parallel. Finally, our saliency perception model also incorporates with the non-uniform sampling, which is a common phenomenon of human vision that directs visual attention to the logarithmic center of the image/video in natural scenes. The experimental results on the public saliency perception datasets demonstrate the effectiveness of the proposed approach compared to eleven state-of-the-art approaches. In addition, we extend the proposed model to moving object extraction in dynamic scenes, and the proposed algorithm is superior to the traditional algorithms. Â© 2013 by the authors; licensee MDPI, Basel, Switzerland.","citedby-count":"11","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60018308","afid":"60018308","affilname":"Xi'an Jiaotong University","affiliation-city":"Xi'an","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "5", "$" :"5"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36699960500","authid":"36699960500","authname":"Li C.","surname":"Li","given-name":"Ce","initials":"C.","afid": [{"@_fa": "true", "$" :"60018308"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/8899818900","authid":"8899818900","authname":"Xue J.","surname":"Xue","given-name":"Jianru","initials":"J.","afid": [{"@_fa": "true", "$" :"60018308"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/7101989704","authid":"7101989704","authname":"Zheng N.","surname":"Zheng","given-name":"Nanning","initials":"N.","afid": [{"@_fa": "true", "$" :"60018308"}]},{"@_fa": "true", "@seq": "4", "author-url":"https://api.elsevier.com/content/author/author_id/7006709790","authid":"7006709790","authname":"Lan X.","surname":"Lan","given-name":"Xuguang","initials":"X.","afid": [{"@_fa": "true", "$" :"60018308"}]},{"@_fa": "true", "@seq": "5", "author-url":"https://api.elsevier.com/content/author/author_id/35194645000","authid":"35194645000","authname":"Tian Z.","surname":"Tian","given-name":"Zhiqiang","initials":"Z.","afid": [{"@_fa": "true", "$" :"60018308"}]}],"authkeywords":"Hypercomplex | Salient object | Spatio-temporal | Spectral contrast | Visual attention | Visual perception","source-id":"130124","fund-no":"undefined","openaccess":"1","openaccessFlag":true,"freetoread":{"value": [{"$" :"all"},{"$" :"publisherfullgold"},{"$" :"repository"},{"$" :"repositoryvor"},{"$" :"repositoryam"}]},"freetoreadLabel":{"value": [{"$" :"All Open Access"},{"$" :"Gold"},{"$" :"Green"}]}},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84873412693"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84873412693?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84873412693&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84873412693&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S143484111200194X"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84873412693","dc:identifier":"SCOPUS_ID:84873412693","eid":"2-s2.0-84873412693","dc:title":"Multiscale texture classification using reduced quaternion wavelet transform","dc:creator":"Gai S.","prism:publicationName":"AEU - International Journal of Electronics and Communications","prism:issn":"14348411","prism:eIssn":"16180399","prism:volume":"67","prism:issueIdentifier":"3","prism:pageRange":"233-241","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.1016/j.aeue.2012.08.004","pii":"S143484111200194X","dc:description":"This article proposes a study of the reduced quaternion wavelet transform (RQWT) which has one shift-invariant magnitude and three angle phases at each scale from digital image analysis application. A new multiscale texture classifier which uses features extracted from the sub-bands of the RQWT decomposition is proposed in the transform domain. The proposed method can achieve a high texture classification rate. The experimental results can demonstrate the robustness of the proposed method and achieve a higher texture classification accuracy rate than a famous wavelet transform based classifier. Â© 2012 Elsevier GmbH.","citedby-count":"37","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/113016739","afid":"113016739","affilname":"University of Nanchang Hangkong","affiliation-city":null,"affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/35748407200","authid":"35748407200","authname":"Gai S.","surname":"Gai","given-name":"Shan","initials":"S.","afid": [{"@_fa": "true", "$" :"113016739"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/7405754282","authid":"7405754282","authname":"Yang G.","surname":"Yang","given-name":"Guowei","initials":"G.","afid": [{"@_fa": "true", "$" :"113016739"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/57770769500","authid":"57770769500","authname":"Zhang S.","surname":"Zhang","given-name":"Sheng","initials":"S.","afid": [{"@_fa": "true", "$" :"113016739"}]}],"authkeywords":"Feature extraction | Reduced quaternion wavelet transform | Texture classification","source-id":"17683","fund-acr":"NSFC","fund-no":"60973048","fund-sponsor":"National Natural Science Foundation of China","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84867335571"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84867335571?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84867335571&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84867335571&origin=inward"},{"@_fa": "true", "@ref": "full-text", "@href": "https://api.elsevier.com/content/article/eid/1-s2.0-S0030399212001880"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84867335571","dc:identifier":"SCOPUS_ID:84867335571","eid":"2-s2.0-84867335571","dc:title":"An automatic registration algorithm for the scattered point clouds based on the curvature feature","dc:creator":"He B.","prism:publicationName":"Optics and Laser Technology","prism:issn":"00303992","prism:volume":"46","prism:issueIdentifier":"1","prism:pageRange":"53-60","prism:coverDate":"2013-03-01","prism:coverDisplayDate":"March 2013","prism:doi":"10.1016/j.optlastec.2012.04.027","pii":"S0030399212001880","dc:description":"Object modeling by the registration of multiple range images has important applications in reverse engineering and computer vision. In order to register multi-view scattered point clouds, a novel curvature-based automatic registration algorithm is proposed in this paper, which can solve the registration problem with partial overlapping point clouds. For two sets of scattered point clouds, the curvature of each point is estimated by using the quadratic surface fitting method. The feature points that have the maximum local curvature variations are then extracted. The initial matching points are acquired by computing the Hausdorff distance of curvature, and then the circumference shape feature of the local surface is used to obtain the accurate matching points from the initial matching points. Finally, the rotation and translation matrix are estimated by the quaternion, and an iterative algorithm is used to improve the registration accuracy. Experimental results show that the algorithm is effective.Â© 2012 Elsevier Ltd. All rights reserved.","citedby-count":"56","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60017605","afid":"60017605","affilname":"Fuzhou University","affiliation-city":"Fuzhou","affiliation-country":"China"},{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60013983","afid":"60013983","affilname":"City University of Hong Kong","affiliation-city":"Hong Kong","affiliation-country":"Hong Kong"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/15753777300","authid":"15753777300","authname":"He B.","surname":"He","given-name":"Bingwei","initials":"B.","afid": [{"@_fa": "true", "$" :"60017605"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/37041491200","authid":"37041491200","authname":"Lin Z.","surname":"Lin","given-name":"Zeming","initials":"Z.","afid": [{"@_fa": "true", "$" :"60017605"}]},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/8589964900","authid":"8589964900","authname":"Li Y.","surname":"Li","given-name":"Y. F.","initials":"Y.F.","afid": [{"@_fa": "true", "$" :"60013983"}]}],"authkeywords":"Circumference feature | Curvature | Registration","source-id":"12346","fund-acr":"NSFC","fund-no":"7002658","fund-sponsor":"City University of Hong Kong","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84885443657"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84885443657?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84885443657&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84885443657&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84885443657","dc:identifier":"SCOPUS_ID:84885443657","eid":"2-s2.0-84885443657","dc:title":"Illumination invariant face recognition using quaternion-based correlation filters","dc:creator":"Rizo-RodrÃ­guez D.","prism:publicationName":"Journal of Mathematical Imaging and Vision","prism:issn":"09249907","prism:volume":"45","prism:issueIdentifier":"2","prism:pageRange":"164-175","prism:coverDate":"2013-02-01","prism:coverDisplayDate":"February 2013","prism:doi":"10.1007/s10851-012-0352-0","dc:description":"Existing face recognition systems decrease their performance when face images are affected by lighting variations. Recently, several quaternionic representations of face image features and a quaternion-based correlation filter have been combined in order to cope with the effects of having non-properly illuminated face images. The use of this approach has the advantage of using only one training face image per person. In this paper, the original idea based on the unconstrained optimal trade-off quaternion filter (UOTQF) is extended and two additional different correlation filters in quaternionic domain are evaluate: a phase only quaternion filter (POQF) and a separable trade-off quaternion filter (STOQF). Three different quaternion-based correlation filters are designed and conjugated with four face feature extraction methods aiming at obtaining the best combination: a two-level discrete wavelet decomposition (DWT), image differentiation (DIF), discrete cosine transform (DCT) and local binary patterns (LBP). Verification and identification experiments confirms that when combining a quaternionic representation with a quaternion-based correlation filter, both with good discriminative power and illumination invariant properties, an improvement in face recognition accuracy is obtained. Â© Springer Science+Business Media, LLC 2012.","citedby-count":"25","prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "3", "$" :"3"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/36622544700","authid":"36622544700","authname":"Rizo-RodrÃ­guez D.","surname":"Rizo-RodrÃ­guez","given-name":"Dayron","initials":"D."},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/36622061300","authid":"36622061300","authname":"MÃ©ndez-VÃ¡zquez H.","surname":"MÃ©ndez-VÃ¡zquez","given-name":"Heydi","initials":"H."},{"@_fa": "true", "@seq": "3", "author-url":"https://api.elsevier.com/content/author/author_id/23472512800","authid":"23472512800","authname":"GarcÃ­a-Reyes E.","surname":"GarcÃ­a-Reyes","given-name":"Edel","initials":"E."}],"authkeywords":"Correlation filters | Illumination invariant face recognition | Quaternions","source-id":"28501","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875081131"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84875081131?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84875081131&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84875081131&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84875081131","dc:identifier":"SCOPUS_ID:84875081131","eid":"2-s2.0-84875081131","dc:title":"Maximum singular value method of quaternion matrix for evaluating color image quality","dc:creator":"Wang Y.","prism:publicationName":"Guangxue Jingmi Gongcheng/Optics and Precision Engineering","prism:issn":"1004924X","prism:volume":"21","prism:issueIdentifier":"2","prism:pageRange":"469-478","prism:coverDate":"2013-02-01","prism:coverDisplayDate":"February 2013","prism:doi":"10.3788/OPE.20132102.0469","dc:description":"A new color image assessment method is proposed to solve the problem of neglecting color information and a poor consistent behavior with the human visual system in traditional image quality assessment methods. The human eye sensitive image structure is enhanced and full color information is used in this method. Three important parts are taken into account in this structure, which are detail information, luminance information and color information. Quaternion is taken as a tool to perform the task. A quaternion matrix is constructed to evaluate color image quality. Then singular value decomposition is performed on the quaternion matrix. Max singular value is used to describe image structure information. Numerical results are obtained by using distortion map. 982 images in LIVE database including five types of distortion are used to investigate the behaviors of the proposed method. The nonlinearity property of the proposed method in the cross-distortion experiment is that the Root Mean Square Error(RMSE) value is 9.176, and Spearman Rank Order Correlation Coefficient(SROCC) value is 0.929 6, however, those of from Structural Similarity Index( SSIM) method are 9.299 and 0.925 6, respectively. The results show that proposed method is more consistent than the traditional methods because of the considering of more image properties and using a quaternion matrix.","citedby-count":"16","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60004828","afid":"60004828","affilname":"Changchun Institute of Optics Fine Mechanics and Physics Chinese Academy of Sciences","affiliation-city":"Changchun","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/57203768643","authid":"57203768643","authname":"Wang Y.","surname":"Wang","given-name":"Yu Qing","initials":"Y.Q.","afid": [{"@_fa": "true", "$" :"60004828"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/9238980500","authid":"9238980500","authname":"Zhu M.","surname":"Zhu","given-name":"Ming","initials":"M.","afid": [{"@_fa": "true", "$" :"60004828"}]}],"authkeywords":"Color image | Local variance | Quality assessment | Quaternion matrix | Singular value decomposition","source-id":"144897","fund-no":"undefined","openaccess":"0","openaccessFlag":false},{"@_fa": "true", "link": [{"@_fa": "true", "@ref": "self", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874535403"},{"@_fa": "true", "@ref": "author-affiliation", "@href": "https://api.elsevier.com/content/abstract/scopus_id/84874535403?field=author,affiliation"},{"@_fa": "true", "@ref": "scopus", "@href": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=84874535403&origin=inward"},{"@_fa": "true", "@ref": "scopus-citedby", "@href": "https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=84874535403&origin=inward"}],"prism:url":"https://api.elsevier.com/content/abstract/scopus_id/84874535403","dc:identifier":"SCOPUS_ID:84874535403","eid":"2-s2.0-84874535403","dc:title":"Dual-quaternion relative position and attitude estimation algorithm of close formation flight based on vision","dc:creator":"Ma K.","prism:publicationName":"Xi Tong Gong Cheng Yu Dian Zi Ji Shu/Systems Engineering and Electronics","prism:issn":"1001506X","prism:volume":"35","prism:issueIdentifier":"2","prism:pageRange":"391-396","prism:coverDate":"2013-02-01","prism:coverDisplayDate":"February 2013","prism:doi":"10.3969/j.issn.1001-506X.2013.02.27","dc:description":"A novel vision-based relative position and attitude estimation algorithm using points to regions correspondence is presented for close formation flying. Given the points on the leader satellite surface and the convex regions in which the correspondent image points lie on the follower satellite image plane, combining dual-quaternion and convex optimization mathematical tools to take full advantage of the simplicity of the dual quaternion description of the coordinate system transformation, the convex optimization problem representation is formulated by using dual-quaternion representing the rotation and translation, by means of which the relative position and attitude parameters are estimated. This algorithm uses the advantage of the dual quaternion description which is better than the traditional quaternion coordinate system transformation, and using convex optimization can reduce the requirement of precise point to point correspondence in the traditional algorithm. Simulation shows that the algorithm can meet the demand of relative pose estimation accuracy and has a good robustness for close formation flying, and this algorithm can provide a reference for vision relative pose estimation between various spacecraft in the current space mission.","citedby-count":"4","affiliation": [{"@_fa": "true", "affiliation-url":"https://api.elsevier.com/content/affiliation/affiliation_id/60021666","afid":"60021666","affilname":"Nanjing University of Aeronautics and Astronautics","affiliation-city":"Nanjing","affiliation-country":"China"}],"prism:aggregationType":"Journal","subtype":"ar","subtypeDescription":"Article","author-count":{"@limit": "100", "@total": "2", "$" :"2"},"author": [{"@_fa": "true", "@seq": "1", "author-url":"https://api.elsevier.com/content/author/author_id/53664017000","authid":"53664017000","authname":"Ma K.","surname":"Ma","given-name":"Ke Xin","initials":"K.X.","afid": [{"@_fa": "true", "$" :"60021666"}]},{"@_fa": "true", "@seq": "2", "author-url":"https://api.elsevier.com/content/author/author_id/12761995000","authid":"12761995000","authname":"Wang H.","surname":"Wang","given-name":"Hui Nan","initials":"H.N.","afid": [{"@_fa": "true", "$" :"60021666"}]}],"authkeywords":"Close formation flying | Convex optimization | Dual-quaternion | Points to regions correspondence | Relative pose estimation","source-id":"15141","fund-no":"undefined","openaccess":"0","openaccessFlag":false}]}}